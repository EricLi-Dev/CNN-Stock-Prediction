{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUkJVg1sOVgB",
        "outputId": "e94ed17b-cfb1-4ec7-cc81-3134de35c34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"drive/MyDrive/CNN Stock Prediction\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lmxBB6fO5dh",
        "outputId": "fb8d4b0d-55ca-4e61-a904-a1419c06b5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/11M8JhuGjMeTkxBAoI1sL3lLEa69ylHrV/CNN Stock Prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "SH7hNbZUOj-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import matplotlib as plt\n",
        "from warnings import simplefilter\n",
        "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
      ],
      "metadata": {
        "id": "CIAig0vUOeq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data (Prices + Indicators + Labels)"
      ],
      "metadata": {
        "id": "0AzXw7n-Oo5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock = \"IBM\"\n",
        "data_path = f\"data/labeled_indicators/IBM_all_labeled_indicators.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "XytQG59IOnpR",
        "outputId": "d3fb7209-cc0f-48bc-bcfb-437a8c991e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date    Open    High    Low   Close  Adj Close   Volume  \\\n",
              "59  2004-07-07  145.42  146.51  81.31  145.51      81.60  5938456   \n",
              "60  2004-07-08  144.89  144.91  79.90  142.59      79.97  7875334   \n",
              "61  2004-07-09  143.87  144.03  79.84  143.00      80.20  6898579   \n",
              "62  2004-07-12  143.20  145.32  79.75  143.36      80.40  6285623   \n",
              "63  2004-07-13  146.42  146.74  81.45  145.31      81.50  6277046   \n",
              "\n",
              "    adjustRatio  Label   RSI_ta_6  ...  AWSM_ta_11  AWSM_ta_12  AWSM_ta_13  \\\n",
              "59         1.78      0  10.900907  ...   -1.007045   -0.709792   -0.436346   \n",
              "60         1.78      1   6.896011  ...   -1.432955   -1.107917   -0.837115   \n",
              "61         1.78      0  12.323443  ...   -1.928409   -1.534792   -1.239038   \n",
              "62         1.78      0  17.397102  ...   -2.335227   -1.991875   -1.582308   \n",
              "63         1.78      0  39.974992  ...   -2.545000   -2.361042   -1.959808   \n",
              "\n",
              "    AWSM_ta_14  AWSM_ta_15  AWSM_ta_16  AWSM_ta_17  AWSM_ta_18  AWSM_ta_19  \\\n",
              "59   -0.237143    0.036833    0.298906    0.521176    0.798333    1.004211   \n",
              "60   -0.604107   -0.379667   -0.099531    0.143529    0.447083    0.668553   \n",
              "61   -0.990536   -0.759667   -0.490469   -0.230147    0.055278    0.327368   \n",
              "62   -1.314821   -1.105833   -0.856562   -0.583971   -0.343889    0.013026   \n",
              "63   -1.593036   -1.354167   -1.152813   -0.869265   -0.620417   -0.345000   \n",
              "\n",
              "    AWSM_ta_20  \n",
              "59    1.098000  \n",
              "60    0.848500  \n",
              "61    0.557500  \n",
              "62    0.230875  \n",
              "63   -0.025000  \n",
              "\n",
              "[5 rows x 429 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-779f196c-3b6f-41cc-bb17-5b879d9381fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>adjustRatio</th>\n",
              "      <th>Label</th>\n",
              "      <th>RSI_ta_6</th>\n",
              "      <th>...</th>\n",
              "      <th>AWSM_ta_11</th>\n",
              "      <th>AWSM_ta_12</th>\n",
              "      <th>AWSM_ta_13</th>\n",
              "      <th>AWSM_ta_14</th>\n",
              "      <th>AWSM_ta_15</th>\n",
              "      <th>AWSM_ta_16</th>\n",
              "      <th>AWSM_ta_17</th>\n",
              "      <th>AWSM_ta_18</th>\n",
              "      <th>AWSM_ta_19</th>\n",
              "      <th>AWSM_ta_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>2004-07-07</td>\n",
              "      <td>145.42</td>\n",
              "      <td>146.51</td>\n",
              "      <td>81.31</td>\n",
              "      <td>145.51</td>\n",
              "      <td>81.60</td>\n",
              "      <td>5938456</td>\n",
              "      <td>1.78</td>\n",
              "      <td>0</td>\n",
              "      <td>10.900907</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.007045</td>\n",
              "      <td>-0.709792</td>\n",
              "      <td>-0.436346</td>\n",
              "      <td>-0.237143</td>\n",
              "      <td>0.036833</td>\n",
              "      <td>0.298906</td>\n",
              "      <td>0.521176</td>\n",
              "      <td>0.798333</td>\n",
              "      <td>1.004211</td>\n",
              "      <td>1.098000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>2004-07-08</td>\n",
              "      <td>144.89</td>\n",
              "      <td>144.91</td>\n",
              "      <td>79.90</td>\n",
              "      <td>142.59</td>\n",
              "      <td>79.97</td>\n",
              "      <td>7875334</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1</td>\n",
              "      <td>6.896011</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.432955</td>\n",
              "      <td>-1.107917</td>\n",
              "      <td>-0.837115</td>\n",
              "      <td>-0.604107</td>\n",
              "      <td>-0.379667</td>\n",
              "      <td>-0.099531</td>\n",
              "      <td>0.143529</td>\n",
              "      <td>0.447083</td>\n",
              "      <td>0.668553</td>\n",
              "      <td>0.848500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>2004-07-09</td>\n",
              "      <td>143.87</td>\n",
              "      <td>144.03</td>\n",
              "      <td>79.84</td>\n",
              "      <td>143.00</td>\n",
              "      <td>80.20</td>\n",
              "      <td>6898579</td>\n",
              "      <td>1.78</td>\n",
              "      <td>0</td>\n",
              "      <td>12.323443</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.928409</td>\n",
              "      <td>-1.534792</td>\n",
              "      <td>-1.239038</td>\n",
              "      <td>-0.990536</td>\n",
              "      <td>-0.759667</td>\n",
              "      <td>-0.490469</td>\n",
              "      <td>-0.230147</td>\n",
              "      <td>0.055278</td>\n",
              "      <td>0.327368</td>\n",
              "      <td>0.557500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>2004-07-12</td>\n",
              "      <td>143.20</td>\n",
              "      <td>145.32</td>\n",
              "      <td>79.75</td>\n",
              "      <td>143.36</td>\n",
              "      <td>80.40</td>\n",
              "      <td>6285623</td>\n",
              "      <td>1.78</td>\n",
              "      <td>0</td>\n",
              "      <td>17.397102</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.335227</td>\n",
              "      <td>-1.991875</td>\n",
              "      <td>-1.582308</td>\n",
              "      <td>-1.314821</td>\n",
              "      <td>-1.105833</td>\n",
              "      <td>-0.856562</td>\n",
              "      <td>-0.583971</td>\n",
              "      <td>-0.343889</td>\n",
              "      <td>0.013026</td>\n",
              "      <td>0.230875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>2004-07-13</td>\n",
              "      <td>146.42</td>\n",
              "      <td>146.74</td>\n",
              "      <td>81.45</td>\n",
              "      <td>145.31</td>\n",
              "      <td>81.50</td>\n",
              "      <td>6277046</td>\n",
              "      <td>1.78</td>\n",
              "      <td>0</td>\n",
              "      <td>39.974992</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.545000</td>\n",
              "      <td>-2.361042</td>\n",
              "      <td>-1.959808</td>\n",
              "      <td>-1.593036</td>\n",
              "      <td>-1.354167</td>\n",
              "      <td>-1.152813</td>\n",
              "      <td>-0.869265</td>\n",
              "      <td>-0.620417</td>\n",
              "      <td>-0.345000</td>\n",
              "      <td>-0.025000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 429 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-779f196c-3b6f-41cc-bb17-5b879d9381fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-779f196c-3b6f-41cc-bb17-5b879d9381fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-779f196c-3b6f-41cc-bb17-5b879d9381fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-028b4d1c-425b-4144-91de-1f16abd91ddc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-028b4d1c-425b-4144-91de-1f16abd91ddc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-028b4d1c-425b-4144-91de-1f16abd91ddc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data"
      ],
      "metadata": {
        "id": "h1fZd4JDL86I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "lUGFZJ8GOzhJ",
        "outputId": "8db4fd2e-aeee-4d29-d8bf-ebe0298d8426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close    Adj Close  \\\n",
              "count  4976.000000  4976.000000  4976.000000  4976.000000  4976.000000   \n",
              "mean    192.264365   193.852006   132.069795   192.372777   133.141668   \n",
              "std      51.676093    51.862838    32.834472    51.703395    32.938430   \n",
              "min     110.000000   113.650000    66.440000   110.190000    68.590000   \n",
              "25%     148.700000   149.965000   111.535000   148.775000   112.735000   \n",
              "50%     183.190000   184.975000   132.595000   183.440000   133.595000   \n",
              "75%     223.232500   224.825000   153.812500   223.260000   154.872500   \n",
              "max     320.960000   321.730000   204.880000   321.580000   206.310000   \n",
              "\n",
              "             Volume  adjustRatio        Label     RSI_ta_6     RSI_ta_7  ...  \\\n",
              "count  4.976000e+03  4976.000000  4976.000000  4976.000000  4976.000000  ...   \n",
              "mean   5.729091e+06     1.463816     0.187098    51.421823    51.349937  ...   \n",
              "std    3.250481e+06     0.235612     0.528734    18.428638    17.127456  ...   \n",
              "min    1.074765e+06     1.000000    -1.000000     1.192917     1.808998  ...   \n",
              "25%    3.714425e+06     1.270000     0.000000    38.046770    38.902163  ...   \n",
              "50%    4.864736e+06     1.520000     0.000000    51.688022    51.456125  ...   \n",
              "75%    6.668982e+06     1.660000     0.000000    64.894104    63.776310  ...   \n",
              "max    3.981442e+07     1.780000     2.000000    97.374535    95.988340  ...   \n",
              "\n",
              "        AWSM_ta_11   AWSM_ta_12   AWSM_ta_13   AWSM_ta_14   AWSM_ta_15  \\\n",
              "count  4976.000000  4976.000000  4976.000000  4976.000000  4976.000000   \n",
              "mean      0.078239     0.085819     0.093587     0.101465     0.109297   \n",
              "std       2.886346     3.011245     3.129132     3.239821     3.343718   \n",
              "min     -15.744773   -16.578958   -17.243846   -17.732321   -18.193500   \n",
              "25%      -1.419830    -1.473854    -1.540337    -1.600446    -1.654000   \n",
              "50%       0.207955     0.259167     0.281731     0.291964     0.339250   \n",
              "75%       1.809716     1.902500     1.991154     2.072366     2.142125   \n",
              "max      10.148409    10.263542    10.302692    10.284464    10.298833   \n",
              "\n",
              "        AWSM_ta_16   AWSM_ta_17   AWSM_ta_18   AWSM_ta_19   AWSM_ta_20  \n",
              "count  4976.000000  4976.000000  4976.000000  4976.000000  4976.000000  \n",
              "mean      0.116997     0.124539     0.132011     0.139361     0.146661  \n",
              "std       3.441570     3.533977     3.621356     3.704261     3.783409  \n",
              "min     -18.525156   -18.901912   -19.180556   -19.398684   -19.598000  \n",
              "25%      -1.707695    -1.761103    -1.811285    -1.853980    -1.871938  \n",
              "50%       0.367969     0.416250     0.418819     0.447434     0.449250  \n",
              "75%       2.224023     2.304559     2.352813     2.422566     2.480250  \n",
              "max      10.283281    10.337353    10.359861    10.394079    10.511500  \n",
              "\n",
              "[8 rows x 428 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c709106-8fdf-4bc3-9144-9e1403a27ccc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>adjustRatio</th>\n",
              "      <th>Label</th>\n",
              "      <th>RSI_ta_6</th>\n",
              "      <th>RSI_ta_7</th>\n",
              "      <th>...</th>\n",
              "      <th>AWSM_ta_11</th>\n",
              "      <th>AWSM_ta_12</th>\n",
              "      <th>AWSM_ta_13</th>\n",
              "      <th>AWSM_ta_14</th>\n",
              "      <th>AWSM_ta_15</th>\n",
              "      <th>AWSM_ta_16</th>\n",
              "      <th>AWSM_ta_17</th>\n",
              "      <th>AWSM_ta_18</th>\n",
              "      <th>AWSM_ta_19</th>\n",
              "      <th>AWSM_ta_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4.976000e+03</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "      <td>4976.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>192.264365</td>\n",
              "      <td>193.852006</td>\n",
              "      <td>132.069795</td>\n",
              "      <td>192.372777</td>\n",
              "      <td>133.141668</td>\n",
              "      <td>5.729091e+06</td>\n",
              "      <td>1.463816</td>\n",
              "      <td>0.187098</td>\n",
              "      <td>51.421823</td>\n",
              "      <td>51.349937</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078239</td>\n",
              "      <td>0.085819</td>\n",
              "      <td>0.093587</td>\n",
              "      <td>0.101465</td>\n",
              "      <td>0.109297</td>\n",
              "      <td>0.116997</td>\n",
              "      <td>0.124539</td>\n",
              "      <td>0.132011</td>\n",
              "      <td>0.139361</td>\n",
              "      <td>0.146661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>51.676093</td>\n",
              "      <td>51.862838</td>\n",
              "      <td>32.834472</td>\n",
              "      <td>51.703395</td>\n",
              "      <td>32.938430</td>\n",
              "      <td>3.250481e+06</td>\n",
              "      <td>0.235612</td>\n",
              "      <td>0.528734</td>\n",
              "      <td>18.428638</td>\n",
              "      <td>17.127456</td>\n",
              "      <td>...</td>\n",
              "      <td>2.886346</td>\n",
              "      <td>3.011245</td>\n",
              "      <td>3.129132</td>\n",
              "      <td>3.239821</td>\n",
              "      <td>3.343718</td>\n",
              "      <td>3.441570</td>\n",
              "      <td>3.533977</td>\n",
              "      <td>3.621356</td>\n",
              "      <td>3.704261</td>\n",
              "      <td>3.783409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>110.000000</td>\n",
              "      <td>113.650000</td>\n",
              "      <td>66.440000</td>\n",
              "      <td>110.190000</td>\n",
              "      <td>68.590000</td>\n",
              "      <td>1.074765e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.192917</td>\n",
              "      <td>1.808998</td>\n",
              "      <td>...</td>\n",
              "      <td>-15.744773</td>\n",
              "      <td>-16.578958</td>\n",
              "      <td>-17.243846</td>\n",
              "      <td>-17.732321</td>\n",
              "      <td>-18.193500</td>\n",
              "      <td>-18.525156</td>\n",
              "      <td>-18.901912</td>\n",
              "      <td>-19.180556</td>\n",
              "      <td>-19.398684</td>\n",
              "      <td>-19.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>148.700000</td>\n",
              "      <td>149.965000</td>\n",
              "      <td>111.535000</td>\n",
              "      <td>148.775000</td>\n",
              "      <td>112.735000</td>\n",
              "      <td>3.714425e+06</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>38.046770</td>\n",
              "      <td>38.902163</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.419830</td>\n",
              "      <td>-1.473854</td>\n",
              "      <td>-1.540337</td>\n",
              "      <td>-1.600446</td>\n",
              "      <td>-1.654000</td>\n",
              "      <td>-1.707695</td>\n",
              "      <td>-1.761103</td>\n",
              "      <td>-1.811285</td>\n",
              "      <td>-1.853980</td>\n",
              "      <td>-1.871938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>183.190000</td>\n",
              "      <td>184.975000</td>\n",
              "      <td>132.595000</td>\n",
              "      <td>183.440000</td>\n",
              "      <td>133.595000</td>\n",
              "      <td>4.864736e+06</td>\n",
              "      <td>1.520000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51.688022</td>\n",
              "      <td>51.456125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.207955</td>\n",
              "      <td>0.259167</td>\n",
              "      <td>0.281731</td>\n",
              "      <td>0.291964</td>\n",
              "      <td>0.339250</td>\n",
              "      <td>0.367969</td>\n",
              "      <td>0.416250</td>\n",
              "      <td>0.418819</td>\n",
              "      <td>0.447434</td>\n",
              "      <td>0.449250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>223.232500</td>\n",
              "      <td>224.825000</td>\n",
              "      <td>153.812500</td>\n",
              "      <td>223.260000</td>\n",
              "      <td>154.872500</td>\n",
              "      <td>6.668982e+06</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.894104</td>\n",
              "      <td>63.776310</td>\n",
              "      <td>...</td>\n",
              "      <td>1.809716</td>\n",
              "      <td>1.902500</td>\n",
              "      <td>1.991154</td>\n",
              "      <td>2.072366</td>\n",
              "      <td>2.142125</td>\n",
              "      <td>2.224023</td>\n",
              "      <td>2.304559</td>\n",
              "      <td>2.352813</td>\n",
              "      <td>2.422566</td>\n",
              "      <td>2.480250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>320.960000</td>\n",
              "      <td>321.730000</td>\n",
              "      <td>204.880000</td>\n",
              "      <td>321.580000</td>\n",
              "      <td>206.310000</td>\n",
              "      <td>3.981442e+07</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>97.374535</td>\n",
              "      <td>95.988340</td>\n",
              "      <td>...</td>\n",
              "      <td>10.148409</td>\n",
              "      <td>10.263542</td>\n",
              "      <td>10.302692</td>\n",
              "      <td>10.284464</td>\n",
              "      <td>10.298833</td>\n",
              "      <td>10.283281</td>\n",
              "      <td>10.337353</td>\n",
              "      <td>10.359861</td>\n",
              "      <td>10.394079</td>\n",
              "      <td>10.511500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 428 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c709106-8fdf-4bc3-9144-9e1403a27ccc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c709106-8fdf-4bc3-9144-9e1403a27ccc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c709106-8fdf-4bc3-9144-9e1403a27ccc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf661375-5c9d-465e-b107-436533c859b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf661375-5c9d-465e-b107-436533c859b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf661375-5c9d-465e-b107-436533c859b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tun9bVuSPa1I",
        "outputId": "e34486eb-5cf4-48e5-80fa-ce087f617509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date          4976\n",
              "Open          4976\n",
              "High          4976\n",
              "Low           4976\n",
              "Close         4976\n",
              "              ... \n",
              "AWSM_ta_16    4976\n",
              "AWSM_ta_17    4976\n",
              "AWSM_ta_18    4976\n",
              "AWSM_ta_19    4976\n",
              "AWSM_ta_20    4976\n",
              "Length: 429, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrGYqumbJyNH",
        "outputId": "cf154072-d843-4fe8-810e-fb1258e10809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4976, 429)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of all features\n",
        "feats = list(df.columns)\n",
        "print(f\"Total Number of features: {len(feats)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBnHVTi_YQpv",
        "outputId": "f560e05e-2a54-4c61-ac29-2b9132809f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of features: 429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"adjustRatio\"]\n",
        "df = df.drop(cols_to_drop, axis = 1)\n",
        "df = df.iloc[:-5, :]"
      ],
      "metadata": {
        "id": "9HTgRzedL8Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwc9tIq_MS8q",
        "outputId": "d783b2e0-0a1c-4bdb-efc2-f0c1b4b96bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4347\n",
              "1     312\n",
              "2     312\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "Mu3apZrUYSOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "NcRSwJjFQF06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, df.columns != 'Label'].iloc[:, :225]\n",
        "y = df.iloc[:, df.columns == 'Label']\n",
        "\n",
        "print(\"Shape of Features: \", X.values.shape)\n",
        "print(\"Shape of Labels: \", y.values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16izVEnqgCd8",
        "outputId": "be6e1a19-10cb-4682-8d6d-ee5221f4c02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Features:  (4971, 225)\n",
            "Shape of Labels:  (4971, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "VbuMyYG9KNxw",
        "outputId": "e19fcded-283f-4c73-a6d1-cc9a529868f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     RSI_ta_6   RSI_ta_7   RSI_ta_8   RSI_ta_9  RSI_ta_10  RSI_ta_11  \\\n",
              "59  10.900907  13.984287  16.808864  19.335721  21.561469  23.502503   \n",
              "60   6.896011   9.373318  11.775636  14.029307  16.097933  17.969272   \n",
              "61  12.323443  14.017505  15.820532  17.601332  19.288652  20.847486   \n",
              "62  17.397102  18.306041  19.523081  20.849862  22.176042  23.441957   \n",
              "63  39.974992  37.884477  36.745996  36.181767  35.963598  35.950929   \n",
              "\n",
              "    RSI_ta_12  RSI_ta_13  RSI_ta_14  RSI_ta_15  ...  VWAP_ta_11  VWAP_ta_12  \\\n",
              "59  25.184977  26.638602  27.893021  28.975873  ...  128.433052  128.588786   \n",
              "60  19.645962  21.139139  22.464201  23.638116  ...  127.439008  127.675569   \n",
              "61  22.264740  23.540211  24.680870  25.697282  ...  126.513412  126.889058   \n",
              "62  24.617978  25.692290  26.663413  27.535602  ...  125.801822  126.162413   \n",
              "63  36.056389  36.225617  36.425001  36.634057  ...  125.232060  125.682250   \n",
              "\n",
              "    VWAP_ta_13  VWAP_ta_14  VWAP_ta_15  VWAP_ta_16  VWAP_ta_17  VWAP_ta_18  \\\n",
              "59  128.883160  129.051384  129.173226  129.346843  129.444530  129.536821   \n",
              "60  127.858840  128.189224  128.379593  128.516978  128.710869  128.830592   \n",
              "61  127.136572  127.332215  127.678722  127.880018  128.025369  128.229909   \n",
              "62  126.527302  126.775006  126.973474  127.322889  127.527401  127.675384   \n",
              "63  126.018673  126.362362  126.599770  126.791908  127.130872  127.330789   \n",
              "\n",
              "    VWAP_ta_19  VWAP_ta_20  \n",
              "59  129.640379  129.705214  \n",
              "60  128.938996  129.067470  \n",
              "61  128.362571  128.480475  \n",
              "62  127.883632  128.022710  \n",
              "63  127.475952  127.680695  \n",
              "\n",
              "[5 rows x 225 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a24ce547-ab34-4858-8242-23d3d5af0c13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RSI_ta_6</th>\n",
              "      <th>RSI_ta_7</th>\n",
              "      <th>RSI_ta_8</th>\n",
              "      <th>RSI_ta_9</th>\n",
              "      <th>RSI_ta_10</th>\n",
              "      <th>RSI_ta_11</th>\n",
              "      <th>RSI_ta_12</th>\n",
              "      <th>RSI_ta_13</th>\n",
              "      <th>RSI_ta_14</th>\n",
              "      <th>RSI_ta_15</th>\n",
              "      <th>...</th>\n",
              "      <th>VWAP_ta_11</th>\n",
              "      <th>VWAP_ta_12</th>\n",
              "      <th>VWAP_ta_13</th>\n",
              "      <th>VWAP_ta_14</th>\n",
              "      <th>VWAP_ta_15</th>\n",
              "      <th>VWAP_ta_16</th>\n",
              "      <th>VWAP_ta_17</th>\n",
              "      <th>VWAP_ta_18</th>\n",
              "      <th>VWAP_ta_19</th>\n",
              "      <th>VWAP_ta_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>10.900907</td>\n",
              "      <td>13.984287</td>\n",
              "      <td>16.808864</td>\n",
              "      <td>19.335721</td>\n",
              "      <td>21.561469</td>\n",
              "      <td>23.502503</td>\n",
              "      <td>25.184977</td>\n",
              "      <td>26.638602</td>\n",
              "      <td>27.893021</td>\n",
              "      <td>28.975873</td>\n",
              "      <td>...</td>\n",
              "      <td>128.433052</td>\n",
              "      <td>128.588786</td>\n",
              "      <td>128.883160</td>\n",
              "      <td>129.051384</td>\n",
              "      <td>129.173226</td>\n",
              "      <td>129.346843</td>\n",
              "      <td>129.444530</td>\n",
              "      <td>129.536821</td>\n",
              "      <td>129.640379</td>\n",
              "      <td>129.705214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>6.896011</td>\n",
              "      <td>9.373318</td>\n",
              "      <td>11.775636</td>\n",
              "      <td>14.029307</td>\n",
              "      <td>16.097933</td>\n",
              "      <td>17.969272</td>\n",
              "      <td>19.645962</td>\n",
              "      <td>21.139139</td>\n",
              "      <td>22.464201</td>\n",
              "      <td>23.638116</td>\n",
              "      <td>...</td>\n",
              "      <td>127.439008</td>\n",
              "      <td>127.675569</td>\n",
              "      <td>127.858840</td>\n",
              "      <td>128.189224</td>\n",
              "      <td>128.379593</td>\n",
              "      <td>128.516978</td>\n",
              "      <td>128.710869</td>\n",
              "      <td>128.830592</td>\n",
              "      <td>128.938996</td>\n",
              "      <td>129.067470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>12.323443</td>\n",
              "      <td>14.017505</td>\n",
              "      <td>15.820532</td>\n",
              "      <td>17.601332</td>\n",
              "      <td>19.288652</td>\n",
              "      <td>20.847486</td>\n",
              "      <td>22.264740</td>\n",
              "      <td>23.540211</td>\n",
              "      <td>24.680870</td>\n",
              "      <td>25.697282</td>\n",
              "      <td>...</td>\n",
              "      <td>126.513412</td>\n",
              "      <td>126.889058</td>\n",
              "      <td>127.136572</td>\n",
              "      <td>127.332215</td>\n",
              "      <td>127.678722</td>\n",
              "      <td>127.880018</td>\n",
              "      <td>128.025369</td>\n",
              "      <td>128.229909</td>\n",
              "      <td>128.362571</td>\n",
              "      <td>128.480475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>17.397102</td>\n",
              "      <td>18.306041</td>\n",
              "      <td>19.523081</td>\n",
              "      <td>20.849862</td>\n",
              "      <td>22.176042</td>\n",
              "      <td>23.441957</td>\n",
              "      <td>24.617978</td>\n",
              "      <td>25.692290</td>\n",
              "      <td>26.663413</td>\n",
              "      <td>27.535602</td>\n",
              "      <td>...</td>\n",
              "      <td>125.801822</td>\n",
              "      <td>126.162413</td>\n",
              "      <td>126.527302</td>\n",
              "      <td>126.775006</td>\n",
              "      <td>126.973474</td>\n",
              "      <td>127.322889</td>\n",
              "      <td>127.527401</td>\n",
              "      <td>127.675384</td>\n",
              "      <td>127.883632</td>\n",
              "      <td>128.022710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>39.974992</td>\n",
              "      <td>37.884477</td>\n",
              "      <td>36.745996</td>\n",
              "      <td>36.181767</td>\n",
              "      <td>35.963598</td>\n",
              "      <td>35.950929</td>\n",
              "      <td>36.056389</td>\n",
              "      <td>36.225617</td>\n",
              "      <td>36.425001</td>\n",
              "      <td>36.634057</td>\n",
              "      <td>...</td>\n",
              "      <td>125.232060</td>\n",
              "      <td>125.682250</td>\n",
              "      <td>126.018673</td>\n",
              "      <td>126.362362</td>\n",
              "      <td>126.599770</td>\n",
              "      <td>126.791908</td>\n",
              "      <td>127.130872</td>\n",
              "      <td>127.330789</td>\n",
              "      <td>127.475952</td>\n",
              "      <td>127.680695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 225 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a24ce547-ab34-4858-8242-23d3d5af0c13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a24ce547-ab34-4858-8242-23d3d5af0c13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a24ce547-ab34-4858-8242-23d3d5af0c13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0436c1e-2df0-4465-8f0d-b3683b34cd58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0436c1e-2df0-4465-8f0d-b3683b34cd58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0436c1e-2df0-4465-8f0d-b3683b34cd58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, train_size=0.8,\n",
        "                                                    test_size=0.2, random_state=2, shuffle=True,\n",
        "                                                    stratify=y.values)\n"
      ],
      "metadata": {
        "id": "bSDXO41lQOoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHw1XY9tZjaF",
        "outputId": "8a9a899d-697e-4197-c85a-90202f6b2198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3976, 225)\n",
            "y_train shape: (3976, 1)\n",
            "X_test shape: (995, 225)\n",
            "y_test shape: (995, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Cross Validation Data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8,\n",
        "                                                    test_size=0.2, random_state=2, shuffle=True,\n",
        "                                                    stratify=y_train)"
      ],
      "metadata": {
        "id": "8feUt61NYAq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iP4pTtFZOeh",
        "outputId": "b52aa314-ed1d-4aa8-9ec8-50ad6665b983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3180, 225)\n",
            "y_train shape: (3180, 1)\n",
            "X_val shape: (796, 225)\n",
            "y_val shape: (796, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshape data as 15x15 images"
      ],
      "metadata": {
        "id": "2qGBCsWpS56Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_images = X_train.reshape(X_train.shape[0], 15, 15)\n",
        "X_val_images = X_val.reshape(X_val.shape[0], 15, 15)\n",
        "X_test_images = X_test.reshape(X_test.shape[0], 15, 15)\n",
        "\n",
        "print(f\"X_train Images shape: {X_train_images.shape}\")\n",
        "print(f\"X_val Images shape: {X_val_images.shape}\")\n",
        "print(f\"X_test Images shape: {X_test_images.shape}\")"
      ],
      "metadata": {
        "id": "LAVZxtqnZxxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69734654-9457-423a-bd4f-5a5c4fb0edc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Images shape: (3180, 15, 15)\n",
            "X_val Images shape: (796, 15, 15)\n",
            "X_test Images shape: (995, 15, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show Images"
      ],
      "metadata": {
        "id": "vNt5DOSdUiH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "KJiU9LoEUsYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "rand_idx = np.random.randint(len(X_train_images))\n",
        "img = X_train_images[rand_idx]\n",
        "label = y_train[rand_idx]\n",
        "\n",
        "if label == 1: label = \"Buy\"\n",
        "if label == 2: label = \"Sell\"\n",
        "plt.title(label)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2Z_vDVL2Uh63",
        "outputId": "e23d575d-edd0-4cdd-db3e-59aed6d5a689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a998c0ae830>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABLIAAATFCAYAAAC0O/+AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9aklEQVR4nO3dfZBVhX34/8/dXVgIhVVIATcuQhwfIho0go7asfqT6DAWY1pjzRglZJo0CT4gaoE2+DBiiE7qs8HotGpHjSYzotZf1FpCfKhPCMHqtKI2BKkWiP0luzz8XHDv+f3xHfcXFJDVu3v43H29Zu4f99xz7/l4PXt375tzz60URVEEAAAAAOzmGsoeAAAAAAB2hZAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQCQwNe//vUYO3bsNssqlUpcdtllpcwDAFAGIQsAoJe8/PLLcdppp8U+++wTgwYNis985jPxxS9+MW688cayRwMASEnIAgDoBc8880xMnDgxXnrppfjmN78ZN910U/zVX/1VNDQ0xPXXX1/2eAAAKTWVPQAAQD268soro6WlJZYuXRp77LHHNretX7++nKEAAJJzRBYAQC/4r//6rxg/fvyHIlZExMiRI7e5ftddd8Xhhx8egwcPjuHDh8cZZ5wRa9as6aNJAQDyELIAAHrBPvvsE8uWLYtXXnllp+tdeeWVcfbZZ8d+++0X11xzTcycOTMWL14cxx57bPz+97/vm2EBAJIQsgAAesFFF10UmzdvjkMPPTSOPvromD17dvzLv/xLbN26tXud1atXx6WXXhrz58+Pe++9N77zne/EJZdcEkuWLIn//u//jh/96Ecl/hcAAOx+hCwAgF7wxS9+MZ599tk45ZRT4qWXXoqrr746TjrppPjMZz4TDz30UERE3H///VGtVuP000+Pd955p/syevTo2G+//WLJkiUl/1cAAOxenOwdAKCXTJo0Ke6///7YsmVLvPTSS7Fo0aK49tpr47TTTosVK1bE66+/HkVRxH777bfd+w8YMKCPJwYA2L0JWQAAvWzgwIExadKkmDRpUuy///4xffr0+NnPfhbVajUqlUo88sgj0djY+KH7/dEf/VEJ0wIA7L6ELACAPjRx4sSIiPif//mf2HfffaMoihg3blzsv//+JU8GALD7c44sAIBesGTJkiiK4kPLf/7zn0dExAEHHBB//ud/Ho2NjXH55Zd/aN2iKOJ///d/+2RWAIAsHJEFANALzj333Ni8eXN8+ctfjgMPPDC2bNkSzzzzTNx3330xduzYmD59euyxxx4xf/78mDt3bvzmN7+JU089NYYOHRqrVq2KRYsWxbe+9a246KKLyv5PAQDYbQhZAAC94Ic//GH87Gc/i5///Odx6623xpYtW2LMmDHx3e9+N773ve/FHnvsERERc+bMif333z+uvfbauPzyyyMioq2tLU488cQ45ZRTSvwvAADY/VSK7R3zDgAAAAC7GefIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUmsoe4IOq1Wq8/fbbMXTo0KhUKmWPAwAAAEAvKooiNmzYEK2trdHQsPNjrna7kPX2229HW1tb2WMAAAAA0IfWrFkTe++9907X2e1C1tChQyMi4gsn/100DhhU8jR5VLrKniCfSrUoe4R0KtWyJ0jIbtZjlcKTBrslP5oAQC957713Y+kvFnQ3oZ3Z7ULW+x8nbBwwKJqErF1WcbazHhOyek7I+hjsZj0mZMFuyo8mANDLduUUU/IHAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQQq+FrJtvvjnGjh0bgwYNiiOPPDJeeOGF3toUAAAAAP1Ar4Ss++67L2bNmhWXXnppLF++PCZMmBAnnXRSrF+/vjc2BwAAAEA/0Csh65prrolvfvObMX369DjooIPilltuiU996lPxj//4j72xOQAAAAD6gZqHrC1btsSyZcti8uTJ//9GGhpi8uTJ8eyzz9Z6cwAAAAD0E021fsB33nknurq6YtSoUdssHzVqVLz66qsfWr+zszM6Ozu7r3d0dNR6JAAAAADqQOnfWrhgwYJoaWnpvrS1tZU9EgAAAAC7oZqHrE9/+tPR2NgY69at22b5unXrYvTo0R9af+7cudHe3t59WbNmTa1HAgAAAKAO1DxkDRw4MA4//PBYvHhx97JqtRqLFy+Oo4466kPrNzc3x7Bhw7a5AAAAAMAH1fwcWRERs2bNimnTpsXEiRPjiCOOiOuuuy42bdoU06dP743NAQAAANAP9ErI+su//Mv47W9/G5dcckmsXbs2Dj300Hj00Uc/dAJ4AAAAANhVvRKyIiLOOeecOOecc3rr4QEAAADoZ0r/1kIAAAAA2BVCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkEJT2QPsyB/93/8eTZUBZY8B/KGiWvYEAJBG0dVV9ggAlKUoyp4glcZi6y6v64gsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUmsoeYEd+9srSGDZUZwMAANiRxor3TEB+HRuqsef+u7auVz0AAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFKoechasGBBTJo0KYYOHRojR46MU089NVauXFnrzQAAAADQz9Q8ZD3xxBMxY8aMeO655+Lxxx+PrVu3xoknnhibNm2q9aYAAAAA6Eeaav2Ajz766DbX77jjjhg5cmQsW7Ysjj322FpvDgAAAIB+otfPkdXe3h4REcOHD+/tTQEAAABQx2p+RNYfqlarMXPmzDjmmGPi4IMP3u46nZ2d0dnZ2X29o6OjN0cCAAAAIKlePSJrxowZ8corr8S99967w3UWLFgQLS0t3Ze2trbeHAkAAACApCpFURS98cDnnHNOPPjgg/Hkk0/GuHHjdrje9o7Iamtri3dWjo1hQ3v9k48AAABpNVa8ZwLy69hQjT33/3W0t7fHsGHDdrpuzT9aWBRFnHvuubFo0aL45S9/udOIFRHR3Nwczc3NtR4DAAAAgDpT85A1Y8aMuOeee+LBBx+MoUOHxtq1ayMioqWlJQYPHlzrzQEAAADQT9T8o4WVSmW7y2+//fb4+te//pH37+joiJaWFh8tBAAA+Ag+WgjUg9I/WggAAAAAtSbfAwAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKTQVPYAO9JYaYjGis4GAAAAwP+hFAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApNBU9gBQlq6iWvYIAAAA1KHGiuOGeotnFgAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFHo9ZP3gBz+ISqUSM2fO7O1NAQAAAFDHejVkLV26NH784x/H5z//+d7cDAAAAAD9QK+FrI0bN8aZZ54Zt912W+y55569tRkAAAAA+oleC1kzZsyIk08+OSZPntxbmwAAAACgH2nqjQe99957Y/ny5bF06dKPXLezszM6Ozu7r3d0dPTGSAAAAAAkV/MjstasWRPnn39+3H333TFo0KCPXH/BggXR0tLSfWlra6v1SAAAAADUgUpRFEUtH/CBBx6IL3/5y9HY2Ni9rKurKyqVSjQ0NERnZ+c2t23viKy2trb43WufjWFDe/1LFenHuopq2SMAAABQhxorekZPdGyoxp77/zra29tj2LBhO1235h8tPOGEE+Lll1/eZtn06dPjwAMPjNmzZ28TsSIimpubo7m5udZjAAAAAFBnah6yhg4dGgcffPA2y4YMGRIjRoz40HIAAAAA2FWOdQMAAAAghV751sIP+uUvf9kXmwEAAACgjjkiCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACCFprIHgLI0VnRcoD50FdWyRwAA4A9sLbrKHiGVrT34e9Y7eQAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFJrKHgAAAICPpxpF2SMA9ClHZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkEKvhKy33norvva1r8WIESNi8ODBccghh8SLL77YG5sCAAAAoJ9oqvUD/u53v4tjjjkmjj/++HjkkUfij//4j+P111+PPffcs9abAgAAAKAfqXnIuuqqq6KtrS1uv/327mXjxo2r9WYAAAAA6Gdq/tHChx56KCZOnBhf+cpXYuTIkXHYYYfFbbfdVuvNAAAAANDP1Dxk/frXv46FCxfGfvvtF4899lh85zvfifPOOy/uvPPO7a7f2dkZHR0d21wAAAAA4IMqRVEUtXzAgQMHxsSJE+OZZ57pXnbeeefF0qVL49lnn/3Q+pdddllcfvnlH1r+u9c+G8OG+lJFAPgoXUW17BEAKEk1avp2DqAUHRuqMfKA1dHe3h7Dhg3b6bo1L0V77bVXHHTQQdss+9znPhdvvvnmdtefO3dutLe3d1/WrFlT65EAAAAAqAM1P9n7McccEytXrtxm2WuvvRb77LPPdtdvbm6O5ubmWo8BAAAAQJ2p+RFZF1xwQTz33HPx/e9/P954442455574tZbb40ZM2bUelMAAAAA9CM1D1mTJk2KRYsWxU9+8pM4+OCD44orrojrrrsuzjzzzFpvCgAAAIB+pOYne/+kOjo6oqWlxcneAWAXOdk7QP/lZO9APSj1ZO8AAAAA0BuELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIIWmsgfYkQlPnBkNnxpU9hhpFNVK2SOks+eeG8seIZ1NvxpR9gjpNGz1s9lThX9i6bFqU1H2CPn40eyxARs8aT31qXV+NntqwGbPWU8N2NBV9gjpDNj4XtkjpNPU/v+WPUI6DRs8Zz3xXrUzIm7apXW9XQAAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASKGp7AF2ZP/5/080NTSXPUYenVvKniCdYuvWskfI5711ZU+QTtFVLXuEfKqesx4rirInyMd+BgD0In9p9Ey12PWm4YgsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSqHnI6urqinnz5sW4ceNi8ODBse+++8YVV1wRRVHUelMAAAAA9CNNtX7Aq666KhYuXBh33nlnjB8/Pl588cWYPn16tLS0xHnnnVfrzQEAAADQT9Q8ZD3zzDPxpS99KU4++eSIiBg7dmz85Cc/iRdeeKHWmwIAAACgH6n5RwuPPvroWLx4cbz22msREfHSSy/F008/HVOmTKn1pgAAAADoR2p+RNacOXOio6MjDjzwwGhsbIyurq648sor48wzz9zu+p2dndHZ2dl9vaOjo9YjAQAAAFAHan5E1k9/+tO4++6745577only5fHnXfeGT/84Q/jzjvv3O76CxYsiJaWlu5LW1tbrUcCAAAAoA5Uihp/nWBbW1vMmTMnZsyY0b1s/vz5cdddd8Wrr776ofW3d0RWW1tbTN5nRjQ1NNdytPrWuaXsCdIptm4te4R83nuv7AnSKbqqZY+QT9Vz1mO+Gbjn7GcAALuN94ot8Yt3fxrt7e0xbNiwna5b848Wbt68ORoatj3Qq7GxMao7+IOxubk5mpsFKwAAAAB2ruYha+rUqXHllVfGmDFjYvz48fGrX/0qrrnmmvjGN75R600BAAAA0I/UPGTdeOONMW/evPjud78b69evj9bW1vjrv/7ruOSSS2q9KQAAAAD6kZqfI+uT6ujoiJaWFufI6innyOox58j6GJwjq8ecI+tjcO6intu9fpXnYD8DANht9OQcWTX/1kIAAAAA6A1CFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkEJT2QPsSHXdb6NaGVj2GNSxoijKHgEAAGC3V6lUyh4BujkiCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAghaayB4CyVCqVskcAAAAAesARWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApNDjkPXkk0/G1KlTo7W1NSqVSjzwwAPb3F4URVxyySWx1157xeDBg2Py5Mnx+uuv12peAAAAAPqpHoesTZs2xYQJE+Lmm2/e7u1XX3113HDDDXHLLbfE888/H0OGDImTTjop3n333U88LAAAAAD9V1NP7zBlypSYMmXKdm8riiKuu+66+N73vhdf+tKXIiLin/7pn2LUqFHxwAMPxBlnnPHJpgUAAACg36rpObJWrVoVa9eujcmTJ3cva2lpiSOPPDKeffbZWm4KAAAAgH6mx0dk7czatWsjImLUqFHbLB81alT3bR/U2dkZnZ2d3dc7OjpqORIAAAAAdaL0by1csGBBtLS0dF/a2trKHgkAAACA3VBNQ9bo0aMjImLdunXbLF+3bl33bR80d+7caG9v776sWbOmliMBAAAAUCdqGrLGjRsXo0ePjsWLF3cv6+joiOeffz6OOuqo7d6nubk5hg0bts0FAAAAAD6ox+fI2rhxY7zxxhvd11etWhUrVqyI4cOHx5gxY2LmzJkxf/782G+//WLcuHExb968aG1tjVNPPbWWcwMAAADQz/Q4ZL344otx/PHHd1+fNWtWRERMmzYt7rjjjvibv/mb2LRpU3zrW9+K3//+9/Enf/In8eijj8agQYNqNzUAAAAA/U6lKIqi7CH+UEdHR7S0tMT/Nej0aKoMLHscAAAAAHrRe8WW+MW7P4329vaPPOVU6d9aCAAAAAC7QsgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSaCp7gB1qbIyoNJY9RR5FUfYE+VSrZU9Af9DodYw+4HdAz/kd0GOF/QyoF1WvZ/SBhkrZE6TSkz8zHJEFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJBCU9kD7EjDyE9HQ0Nz2WPk0dVV9gT5VIuyJ8in8Jz1mOes56rVsicAtqfBv3/SByqVsifIx3NGX2iwn9G7impnxJu7tq6/SAAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASKHHIevJJ5+MqVOnRmtra1QqlXjggQe6b9u6dWvMnj07DjnkkBgyZEi0trbG2WefHW+//XYtZwYAAACgH+pxyNq0aVNMmDAhbr755g/dtnnz5li+fHnMmzcvli9fHvfff3+sXLkyTjnllJoMCwAAAED/1dTTO0yZMiWmTJmy3dtaWlri8ccf32bZTTfdFEcccUS8+eabMWbMmI83JQAAAAD9Xq+fI6u9vT0qlUrssccevb0pAAAAAOpYj4/I6ol33303Zs+eHV/96ldj2LBh212ns7MzOjs7u693dHT05kgAAAAAJNVrR2Rt3bo1Tj/99CiKIhYuXLjD9RYsWBAtLS3dl7a2tt4aCQAAAIDEeiVkvR+xVq9eHY8//vgOj8aKiJg7d260t7d3X9asWdMbIwEAAACQXM0/Wvh+xHr99ddjyZIlMWLEiJ2u39zcHM3NzbUeAwAAAIA60+OQtXHjxnjjjTe6r69atSpWrFgRw4cPj7322itOO+20WL58eTz88MPR1dUVa9eujYiI4cOHx8CBA2s3OQAAAAD9So9D1osvvhjHH3989/VZs2ZFRMS0adPisssui4ceeigiIg499NBt7rdkyZI47rjjPv6kAAAAAPRrPQ5Zxx13XBRFscPbd3YbAAAAAHxcvfathQAAAABQS0IWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQQlPZA+zIO0eNjsaBg8oeI42Bm6plj5BOY2dR9gjpdA2slD1COtUBnrOeatjqZ7OnGrd4znqq0uU566mG9zxnPVVt9Dugpxr8bPaY17Oe85z1XKXwnPVU0eB3QE+89967EW/u2rqOyAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASKGp7AF25Ht/c2cMGdpY9hhpVDVJ+kBDVMsegX7A6xlQL/zeBIBds2lDVzx16K6t690CAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAAp9DhkPfnkkzF16tRobW2NSqUSDzzwwA7X/fa3vx2VSiWuu+66TzAiAAAAAHyMkLVp06aYMGFC3HzzzTtdb9GiRfHcc89Fa2vrxx4OAAAAAN7X1NM7TJkyJaZMmbLTdd56660499xz47HHHouTTz75Yw8HAAAAAO+r+TmyqtVqnHXWWXHxxRfH+PHja/3wAAAAAPRTPT4i66NcddVV0dTUFOedd94urd/Z2RmdnZ3d1zs6Omo9EgAAAAB1oKZHZC1btiyuv/76uOOOO6JSqezSfRYsWBAtLS3dl7a2tlqOBAAAAECdqGnIeuqpp2L9+vUxZsyYaGpqiqampli9enVceOGFMXbs2O3eZ+7cudHe3t59WbNmTS1HAgAAAKBO1PSjhWeddVZMnjx5m2UnnXRSnHXWWTF9+vTt3qe5uTmam5trOQYAAAAAdajHIWvjxo3xxhtvdF9ftWpVrFixIoYPHx5jxoyJESNGbLP+gAEDYvTo0XHAAQd88mkBAAAA6Ld6HLJefPHFOP7447uvz5o1KyIipk2bFnfccUfNBgMAAACAP9TjkHXcccdFURS7vP5vfvObnm4CAAAAAD6kpid7BwAAAIDeImQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApNZQ/wQUVRRETE5o1dJU+SSxFF2SPQD1SiWvYI9ANez4B64fcmAOya9xvQ+01oZ3a7kLVhw4aIiDj7T/6r5EkAAAAA6CsbNmyIlpaWna5TKXYld/WharUab7/9dgwdOjQqlUrZ42yjo6Mj2traYs2aNTFs2LCyx6FO2c/oC/Yz+oL9jL5gP6Mv2M/oC/Yz+sLuup8VRREbNmyI1tbWaGjY+VmwdrsjshoaGmLvvfcue4ydGjZs2G71P5z6ZD+jL9jP6Av2M/qC/Yy+YD+jL9jP6Au74372UUdivc/J3gEAAABIQcgCAAAAIAUhqweam5vj0ksvjebm5rJHoY7Zz+gL9jP6gv2MvmA/oy/Yz+gL9jP6Qj3sZ7vdyd4BAAAAYHsckQUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQtYtuvvnmGDt2bAwaNCiOPPLIeOGFF8oeiTqyYMGCmDRpUgwdOjRGjhwZp556aqxcubLssahzP/jBD6JSqcTMmTPLHoU689Zbb8XXvva1GDFiRAwePDgOOeSQePHFF8seizrS1dUV8+bNi3HjxsXgwYNj3333jSuuuCJ8hxGf1JNPPhlTp06N1tbWqFQq8cADD2xze1EUcckll8Ree+0VgwcPjsmTJ8frr79ezrCktbP9bOvWrTF79uw45JBDYsiQIdHa2hpnn312vP322+UNTEof9Xr2h7797W9HpVKJ6667rs/m+ySErF1w3333xaxZs+LSSy+N5cuXx4QJE+Kkk06K9evXlz0adeKJJ56IGTNmxHPPPRePP/54bN26NU488cTYtGlT2aNRp5YuXRo//vGP4/Of/3zZo1Bnfve738UxxxwTAwYMiEceeST+4z/+I/7+7/8+9txzz7JHo45cddVVsXDhwrjpppviP//zP+Oqq66Kq6++Om688cayRyO5TZs2xYQJE+Lmm2/e7u1XX3113HDDDXHLLbfE888/H0OGDImTTjop3n333T6elMx2tp9t3rw5li9fHvPmzYvly5fH/fffHytXroxTTjmlhEnJ7KNez963aNGieO6556K1tbWPJvvkKoV/uvpIRx55ZEyaNCluuummiIioVqvR1tYW5557bsyZM6fk6ahHv/3tb2PkyJHxxBNPxLHHHlv2ONSZjRs3xhe+8IX40Y9+FPPnz49DDz00zb++sPubM2dO/Nu//Vs89dRTZY9CHfuzP/uzGDVqVPzDP/xD97K/+Iu/iMGDB8ddd91V4mTUk0qlEosWLYpTTz01Iv7P0Vitra1x4YUXxkUXXRQREe3t7TFq1Ki444474owzzihxWrL64H62PUuXLo0jjjgiVq9eHWPGjOm74agbO9rP3nrrrTjyyCPjsccei5NPPjlmzpyZ4tMajsj6CFu2bIlly5bF5MmTu5c1NDTE5MmT49lnny1xMupZe3t7REQMHz685EmoRzNmzIiTTz55m9c1qJWHHnooJk6cGF/5yldi5MiRcdhhh8Vtt91W9ljUmaOPPjoWL14cr732WkREvPTSS/H000/HlClTSp6MerZq1apYu3btNr8/W1pa4sgjj/S+gF7V3t4elUol9thjj7JHoY5Uq9U466yz4uKLL47x48eXPU6PNJU9wO7unXfeia6urhg1atQ2y0eNGhWvvvpqSVNRz6rVasycOTOOOeaYOPjgg8sehzpz7733xvLly2Pp0qVlj0Kd+vWvfx0LFy6MWbNmxd/+7d/G0qVL47zzzouBAwfGtGnTyh6POjFnzpzo6OiIAw88MBobG6OrqyuuvPLKOPPMM8sejTq2du3aiIjtvi94/zaotXfffTdmz54dX/3qV2PYsGFlj0Mdueqqq6KpqSnOO++8skfpMSELdjMzZsyIV155JZ5++umyR6HOrFmzJs4///x4/PHHY9CgQWWPQ52qVqsxceLE+P73vx8REYcddli88sorccsttwhZ1MxPf/rTuPvuu+Oee+6J8ePHx4oVK2LmzJnR2tpqPwPqxtatW+P000+Poihi4cKFZY9DHVm2bFlcf/31sXz58qhUKmWP02M+WvgRPv3pT0djY2OsW7dum+Xr1q2L0aNHlzQV9eqcc86Jhx9+OJYsWRJ777132eNQZ5YtWxbr16+PL3zhC9HU1BRNTU3xxBNPxA033BBNTU3R1dVV9ojUgb322isOOuigbZZ97nOfizfffLOkiahHF198ccyZMyfOOOOMOOSQQ+Kss86KCy64IBYsWFD2aNSx9//2976AvvB+xFq9enU8/vjjjsaipp566qlYv359jBkzpvt9werVq+PCCy+MsWPHlj3eRxKyPsLAgQPj8MMPj8WLF3cvq1arsXjx4jjqqKNKnIx6UhRFnHPOObFo0aL4xS9+EePGjSt7JOrQCSecEC+//HKsWLGi+zJx4sQ488wzY8WKFdHY2Fj2iNSBY445JlauXLnNstdeey322WefkiaiHm3evDkaGrb9M7axsTGq1WpJE9EfjBs3LkaPHr3N+4KOjo54/vnnvS+gpt6PWK+//nr867/+a4wYMaLskagzZ511Vvz7v//7Nu8LWltb4+KLL47HHnus7PE+ko8W7oJZs2bFtGnTYuLEiXHEEUfEddddF5s2bYrp06eXPRp1YsaMGXHPPffEgw8+GEOHDu0+z0JLS0sMHjy45OmoF0OHDv3QedeGDBkSI0aMcD42auaCCy6Io48+Or7//e/H6aefHi+88ELceuutceutt5Y9GnVk6tSpceWVV8aYMWNi/Pjx8atf/Squueaa+MY3vlH2aCS3cePGeOONN7qvr1q1KlasWBHDhw+PMWPGxMyZM2P+/Pmx3377xbhx42LevHnR2tq602+cgw/a2X621157xWmnnRbLly+Phx9+OLq6urrfGwwfPjwGDhxY1tgk81GvZx8MpAMGDIjRo0fHAQcc0Nej9lzBLrnxxhuLMWPGFAMHDiyOOOKI4rnnnit7JOpIRGz3cvvtt5c9GnXuT//0T4vzzz+/7DGoM//8z/9cHHzwwUVzc3Nx4IEHFrfeemvZI1FnOjo6ivPPP78YM2ZMMWjQoOKzn/1s8Xd/93dFZ2dn2aOR3JIlS7b7N9m0adOKoiiKarVazJs3rxg1alTR3NxcnHDCCcXKlSvLHZp0drafrVq1aofvDZYsWVL26CTyUa9nH7TPPvsU1157bZ/O+HFViqIo+qiZAQAAAMDH5hxZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKfx/nq3Saz5eG3UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize and Encode Data"
      ],
      "metadata": {
        "id": "RBG4vhf8Z0hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
      ],
      "metadata": {
        "id": "qPUzw115Z_cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler Features\n",
        "MM_SCALER = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "X_train = MM_SCALER.fit_transform(X_train)\n",
        "X_val = MM_SCALER.transform(X_val)\n",
        "X_test = MM_SCALER.transform(X_test)"
      ],
      "metadata": {
        "id": "_ACcffnTaMt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encode Labels\n",
        "\"\"\"\n",
        "0 -> [1, 0, 0]\n",
        "1 -> [0, 1, 0]\n",
        "2 -> [0, 0, 1]\n",
        "\"\"\"\n",
        "OHE = OneHotEncoder(sparse=False, categories='auto')\n",
        "\n",
        "y_train = OHE.fit_transform(y_train.reshape(-1, 1)) # Reshapes to a column vector\n",
        "y_val = OHE.transform(y_val.reshape(-1, 1))\n",
        "y_test = OHE.transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyub6NasZ2OP",
        "outputId": "7e0b8910-505b-4c38-ae5e-e71b392e6ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train Images shape: {X_train_images.shape}\")\n",
        "print(f\"y_train labels shape: {y_train.shape}\\n\")\n",
        "\n",
        "print(f\"X_val Images shape: {X_val_images.shape}\")\n",
        "print(f\"y_val labels shape: {y_val.shape}\\n\")\n",
        "\n",
        "print(f\"X_test Images shape: {X_test_images.shape}\")\n",
        "print(f\"y_test labels shape: {y_test.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGjmhWmPbZKM",
        "outputId": "6a95cdd7-c1ae-4a16-bd9d-fca1bd324ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Images shape: (3180, 15, 15)\n",
            "y_train labels shape: (3180, 3)\n",
            "\n",
            "X_val Images shape: (796, 15, 15)\n",
            "y_val labels shape: (796, 3)\n",
            "\n",
            "X_test Images shape: (995, 15, 15)\n",
            "y_test labels shape: (995, 3)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model"
      ],
      "metadata": {
        "id": "8rAlehV1NmGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "!pip install h5py"
      ],
      "metadata": {
        "id": "ClKLwxI5NwKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01dc184-c7a4-459b-fb05-d563a203d23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model Implementation"
      ],
      "metadata": {
        "id": "c7g300nEN-D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"input_w\": 15,\n",
        "    \"input_h\": 15,\n",
        "    \"input_c\": 3,\n",
        "    \"num_classes\": 3,\n",
        "    \"batch_size\": 1024,\n",
        "    \"epochs\": 3000\n",
        "    }"
      ],
      "metadata": {
        "id": "J5C3ZWfuUUV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# CNN model\n",
        "model = Sequential()\n",
        "# Conv2D\n",
        "model.add(Conv2D(filters = 20,\n",
        "                 kernel_size = 2,\n",
        "                 strides = 1,\n",
        "                 padding = 'valid',\n",
        "                 activation='relu',\n",
        "                 use_bias = True,\n",
        "                 kernel_regularizer=regularizers.l2(0.0),\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 input_shape=(params[\"input_w\"],\n",
        "                              params[\"input_h\"],\n",
        "                              params[\"input_c\"])\n",
        "                  ))\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.22))\n",
        "\n",
        "# Conv2D\n",
        "model.add(Conv2D(filters = 40,\n",
        "                 kernel_size = 2,\n",
        "                 strides = 2,\n",
        "                 padding = 'valid',\n",
        "                 activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(0.0),\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 ))\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense\n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.22))\n",
        "\n",
        "# Dense\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae', 'mse'])"
      ],
      "metadata": {
        "id": "TLCY-GOdB7-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Old CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(params[\"input_w\"], params[\"input_h\"], params[\"input_c\"])))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(params[\"num_classes\"], activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy', 'mae', 'mse'])"
      ],
      "metadata": {
        "id": "zsT6aunf8pLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Model\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "TTi979wcWVzv",
        "outputId": "03df3be7-8441-4dfe-c5bb-13fb38174726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Checkpoint Callbacks"
      ],
      "metadata": {
        "id": "lPmv0U-nXFu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
        "\n",
        "best_model_path = \"data/Eric_best_model_keras.h5\"\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
        "                   patience=100, min_delta=0.0001) # Stops the training early when validation loss stops improving, prevent overfitting\n",
        "\n",
        "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
        "                        min_delta=0.001, cooldown=1, min_lr=0.0001) # Adjusts Learning Rate on validation loss\n",
        "\n",
        "mcp = ModelCheckpoint(best_model_path, monitor='val_loss', verbose=1,\n",
        "                      save_best_only=True, save_weights_only=False, mode='min', save_freq=\"epoch\")  # val_f1_metric"
      ],
      "metadata": {
        "id": "Lb60bddQXFgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "8AevTBfgOBlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input images to include a single channel to fit CNN Sequential Layer\n",
        "X_train_images = np.expand_dims(X_train_images, axis=-1)\n",
        "X_val_images = np.expand_dims(X_val_images, axis=-1)\n",
        "X_test_images = np.expand_dims(X_test_images, axis=-1)"
      ],
      "metadata": {
        "id": "E3baGzwUd2EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape into 3 channels\n",
        "X_train_images = np.stack((X_train_images,)*3, axis=-1)\n",
        "X_val_images = np.stack((X_val_images,)*3, axis=-1)\n",
        "X_test_images = np.stack((X_test_images,)*3, axis=-1)"
      ],
      "metadata": {
        "id": "TF2n3956Fdws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train Images shape: {X_train_images.shape}\")\n",
        "print(f\"y_train labels shape: {y_train.shape}\\n\")\n",
        "\n",
        "print(f\"X_val Images shape: {X_val_images.shape}\")\n",
        "print(f\"y_val labels shape: {y_val.shape}\\n\")\n",
        "\n",
        "print(f\"X_test Images shape: {X_test_images.shape}\")\n",
        "print(f\"y_test labels shape: {y_test.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsJhJSAioawk",
        "outputId": "38b50386-4e7a-4969-ffc7-289f26f95ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Images shape: (3180, 15, 15, 3)\n",
            "y_train labels shape: (3180, 3)\n",
            "\n",
            "X_val Images shape: (796, 15, 15, 3)\n",
            "y_val labels shape: (796, 3)\n",
            "\n",
            "X_test Images shape: (995, 15, 15, 3)\n",
            "y_test labels shape: (995, 3)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "hist = model.fit(X_train_images, y_train,\n",
        "          batch_size=params[\"batch_size\"],\n",
        "          epochs=1500,\n",
        "          callbacks=[mcp, rlp],\n",
        "          validation_data = (X_val_images, y_val),\n",
        "          verbose=1)"
      ],
      "metadata": {
        "id": "qNBCC2GxN816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfdc046-544d-43ba-b747-a26d8da5e152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 251: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3476 - accuracy: 0.8745 - mae: 0.1462 - mse: 0.0695 - val_loss: 0.3346 - val_accuracy: 0.8744 - val_mae: 0.1444 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 252/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3446 - accuracy: 0.8682 - mae: 0.1445 - mse: 0.0705\n",
            "Epoch 252: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3446 - accuracy: 0.8745 - mae: 0.1436 - mse: 0.0689 - val_loss: 0.3337 - val_accuracy: 0.8744 - val_mae: 0.1425 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 253/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3501 - accuracy: 0.8750 - mae: 0.1448 - mse: 0.0698\n",
            "Epoch 253: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3438 - accuracy: 0.8742 - mae: 0.1427 - mse: 0.0691 - val_loss: 0.3333 - val_accuracy: 0.8744 - val_mae: 0.1416 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 254/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3366 - accuracy: 0.8818 - mae: 0.1397 - mse: 0.0663\n",
            "Epoch 254: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3502 - accuracy: 0.8748 - mae: 0.1440 - mse: 0.0701 - val_loss: 0.3341 - val_accuracy: 0.8744 - val_mae: 0.1419 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 255/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8770 - mae: 0.1378 - mse: 0.0670\n",
            "Epoch 255: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3466 - accuracy: 0.8745 - mae: 0.1435 - mse: 0.0693 - val_loss: 0.3342 - val_accuracy: 0.8744 - val_mae: 0.1419 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 256/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8711 - mae: 0.1465 - mse: 0.0724\n",
            "Epoch 256: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3446 - accuracy: 0.8745 - mae: 0.1421 - mse: 0.0692 - val_loss: 0.3334 - val_accuracy: 0.8744 - val_mae: 0.1416 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 257/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3237 - accuracy: 0.8838 - mae: 0.1374 - mse: 0.0645\n",
            "Epoch 257: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3414 - accuracy: 0.8745 - mae: 0.1426 - mse: 0.0686 - val_loss: 0.3331 - val_accuracy: 0.8744 - val_mae: 0.1427 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 258/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3525 - accuracy: 0.8740 - mae: 0.1465 - mse: 0.0713\n",
            "Epoch 258: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3430 - accuracy: 0.8742 - mae: 0.1437 - mse: 0.0692 - val_loss: 0.3337 - val_accuracy: 0.8744 - val_mae: 0.1445 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 259/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3631 - accuracy: 0.8643 - mae: 0.1491 - mse: 0.0730\n",
            "Epoch 259: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3409 - accuracy: 0.8733 - mae: 0.1448 - mse: 0.0688 - val_loss: 0.3328 - val_accuracy: 0.8744 - val_mae: 0.1442 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 260/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8887 - mae: 0.1373 - mse: 0.0635\n",
            "Epoch 260: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3434 - accuracy: 0.8745 - mae: 0.1439 - mse: 0.0686 - val_loss: 0.3312 - val_accuracy: 0.8744 - val_mae: 0.1423 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 261/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3551 - accuracy: 0.8691 - mae: 0.1483 - mse: 0.0719\n",
            "Epoch 261: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3443 - accuracy: 0.8745 - mae: 0.1429 - mse: 0.0691 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1399 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 262/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8838 - mae: 0.1363 - mse: 0.0661\n",
            "Epoch 262: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3512 - accuracy: 0.8745 - mae: 0.1422 - mse: 0.0696 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1390 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 263/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3509 - accuracy: 0.8701 - mae: 0.1408 - mse: 0.0712\n",
            "Epoch 263: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3397 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0684 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 264/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3499 - accuracy: 0.8740 - mae: 0.1397 - mse: 0.0692\n",
            "Epoch 264: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3452 - accuracy: 0.8742 - mae: 0.1383 - mse: 0.0687 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 265/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3422 - accuracy: 0.8740 - mae: 0.1408 - mse: 0.0692\n",
            "Epoch 265: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3455 - accuracy: 0.8745 - mae: 0.1390 - mse: 0.0689 - val_loss: 0.3298 - val_accuracy: 0.8744 - val_mae: 0.1385 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 266/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3474 - accuracy: 0.8730 - mae: 0.1386 - mse: 0.0701\n",
            "Epoch 266: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3454 - accuracy: 0.8745 - mae: 0.1391 - mse: 0.0691 - val_loss: 0.3317 - val_accuracy: 0.8744 - val_mae: 0.1397 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 267/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3743 - accuracy: 0.8633 - mae: 0.1459 - mse: 0.0740\n",
            "Epoch 267: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3487 - accuracy: 0.8748 - mae: 0.1407 - mse: 0.0692 - val_loss: 0.3331 - val_accuracy: 0.8744 - val_mae: 0.1400 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 268/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8828 - mae: 0.1352 - mse: 0.0667\n",
            "Epoch 268: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3448 - accuracy: 0.8742 - mae: 0.1404 - mse: 0.0692 - val_loss: 0.3345 - val_accuracy: 0.8744 - val_mae: 0.1405 - val_mse: 0.0684 - lr: 1.0000e-04\n",
            "Epoch 269/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3405 - accuracy: 0.8809 - mae: 0.1371 - mse: 0.0666\n",
            "Epoch 269: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3488 - accuracy: 0.8736 - mae: 0.1418 - mse: 0.0699 - val_loss: 0.3353 - val_accuracy: 0.8744 - val_mae: 0.1413 - val_mse: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 270/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8633 - mae: 0.1430 - mse: 0.0723\n",
            "Epoch 270: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3411 - accuracy: 0.8742 - mae: 0.1394 - mse: 0.0686 - val_loss: 0.3352 - val_accuracy: 0.8744 - val_mae: 0.1420 - val_mse: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 271/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3290 - accuracy: 0.8789 - mae: 0.1394 - mse: 0.0660\n",
            "Epoch 271: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3487 - accuracy: 0.8742 - mae: 0.1425 - mse: 0.0696 - val_loss: 0.3359 - val_accuracy: 0.8744 - val_mae: 0.1427 - val_mse: 0.0687 - lr: 1.0000e-04\n",
            "Epoch 272/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8809 - mae: 0.1401 - mse: 0.0670\n",
            "Epoch 272: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3402 - accuracy: 0.8745 - mae: 0.1422 - mse: 0.0689 - val_loss: 0.3354 - val_accuracy: 0.8744 - val_mae: 0.1426 - val_mse: 0.0686 - lr: 1.0000e-04\n",
            "Epoch 273/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8867 - mae: 0.1381 - mse: 0.0638\n",
            "Epoch 273: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3424 - accuracy: 0.8748 - mae: 0.1411 - mse: 0.0687 - val_loss: 0.3342 - val_accuracy: 0.8744 - val_mae: 0.1414 - val_mse: 0.0684 - lr: 1.0000e-04\n",
            "Epoch 274/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8691 - mae: 0.1415 - mse: 0.0715\n",
            "Epoch 274: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3468 - accuracy: 0.8745 - mae: 0.1412 - mse: 0.0694 - val_loss: 0.3339 - val_accuracy: 0.8744 - val_mae: 0.1411 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 275/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3066 - accuracy: 0.8857 - mae: 0.1317 - mse: 0.0620\n",
            "Epoch 275: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3400 - accuracy: 0.8745 - mae: 0.1400 - mse: 0.0684 - val_loss: 0.3316 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 276/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8838 - mae: 0.1321 - mse: 0.0649\n",
            "Epoch 276: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3408 - accuracy: 0.8745 - mae: 0.1377 - mse: 0.0686 - val_loss: 0.3300 - val_accuracy: 0.8744 - val_mae: 0.1375 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 277/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8770 - mae: 0.1377 - mse: 0.0688\n",
            "Epoch 277: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3466 - accuracy: 0.8748 - mae: 0.1380 - mse: 0.0693 - val_loss: 0.3299 - val_accuracy: 0.8744 - val_mae: 0.1376 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 278/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8857 - mae: 0.1311 - mse: 0.0647\n",
            "Epoch 278: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3532 - accuracy: 0.8748 - mae: 0.1384 - mse: 0.0699 - val_loss: 0.3307 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 279/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3756 - accuracy: 0.8545 - mae: 0.1525 - mse: 0.0758\n",
            "Epoch 279: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3450 - accuracy: 0.8739 - mae: 0.1406 - mse: 0.0688 - val_loss: 0.3323 - val_accuracy: 0.8744 - val_mae: 0.1410 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 280/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3241 - accuracy: 0.8926 - mae: 0.1332 - mse: 0.0616\n",
            "Epoch 280: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3459 - accuracy: 0.8742 - mae: 0.1415 - mse: 0.0689 - val_loss: 0.3328 - val_accuracy: 0.8744 - val_mae: 0.1420 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 281/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3360 - accuracy: 0.8799 - mae: 0.1384 - mse: 0.0661\n",
            "Epoch 281: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3446 - accuracy: 0.8745 - mae: 0.1435 - mse: 0.0690 - val_loss: 0.3322 - val_accuracy: 0.8744 - val_mae: 0.1418 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 282/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8701 - mae: 0.1465 - mse: 0.0715\n",
            "Epoch 282: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3452 - accuracy: 0.8745 - mae: 0.1420 - mse: 0.0691 - val_loss: 0.3318 - val_accuracy: 0.8744 - val_mae: 0.1415 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 283/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3439 - accuracy: 0.8799 - mae: 0.1417 - mse: 0.0683\n",
            "Epoch 283: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3454 - accuracy: 0.8745 - mae: 0.1439 - mse: 0.0692 - val_loss: 0.3318 - val_accuracy: 0.8744 - val_mae: 0.1423 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 284/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3521 - accuracy: 0.8652 - mae: 0.1450 - mse: 0.0718\n",
            "Epoch 284: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3424 - accuracy: 0.8742 - mae: 0.1429 - mse: 0.0689 - val_loss: 0.3305 - val_accuracy: 0.8744 - val_mae: 0.1409 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 285/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3167 - accuracy: 0.8887 - mae: 0.1345 - mse: 0.0620\n",
            "Epoch 285: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3471 - accuracy: 0.8742 - mae: 0.1412 - mse: 0.0691 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1389 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 286/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3412 - accuracy: 0.8701 - mae: 0.1391 - mse: 0.0693\n",
            "Epoch 286: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3403 - accuracy: 0.8752 - mae: 0.1395 - mse: 0.0684 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1380 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 287/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8672 - mae: 0.1431 - mse: 0.0714\n",
            "Epoch 287: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3392 - accuracy: 0.8745 - mae: 0.1379 - mse: 0.0681 - val_loss: 0.3286 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 288/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3530 - accuracy: 0.8682 - mae: 0.1412 - mse: 0.0719\n",
            "Epoch 288: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3455 - accuracy: 0.8745 - mae: 0.1391 - mse: 0.0694 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1376 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 289/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8750 - mae: 0.1362 - mse: 0.0678\n",
            "Epoch 289: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3396 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0683 - val_loss: 0.3301 - val_accuracy: 0.8744 - val_mae: 0.1389 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 290/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3411 - accuracy: 0.8750 - mae: 0.1384 - mse: 0.0686\n",
            "Epoch 290: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3439 - accuracy: 0.8745 - mae: 0.1401 - mse: 0.0692 - val_loss: 0.3310 - val_accuracy: 0.8744 - val_mae: 0.1412 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 291/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3575 - accuracy: 0.8662 - mae: 0.1460 - mse: 0.0723\n",
            "Epoch 291: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3448 - accuracy: 0.8742 - mae: 0.1411 - mse: 0.0688 - val_loss: 0.3311 - val_accuracy: 0.8744 - val_mae: 0.1419 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 292/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8652 - mae: 0.1433 - mse: 0.0717\n",
            "Epoch 292: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3472 - accuracy: 0.8742 - mae: 0.1430 - mse: 0.0694 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1399 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 293/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3290 - accuracy: 0.8770 - mae: 0.1364 - mse: 0.0665\n",
            "Epoch 293: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3399 - accuracy: 0.8745 - mae: 0.1390 - mse: 0.0683 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 294/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8721 - mae: 0.1391 - mse: 0.0693\n",
            "Epoch 294: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3456 - accuracy: 0.8748 - mae: 0.1394 - mse: 0.0692 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 295/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3537 - accuracy: 0.8643 - mae: 0.1398 - mse: 0.0725\n",
            "Epoch 295: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3438 - accuracy: 0.8742 - mae: 0.1378 - mse: 0.0684 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 296/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3259 - accuracy: 0.8857 - mae: 0.1337 - mse: 0.0644\n",
            "Epoch 296: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3445 - accuracy: 0.8742 - mae: 0.1398 - mse: 0.0688 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1382 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 297/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3612 - accuracy: 0.8643 - mae: 0.1482 - mse: 0.0737\n",
            "Epoch 297: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3467 - accuracy: 0.8748 - mae: 0.1407 - mse: 0.0694 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1398 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 298/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8770 - mae: 0.1409 - mse: 0.0676\n",
            "Epoch 298: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3434 - accuracy: 0.8745 - mae: 0.1415 - mse: 0.0688 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1414 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 299/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3470 - accuracy: 0.8711 - mae: 0.1429 - mse: 0.0700\n",
            "Epoch 299: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3456 - accuracy: 0.8752 - mae: 0.1432 - mse: 0.0688 - val_loss: 0.3293 - val_accuracy: 0.8744 - val_mae: 0.1422 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 300/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8711 - mae: 0.1446 - mse: 0.0687\n",
            "Epoch 300: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3414 - accuracy: 0.8739 - mae: 0.1441 - mse: 0.0684 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1402 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 301/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3586 - accuracy: 0.8682 - mae: 0.1437 - mse: 0.0717\n",
            "Epoch 301: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3419 - accuracy: 0.8748 - mae: 0.1419 - mse: 0.0687 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1386 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 302/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3499 - accuracy: 0.8730 - mae: 0.1403 - mse: 0.0693\n",
            "Epoch 302: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3468 - accuracy: 0.8742 - mae: 0.1410 - mse: 0.0693 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1373 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 303/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3165 - accuracy: 0.8857 - mae: 0.1347 - mse: 0.0634\n",
            "Epoch 303: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3417 - accuracy: 0.8742 - mae: 0.1388 - mse: 0.0689 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1375 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 304/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8760 - mae: 0.1390 - mse: 0.0678\n",
            "Epoch 304: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3343 - accuracy: 0.8745 - mae: 0.1392 - mse: 0.0680 - val_loss: 0.3286 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 305/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8701 - mae: 0.1410 - mse: 0.0704\n",
            "Epoch 305: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3420 - accuracy: 0.8742 - mae: 0.1415 - mse: 0.0688 - val_loss: 0.3306 - val_accuracy: 0.8744 - val_mae: 0.1413 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 306/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3603 - accuracy: 0.8701 - mae: 0.1462 - mse: 0.0724\n",
            "Epoch 306: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3476 - accuracy: 0.8745 - mae: 0.1436 - mse: 0.0696 - val_loss: 0.3320 - val_accuracy: 0.8744 - val_mae: 0.1429 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 307/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3611 - accuracy: 0.8770 - mae: 0.1469 - mse: 0.0703\n",
            "Epoch 307: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3449 - accuracy: 0.8745 - mae: 0.1441 - mse: 0.0690 - val_loss: 0.3316 - val_accuracy: 0.8744 - val_mae: 0.1416 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 308/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8711 - mae: 0.1447 - mse: 0.0705\n",
            "Epoch 308: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3380 - accuracy: 0.8742 - mae: 0.1415 - mse: 0.0684 - val_loss: 0.3302 - val_accuracy: 0.8744 - val_mae: 0.1394 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 309/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.8742 - mae: 0.1398 - mse: 0.0683\n",
            "Epoch 309: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3423 - accuracy: 0.8742 - mae: 0.1398 - mse: 0.0683 - val_loss: 0.3295 - val_accuracy: 0.8744 - val_mae: 0.1383 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 310/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3695 - accuracy: 0.8613 - mae: 0.1467 - mse: 0.0748\n",
            "Epoch 310: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3415 - accuracy: 0.8745 - mae: 0.1409 - mse: 0.0689 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 311/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3289 - accuracy: 0.8838 - mae: 0.1352 - mse: 0.0650\n",
            "Epoch 311: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3367 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0680 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 312/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3169 - accuracy: 0.8936 - mae: 0.1281 - mse: 0.0608\n",
            "Epoch 312: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3451 - accuracy: 0.8745 - mae: 0.1375 - mse: 0.0689 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 313/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3464 - accuracy: 0.8701 - mae: 0.1399 - mse: 0.0702\n",
            "Epoch 313: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3421 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0685 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1383 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 314/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3422 - accuracy: 0.8750 - mae: 0.1393 - mse: 0.0675\n",
            "Epoch 314: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3415 - accuracy: 0.8745 - mae: 0.1401 - mse: 0.0685 - val_loss: 0.3306 - val_accuracy: 0.8744 - val_mae: 0.1410 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 315/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3158 - accuracy: 0.8828 - mae: 0.1356 - mse: 0.0639\n",
            "Epoch 315: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3415 - accuracy: 0.8748 - mae: 0.1433 - mse: 0.0687 - val_loss: 0.3326 - val_accuracy: 0.8744 - val_mae: 0.1439 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 316/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3366 - accuracy: 0.8750 - mae: 0.1417 - mse: 0.0674\n",
            "Epoch 316: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3383 - accuracy: 0.8742 - mae: 0.1449 - mse: 0.0685 - val_loss: 0.3330 - val_accuracy: 0.8744 - val_mae: 0.1446 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 317/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3418 - accuracy: 0.8779 - mae: 0.1432 - mse: 0.0682\n",
            "Epoch 317: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3419 - accuracy: 0.8742 - mae: 0.1447 - mse: 0.0690 - val_loss: 0.3309 - val_accuracy: 0.8744 - val_mae: 0.1424 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 318/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8809 - mae: 0.1403 - mse: 0.0669\n",
            "Epoch 318: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3404 - accuracy: 0.8742 - mae: 0.1425 - mse: 0.0688 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1402 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 319/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3620 - accuracy: 0.8604 - mae: 0.1469 - mse: 0.0741\n",
            "Epoch 319: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3430 - accuracy: 0.8742 - mae: 0.1421 - mse: 0.0688 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1390 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 320/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8975 - mae: 0.1333 - mse: 0.0611\n",
            "Epoch 320: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3451 - accuracy: 0.8742 - mae: 0.1407 - mse: 0.0693 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1360 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 321/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8623 - mae: 0.1419 - mse: 0.0736\n",
            "Epoch 321: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3397 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0687 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 322/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8770 - mae: 0.1358 - mse: 0.0671\n",
            "Epoch 322: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3347 - accuracy: 0.8745 - mae: 0.1354 - mse: 0.0678 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 323/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3665 - accuracy: 0.8604 - mae: 0.1405 - mse: 0.0746\n",
            "Epoch 323: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3398 - accuracy: 0.8745 - mae: 0.1350 - mse: 0.0686 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 324/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3280 - accuracy: 0.8799 - mae: 0.1324 - mse: 0.0653\n",
            "Epoch 324: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3452 - accuracy: 0.8739 - mae: 0.1376 - mse: 0.0692 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1363 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 325/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3564 - accuracy: 0.8691 - mae: 0.1373 - mse: 0.0707\n",
            "Epoch 325: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3452 - accuracy: 0.8748 - mae: 0.1384 - mse: 0.0689 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1397 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 326/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8770 - mae: 0.1386 - mse: 0.0673\n",
            "Epoch 326: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3429 - accuracy: 0.8748 - mae: 0.1408 - mse: 0.0683 - val_loss: 0.3291 - val_accuracy: 0.8744 - val_mae: 0.1409 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 327/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3474 - accuracy: 0.8770 - mae: 0.1426 - mse: 0.0694\n",
            "Epoch 327: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3418 - accuracy: 0.8739 - mae: 0.1426 - mse: 0.0693 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1403 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 328/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3146 - accuracy: 0.8936 - mae: 0.1344 - mse: 0.0615\n",
            "Epoch 328: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3421 - accuracy: 0.8752 - mae: 0.1417 - mse: 0.0691 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 329/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3494 - accuracy: 0.8701 - mae: 0.1433 - mse: 0.0708\n",
            "Epoch 329: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3368 - accuracy: 0.8748 - mae: 0.1394 - mse: 0.0679 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1370 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 330/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3557 - accuracy: 0.8730 - mae: 0.1391 - mse: 0.0706\n",
            "Epoch 330: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3434 - accuracy: 0.8742 - mae: 0.1395 - mse: 0.0689 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1378 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 331/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3647 - accuracy: 0.8682 - mae: 0.1451 - mse: 0.0715\n",
            "Epoch 331: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3461 - accuracy: 0.8742 - mae: 0.1410 - mse: 0.0693 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 332/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8750 - mae: 0.1409 - mse: 0.0687\n",
            "Epoch 332: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3410 - accuracy: 0.8745 - mae: 0.1412 - mse: 0.0686 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1399 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 333/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3527 - accuracy: 0.8809 - mae: 0.1427 - mse: 0.0688\n",
            "Epoch 333: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3465 - accuracy: 0.8745 - mae: 0.1418 - mse: 0.0689 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1389 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 334/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3303 - accuracy: 0.8838 - mae: 0.1372 - mse: 0.0650\n",
            "Epoch 334: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3451 - accuracy: 0.8742 - mae: 0.1409 - mse: 0.0691 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1383 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 335/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8672 - mae: 0.1412 - mse: 0.0698\n",
            "Epoch 335: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3351 - accuracy: 0.8742 - mae: 0.1405 - mse: 0.0679 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 336/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3586 - accuracy: 0.8701 - mae: 0.1471 - mse: 0.0714\n",
            "Epoch 336: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3390 - accuracy: 0.8733 - mae: 0.1408 - mse: 0.0686 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 337/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3421 - accuracy: 0.8770 - mae: 0.1406 - mse: 0.0681\n",
            "Epoch 337: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3439 - accuracy: 0.8748 - mae: 0.1402 - mse: 0.0686 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 338/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3225 - accuracy: 0.8770 - mae: 0.1375 - mse: 0.0663\n",
            "Epoch 338: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3421 - accuracy: 0.8739 - mae: 0.1389 - mse: 0.0686 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1365 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 339/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3488 - accuracy: 0.8633 - mae: 0.1407 - mse: 0.0718\n",
            "Epoch 339: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3454 - accuracy: 0.8745 - mae: 0.1385 - mse: 0.0689 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1383 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 340/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3329 - accuracy: 0.8740 - mae: 0.1373 - mse: 0.0685\n",
            "Epoch 340: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3341 - accuracy: 0.8742 - mae: 0.1391 - mse: 0.0678 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1385 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 341/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3331 - accuracy: 0.8730 - mae: 0.1399 - mse: 0.0679\n",
            "Epoch 341: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3343 - accuracy: 0.8745 - mae: 0.1390 - mse: 0.0679 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1364 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 342/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8711 - mae: 0.1411 - mse: 0.0712\n",
            "Epoch 342: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3425 - accuracy: 0.8739 - mae: 0.1375 - mse: 0.0688 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 343/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8740 - mae: 0.1395 - mse: 0.0690\n",
            "Epoch 343: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3364 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0680 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1365 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 344/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3375 - accuracy: 0.8750 - mae: 0.1383 - mse: 0.0677\n",
            "Epoch 344: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3423 - accuracy: 0.8745 - mae: 0.1392 - mse: 0.0689 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1384 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 345/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8730 - mae: 0.1443 - mse: 0.0705\n",
            "Epoch 345: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3473 - accuracy: 0.8745 - mae: 0.1416 - mse: 0.0692 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1392 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 346/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3479 - accuracy: 0.8672 - mae: 0.1435 - mse: 0.0712\n",
            "Epoch 346: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3488 - accuracy: 0.8742 - mae: 0.1418 - mse: 0.0699 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1399 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 347/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3141 - accuracy: 0.8848 - mae: 0.1332 - mse: 0.0630\n",
            "Epoch 347: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3378 - accuracy: 0.8745 - mae: 0.1407 - mse: 0.0680 - val_loss: 0.3301 - val_accuracy: 0.8744 - val_mae: 0.1418 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 348/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8760 - mae: 0.1424 - mse: 0.0680\n",
            "Epoch 348: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3414 - accuracy: 0.8748 - mae: 0.1441 - mse: 0.0691 - val_loss: 0.3311 - val_accuracy: 0.8744 - val_mae: 0.1423 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 349/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8760 - mae: 0.1419 - mse: 0.0668\n",
            "Epoch 349: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3388 - accuracy: 0.8745 - mae: 0.1427 - mse: 0.0684 - val_loss: 0.3307 - val_accuracy: 0.8744 - val_mae: 0.1402 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 350/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3570 - accuracy: 0.8662 - mae: 0.1452 - mse: 0.0718\n",
            "Epoch 350: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3407 - accuracy: 0.8745 - mae: 0.1409 - mse: 0.0684 - val_loss: 0.3301 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 351/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3428 - accuracy: 0.8779 - mae: 0.1383 - mse: 0.0673\n",
            "Epoch 351: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3457 - accuracy: 0.8745 - mae: 0.1397 - mse: 0.0691 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 352/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3489 - accuracy: 0.8730 - mae: 0.1389 - mse: 0.0704\n",
            "Epoch 352: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3452 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0691 - val_loss: 0.3299 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 353/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8779 - mae: 0.1338 - mse: 0.0667\n",
            "Epoch 353: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3350 - accuracy: 0.8745 - mae: 0.1353 - mse: 0.0679 - val_loss: 0.3309 - val_accuracy: 0.8744 - val_mae: 0.1377 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 354/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3150 - accuracy: 0.8906 - mae: 0.1301 - mse: 0.0619\n",
            "Epoch 354: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3402 - accuracy: 0.8745 - mae: 0.1397 - mse: 0.0687 - val_loss: 0.3337 - val_accuracy: 0.8744 - val_mae: 0.1421 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 355/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8828 - mae: 0.1383 - mse: 0.0658\n",
            "Epoch 355: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3433 - accuracy: 0.8742 - mae: 0.1424 - mse: 0.0690 - val_loss: 0.3356 - val_accuracy: 0.8744 - val_mae: 0.1441 - val_mse: 0.0686 - lr: 1.0000e-04\n",
            "Epoch 356/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3253 - accuracy: 0.8789 - mae: 0.1384 - mse: 0.0656\n",
            "Epoch 356: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3375 - accuracy: 0.8745 - mae: 0.1442 - mse: 0.0684 - val_loss: 0.3350 - val_accuracy: 0.8744 - val_mae: 0.1431 - val_mse: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 357/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3549 - accuracy: 0.8799 - mae: 0.1418 - mse: 0.0678\n",
            "Epoch 357: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3445 - accuracy: 0.8742 - mae: 0.1411 - mse: 0.0687 - val_loss: 0.3328 - val_accuracy: 0.8744 - val_mae: 0.1394 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 358/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8662 - mae: 0.1457 - mse: 0.0731\n",
            "Epoch 358: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3455 - accuracy: 0.8739 - mae: 0.1410 - mse: 0.0694 - val_loss: 0.3317 - val_accuracy: 0.8744 - val_mae: 0.1378 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 359/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8770 - mae: 0.1394 - mse: 0.0691\n",
            "Epoch 359: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3429 - accuracy: 0.8745 - mae: 0.1382 - mse: 0.0686 - val_loss: 0.3319 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 360/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8682 - mae: 0.1380 - mse: 0.0703\n",
            "Epoch 360: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3379 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0680 - val_loss: 0.3320 - val_accuracy: 0.8744 - val_mae: 0.1370 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 361/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8730 - mae: 0.1378 - mse: 0.0694\n",
            "Epoch 361: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3453 - accuracy: 0.8748 - mae: 0.1385 - mse: 0.0690 - val_loss: 0.3312 - val_accuracy: 0.8744 - val_mae: 0.1375 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 362/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3120 - accuracy: 0.8887 - mae: 0.1344 - mse: 0.0619\n",
            "Epoch 362: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3382 - accuracy: 0.8739 - mae: 0.1379 - mse: 0.0685 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1381 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 363/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8721 - mae: 0.1401 - mse: 0.0684\n",
            "Epoch 363: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3390 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0679 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1382 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 364/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8721 - mae: 0.1422 - mse: 0.0705\n",
            "Epoch 364: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3386 - accuracy: 0.8742 - mae: 0.1397 - mse: 0.0685 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 365/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8750 - mae: 0.1384 - mse: 0.0683\n",
            "Epoch 365: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3402 - accuracy: 0.8733 - mae: 0.1390 - mse: 0.0685 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 366/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3598 - accuracy: 0.8691 - mae: 0.1418 - mse: 0.0722\n",
            "Epoch 366: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3419 - accuracy: 0.8742 - mae: 0.1384 - mse: 0.0687 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 367/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8760 - mae: 0.1379 - mse: 0.0683\n",
            "Epoch 367: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3381 - accuracy: 0.8752 - mae: 0.1395 - mse: 0.0684 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 368/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3409 - accuracy: 0.8750 - mae: 0.1402 - mse: 0.0691\n",
            "Epoch 368: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3410 - accuracy: 0.8745 - mae: 0.1397 - mse: 0.0686 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 369/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8770 - mae: 0.1383 - mse: 0.0679\n",
            "Epoch 369: val_loss did not improve from 0.32496\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3394 - accuracy: 0.8742 - mae: 0.1397 - mse: 0.0687 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 370/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8691 - mae: 0.1412 - mse: 0.0707\n",
            "Epoch 370: val_loss improved from 0.32496 to 0.32493, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.3443 - accuracy: 0.8742 - mae: 0.1390 - mse: 0.0691 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 371/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3397 - accuracy: 0.8770 - mae: 0.1344 - mse: 0.0669\n",
            "Epoch 371: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3403 - accuracy: 0.8742 - mae: 0.1365 - mse: 0.0683 - val_loss: 0.3251 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 372/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3565 - accuracy: 0.8740 - mae: 0.1415 - mse: 0.0707\n",
            "Epoch 372: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3507 - accuracy: 0.8742 - mae: 0.1384 - mse: 0.0695 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 373/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8711 - mae: 0.1388 - mse: 0.0688\n",
            "Epoch 373: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3412 - accuracy: 0.8748 - mae: 0.1388 - mse: 0.0682 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 374/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8721 - mae: 0.1395 - mse: 0.0698\n",
            "Epoch 374: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3447 - accuracy: 0.8745 - mae: 0.1405 - mse: 0.0684 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1386 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 375/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3595 - accuracy: 0.8604 - mae: 0.1442 - mse: 0.0738\n",
            "Epoch 375: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3343 - accuracy: 0.8742 - mae: 0.1392 - mse: 0.0677 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1377 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 376/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3369 - accuracy: 0.8818 - mae: 0.1369 - mse: 0.0667\n",
            "Epoch 376: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3370 - accuracy: 0.8745 - mae: 0.1382 - mse: 0.0681 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1375 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 377/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3189 - accuracy: 0.8848 - mae: 0.1335 - mse: 0.0639\n",
            "Epoch 377: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3378 - accuracy: 0.8745 - mae: 0.1396 - mse: 0.0685 - val_loss: 0.3291 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 378/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8779 - mae: 0.1360 - mse: 0.0680\n",
            "Epoch 378: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3408 - accuracy: 0.8742 - mae: 0.1379 - mse: 0.0688 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 379/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3593 - accuracy: 0.8643 - mae: 0.1420 - mse: 0.0730\n",
            "Epoch 379: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3425 - accuracy: 0.8748 - mae: 0.1377 - mse: 0.0686 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 380/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3604 - accuracy: 0.8662 - mae: 0.1402 - mse: 0.0725\n",
            "Epoch 380: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3414 - accuracy: 0.8748 - mae: 0.1366 - mse: 0.0684 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1340 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 381/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3259 - accuracy: 0.8828 - mae: 0.1357 - mse: 0.0655\n",
            "Epoch 381: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3441 - accuracy: 0.8745 - mae: 0.1379 - mse: 0.0691 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 382/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3621 - accuracy: 0.8711 - mae: 0.1405 - mse: 0.0718\n",
            "Epoch 382: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3467 - accuracy: 0.8748 - mae: 0.1375 - mse: 0.0689 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 383/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3568 - accuracy: 0.8672 - mae: 0.1397 - mse: 0.0719\n",
            "Epoch 383: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3419 - accuracy: 0.8745 - mae: 0.1375 - mse: 0.0685 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 384/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8730 - mae: 0.1372 - mse: 0.0677\n",
            "Epoch 384: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3427 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0682 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1346 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 385/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3222 - accuracy: 0.8809 - mae: 0.1347 - mse: 0.0655\n",
            "Epoch 385: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3347 - accuracy: 0.8745 - mae: 0.1388 - mse: 0.0683 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 386/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8662 - mae: 0.1419 - mse: 0.0706\n",
            "Epoch 386: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3364 - accuracy: 0.8736 - mae: 0.1400 - mse: 0.0682 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1398 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 387/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8701 - mae: 0.1472 - mse: 0.0724\n",
            "Epoch 387: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3462 - accuracy: 0.8742 - mae: 0.1435 - mse: 0.0692 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1425 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 388/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3202 - accuracy: 0.8887 - mae: 0.1373 - mse: 0.0627\n",
            "Epoch 388: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3396 - accuracy: 0.8742 - mae: 0.1453 - mse: 0.0683 - val_loss: 0.3295 - val_accuracy: 0.8744 - val_mae: 0.1447 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 389/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3567 - accuracy: 0.8711 - mae: 0.1514 - mse: 0.0727\n",
            "Epoch 389: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3469 - accuracy: 0.8748 - mae: 0.1467 - mse: 0.0696 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1432 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 390/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3389 - accuracy: 0.8730 - mae: 0.1438 - mse: 0.0684\n",
            "Epoch 390: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3446 - accuracy: 0.8742 - mae: 0.1448 - mse: 0.0691 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1410 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 391/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3454 - accuracy: 0.8730 - mae: 0.1440 - mse: 0.0692\n",
            "Epoch 391: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3443 - accuracy: 0.8748 - mae: 0.1425 - mse: 0.0690 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1398 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 392/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8760 - mae: 0.1406 - mse: 0.0661\n",
            "Epoch 392: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3347 - accuracy: 0.8745 - mae: 0.1416 - mse: 0.0677 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1382 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 393/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3725 - accuracy: 0.8672 - mae: 0.1462 - mse: 0.0740\n",
            "Epoch 393: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3439 - accuracy: 0.8742 - mae: 0.1408 - mse: 0.0692 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 394/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3409 - accuracy: 0.8682 - mae: 0.1433 - mse: 0.0704\n",
            "Epoch 394: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3327 - accuracy: 0.8752 - mae: 0.1394 - mse: 0.0680 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 395/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3453 - accuracy: 0.8662 - mae: 0.1401 - mse: 0.0710\n",
            "Epoch 395: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3400 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0680 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 396/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3585 - accuracy: 0.8613 - mae: 0.1457 - mse: 0.0738\n",
            "Epoch 396: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3443 - accuracy: 0.8742 - mae: 0.1399 - mse: 0.0690 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 397/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8848 - mae: 0.1306 - mse: 0.0633\n",
            "Epoch 397: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3418 - accuracy: 0.8742 - mae: 0.1374 - mse: 0.0684 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 398/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3786 - accuracy: 0.8691 - mae: 0.1422 - mse: 0.0726\n",
            "Epoch 398: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3482 - accuracy: 0.8742 - mae: 0.1396 - mse: 0.0693 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 399/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3506 - accuracy: 0.8721 - mae: 0.1431 - mse: 0.0703\n",
            "Epoch 399: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3420 - accuracy: 0.8742 - mae: 0.1410 - mse: 0.0686 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 400/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8770 - mae: 0.1414 - mse: 0.0679\n",
            "Epoch 400: val_loss did not improve from 0.32493\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3458 - accuracy: 0.8745 - mae: 0.1400 - mse: 0.0684 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 401/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3267 - accuracy: 0.8867 - mae: 0.1331 - mse: 0.0640\n",
            "Epoch 401: val_loss improved from 0.32493 to 0.32480, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3415 - accuracy: 0.8742 - mae: 0.1405 - mse: 0.0686 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 402/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3695 - accuracy: 0.8584 - mae: 0.1464 - mse: 0.0747\n",
            "Epoch 402: val_loss improved from 0.32480 to 0.32470, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.3440 - accuracy: 0.8742 - mae: 0.1408 - mse: 0.0688 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1386 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 403/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3486 - accuracy: 0.8691 - mae: 0.1439 - mse: 0.0709\n",
            "Epoch 403: val_loss did not improve from 0.32470\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3377 - accuracy: 0.8752 - mae: 0.1419 - mse: 0.0682 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1381 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 404/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8711 - mae: 0.1468 - mse: 0.0718\n",
            "Epoch 404: val_loss did not improve from 0.32470\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3455 - accuracy: 0.8745 - mae: 0.1415 - mse: 0.0691 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1373 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 405/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3141 - accuracy: 0.8838 - mae: 0.1345 - mse: 0.0631\n",
            "Epoch 405: val_loss did not improve from 0.32470\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3357 - accuracy: 0.8748 - mae: 0.1399 - mse: 0.0674 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 406/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3616 - accuracy: 0.8633 - mae: 0.1501 - mse: 0.0739\n",
            "Epoch 406: val_loss improved from 0.32470 to 0.32469, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3378 - accuracy: 0.8742 - mae: 0.1410 - mse: 0.0683 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 407/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3458 - accuracy: 0.8721 - mae: 0.1426 - mse: 0.0693\n",
            "Epoch 407: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3447 - accuracy: 0.8742 - mae: 0.1422 - mse: 0.0691 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 408/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3417 - accuracy: 0.8721 - mae: 0.1371 - mse: 0.0681\n",
            "Epoch 408: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3373 - accuracy: 0.8739 - mae: 0.1387 - mse: 0.0680 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 409/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3565 - accuracy: 0.8770 - mae: 0.1400 - mse: 0.0701\n",
            "Epoch 409: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3459 - accuracy: 0.8745 - mae: 0.1381 - mse: 0.0689 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 410/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8652 - mae: 0.1394 - mse: 0.0711\n",
            "Epoch 410: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3420 - accuracy: 0.8745 - mae: 0.1372 - mse: 0.0684 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 411/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2921 - accuracy: 0.8936 - mae: 0.1249 - mse: 0.0583\n",
            "Epoch 411: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3384 - accuracy: 0.8745 - mae: 0.1367 - mse: 0.0683 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 412/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3532 - accuracy: 0.8730 - mae: 0.1440 - mse: 0.0703\n",
            "Epoch 412: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3419 - accuracy: 0.8745 - mae: 0.1408 - mse: 0.0687 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 413/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3603 - accuracy: 0.8691 - mae: 0.1441 - mse: 0.0723\n",
            "Epoch 413: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3445 - accuracy: 0.8745 - mae: 0.1419 - mse: 0.0689 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 414/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3492 - accuracy: 0.8682 - mae: 0.1457 - mse: 0.0715\n",
            "Epoch 414: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3392 - accuracy: 0.8742 - mae: 0.1410 - mse: 0.0684 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 415/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3402 - accuracy: 0.8721 - mae: 0.1409 - mse: 0.0697\n",
            "Epoch 415: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3397 - accuracy: 0.8745 - mae: 0.1394 - mse: 0.0683 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1363 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 416/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8770 - mae: 0.1386 - mse: 0.0672\n",
            "Epoch 416: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3412 - accuracy: 0.8748 - mae: 0.1405 - mse: 0.0691 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 417/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3235 - accuracy: 0.8770 - mae: 0.1350 - mse: 0.0657\n",
            "Epoch 417: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3368 - accuracy: 0.8748 - mae: 0.1402 - mse: 0.0678 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1380 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 418/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3462 - accuracy: 0.8750 - mae: 0.1424 - mse: 0.0692\n",
            "Epoch 418: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3412 - accuracy: 0.8748 - mae: 0.1413 - mse: 0.0686 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1378 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 419/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8682 - mae: 0.1427 - mse: 0.0708\n",
            "Epoch 419: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3351 - accuracy: 0.8745 - mae: 0.1405 - mse: 0.0681 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 420/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8799 - mae: 0.1375 - mse: 0.0669\n",
            "Epoch 420: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3414 - accuracy: 0.8745 - mae: 0.1395 - mse: 0.0682 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 421/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8848 - mae: 0.1330 - mse: 0.0649\n",
            "Epoch 421: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3414 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0685 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 422/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3544 - accuracy: 0.8633 - mae: 0.1417 - mse: 0.0725\n",
            "Epoch 422: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3416 - accuracy: 0.8742 - mae: 0.1392 - mse: 0.0684 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 423/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3439 - accuracy: 0.8750 - mae: 0.1400 - mse: 0.0686\n",
            "Epoch 423: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3426 - accuracy: 0.8745 - mae: 0.1392 - mse: 0.0685 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 424/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8857 - mae: 0.1334 - mse: 0.0647\n",
            "Epoch 424: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3375 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0682 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 425/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8818 - mae: 0.1319 - mse: 0.0642\n",
            "Epoch 425: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3435 - accuracy: 0.8745 - mae: 0.1396 - mse: 0.0687 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1386 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 426/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3318 - accuracy: 0.8828 - mae: 0.1384 - mse: 0.0654\n",
            "Epoch 426: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3396 - accuracy: 0.8739 - mae: 0.1418 - mse: 0.0683 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 427/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8740 - mae: 0.1414 - mse: 0.0680\n",
            "Epoch 427: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3383 - accuracy: 0.8745 - mae: 0.1406 - mse: 0.0679 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 428/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8838 - mae: 0.1336 - mse: 0.0649\n",
            "Epoch 428: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3388 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0680 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 429/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3528 - accuracy: 0.8672 - mae: 0.1407 - mse: 0.0713\n",
            "Epoch 429: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3454 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0686 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 430/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3486 - accuracy: 0.8750 - mae: 0.1412 - mse: 0.0690\n",
            "Epoch 430: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3416 - accuracy: 0.8745 - mae: 0.1396 - mse: 0.0687 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 431/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8779 - mae: 0.1370 - mse: 0.0657\n",
            "Epoch 431: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3352 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0680 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1376 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 432/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3660 - accuracy: 0.8594 - mae: 0.1483 - mse: 0.0750\n",
            "Epoch 432: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3386 - accuracy: 0.8748 - mae: 0.1392 - mse: 0.0682 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1385 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 433/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3452 - accuracy: 0.8691 - mae: 0.1409 - mse: 0.0701\n",
            "Epoch 433: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3385 - accuracy: 0.8745 - mae: 0.1401 - mse: 0.0682 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1384 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 434/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8643 - mae: 0.1459 - mse: 0.0715\n",
            "Epoch 434: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3353 - accuracy: 0.8745 - mae: 0.1405 - mse: 0.0677 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 435/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3449 - accuracy: 0.8721 - mae: 0.1408 - mse: 0.0694\n",
            "Epoch 435: val_loss did not improve from 0.32469\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3408 - accuracy: 0.8742 - mae: 0.1393 - mse: 0.0685 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 436/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3300 - accuracy: 0.8789 - mae: 0.1357 - mse: 0.0663\n",
            "Epoch 436: val_loss improved from 0.32469 to 0.32447, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3385 - accuracy: 0.8742 - mae: 0.1374 - mse: 0.0681 - val_loss: 0.3245 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 437/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3241 - accuracy: 0.8828 - mae: 0.1319 - mse: 0.0651\n",
            "Epoch 437: val_loss improved from 0.32447 to 0.32398, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3372 - accuracy: 0.8742 - mae: 0.1360 - mse: 0.0680 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 438/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3541 - accuracy: 0.8652 - mae: 0.1373 - mse: 0.0707\n",
            "Epoch 438: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3408 - accuracy: 0.8745 - mae: 0.1358 - mse: 0.0678 - val_loss: 0.3245 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 439/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3237 - accuracy: 0.8789 - mae: 0.1369 - mse: 0.0654\n",
            "Epoch 439: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3417 - accuracy: 0.8745 - mae: 0.1389 - mse: 0.0684 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 440/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8789 - mae: 0.1358 - mse: 0.0660\n",
            "Epoch 440: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3371 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0680 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 441/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3528 - accuracy: 0.8643 - mae: 0.1449 - mse: 0.0725\n",
            "Epoch 441: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3402 - accuracy: 0.8745 - mae: 0.1396 - mse: 0.0681 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 442/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3561 - accuracy: 0.8643 - mae: 0.1455 - mse: 0.0721\n",
            "Epoch 442: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3395 - accuracy: 0.8745 - mae: 0.1414 - mse: 0.0682 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1397 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 443/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3316 - accuracy: 0.8809 - mae: 0.1410 - mse: 0.0667\n",
            "Epoch 443: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3360 - accuracy: 0.8745 - mae: 0.1420 - mse: 0.0681 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1392 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 444/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3368 - accuracy: 0.8818 - mae: 0.1418 - mse: 0.0675\n",
            "Epoch 444: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3388 - accuracy: 0.8745 - mae: 0.1431 - mse: 0.0689 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1374 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 445/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8750 - mae: 0.1374 - mse: 0.0677\n",
            "Epoch 445: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3380 - accuracy: 0.8742 - mae: 0.1396 - mse: 0.0682 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1374 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 446/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8730 - mae: 0.1415 - mse: 0.0696\n",
            "Epoch 446: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3381 - accuracy: 0.8748 - mae: 0.1392 - mse: 0.0675 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 447/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3528 - accuracy: 0.8652 - mae: 0.1416 - mse: 0.0716\n",
            "Epoch 447: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3378 - accuracy: 0.8742 - mae: 0.1385 - mse: 0.0682 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 448/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3366 - accuracy: 0.8799 - mae: 0.1337 - mse: 0.0656\n",
            "Epoch 448: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3393 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0675 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1344 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 449/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3569 - accuracy: 0.8643 - mae: 0.1416 - mse: 0.0722\n",
            "Epoch 449: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3415 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0685 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 450/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3539 - accuracy: 0.8682 - mae: 0.1422 - mse: 0.0708\n",
            "Epoch 450: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3331 - accuracy: 0.8748 - mae: 0.1375 - mse: 0.0675 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 451/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3555 - accuracy: 0.8672 - mae: 0.1444 - mse: 0.0714\n",
            "Epoch 451: val_loss did not improve from 0.32398\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3427 - accuracy: 0.8745 - mae: 0.1386 - mse: 0.0684 - val_loss: 0.3254 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 452/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8691 - mae: 0.1394 - mse: 0.0687\n",
            "Epoch 452: val_loss improved from 0.32398 to 0.32351, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3328 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0672 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 453/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8701 - mae: 0.1394 - mse: 0.0713\n",
            "Epoch 453: val_loss improved from 0.32351 to 0.32346, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3429 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0689 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 454/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3578 - accuracy: 0.8711 - mae: 0.1411 - mse: 0.0709\n",
            "Epoch 454: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3435 - accuracy: 0.8742 - mae: 0.1382 - mse: 0.0687 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 455/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8691 - mae: 0.1414 - mse: 0.0711\n",
            "Epoch 455: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3395 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0686 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 456/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3548 - accuracy: 0.8711 - mae: 0.1435 - mse: 0.0708\n",
            "Epoch 456: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3402 - accuracy: 0.8748 - mae: 0.1396 - mse: 0.0683 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 457/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3261 - accuracy: 0.8818 - mae: 0.1341 - mse: 0.0651\n",
            "Epoch 457: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3465 - accuracy: 0.8745 - mae: 0.1388 - mse: 0.0687 - val_loss: 0.3301 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 458/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8652 - mae: 0.1404 - mse: 0.0709\n",
            "Epoch 458: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3375 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0681 - val_loss: 0.3313 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 459/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3441 - accuracy: 0.8643 - mae: 0.1405 - mse: 0.0713\n",
            "Epoch 459: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3403 - accuracy: 0.8745 - mae: 0.1382 - mse: 0.0684 - val_loss: 0.3319 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 460/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3543 - accuracy: 0.8701 - mae: 0.1428 - mse: 0.0705\n",
            "Epoch 460: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3381 - accuracy: 0.8745 - mae: 0.1393 - mse: 0.0677 - val_loss: 0.3311 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 461/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3936 - accuracy: 0.8555 - mae: 0.1510 - mse: 0.0795\n",
            "Epoch 461: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3462 - accuracy: 0.8745 - mae: 0.1405 - mse: 0.0694 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 462/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3356 - accuracy: 0.8799 - mae: 0.1366 - mse: 0.0660\n",
            "Epoch 462: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3439 - accuracy: 0.8745 - mae: 0.1381 - mse: 0.0687 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 463/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3532 - accuracy: 0.8584 - mae: 0.1414 - mse: 0.0730\n",
            "Epoch 463: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3397 - accuracy: 0.8748 - mae: 0.1358 - mse: 0.0683 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1330 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 464/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3678 - accuracy: 0.8623 - mae: 0.1422 - mse: 0.0752\n",
            "Epoch 464: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3409 - accuracy: 0.8748 - mae: 0.1359 - mse: 0.0689 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1340 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 465/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3300 - accuracy: 0.8730 - mae: 0.1354 - mse: 0.0674\n",
            "Epoch 465: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3425 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0685 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 466/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8799 - mae: 0.1357 - mse: 0.0669\n",
            "Epoch 466: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3424 - accuracy: 0.8745 - mae: 0.1380 - mse: 0.0685 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1362 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 467/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3776 - accuracy: 0.8555 - mae: 0.1458 - mse: 0.0762\n",
            "Epoch 467: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3430 - accuracy: 0.8745 - mae: 0.1406 - mse: 0.0686 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1392 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 468/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8682 - mae: 0.1443 - mse: 0.0702\n",
            "Epoch 468: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3412 - accuracy: 0.8745 - mae: 0.1420 - mse: 0.0687 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 469/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3626 - accuracy: 0.8594 - mae: 0.1474 - mse: 0.0743\n",
            "Epoch 469: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3377 - accuracy: 0.8745 - mae: 0.1408 - mse: 0.0682 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 470/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8613 - mae: 0.1440 - mse: 0.0736\n",
            "Epoch 470: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3397 - accuracy: 0.8748 - mae: 0.1385 - mse: 0.0684 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 471/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3364 - accuracy: 0.8828 - mae: 0.1358 - mse: 0.0658\n",
            "Epoch 471: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3415 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0680 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 472/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3509 - accuracy: 0.8643 - mae: 0.1438 - mse: 0.0724\n",
            "Epoch 472: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3354 - accuracy: 0.8745 - mae: 0.1375 - mse: 0.0681 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 473/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3417 - accuracy: 0.8760 - mae: 0.1364 - mse: 0.0685\n",
            "Epoch 473: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3402 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0684 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 474/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8857 - mae: 0.1372 - mse: 0.0652\n",
            "Epoch 474: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3327 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0673 - val_loss: 0.3295 - val_accuracy: 0.8744 - val_mae: 0.1393 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 475/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8721 - mae: 0.1396 - mse: 0.0686\n",
            "Epoch 475: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3408 - accuracy: 0.8745 - mae: 0.1417 - mse: 0.0681 - val_loss: 0.3301 - val_accuracy: 0.8744 - val_mae: 0.1406 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 476/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8682 - mae: 0.1454 - mse: 0.0705\n",
            "Epoch 476: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3380 - accuracy: 0.8745 - mae: 0.1436 - mse: 0.0684 - val_loss: 0.3304 - val_accuracy: 0.8744 - val_mae: 0.1409 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 477/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8867 - mae: 0.1399 - mse: 0.0646\n",
            "Epoch 477: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3398 - accuracy: 0.8745 - mae: 0.1430 - mse: 0.0689 - val_loss: 0.3295 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 478/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3726 - accuracy: 0.8623 - mae: 0.1515 - mse: 0.0753\n",
            "Epoch 478: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3387 - accuracy: 0.8745 - mae: 0.1412 - mse: 0.0681 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 479/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3156 - accuracy: 0.8926 - mae: 0.1322 - mse: 0.0617\n",
            "Epoch 479: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3401 - accuracy: 0.8748 - mae: 0.1384 - mse: 0.0684 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 480/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3489 - accuracy: 0.8682 - mae: 0.1370 - mse: 0.0705\n",
            "Epoch 480: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3366 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0681 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 481/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3487 - accuracy: 0.8730 - mae: 0.1381 - mse: 0.0689\n",
            "Epoch 481: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3421 - accuracy: 0.8745 - mae: 0.1373 - mse: 0.0687 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 482/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3565 - accuracy: 0.8633 - mae: 0.1418 - mse: 0.0728\n",
            "Epoch 482: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3371 - accuracy: 0.8745 - mae: 0.1394 - mse: 0.0680 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 483/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8828 - mae: 0.1407 - mse: 0.0649\n",
            "Epoch 483: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3382 - accuracy: 0.8745 - mae: 0.1419 - mse: 0.0683 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 484/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3350 - accuracy: 0.8760 - mae: 0.1408 - mse: 0.0677\n",
            "Epoch 484: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3374 - accuracy: 0.8745 - mae: 0.1424 - mse: 0.0683 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1383 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 485/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8721 - mae: 0.1417 - mse: 0.0677\n",
            "Epoch 485: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3395 - accuracy: 0.8748 - mae: 0.1411 - mse: 0.0682 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 486/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3285 - accuracy: 0.8809 - mae: 0.1404 - mse: 0.0661\n",
            "Epoch 486: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3395 - accuracy: 0.8742 - mae: 0.1405 - mse: 0.0687 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1370 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 487/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3000 - accuracy: 0.8906 - mae: 0.1297 - mse: 0.0601\n",
            "Epoch 487: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3317 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0672 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1370 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 488/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3385 - accuracy: 0.8750 - mae: 0.1380 - mse: 0.0682\n",
            "Epoch 488: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3366 - accuracy: 0.8745 - mae: 0.1386 - mse: 0.0681 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1362 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 489/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3492 - accuracy: 0.8730 - mae: 0.1380 - mse: 0.0698\n",
            "Epoch 489: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3403 - accuracy: 0.8748 - mae: 0.1391 - mse: 0.0686 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 490/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3377 - accuracy: 0.8799 - mae: 0.1348 - mse: 0.0671\n",
            "Epoch 490: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3394 - accuracy: 0.8748 - mae: 0.1362 - mse: 0.0679 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 491/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3473 - accuracy: 0.8740 - mae: 0.1401 - mse: 0.0698\n",
            "Epoch 491: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3415 - accuracy: 0.8745 - mae: 0.1376 - mse: 0.0688 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 492/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3347 - accuracy: 0.8799 - mae: 0.1377 - mse: 0.0668\n",
            "Epoch 492: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3412 - accuracy: 0.8748 - mae: 0.1375 - mse: 0.0686 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 493/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3487 - accuracy: 0.8613 - mae: 0.1405 - mse: 0.0725\n",
            "Epoch 493: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3335 - accuracy: 0.8742 - mae: 0.1368 - mse: 0.0675 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1332 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 494/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8701 - mae: 0.1392 - mse: 0.0693\n",
            "Epoch 494: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3336 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0675 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 495/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3554 - accuracy: 0.8672 - mae: 0.1417 - mse: 0.0722\n",
            "Epoch 495: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3410 - accuracy: 0.8742 - mae: 0.1382 - mse: 0.0685 - val_loss: 0.3254 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 496/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3288 - accuracy: 0.8799 - mae: 0.1353 - mse: 0.0662\n",
            "Epoch 496: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3375 - accuracy: 0.8745 - mae: 0.1385 - mse: 0.0681 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 497/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8770 - mae: 0.1377 - mse: 0.0669\n",
            "Epoch 497: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3346 - accuracy: 0.8742 - mae: 0.1382 - mse: 0.0676 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 498/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3490 - accuracy: 0.8662 - mae: 0.1436 - mse: 0.0714\n",
            "Epoch 498: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3378 - accuracy: 0.8745 - mae: 0.1403 - mse: 0.0682 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 499/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8779 - mae: 0.1397 - mse: 0.0674\n",
            "Epoch 499: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3380 - accuracy: 0.8745 - mae: 0.1413 - mse: 0.0685 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 500/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3396 - accuracy: 0.8742 - mae: 0.1416 - mse: 0.0687\n",
            "Epoch 500: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3396 - accuracy: 0.8742 - mae: 0.1416 - mse: 0.0687 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 501/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3457 - accuracy: 0.8701 - mae: 0.1451 - mse: 0.0702\n",
            "Epoch 501: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3312 - accuracy: 0.8745 - mae: 0.1408 - mse: 0.0674 - val_loss: 0.3246 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 502/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3510 - accuracy: 0.8652 - mae: 0.1425 - mse: 0.0724\n",
            "Epoch 502: val_loss did not improve from 0.32346\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3420 - accuracy: 0.8748 - mae: 0.1405 - mse: 0.0688 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 503/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3350 - accuracy: 0.8721 - mae: 0.1387 - mse: 0.0681\n",
            "Epoch 503: val_loss improved from 0.32346 to 0.32344, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3354 - accuracy: 0.8742 - mae: 0.1375 - mse: 0.0672 - val_loss: 0.3234 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 504/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3548 - accuracy: 0.8730 - mae: 0.1437 - mse: 0.0703\n",
            "Epoch 504: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3409 - accuracy: 0.8745 - mae: 0.1401 - mse: 0.0683 - val_loss: 0.3237 - val_accuracy: 0.8744 - val_mae: 0.1340 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 505/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3549 - accuracy: 0.8662 - mae: 0.1449 - mse: 0.0721\n",
            "Epoch 505: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3363 - accuracy: 0.8745 - mae: 0.1393 - mse: 0.0682 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 506/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3509 - accuracy: 0.8623 - mae: 0.1418 - mse: 0.0722\n",
            "Epoch 506: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.3324 - accuracy: 0.8748 - mae: 0.1376 - mse: 0.0673 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 507/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3597 - accuracy: 0.8711 - mae: 0.1407 - mse: 0.0707\n",
            "Epoch 507: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3404 - accuracy: 0.8748 - mae: 0.1387 - mse: 0.0680 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 508/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8799 - mae: 0.1362 - mse: 0.0674\n",
            "Epoch 508: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3384 - accuracy: 0.8745 - mae: 0.1382 - mse: 0.0681 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 509/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3269 - accuracy: 0.8848 - mae: 0.1341 - mse: 0.0645\n",
            "Epoch 509: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.3390 - accuracy: 0.8742 - mae: 0.1383 - mse: 0.0682 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 510/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8906 - mae: 0.1288 - mse: 0.0607\n",
            "Epoch 510: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3373 - accuracy: 0.8742 - mae: 0.1370 - mse: 0.0680 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 511/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8799 - mae: 0.1342 - mse: 0.0656\n",
            "Epoch 511: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3358 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0677 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 512/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3207 - accuracy: 0.8838 - mae: 0.1339 - mse: 0.0640\n",
            "Epoch 512: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3368 - accuracy: 0.8742 - mae: 0.1368 - mse: 0.0678 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 513/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3414 - accuracy: 0.8740 - mae: 0.1393 - mse: 0.0688\n",
            "Epoch 513: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3415 - accuracy: 0.8742 - mae: 0.1389 - mse: 0.0688 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 514/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3242 - accuracy: 0.8789 - mae: 0.1377 - mse: 0.0653\n",
            "Epoch 514: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3347 - accuracy: 0.8739 - mae: 0.1389 - mse: 0.0677 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1362 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 515/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3475 - accuracy: 0.8750 - mae: 0.1409 - mse: 0.0698\n",
            "Epoch 515: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3383 - accuracy: 0.8748 - mae: 0.1401 - mse: 0.0684 - val_loss: 0.3306 - val_accuracy: 0.8744 - val_mae: 0.1381 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 516/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3390 - accuracy: 0.8789 - mae: 0.1393 - mse: 0.0674\n",
            "Epoch 516: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3366 - accuracy: 0.8748 - mae: 0.1411 - mse: 0.0679 - val_loss: 0.3310 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 517/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3240 - accuracy: 0.8857 - mae: 0.1392 - mse: 0.0643\n",
            "Epoch 517: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3355 - accuracy: 0.8748 - mae: 0.1421 - mse: 0.0680 - val_loss: 0.3300 - val_accuracy: 0.8744 - val_mae: 0.1370 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 518/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3170 - accuracy: 0.8867 - mae: 0.1360 - mse: 0.0625\n",
            "Epoch 518: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3396 - accuracy: 0.8742 - mae: 0.1401 - mse: 0.0684 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1346 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 519/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3498 - accuracy: 0.8682 - mae: 0.1438 - mse: 0.0707\n",
            "Epoch 519: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3350 - accuracy: 0.8745 - mae: 0.1387 - mse: 0.0678 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 520/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3260 - accuracy: 0.8799 - mae: 0.1339 - mse: 0.0656\n",
            "Epoch 520: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3349 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0678 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 521/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8672 - mae: 0.1424 - mse: 0.0706\n",
            "Epoch 521: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3376 - accuracy: 0.8745 - mae: 0.1394 - mse: 0.0682 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1355 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 522/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3251 - accuracy: 0.8799 - mae: 0.1361 - mse: 0.0657\n",
            "Epoch 522: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3427 - accuracy: 0.8745 - mae: 0.1390 - mse: 0.0688 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 523/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3241 - accuracy: 0.8848 - mae: 0.1332 - mse: 0.0639\n",
            "Epoch 523: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3357 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0679 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 524/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3431 - accuracy: 0.8711 - mae: 0.1391 - mse: 0.0697\n",
            "Epoch 524: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3390 - accuracy: 0.8752 - mae: 0.1367 - mse: 0.0684 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 525/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8682 - mae: 0.1389 - mse: 0.0715\n",
            "Epoch 525: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3389 - accuracy: 0.8742 - mae: 0.1355 - mse: 0.0684 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 526/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8584 - mae: 0.1413 - mse: 0.0745\n",
            "Epoch 526: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3422 - accuracy: 0.8748 - mae: 0.1348 - mse: 0.0686 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 527/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8711 - mae: 0.1364 - mse: 0.0692\n",
            "Epoch 527: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3360 - accuracy: 0.8742 - mae: 0.1356 - mse: 0.0680 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 528/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8809 - mae: 0.1323 - mse: 0.0647\n",
            "Epoch 528: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3380 - accuracy: 0.8748 - mae: 0.1359 - mse: 0.0683 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 529/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3153 - accuracy: 0.8848 - mae: 0.1302 - mse: 0.0624\n",
            "Epoch 529: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3359 - accuracy: 0.8745 - mae: 0.1359 - mse: 0.0677 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1340 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 530/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8945 - mae: 0.1305 - mse: 0.0612\n",
            "Epoch 530: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3414 - accuracy: 0.8745 - mae: 0.1394 - mse: 0.0688 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 531/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3515 - accuracy: 0.8643 - mae: 0.1453 - mse: 0.0718\n",
            "Epoch 531: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3397 - accuracy: 0.8745 - mae: 0.1400 - mse: 0.0680 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1381 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 532/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3498 - accuracy: 0.8662 - mae: 0.1440 - mse: 0.0715\n",
            "Epoch 532: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3393 - accuracy: 0.8745 - mae: 0.1430 - mse: 0.0685 - val_loss: 0.3290 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 533/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8760 - mae: 0.1398 - mse: 0.0671\n",
            "Epoch 533: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3392 - accuracy: 0.8745 - mae: 0.1422 - mse: 0.0680 - val_loss: 0.3286 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 534/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3432 - accuracy: 0.8701 - mae: 0.1420 - mse: 0.0695\n",
            "Epoch 534: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3344 - accuracy: 0.8745 - mae: 0.1395 - mse: 0.0677 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1340 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 535/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8799 - mae: 0.1355 - mse: 0.0671\n",
            "Epoch 535: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3375 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0681 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1305 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 536/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3357 - accuracy: 0.8809 - mae: 0.1318 - mse: 0.0656\n",
            "Epoch 536: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3372 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0679 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 537/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8789 - mae: 0.1312 - mse: 0.0654\n",
            "Epoch 537: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3413 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0684 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1309 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 538/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3162 - accuracy: 0.8828 - mae: 0.1310 - mse: 0.0638\n",
            "Epoch 538: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3346 - accuracy: 0.8748 - mae: 0.1344 - mse: 0.0677 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 539/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3470 - accuracy: 0.8613 - mae: 0.1384 - mse: 0.0722\n",
            "Epoch 539: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3348 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0682 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 540/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8857 - mae: 0.1306 - mse: 0.0633\n",
            "Epoch 540: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3392 - accuracy: 0.8752 - mae: 0.1379 - mse: 0.0684 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 541/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8652 - mae: 0.1437 - mse: 0.0730\n",
            "Epoch 541: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3369 - accuracy: 0.8745 - mae: 0.1385 - mse: 0.0680 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1363 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 542/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8613 - mae: 0.1477 - mse: 0.0750\n",
            "Epoch 542: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3381 - accuracy: 0.8748 - mae: 0.1400 - mse: 0.0685 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 543/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3668 - accuracy: 0.8574 - mae: 0.1443 - mse: 0.0748\n",
            "Epoch 543: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3411 - accuracy: 0.8742 - mae: 0.1393 - mse: 0.0684 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 544/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8760 - mae: 0.1360 - mse: 0.0678\n",
            "Epoch 544: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3388 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0684 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 545/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8701 - mae: 0.1397 - mse: 0.0702\n",
            "Epoch 545: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3390 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0679 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1355 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 546/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8730 - mae: 0.1392 - mse: 0.0675\n",
            "Epoch 546: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3364 - accuracy: 0.8742 - mae: 0.1398 - mse: 0.0680 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1385 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 547/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8682 - mae: 0.1467 - mse: 0.0717\n",
            "Epoch 547: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3417 - accuracy: 0.8745 - mae: 0.1414 - mse: 0.0685 - val_loss: 0.3308 - val_accuracy: 0.8744 - val_mae: 0.1390 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 548/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3403 - accuracy: 0.8721 - mae: 0.1427 - mse: 0.0688\n",
            "Epoch 548: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3365 - accuracy: 0.8745 - mae: 0.1411 - mse: 0.0679 - val_loss: 0.3314 - val_accuracy: 0.8744 - val_mae: 0.1384 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 549/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3452 - accuracy: 0.8691 - mae: 0.1431 - mse: 0.0705\n",
            "Epoch 549: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3334 - accuracy: 0.8745 - mae: 0.1393 - mse: 0.0680 - val_loss: 0.3305 - val_accuracy: 0.8744 - val_mae: 0.1362 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 550/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8691 - mae: 0.1418 - mse: 0.0702\n",
            "Epoch 550: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3383 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0677 - val_loss: 0.3291 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 551/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8691 - mae: 0.1357 - mse: 0.0691\n",
            "Epoch 551: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3451 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0685 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 552/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3105 - accuracy: 0.8867 - mae: 0.1294 - mse: 0.0618\n",
            "Epoch 552: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3380 - accuracy: 0.8748 - mae: 0.1361 - mse: 0.0681 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 553/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3395 - accuracy: 0.8750 - mae: 0.1348 - mse: 0.0676\n",
            "Epoch 553: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3364 - accuracy: 0.8748 - mae: 0.1357 - mse: 0.0679 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 554/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3294 - accuracy: 0.8711 - mae: 0.1386 - mse: 0.0683\n",
            "Epoch 554: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3353 - accuracy: 0.8748 - mae: 0.1367 - mse: 0.0681 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 555/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8633 - mae: 0.1431 - mse: 0.0709\n",
            "Epoch 555: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3382 - accuracy: 0.8742 - mae: 0.1397 - mse: 0.0680 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1379 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 556/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3413 - accuracy: 0.8789 - mae: 0.1421 - mse: 0.0674\n",
            "Epoch 556: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3389 - accuracy: 0.8745 - mae: 0.1422 - mse: 0.0681 - val_loss: 0.3302 - val_accuracy: 0.8744 - val_mae: 0.1395 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 557/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8760 - mae: 0.1419 - mse: 0.0686\n",
            "Epoch 557: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3365 - accuracy: 0.8752 - mae: 0.1419 - mse: 0.0682 - val_loss: 0.3300 - val_accuracy: 0.8744 - val_mae: 0.1384 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 558/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3199 - accuracy: 0.8877 - mae: 0.1389 - mse: 0.0635\n",
            "Epoch 558: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3388 - accuracy: 0.8742 - mae: 0.1423 - mse: 0.0686 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 559/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8740 - mae: 0.1397 - mse: 0.0695\n",
            "Epoch 559: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3335 - accuracy: 0.8748 - mae: 0.1376 - mse: 0.0678 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 560/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3602 - accuracy: 0.8545 - mae: 0.1448 - mse: 0.0756\n",
            "Epoch 560: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3387 - accuracy: 0.8733 - mae: 0.1362 - mse: 0.0681 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 561/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3299 - accuracy: 0.8770 - mae: 0.1328 - mse: 0.0670\n",
            "Epoch 561: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3345 - accuracy: 0.8745 - mae: 0.1357 - mse: 0.0678 - val_loss: 0.3286 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 562/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3210 - accuracy: 0.8867 - mae: 0.1326 - mse: 0.0630\n",
            "Epoch 562: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3353 - accuracy: 0.8736 - mae: 0.1373 - mse: 0.0677 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 563/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3564 - accuracy: 0.8701 - mae: 0.1431 - mse: 0.0710\n",
            "Epoch 563: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3382 - accuracy: 0.8742 - mae: 0.1392 - mse: 0.0680 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 564/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3138 - accuracy: 0.8887 - mae: 0.1300 - mse: 0.0619\n",
            "Epoch 564: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3403 - accuracy: 0.8748 - mae: 0.1373 - mse: 0.0681 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 565/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3371 - accuracy: 0.8740 - mae: 0.1393 - mse: 0.0690\n",
            "Epoch 565: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3313 - accuracy: 0.8745 - mae: 0.1365 - mse: 0.0677 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 566/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3449 - accuracy: 0.8730 - mae: 0.1414 - mse: 0.0698\n",
            "Epoch 566: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3334 - accuracy: 0.8748 - mae: 0.1389 - mse: 0.0676 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 567/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3216 - accuracy: 0.8799 - mae: 0.1349 - mse: 0.0650\n",
            "Epoch 567: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3342 - accuracy: 0.8748 - mae: 0.1399 - mse: 0.0676 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 568/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3129 - accuracy: 0.8896 - mae: 0.1315 - mse: 0.0618\n",
            "Epoch 568: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3357 - accuracy: 0.8748 - mae: 0.1388 - mse: 0.0677 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1332 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 569/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3446 - accuracy: 0.8760 - mae: 0.1379 - mse: 0.0687\n",
            "Epoch 569: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3338 - accuracy: 0.8742 - mae: 0.1364 - mse: 0.0676 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 570/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8818 - mae: 0.1328 - mse: 0.0655\n",
            "Epoch 570: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3364 - accuracy: 0.8748 - mae: 0.1346 - mse: 0.0676 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1310 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 571/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3298 - accuracy: 0.8750 - mae: 0.1335 - mse: 0.0670\n",
            "Epoch 571: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3362 - accuracy: 0.8742 - mae: 0.1347 - mse: 0.0678 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 572/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3405 - accuracy: 0.8711 - mae: 0.1388 - mse: 0.0690\n",
            "Epoch 572: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3424 - accuracy: 0.8745 - mae: 0.1376 - mse: 0.0686 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 573/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3544 - accuracy: 0.8643 - mae: 0.1444 - mse: 0.0729\n",
            "Epoch 573: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3369 - accuracy: 0.8745 - mae: 0.1385 - mse: 0.0677 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 574/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3434 - accuracy: 0.8711 - mae: 0.1445 - mse: 0.0697\n",
            "Epoch 574: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3366 - accuracy: 0.8745 - mae: 0.1402 - mse: 0.0679 - val_loss: 0.3302 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 575/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3546 - accuracy: 0.8652 - mae: 0.1457 - mse: 0.0713\n",
            "Epoch 575: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3359 - accuracy: 0.8742 - mae: 0.1401 - mse: 0.0678 - val_loss: 0.3304 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 576/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3580 - accuracy: 0.8682 - mae: 0.1461 - mse: 0.0722\n",
            "Epoch 576: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3385 - accuracy: 0.8739 - mae: 0.1403 - mse: 0.0685 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1358 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 577/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3358 - accuracy: 0.8779 - mae: 0.1412 - mse: 0.0681\n",
            "Epoch 577: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3407 - accuracy: 0.8739 - mae: 0.1401 - mse: 0.0688 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1344 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 578/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8701 - mae: 0.1388 - mse: 0.0679\n",
            "Epoch 578: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3327 - accuracy: 0.8748 - mae: 0.1371 - mse: 0.0672 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 579/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3542 - accuracy: 0.8623 - mae: 0.1416 - mse: 0.0726\n",
            "Epoch 579: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3357 - accuracy: 0.8745 - mae: 0.1346 - mse: 0.0676 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 580/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3678 - accuracy: 0.8584 - mae: 0.1423 - mse: 0.0749\n",
            "Epoch 580: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3391 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0682 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 581/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3849 - accuracy: 0.8525 - mae: 0.1471 - mse: 0.0780\n",
            "Epoch 581: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3373 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0678 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 582/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3600 - accuracy: 0.8633 - mae: 0.1433 - mse: 0.0736\n",
            "Epoch 582: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3394 - accuracy: 0.8742 - mae: 0.1387 - mse: 0.0687 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 583/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3513 - accuracy: 0.8730 - mae: 0.1408 - mse: 0.0697\n",
            "Epoch 583: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3408 - accuracy: 0.8739 - mae: 0.1374 - mse: 0.0682 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1307 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 584/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8809 - mae: 0.1331 - mse: 0.0661\n",
            "Epoch 584: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3354 - accuracy: 0.8748 - mae: 0.1349 - mse: 0.0677 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 585/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3433 - accuracy: 0.8662 - mae: 0.1364 - mse: 0.0698\n",
            "Epoch 585: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3352 - accuracy: 0.8745 - mae: 0.1334 - mse: 0.0673 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 586/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8867 - mae: 0.1244 - mse: 0.0610\n",
            "Epoch 586: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3363 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0678 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 587/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3319 - accuracy: 0.8779 - mae: 0.1388 - mse: 0.0668\n",
            "Epoch 587: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3367 - accuracy: 0.8745 - mae: 0.1388 - mse: 0.0679 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1356 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 588/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8770 - mae: 0.1394 - mse: 0.0670\n",
            "Epoch 588: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3380 - accuracy: 0.8742 - mae: 0.1408 - mse: 0.0682 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 589/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3331 - accuracy: 0.8721 - mae: 0.1383 - mse: 0.0681\n",
            "Epoch 589: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3377 - accuracy: 0.8742 - mae: 0.1401 - mse: 0.0684 - val_loss: 0.3254 - val_accuracy: 0.8744 - val_mae: 0.1363 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 590/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3515 - accuracy: 0.8672 - mae: 0.1436 - mse: 0.0713\n",
            "Epoch 590: val_loss did not improve from 0.32344\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3347 - accuracy: 0.8742 - mae: 0.1404 - mse: 0.0678 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 591/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3345 - accuracy: 0.8838 - mae: 0.1383 - mse: 0.0660\n",
            "Epoch 591: val_loss improved from 0.32344 to 0.32207, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.3387 - accuracy: 0.8745 - mae: 0.1404 - mse: 0.0683 - val_loss: 0.3221 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 592/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3385 - accuracy: 0.8672 - mae: 0.1399 - mse: 0.0699\n",
            "Epoch 592: val_loss improved from 0.32207 to 0.32143, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3420 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0684 - val_loss: 0.3214 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 593/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3278 - accuracy: 0.8691 - mae: 0.1360 - mse: 0.0678\n",
            "Epoch 593: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3345 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0675 - val_loss: 0.3219 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 594/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3294 - accuracy: 0.8711 - mae: 0.1388 - mse: 0.0680\n",
            "Epoch 594: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3292 - accuracy: 0.8745 - mae: 0.1379 - mse: 0.0674 - val_loss: 0.3225 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 595/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8662 - mae: 0.1407 - mse: 0.0696\n",
            "Epoch 595: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3332 - accuracy: 0.8736 - mae: 0.1391 - mse: 0.0675 - val_loss: 0.3223 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 596/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8740 - mae: 0.1397 - mse: 0.0674\n",
            "Epoch 596: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3334 - accuracy: 0.8739 - mae: 0.1400 - mse: 0.0681 - val_loss: 0.3236 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 597/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3496 - accuracy: 0.8730 - mae: 0.1412 - mse: 0.0693\n",
            "Epoch 597: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3359 - accuracy: 0.8742 - mae: 0.1405 - mse: 0.0676 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 598/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8770 - mae: 0.1402 - mse: 0.0658\n",
            "Epoch 598: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3392 - accuracy: 0.8742 - mae: 0.1421 - mse: 0.0687 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1390 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 599/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3226 - accuracy: 0.8848 - mae: 0.1380 - mse: 0.0650\n",
            "Epoch 599: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3389 - accuracy: 0.8745 - mae: 0.1429 - mse: 0.0687 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1397 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 600/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8662 - mae: 0.1459 - mse: 0.0715\n",
            "Epoch 600: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3390 - accuracy: 0.8748 - mae: 0.1434 - mse: 0.0683 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1380 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 601/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8711 - mae: 0.1437 - mse: 0.0705\n",
            "Epoch 601: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3414 - accuracy: 0.8748 - mae: 0.1416 - mse: 0.0685 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 602/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3269 - accuracy: 0.8818 - mae: 0.1364 - mse: 0.0654\n",
            "Epoch 602: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3391 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0681 - val_loss: 0.3243 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 603/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3531 - accuracy: 0.8682 - mae: 0.1385 - mse: 0.0715\n",
            "Epoch 603: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3383 - accuracy: 0.8745 - mae: 0.1339 - mse: 0.0680 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1289 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 604/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8799 - mae: 0.1278 - mse: 0.0637\n",
            "Epoch 604: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3341 - accuracy: 0.8745 - mae: 0.1330 - mse: 0.0677 - val_loss: 0.3227 - val_accuracy: 0.8744 - val_mae: 0.1294 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 605/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3417 - accuracy: 0.8652 - mae: 0.1385 - mse: 0.0706\n",
            "Epoch 605: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3337 - accuracy: 0.8742 - mae: 0.1341 - mse: 0.0675 - val_loss: 0.3225 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 606/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3508 - accuracy: 0.8691 - mae: 0.1383 - mse: 0.0702\n",
            "Epoch 606: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3359 - accuracy: 0.8745 - mae: 0.1372 - mse: 0.0677 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 607/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3332 - accuracy: 0.8721 - mae: 0.1424 - mse: 0.0682\n",
            "Epoch 607: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3317 - accuracy: 0.8752 - mae: 0.1411 - mse: 0.0677 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1396 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 608/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3253 - accuracy: 0.8789 - mae: 0.1409 - mse: 0.0656\n",
            "Epoch 608: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3380 - accuracy: 0.8742 - mae: 0.1437 - mse: 0.0682 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1377 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 609/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8750 - mae: 0.1433 - mse: 0.0679\n",
            "Epoch 609: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3367 - accuracy: 0.8745 - mae: 0.1408 - mse: 0.0678 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 610/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3479 - accuracy: 0.8662 - mae: 0.1408 - mse: 0.0711\n",
            "Epoch 610: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3356 - accuracy: 0.8745 - mae: 0.1372 - mse: 0.0676 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 611/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3269 - accuracy: 0.8760 - mae: 0.1354 - mse: 0.0672\n",
            "Epoch 611: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3389 - accuracy: 0.8742 - mae: 0.1375 - mse: 0.0684 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 612/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8818 - mae: 0.1354 - mse: 0.0652\n",
            "Epoch 612: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3390 - accuracy: 0.8736 - mae: 0.1362 - mse: 0.0682 - val_loss: 0.3237 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 613/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3419 - accuracy: 0.8643 - mae: 0.1363 - mse: 0.0704\n",
            "Epoch 613: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3358 - accuracy: 0.8742 - mae: 0.1333 - mse: 0.0679 - val_loss: 0.3229 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 614/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3483 - accuracy: 0.8652 - mae: 0.1393 - mse: 0.0719\n",
            "Epoch 614: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3378 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0681 - val_loss: 0.3219 - val_accuracy: 0.8744 - val_mae: 0.1302 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 615/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3429 - accuracy: 0.8760 - mae: 0.1373 - mse: 0.0692\n",
            "Epoch 615: val_loss did not improve from 0.32143\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3366 - accuracy: 0.8748 - mae: 0.1349 - mse: 0.0679 - val_loss: 0.3215 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 616/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3460 - accuracy: 0.8672 - mae: 0.1373 - mse: 0.0710\n",
            "Epoch 616: val_loss improved from 0.32143 to 0.32131, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.3373 - accuracy: 0.8739 - mae: 0.1366 - mse: 0.0682 - val_loss: 0.3213 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 617/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8789 - mae: 0.1361 - mse: 0.0676\n",
            "Epoch 617: val_loss improved from 0.32131 to 0.32066, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3372 - accuracy: 0.8742 - mae: 0.1369 - mse: 0.0680 - val_loss: 0.3207 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0662 - lr: 1.0000e-04\n",
            "Epoch 618/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8711 - mae: 0.1401 - mse: 0.0690\n",
            "Epoch 618: val_loss improved from 0.32066 to 0.32062, saving model to data/Eric_best_model_keras.h5\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3333 - accuracy: 0.8742 - mae: 0.1370 - mse: 0.0676 - val_loss: 0.3206 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0662 - lr: 1.0000e-04\n",
            "Epoch 619/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8799 - mae: 0.1341 - mse: 0.0658\n",
            "Epoch 619: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3384 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0683 - val_loss: 0.3215 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 620/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8742 - mae: 0.1371 - mse: 0.0681\n",
            "Epoch 620: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.3372 - accuracy: 0.8742 - mae: 0.1371 - mse: 0.0681 - val_loss: 0.3231 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 621/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8789 - mae: 0.1367 - mse: 0.0673\n",
            "Epoch 621: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3405 - accuracy: 0.8748 - mae: 0.1407 - mse: 0.0687 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1373 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 622/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3604 - accuracy: 0.8555 - mae: 0.1470 - mse: 0.0743\n",
            "Epoch 622: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3340 - accuracy: 0.8745 - mae: 0.1418 - mse: 0.0679 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1393 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 623/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8721 - mae: 0.1450 - mse: 0.0689\n",
            "Epoch 623: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3388 - accuracy: 0.8742 - mae: 0.1425 - mse: 0.0681 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1396 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 624/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3214 - accuracy: 0.8848 - mae: 0.1398 - mse: 0.0642\n",
            "Epoch 624: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3358 - accuracy: 0.8745 - mae: 0.1422 - mse: 0.0676 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1394 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 625/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3712 - accuracy: 0.8652 - mae: 0.1516 - mse: 0.0744\n",
            "Epoch 625: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3382 - accuracy: 0.8745 - mae: 0.1424 - mse: 0.0683 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1373 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 626/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8770 - mae: 0.1402 - mse: 0.0672\n",
            "Epoch 626: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3364 - accuracy: 0.8745 - mae: 0.1404 - mse: 0.0680 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 627/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8604 - mae: 0.1462 - mse: 0.0740\n",
            "Epoch 627: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3315 - accuracy: 0.8748 - mae: 0.1373 - mse: 0.0673 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 628/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3532 - accuracy: 0.8633 - mae: 0.1398 - mse: 0.0731\n",
            "Epoch 628: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3388 - accuracy: 0.8745 - mae: 0.1361 - mse: 0.0680 - val_loss: 0.3238 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 629/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8662 - mae: 0.1397 - mse: 0.0700\n",
            "Epoch 629: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3334 - accuracy: 0.8745 - mae: 0.1358 - mse: 0.0674 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 630/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3086 - accuracy: 0.8906 - mae: 0.1316 - mse: 0.0613\n",
            "Epoch 630: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3326 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0677 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 631/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8701 - mae: 0.1385 - mse: 0.0688\n",
            "Epoch 631: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3329 - accuracy: 0.8742 - mae: 0.1359 - mse: 0.0675 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 632/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3585 - accuracy: 0.8652 - mae: 0.1416 - mse: 0.0734\n",
            "Epoch 632: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3370 - accuracy: 0.8752 - mae: 0.1369 - mse: 0.0681 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 633/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8779 - mae: 0.1317 - mse: 0.0648\n",
            "Epoch 633: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3280 - accuracy: 0.8748 - mae: 0.1364 - mse: 0.0670 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 634/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3696 - accuracy: 0.8604 - mae: 0.1425 - mse: 0.0750\n",
            "Epoch 634: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3370 - accuracy: 0.8742 - mae: 0.1352 - mse: 0.0678 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 635/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3291 - accuracy: 0.8740 - mae: 0.1356 - mse: 0.0668\n",
            "Epoch 635: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3363 - accuracy: 0.8748 - mae: 0.1340 - mse: 0.0680 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1310 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 636/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3595 - accuracy: 0.8652 - mae: 0.1391 - mse: 0.0733\n",
            "Epoch 636: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3360 - accuracy: 0.8748 - mae: 0.1350 - mse: 0.0679 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1330 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 637/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3401 - accuracy: 0.8750 - mae: 0.1369 - mse: 0.0685\n",
            "Epoch 637: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3359 - accuracy: 0.8748 - mae: 0.1364 - mse: 0.0680 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 638/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3320 - accuracy: 0.8828 - mae: 0.1334 - mse: 0.0653\n",
            "Epoch 638: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3380 - accuracy: 0.8748 - mae: 0.1374 - mse: 0.0682 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 639/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8809 - mae: 0.1373 - mse: 0.0655\n",
            "Epoch 639: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3349 - accuracy: 0.8739 - mae: 0.1393 - mse: 0.0678 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1377 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 640/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3492 - accuracy: 0.8633 - mae: 0.1436 - mse: 0.0723\n",
            "Epoch 640: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3326 - accuracy: 0.8748 - mae: 0.1416 - mse: 0.0676 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1376 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 641/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.8745 - mae: 0.1402 - mse: 0.0676\n",
            "Epoch 641: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3346 - accuracy: 0.8745 - mae: 0.1402 - mse: 0.0676 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1356 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 642/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8721 - mae: 0.1391 - mse: 0.0682\n",
            "Epoch 642: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3340 - accuracy: 0.8742 - mae: 0.1384 - mse: 0.0676 - val_loss: 0.3238 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 643/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3232 - accuracy: 0.8828 - mae: 0.1323 - mse: 0.0641\n",
            "Epoch 643: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3396 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0682 - val_loss: 0.3233 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 644/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3153 - accuracy: 0.8926 - mae: 0.1303 - mse: 0.0614\n",
            "Epoch 644: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3384 - accuracy: 0.8745 - mae: 0.1361 - mse: 0.0683 - val_loss: 0.3233 - val_accuracy: 0.8744 - val_mae: 0.1313 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 645/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8730 - mae: 0.1368 - mse: 0.0685\n",
            "Epoch 645: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3358 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0680 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 646/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3234 - accuracy: 0.8848 - mae: 0.1336 - mse: 0.0646\n",
            "Epoch 646: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3361 - accuracy: 0.8745 - mae: 0.1363 - mse: 0.0679 - val_loss: 0.3233 - val_accuracy: 0.8744 - val_mae: 0.1310 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 647/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3236 - accuracy: 0.8779 - mae: 0.1346 - mse: 0.0656\n",
            "Epoch 647: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3311 - accuracy: 0.8748 - mae: 0.1347 - mse: 0.0672 - val_loss: 0.3237 - val_accuracy: 0.8744 - val_mae: 0.1320 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 648/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3736 - accuracy: 0.8613 - mae: 0.1441 - mse: 0.0747\n",
            "Epoch 648: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3407 - accuracy: 0.8748 - mae: 0.1366 - mse: 0.0679 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 649/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3582 - accuracy: 0.8613 - mae: 0.1477 - mse: 0.0742\n",
            "Epoch 649: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3352 - accuracy: 0.8745 - mae: 0.1392 - mse: 0.0679 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 650/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3432 - accuracy: 0.8701 - mae: 0.1426 - mse: 0.0698\n",
            "Epoch 650: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3380 - accuracy: 0.8752 - mae: 0.1412 - mse: 0.0683 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1375 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 651/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8711 - mae: 0.1427 - mse: 0.0677\n",
            "Epoch 651: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3279 - accuracy: 0.8739 - mae: 0.1394 - mse: 0.0669 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 652/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3378 - accuracy: 0.8711 - mae: 0.1392 - mse: 0.0693\n",
            "Epoch 652: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3339 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0680 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 653/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3382 - accuracy: 0.8740 - mae: 0.1351 - mse: 0.0675\n",
            "Epoch 653: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3329 - accuracy: 0.8752 - mae: 0.1366 - mse: 0.0674 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 654/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3330 - accuracy: 0.8740 - mae: 0.1384 - mse: 0.0680\n",
            "Epoch 654: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3405 - accuracy: 0.8745 - mae: 0.1376 - mse: 0.0689 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 655/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3310 - accuracy: 0.8770 - mae: 0.1358 - mse: 0.0670\n",
            "Epoch 655: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3304 - accuracy: 0.8745 - mae: 0.1349 - mse: 0.0670 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 656/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8779 - mae: 0.1370 - mse: 0.0664\n",
            "Epoch 656: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3329 - accuracy: 0.8745 - mae: 0.1365 - mse: 0.0675 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 657/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3149 - accuracy: 0.8857 - mae: 0.1338 - mse: 0.0632\n",
            "Epoch 657: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3379 - accuracy: 0.8742 - mae: 0.1382 - mse: 0.0682 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1340 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 658/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8789 - mae: 0.1357 - mse: 0.0660\n",
            "Epoch 658: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3335 - accuracy: 0.8742 - mae: 0.1363 - mse: 0.0672 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 659/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8750 - mae: 0.1374 - mse: 0.0681\n",
            "Epoch 659: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3373 - accuracy: 0.8745 - mae: 0.1367 - mse: 0.0678 - val_loss: 0.3243 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 660/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3488 - accuracy: 0.8701 - mae: 0.1374 - mse: 0.0694\n",
            "Epoch 660: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3390 - accuracy: 0.8748 - mae: 0.1381 - mse: 0.0681 - val_loss: 0.3241 - val_accuracy: 0.8744 - val_mae: 0.1344 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 661/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3659 - accuracy: 0.8623 - mae: 0.1436 - mse: 0.0737\n",
            "Epoch 661: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3401 - accuracy: 0.8745 - mae: 0.1397 - mse: 0.0684 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 662/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3211 - accuracy: 0.8916 - mae: 0.1371 - mse: 0.0627\n",
            "Epoch 662: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3356 - accuracy: 0.8742 - mae: 0.1414 - mse: 0.0680 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 663/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3329 - accuracy: 0.8760 - mae: 0.1401 - mse: 0.0669\n",
            "Epoch 663: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3336 - accuracy: 0.8748 - mae: 0.1405 - mse: 0.0674 - val_loss: 0.3245 - val_accuracy: 0.8744 - val_mae: 0.1361 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 664/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3141 - accuracy: 0.8936 - mae: 0.1311 - mse: 0.0608\n",
            "Epoch 664: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3385 - accuracy: 0.8742 - mae: 0.1402 - mse: 0.0682 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 665/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8740 - mae: 0.1385 - mse: 0.0670\n",
            "Epoch 665: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3308 - accuracy: 0.8748 - mae: 0.1387 - mse: 0.0669 - val_loss: 0.3237 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 666/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3155 - accuracy: 0.8789 - mae: 0.1359 - mse: 0.0641\n",
            "Epoch 666: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3342 - accuracy: 0.8739 - mae: 0.1385 - mse: 0.0676 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 667/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8662 - mae: 0.1394 - mse: 0.0710\n",
            "Epoch 667: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3306 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0672 - val_loss: 0.3232 - val_accuracy: 0.8744 - val_mae: 0.1313 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 668/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8584 - mae: 0.1413 - mse: 0.0729\n",
            "Epoch 668: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3351 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0680 - val_loss: 0.3226 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 669/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8730 - mae: 0.1347 - mse: 0.0677\n",
            "Epoch 669: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3355 - accuracy: 0.8745 - mae: 0.1355 - mse: 0.0679 - val_loss: 0.3223 - val_accuracy: 0.8744 - val_mae: 0.1290 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 670/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3219 - accuracy: 0.8760 - mae: 0.1296 - mse: 0.0656\n",
            "Epoch 670: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3310 - accuracy: 0.8745 - mae: 0.1331 - mse: 0.0673 - val_loss: 0.3229 - val_accuracy: 0.8744 - val_mae: 0.1288 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 671/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3269 - accuracy: 0.8828 - mae: 0.1284 - mse: 0.0640\n",
            "Epoch 671: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3370 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0683 - val_loss: 0.3233 - val_accuracy: 0.8744 - val_mae: 0.1296 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 672/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3427 - accuracy: 0.8721 - mae: 0.1342 - mse: 0.0687\n",
            "Epoch 672: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3375 - accuracy: 0.8745 - mae: 0.1343 - mse: 0.0678 - val_loss: 0.3235 - val_accuracy: 0.8744 - val_mae: 0.1320 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 673/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8818 - mae: 0.1353 - mse: 0.0645\n",
            "Epoch 673: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3317 - accuracy: 0.8742 - mae: 0.1373 - mse: 0.0673 - val_loss: 0.3241 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 674/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8799 - mae: 0.1338 - mse: 0.0649\n",
            "Epoch 674: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3358 - accuracy: 0.8745 - mae: 0.1398 - mse: 0.0681 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 675/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3417 - accuracy: 0.8633 - mae: 0.1416 - mse: 0.0695\n",
            "Epoch 675: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3306 - accuracy: 0.8739 - mae: 0.1396 - mse: 0.0673 - val_loss: 0.3243 - val_accuracy: 0.8744 - val_mae: 0.1356 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 676/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3454 - accuracy: 0.8672 - mae: 0.1435 - mse: 0.0713\n",
            "Epoch 676: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3363 - accuracy: 0.8745 - mae: 0.1408 - mse: 0.0682 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 677/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3266 - accuracy: 0.8789 - mae: 0.1390 - mse: 0.0661\n",
            "Epoch 677: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3279 - accuracy: 0.8748 - mae: 0.1387 - mse: 0.0669 - val_loss: 0.3242 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 678/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3256 - accuracy: 0.8711 - mae: 0.1387 - mse: 0.0675\n",
            "Epoch 678: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3342 - accuracy: 0.8742 - mae: 0.1384 - mse: 0.0680 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 679/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8662 - mae: 0.1416 - mse: 0.0726\n",
            "Epoch 679: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3379 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0679 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 680/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3156 - accuracy: 0.8848 - mae: 0.1329 - mse: 0.0633\n",
            "Epoch 680: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3362 - accuracy: 0.8742 - mae: 0.1395 - mse: 0.0685 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 681/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3571 - accuracy: 0.8584 - mae: 0.1459 - mse: 0.0738\n",
            "Epoch 681: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3309 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0673 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1317 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 682/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8652 - mae: 0.1378 - mse: 0.0705\n",
            "Epoch 682: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3346 - accuracy: 0.8745 - mae: 0.1355 - mse: 0.0677 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1302 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 683/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8721 - mae: 0.1381 - mse: 0.0701\n",
            "Epoch 683: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3355 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0677 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 684/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8701 - mae: 0.1390 - mse: 0.0710\n",
            "Epoch 684: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3403 - accuracy: 0.8752 - mae: 0.1357 - mse: 0.0683 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 685/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3013 - accuracy: 0.8916 - mae: 0.1295 - mse: 0.0600\n",
            "Epoch 685: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3270 - accuracy: 0.8748 - mae: 0.1355 - mse: 0.0663 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 686/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8721 - mae: 0.1402 - mse: 0.0699\n",
            "Epoch 686: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3349 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0679 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 687/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8623 - mae: 0.1446 - mse: 0.0731\n",
            "Epoch 687: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3323 - accuracy: 0.8745 - mae: 0.1398 - mse: 0.0676 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 688/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3527 - accuracy: 0.8691 - mae: 0.1416 - mse: 0.0705\n",
            "Epoch 688: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3322 - accuracy: 0.8748 - mae: 0.1377 - mse: 0.0671 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1332 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 689/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3077 - accuracy: 0.8926 - mae: 0.1286 - mse: 0.0604\n",
            "Epoch 689: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3331 - accuracy: 0.8745 - mae: 0.1357 - mse: 0.0674 - val_loss: 0.3298 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 690/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3374 - accuracy: 0.8770 - mae: 0.1330 - mse: 0.0665\n",
            "Epoch 690: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3365 - accuracy: 0.8745 - mae: 0.1342 - mse: 0.0674 - val_loss: 0.3299 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 691/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8730 - mae: 0.1356 - mse: 0.0687\n",
            "Epoch 691: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3402 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0685 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1317 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 692/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3259 - accuracy: 0.8818 - mae: 0.1362 - mse: 0.0655\n",
            "Epoch 692: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3377 - accuracy: 0.8748 - mae: 0.1357 - mse: 0.0683 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 693/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8691 - mae: 0.1356 - mse: 0.0670\n",
            "Epoch 693: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3273 - accuracy: 0.8742 - mae: 0.1358 - mse: 0.0669 - val_loss: 0.3243 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 694/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3502 - accuracy: 0.8701 - mae: 0.1393 - mse: 0.0707\n",
            "Epoch 694: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3347 - accuracy: 0.8748 - mae: 0.1369 - mse: 0.0677 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1305 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 695/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8662 - mae: 0.1371 - mse: 0.0702\n",
            "Epoch 695: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3341 - accuracy: 0.8739 - mae: 0.1359 - mse: 0.0677 - val_loss: 0.3246 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 696/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8789 - mae: 0.1312 - mse: 0.0655\n",
            "Epoch 696: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3381 - accuracy: 0.8748 - mae: 0.1358 - mse: 0.0680 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 697/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8740 - mae: 0.1347 - mse: 0.0661\n",
            "Epoch 697: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3318 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0675 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 698/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3405 - accuracy: 0.8623 - mae: 0.1440 - mse: 0.0710\n",
            "Epoch 698: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3323 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0674 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 699/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8740 - mae: 0.1385 - mse: 0.0703\n",
            "Epoch 699: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3374 - accuracy: 0.8745 - mae: 0.1353 - mse: 0.0684 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 700/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8691 - mae: 0.1397 - mse: 0.0698\n",
            "Epoch 700: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3364 - accuracy: 0.8742 - mae: 0.1367 - mse: 0.0673 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 701/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8770 - mae: 0.1377 - mse: 0.0668\n",
            "Epoch 701: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3310 - accuracy: 0.8748 - mae: 0.1374 - mse: 0.0672 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 702/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3403 - accuracy: 0.8682 - mae: 0.1388 - mse: 0.0698\n",
            "Epoch 702: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3355 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0675 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 703/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3318 - accuracy: 0.8750 - mae: 0.1372 - mse: 0.0675\n",
            "Epoch 703: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3331 - accuracy: 0.8733 - mae: 0.1393 - mse: 0.0678 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1355 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 704/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8740 - mae: 0.1404 - mse: 0.0690\n",
            "Epoch 704: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3363 - accuracy: 0.8745 - mae: 0.1403 - mse: 0.0679 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1363 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 705/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3128 - accuracy: 0.8857 - mae: 0.1344 - mse: 0.0623\n",
            "Epoch 705: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3309 - accuracy: 0.8748 - mae: 0.1403 - mse: 0.0674 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 706/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8906 - mae: 0.1309 - mse: 0.0615\n",
            "Epoch 706: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3316 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0675 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 707/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3170 - accuracy: 0.8857 - mae: 0.1341 - mse: 0.0629\n",
            "Epoch 707: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3320 - accuracy: 0.8748 - mae: 0.1369 - mse: 0.0671 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 708/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3475 - accuracy: 0.8643 - mae: 0.1435 - mse: 0.0718\n",
            "Epoch 708: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3284 - accuracy: 0.8742 - mae: 0.1369 - mse: 0.0674 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 709/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8770 - mae: 0.1362 - mse: 0.0672\n",
            "Epoch 709: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3341 - accuracy: 0.8742 - mae: 0.1370 - mse: 0.0677 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 710/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8701 - mae: 0.1394 - mse: 0.0689\n",
            "Epoch 710: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3340 - accuracy: 0.8739 - mae: 0.1384 - mse: 0.0676 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1346 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 711/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3630 - accuracy: 0.8613 - mae: 0.1448 - mse: 0.0740\n",
            "Epoch 711: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3347 - accuracy: 0.8748 - mae: 0.1389 - mse: 0.0680 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 712/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3229 - accuracy: 0.8770 - mae: 0.1387 - mse: 0.0661\n",
            "Epoch 712: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3349 - accuracy: 0.8742 - mae: 0.1395 - mse: 0.0680 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 713/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3306 - accuracy: 0.8770 - mae: 0.1371 - mse: 0.0663\n",
            "Epoch 713: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3342 - accuracy: 0.8745 - mae: 0.1389 - mse: 0.0677 - val_loss: 0.3242 - val_accuracy: 0.8744 - val_mae: 0.1331 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 714/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3539 - accuracy: 0.8672 - mae: 0.1415 - mse: 0.0713\n",
            "Epoch 714: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3352 - accuracy: 0.8745 - mae: 0.1394 - mse: 0.0680 - val_loss: 0.3237 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 715/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3377 - accuracy: 0.8691 - mae: 0.1405 - mse: 0.0688\n",
            "Epoch 715: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3375 - accuracy: 0.8742 - mae: 0.1399 - mse: 0.0678 - val_loss: 0.3234 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 716/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3272 - accuracy: 0.8789 - mae: 0.1364 - mse: 0.0656\n",
            "Epoch 716: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3311 - accuracy: 0.8752 - mae: 0.1387 - mse: 0.0671 - val_loss: 0.3230 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 717/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8750 - mae: 0.1427 - mse: 0.0692\n",
            "Epoch 717: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3356 - accuracy: 0.8736 - mae: 0.1394 - mse: 0.0679 - val_loss: 0.3222 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 718/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3306 - accuracy: 0.8760 - mae: 0.1411 - mse: 0.0671\n",
            "Epoch 718: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3333 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0672 - val_loss: 0.3220 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 719/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3146 - accuracy: 0.8926 - mae: 0.1303 - mse: 0.0612\n",
            "Epoch 719: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3362 - accuracy: 0.8752 - mae: 0.1374 - mse: 0.0676 - val_loss: 0.3230 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 720/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3086 - accuracy: 0.8818 - mae: 0.1359 - mse: 0.0630\n",
            "Epoch 720: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3231 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0663 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 721/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8770 - mae: 0.1370 - mse: 0.0669\n",
            "Epoch 721: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3341 - accuracy: 0.8745 - mae: 0.1376 - mse: 0.0676 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 722/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3243 - accuracy: 0.8779 - mae: 0.1356 - mse: 0.0657\n",
            "Epoch 722: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3321 - accuracy: 0.8748 - mae: 0.1391 - mse: 0.0673 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 723/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8770 - mae: 0.1422 - mse: 0.0670\n",
            "Epoch 723: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3326 - accuracy: 0.8745 - mae: 0.1407 - mse: 0.0671 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 724/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8818 - mae: 0.1398 - mse: 0.0655\n",
            "Epoch 724: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3303 - accuracy: 0.8748 - mae: 0.1416 - mse: 0.0671 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 725/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3660 - accuracy: 0.8525 - mae: 0.1504 - mse: 0.0760\n",
            "Epoch 725: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3342 - accuracy: 0.8742 - mae: 0.1385 - mse: 0.0674 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 726/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3298 - accuracy: 0.8789 - mae: 0.1339 - mse: 0.0664\n",
            "Epoch 726: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3343 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0677 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 727/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8730 - mae: 0.1337 - mse: 0.0669\n",
            "Epoch 727: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3311 - accuracy: 0.8745 - mae: 0.1339 - mse: 0.0669 - val_loss: 0.3245 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 728/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3692 - accuracy: 0.8672 - mae: 0.1402 - mse: 0.0732\n",
            "Epoch 728: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3413 - accuracy: 0.8742 - mae: 0.1357 - mse: 0.0683 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1286 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 729/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3229 - accuracy: 0.8838 - mae: 0.1287 - mse: 0.0644\n",
            "Epoch 729: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3311 - accuracy: 0.8748 - mae: 0.1329 - mse: 0.0671 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1272 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 730/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8750 - mae: 0.1327 - mse: 0.0679\n",
            "Epoch 730: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3362 - accuracy: 0.8748 - mae: 0.1326 - mse: 0.0679 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1277 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 731/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8789 - mae: 0.1329 - mse: 0.0677\n",
            "Epoch 731: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3350 - accuracy: 0.8745 - mae: 0.1342 - mse: 0.0680 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1309 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 732/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3427 - accuracy: 0.8682 - mae: 0.1388 - mse: 0.0702\n",
            "Epoch 732: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3346 - accuracy: 0.8748 - mae: 0.1363 - mse: 0.0680 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 733/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8740 - mae: 0.1397 - mse: 0.0678\n",
            "Epoch 733: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3330 - accuracy: 0.8752 - mae: 0.1389 - mse: 0.0673 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 734/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8740 - mae: 0.1402 - mse: 0.0683\n",
            "Epoch 734: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3348 - accuracy: 0.8745 - mae: 0.1400 - mse: 0.0677 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1356 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 735/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3081 - accuracy: 0.8945 - mae: 0.1311 - mse: 0.0604\n",
            "Epoch 735: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3283 - accuracy: 0.8752 - mae: 0.1394 - mse: 0.0670 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 736/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3435 - accuracy: 0.8711 - mae: 0.1422 - mse: 0.0696\n",
            "Epoch 736: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3347 - accuracy: 0.8736 - mae: 0.1405 - mse: 0.0678 - val_loss: 0.3238 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 737/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3288 - accuracy: 0.8779 - mae: 0.1385 - mse: 0.0670\n",
            "Epoch 737: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3357 - accuracy: 0.8752 - mae: 0.1383 - mse: 0.0679 - val_loss: 0.3233 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 738/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3416 - accuracy: 0.8789 - mae: 0.1363 - mse: 0.0672\n",
            "Epoch 738: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3329 - accuracy: 0.8745 - mae: 0.1361 - mse: 0.0672 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 739/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3390 - accuracy: 0.8730 - mae: 0.1363 - mse: 0.0688\n",
            "Epoch 739: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3351 - accuracy: 0.8742 - mae: 0.1358 - mse: 0.0675 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1331 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 740/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3091 - accuracy: 0.8838 - mae: 0.1321 - mse: 0.0629\n",
            "Epoch 740: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3323 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0674 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1331 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 741/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8770 - mae: 0.1404 - mse: 0.0682\n",
            "Epoch 741: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3321 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0678 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 742/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8672 - mae: 0.1392 - mse: 0.0704\n",
            "Epoch 742: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3337 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0678 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 743/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3330 - accuracy: 0.8857 - mae: 0.1339 - mse: 0.0646\n",
            "Epoch 743: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3417 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0682 - val_loss: 0.3251 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 744/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3278 - accuracy: 0.8730 - mae: 0.1368 - mse: 0.0671\n",
            "Epoch 744: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3336 - accuracy: 0.8739 - mae: 0.1395 - mse: 0.0678 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1354 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 745/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8857 - mae: 0.1325 - mse: 0.0608\n",
            "Epoch 745: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3282 - accuracy: 0.8742 - mae: 0.1389 - mse: 0.0671 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 746/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8682 - mae: 0.1439 - mse: 0.0699\n",
            "Epoch 746: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3319 - accuracy: 0.8742 - mae: 0.1413 - mse: 0.0677 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1368 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 747/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8745 - mae: 0.1413 - mse: 0.0678\n",
            "Epoch 747: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3339 - accuracy: 0.8745 - mae: 0.1413 - mse: 0.0678 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 748/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3462 - accuracy: 0.8623 - mae: 0.1438 - mse: 0.0721\n",
            "Epoch 748: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.3323 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0675 - val_loss: 0.3247 - val_accuracy: 0.8744 - val_mae: 0.1306 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 749/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8711 - mae: 0.1343 - mse: 0.0672\n",
            "Epoch 749: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3283 - accuracy: 0.8745 - mae: 0.1339 - mse: 0.0669 - val_loss: 0.3241 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 750/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3303 - accuracy: 0.8682 - mae: 0.1344 - mse: 0.0687\n",
            "Epoch 750: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3259 - accuracy: 0.8748 - mae: 0.1340 - mse: 0.0665 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 751/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3261 - accuracy: 0.8779 - mae: 0.1371 - mse: 0.0661\n",
            "Epoch 751: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3351 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0677 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 752/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3242 - accuracy: 0.8916 - mae: 0.1297 - mse: 0.0620\n",
            "Epoch 752: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3329 - accuracy: 0.8742 - mae: 0.1369 - mse: 0.0672 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 753/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3475 - accuracy: 0.8662 - mae: 0.1411 - mse: 0.0710\n",
            "Epoch 753: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3322 - accuracy: 0.8745 - mae: 0.1380 - mse: 0.0674 - val_loss: 0.3251 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 754/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8740 - mae: 0.1372 - mse: 0.0672\n",
            "Epoch 754: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3276 - accuracy: 0.8748 - mae: 0.1369 - mse: 0.0671 - val_loss: 0.3243 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 755/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3497 - accuracy: 0.8701 - mae: 0.1415 - mse: 0.0705\n",
            "Epoch 755: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3328 - accuracy: 0.8745 - mae: 0.1359 - mse: 0.0673 - val_loss: 0.3237 - val_accuracy: 0.8744 - val_mae: 0.1307 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 756/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3620 - accuracy: 0.8604 - mae: 0.1431 - mse: 0.0739\n",
            "Epoch 756: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3283 - accuracy: 0.8739 - mae: 0.1348 - mse: 0.0670 - val_loss: 0.3236 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 757/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8887 - mae: 0.1264 - mse: 0.0619\n",
            "Epoch 757: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3378 - accuracy: 0.8742 - mae: 0.1349 - mse: 0.0678 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1296 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 758/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3370 - accuracy: 0.8730 - mae: 0.1398 - mse: 0.0685\n",
            "Epoch 758: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3296 - accuracy: 0.8752 - mae: 0.1342 - mse: 0.0669 - val_loss: 0.3251 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 759/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8721 - mae: 0.1364 - mse: 0.0676\n",
            "Epoch 759: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3255 - accuracy: 0.8748 - mae: 0.1355 - mse: 0.0666 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 760/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3414 - accuracy: 0.8672 - mae: 0.1389 - mse: 0.0699\n",
            "Epoch 760: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3299 - accuracy: 0.8748 - mae: 0.1367 - mse: 0.0670 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 761/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3411 - accuracy: 0.8672 - mae: 0.1421 - mse: 0.0694\n",
            "Epoch 761: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3316 - accuracy: 0.8745 - mae: 0.1377 - mse: 0.0672 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 762/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3219 - accuracy: 0.8818 - mae: 0.1324 - mse: 0.0637\n",
            "Epoch 762: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3352 - accuracy: 0.8752 - mae: 0.1366 - mse: 0.0677 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 763/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3458 - accuracy: 0.8613 - mae: 0.1418 - mse: 0.0727\n",
            "Epoch 763: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3323 - accuracy: 0.8745 - mae: 0.1347 - mse: 0.0671 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1317 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 764/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3357 - accuracy: 0.8740 - mae: 0.1325 - mse: 0.0674\n",
            "Epoch 764: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3369 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0681 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 765/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8789 - mae: 0.1331 - mse: 0.0651\n",
            "Epoch 765: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3309 - accuracy: 0.8730 - mae: 0.1360 - mse: 0.0673 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 766/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8857 - mae: 0.1310 - mse: 0.0636\n",
            "Epoch 766: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3388 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0685 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 767/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3014 - accuracy: 0.8926 - mae: 0.1294 - mse: 0.0597\n",
            "Epoch 767: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3318 - accuracy: 0.8739 - mae: 0.1395 - mse: 0.0676 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 768/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3278 - accuracy: 0.8721 - mae: 0.1391 - mse: 0.0671\n",
            "Epoch 768: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3302 - accuracy: 0.8742 - mae: 0.1383 - mse: 0.0673 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 769/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8799 - mae: 0.1355 - mse: 0.0665\n",
            "Epoch 769: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3324 - accuracy: 0.8748 - mae: 0.1369 - mse: 0.0671 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 770/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3239 - accuracy: 0.8818 - mae: 0.1346 - mse: 0.0652\n",
            "Epoch 770: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3323 - accuracy: 0.8742 - mae: 0.1373 - mse: 0.0678 - val_loss: 0.3245 - val_accuracy: 0.8744 - val_mae: 0.1313 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 771/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3302 - accuracy: 0.8809 - mae: 0.1322 - mse: 0.0656\n",
            "Epoch 771: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3427 - accuracy: 0.8742 - mae: 0.1377 - mse: 0.0686 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1330 - val_mse: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 772/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3135 - accuracy: 0.8848 - mae: 0.1340 - mse: 0.0627\n",
            "Epoch 772: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3346 - accuracy: 0.8745 - mae: 0.1396 - mse: 0.0678 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1373 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 773/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8789 - mae: 0.1373 - mse: 0.0650\n",
            "Epoch 773: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3315 - accuracy: 0.8752 - mae: 0.1418 - mse: 0.0674 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1406 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 774/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3668 - accuracy: 0.8594 - mae: 0.1540 - mse: 0.0754\n",
            "Epoch 774: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3340 - accuracy: 0.8742 - mae: 0.1453 - mse: 0.0679 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1392 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 775/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3149 - accuracy: 0.8799 - mae: 0.1397 - mse: 0.0644\n",
            "Epoch 775: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3311 - accuracy: 0.8742 - mae: 0.1422 - mse: 0.0672 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 776/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8867 - mae: 0.1361 - mse: 0.0642\n",
            "Epoch 776: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3361 - accuracy: 0.8745 - mae: 0.1386 - mse: 0.0680 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1302 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 777/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3392 - accuracy: 0.8701 - mae: 0.1409 - mse: 0.0696\n",
            "Epoch 777: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3332 - accuracy: 0.8748 - mae: 0.1358 - mse: 0.0676 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1277 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 778/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8740 - mae: 0.1307 - mse: 0.0673\n",
            "Epoch 778: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3301 - accuracy: 0.8748 - mae: 0.1323 - mse: 0.0670 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1279 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 779/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3161 - accuracy: 0.8857 - mae: 0.1275 - mse: 0.0627\n",
            "Epoch 779: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3293 - accuracy: 0.8745 - mae: 0.1325 - mse: 0.0670 - val_loss: 0.3254 - val_accuracy: 0.8744 - val_mae: 0.1289 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 780/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8760 - mae: 0.1318 - mse: 0.0666\n",
            "Epoch 780: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3378 - accuracy: 0.8742 - mae: 0.1345 - mse: 0.0678 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1305 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 781/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3384 - accuracy: 0.8721 - mae: 0.1369 - mse: 0.0687\n",
            "Epoch 781: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3282 - accuracy: 0.8745 - mae: 0.1343 - mse: 0.0667 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 782/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3250 - accuracy: 0.8750 - mae: 0.1333 - mse: 0.0654\n",
            "Epoch 782: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3336 - accuracy: 0.8739 - mae: 0.1361 - mse: 0.0672 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 783/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8838 - mae: 0.1329 - mse: 0.0651\n",
            "Epoch 783: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3359 - accuracy: 0.8752 - mae: 0.1359 - mse: 0.0679 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1307 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 784/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3394 - accuracy: 0.8740 - mae: 0.1347 - mse: 0.0672\n",
            "Epoch 784: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3389 - accuracy: 0.8748 - mae: 0.1366 - mse: 0.0677 - val_loss: 0.3246 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 785/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3098 - accuracy: 0.8857 - mae: 0.1319 - mse: 0.0625\n",
            "Epoch 785: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3252 - accuracy: 0.8752 - mae: 0.1363 - mse: 0.0662 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 786/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8896 - mae: 0.1334 - mse: 0.0630\n",
            "Epoch 786: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3369 - accuracy: 0.8748 - mae: 0.1382 - mse: 0.0680 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 787/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3502 - accuracy: 0.8662 - mae: 0.1411 - mse: 0.0710\n",
            "Epoch 787: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3347 - accuracy: 0.8745 - mae: 0.1375 - mse: 0.0675 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 788/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8789 - mae: 0.1378 - mse: 0.0664\n",
            "Epoch 788: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3320 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0677 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 789/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3257 - accuracy: 0.8779 - mae: 0.1367 - mse: 0.0658\n",
            "Epoch 789: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3287 - accuracy: 0.8745 - mae: 0.1378 - mse: 0.0670 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 790/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3149 - accuracy: 0.8770 - mae: 0.1370 - mse: 0.0643\n",
            "Epoch 790: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3299 - accuracy: 0.8742 - mae: 0.1400 - mse: 0.0675 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 791/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3381 - accuracy: 0.8721 - mae: 0.1401 - mse: 0.0685\n",
            "Epoch 791: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3270 - accuracy: 0.8752 - mae: 0.1373 - mse: 0.0664 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 792/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3196 - accuracy: 0.8799 - mae: 0.1343 - mse: 0.0645\n",
            "Epoch 792: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3319 - accuracy: 0.8742 - mae: 0.1369 - mse: 0.0671 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 793/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3294 - accuracy: 0.8838 - mae: 0.1336 - mse: 0.0650\n",
            "Epoch 793: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3342 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0672 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 794/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8867 - mae: 0.1298 - mse: 0.0612\n",
            "Epoch 794: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3326 - accuracy: 0.8739 - mae: 0.1384 - mse: 0.0677 - val_loss: 0.3304 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 795/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3413 - accuracy: 0.8721 - mae: 0.1400 - mse: 0.0692\n",
            "Epoch 795: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3314 - accuracy: 0.8748 - mae: 0.1379 - mse: 0.0673 - val_loss: 0.3305 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 796/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3244 - accuracy: 0.8877 - mae: 0.1322 - mse: 0.0640\n",
            "Epoch 796: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3344 - accuracy: 0.8742 - mae: 0.1379 - mse: 0.0681 - val_loss: 0.3300 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 797/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8701 - mae: 0.1404 - mse: 0.0701\n",
            "Epoch 797: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3272 - accuracy: 0.8755 - mae: 0.1368 - mse: 0.0667 - val_loss: 0.3298 - val_accuracy: 0.8744 - val_mae: 0.1348 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 798/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3566 - accuracy: 0.8682 - mae: 0.1444 - mse: 0.0720\n",
            "Epoch 798: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3300 - accuracy: 0.8742 - mae: 0.1377 - mse: 0.0671 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 799/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8818 - mae: 0.1325 - mse: 0.0644\n",
            "Epoch 799: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3350 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0676 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 800/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3485 - accuracy: 0.8721 - mae: 0.1390 - mse: 0.0696\n",
            "Epoch 800: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3296 - accuracy: 0.8752 - mae: 0.1352 - mse: 0.0668 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 801/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8896 - mae: 0.1288 - mse: 0.0609\n",
            "Epoch 801: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3300 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0670 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 802/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8721 - mae: 0.1384 - mse: 0.0691\n",
            "Epoch 802: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3298 - accuracy: 0.8739 - mae: 0.1372 - mse: 0.0675 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 803/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3499 - accuracy: 0.8604 - mae: 0.1429 - mse: 0.0721\n",
            "Epoch 803: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3292 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0671 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 804/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8848 - mae: 0.1316 - mse: 0.0630\n",
            "Epoch 804: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3327 - accuracy: 0.8742 - mae: 0.1391 - mse: 0.0678 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1371 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 805/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3455 - accuracy: 0.8721 - mae: 0.1439 - mse: 0.0697\n",
            "Epoch 805: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3364 - accuracy: 0.8748 - mae: 0.1423 - mse: 0.0682 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1387 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 806/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3350 - accuracy: 0.8730 - mae: 0.1427 - mse: 0.0684\n",
            "Epoch 806: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3362 - accuracy: 0.8748 - mae: 0.1434 - mse: 0.0679 - val_loss: 0.3291 - val_accuracy: 0.8744 - val_mae: 0.1381 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 807/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3358 - accuracy: 0.8643 - mae: 0.1427 - mse: 0.0692\n",
            "Epoch 807: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3303 - accuracy: 0.8748 - mae: 0.1396 - mse: 0.0666 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1347 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 808/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2975 - accuracy: 0.8945 - mae: 0.1319 - mse: 0.0594\n",
            "Epoch 808: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3366 - accuracy: 0.8745 - mae: 0.1372 - mse: 0.0675 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 809/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0673\n",
            "Epoch 809: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.3286 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0673 - val_loss: 0.3305 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 810/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3393 - accuracy: 0.8750 - mae: 0.1386 - mse: 0.0680\n",
            "Epoch 810: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 103ms/step - loss: 0.3383 - accuracy: 0.8752 - mae: 0.1385 - mse: 0.0679 - val_loss: 0.3323 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 811/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3328 - accuracy: 0.8753 - mae: 0.1387 - mse: 0.0671\n",
            "Epoch 811: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.3326 - accuracy: 0.8748 - mae: 0.1387 - mse: 0.0671 - val_loss: 0.3321 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 812/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3304 - accuracy: 0.8740 - mae: 0.1370 - mse: 0.0671\n",
            "Epoch 812: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.3293 - accuracy: 0.8739 - mae: 0.1369 - mse: 0.0669 - val_loss: 0.3312 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 813/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3151 - accuracy: 0.8809 - mae: 0.1307 - mse: 0.0644\n",
            "Epoch 813: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3320 - accuracy: 0.8742 - mae: 0.1342 - mse: 0.0677 - val_loss: 0.3310 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 814/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3338 - accuracy: 0.8682 - mae: 0.1344 - mse: 0.0688\n",
            "Epoch 814: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3291 - accuracy: 0.8742 - mae: 0.1355 - mse: 0.0672 - val_loss: 0.3311 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 815/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3159 - accuracy: 0.8818 - mae: 0.1312 - mse: 0.0635\n",
            "Epoch 815: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3287 - accuracy: 0.8739 - mae: 0.1370 - mse: 0.0672 - val_loss: 0.3325 - val_accuracy: 0.8744 - val_mae: 0.1360 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 816/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8701 - mae: 0.1385 - mse: 0.0672\n",
            "Epoch 816: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3333 - accuracy: 0.8745 - mae: 0.1386 - mse: 0.0673 - val_loss: 0.3334 - val_accuracy: 0.8744 - val_mae: 0.1369 - val_mse: 0.0684 - lr: 1.0000e-04\n",
            "Epoch 817/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3389 - accuracy: 0.8682 - mae: 0.1412 - mse: 0.0698\n",
            "Epoch 817: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3325 - accuracy: 0.8742 - mae: 0.1401 - mse: 0.0678 - val_loss: 0.3326 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 818/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8721 - mae: 0.1368 - mse: 0.0672\n",
            "Epoch 818: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3307 - accuracy: 0.8736 - mae: 0.1372 - mse: 0.0673 - val_loss: 0.3317 - val_accuracy: 0.8744 - val_mae: 0.1316 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 819/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8740 - mae: 0.1347 - mse: 0.0670\n",
            "Epoch 819: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3316 - accuracy: 0.8755 - mae: 0.1350 - mse: 0.0673 - val_loss: 0.3305 - val_accuracy: 0.8744 - val_mae: 0.1298 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 820/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8750 - mae: 0.1324 - mse: 0.0659\n",
            "Epoch 820: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3300 - accuracy: 0.8739 - mae: 0.1338 - mse: 0.0673 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1290 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 821/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8633 - mae: 0.1381 - mse: 0.0708\n",
            "Epoch 821: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3376 - accuracy: 0.8748 - mae: 0.1338 - mse: 0.0677 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1285 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 822/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3491 - accuracy: 0.8701 - mae: 0.1339 - mse: 0.0696\n",
            "Epoch 822: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3322 - accuracy: 0.8745 - mae: 0.1338 - mse: 0.0674 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1301 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 823/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3252 - accuracy: 0.8799 - mae: 0.1314 - mse: 0.0660\n",
            "Epoch 823: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3352 - accuracy: 0.8745 - mae: 0.1354 - mse: 0.0676 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 824/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8643 - mae: 0.1430 - mse: 0.0727\n",
            "Epoch 824: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3327 - accuracy: 0.8742 - mae: 0.1369 - mse: 0.0677 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 825/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3140 - accuracy: 0.8799 - mae: 0.1345 - mse: 0.0640\n",
            "Epoch 825: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3336 - accuracy: 0.8752 - mae: 0.1376 - mse: 0.0675 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 826/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3140 - accuracy: 0.8818 - mae: 0.1317 - mse: 0.0638\n",
            "Epoch 826: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3305 - accuracy: 0.8745 - mae: 0.1375 - mse: 0.0672 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1331 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 827/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8779 - mae: 0.1362 - mse: 0.0663\n",
            "Epoch 827: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3318 - accuracy: 0.8739 - mae: 0.1373 - mse: 0.0673 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 828/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8965 - mae: 0.1284 - mse: 0.0584\n",
            "Epoch 828: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3255 - accuracy: 0.8739 - mae: 0.1369 - mse: 0.0666 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 829/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3556 - accuracy: 0.8623 - mae: 0.1420 - mse: 0.0730\n",
            "Epoch 829: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3349 - accuracy: 0.8742 - mae: 0.1359 - mse: 0.0677 - val_loss: 0.3261 - val_accuracy: 0.8744 - val_mae: 0.1304 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 830/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3478 - accuracy: 0.8672 - mae: 0.1361 - mse: 0.0699\n",
            "Epoch 830: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3361 - accuracy: 0.8742 - mae: 0.1363 - mse: 0.0678 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 831/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8711 - mae: 0.1390 - mse: 0.0689\n",
            "Epoch 831: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3334 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0673 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 832/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3430 - accuracy: 0.8672 - mae: 0.1360 - mse: 0.0702\n",
            "Epoch 832: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3299 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0671 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 833/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8789 - mae: 0.1358 - mse: 0.0659\n",
            "Epoch 833: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3328 - accuracy: 0.8752 - mae: 0.1374 - mse: 0.0679 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 834/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3266 - accuracy: 0.8662 - mae: 0.1376 - mse: 0.0681\n",
            "Epoch 834: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3318 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0672 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 835/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3101 - accuracy: 0.8799 - mae: 0.1334 - mse: 0.0641\n",
            "Epoch 835: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3223 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0663 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 836/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3488 - accuracy: 0.8633 - mae: 0.1432 - mse: 0.0718\n",
            "Epoch 836: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3317 - accuracy: 0.8745 - mae: 0.1395 - mse: 0.0676 - val_loss: 0.3295 - val_accuracy: 0.8744 - val_mae: 0.1353 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 837/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3209 - accuracy: 0.8857 - mae: 0.1372 - mse: 0.0639\n",
            "Epoch 837: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3344 - accuracy: 0.8745 - mae: 0.1400 - mse: 0.0677 - val_loss: 0.3293 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 838/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3568 - accuracy: 0.8662 - mae: 0.1444 - mse: 0.0712\n",
            "Epoch 838: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3354 - accuracy: 0.8742 - mae: 0.1380 - mse: 0.0676 - val_loss: 0.3293 - val_accuracy: 0.8744 - val_mae: 0.1337 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 839/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8799 - mae: 0.1373 - mse: 0.0664\n",
            "Epoch 839: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3345 - accuracy: 0.8748 - mae: 0.1381 - mse: 0.0672 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1344 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 840/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3026 - accuracy: 0.8887 - mae: 0.1306 - mse: 0.0605\n",
            "Epoch 840: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3268 - accuracy: 0.8745 - mae: 0.1381 - mse: 0.0666 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1320 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 841/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3124 - accuracy: 0.8828 - mae: 0.1327 - mse: 0.0631\n",
            "Epoch 841: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3328 - accuracy: 0.8748 - mae: 0.1352 - mse: 0.0673 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 842/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8809 - mae: 0.1315 - mse: 0.0654\n",
            "Epoch 842: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3332 - accuracy: 0.8745 - mae: 0.1343 - mse: 0.0677 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 843/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3026 - accuracy: 0.8965 - mae: 0.1267 - mse: 0.0586\n",
            "Epoch 843: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3334 - accuracy: 0.8745 - mae: 0.1351 - mse: 0.0675 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1296 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 844/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3200 - accuracy: 0.8809 - mae: 0.1305 - mse: 0.0643\n",
            "Epoch 844: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3323 - accuracy: 0.8745 - mae: 0.1346 - mse: 0.0671 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1284 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 845/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3317 - accuracy: 0.8770 - mae: 0.1319 - mse: 0.0664\n",
            "Epoch 845: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3371 - accuracy: 0.8745 - mae: 0.1340 - mse: 0.0677 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1288 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 846/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3482 - accuracy: 0.8643 - mae: 0.1374 - mse: 0.0713\n",
            "Epoch 846: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3317 - accuracy: 0.8742 - mae: 0.1347 - mse: 0.0673 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1302 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 847/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8730 - mae: 0.1387 - mse: 0.0674\n",
            "Epoch 847: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3235 - accuracy: 0.8748 - mae: 0.1354 - mse: 0.0665 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 848/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8848 - mae: 0.1309 - mse: 0.0628\n",
            "Epoch 848: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3355 - accuracy: 0.8742 - mae: 0.1374 - mse: 0.0678 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 849/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3536 - accuracy: 0.8662 - mae: 0.1429 - mse: 0.0717\n",
            "Epoch 849: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3359 - accuracy: 0.8752 - mae: 0.1387 - mse: 0.0678 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 850/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3272 - accuracy: 0.8750 - mae: 0.1353 - mse: 0.0661\n",
            "Epoch 850: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3278 - accuracy: 0.8748 - mae: 0.1369 - mse: 0.0668 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1306 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 851/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8662 - mae: 0.1388 - mse: 0.0708\n",
            "Epoch 851: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3324 - accuracy: 0.8748 - mae: 0.1363 - mse: 0.0675 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 852/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3467 - accuracy: 0.8633 - mae: 0.1420 - mse: 0.0718\n",
            "Epoch 852: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3325 - accuracy: 0.8748 - mae: 0.1345 - mse: 0.0674 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1290 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 853/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8711 - mae: 0.1361 - mse: 0.0687\n",
            "Epoch 853: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3339 - accuracy: 0.8748 - mae: 0.1342 - mse: 0.0671 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 854/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8740 - mae: 0.1336 - mse: 0.0661\n",
            "Epoch 854: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3252 - accuracy: 0.8752 - mae: 0.1331 - mse: 0.0663 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 855/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3286 - accuracy: 0.8747 - mae: 0.1342 - mse: 0.0670\n",
            "Epoch 855: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 105ms/step - loss: 0.3292 - accuracy: 0.8742 - mae: 0.1342 - mse: 0.0671 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1276 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 856/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3366 - accuracy: 0.8727 - mae: 0.1337 - mse: 0.0685\n",
            "Epoch 856: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.3334 - accuracy: 0.8748 - mae: 0.1327 - mse: 0.0676 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1268 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 857/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3343 - accuracy: 0.8743 - mae: 0.1326 - mse: 0.0676\n",
            "Epoch 857: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.3330 - accuracy: 0.8739 - mae: 0.1323 - mse: 0.0675 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1266 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 858/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.8745 - mae: 0.1332 - mse: 0.0673\n",
            "Epoch 858: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.3315 - accuracy: 0.8745 - mae: 0.1332 - mse: 0.0673 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1272 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 859/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8799 - mae: 0.1336 - mse: 0.0667\n",
            "Epoch 859: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3290 - accuracy: 0.8745 - mae: 0.1332 - mse: 0.0672 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1270 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 860/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3320 - accuracy: 0.8643 - mae: 0.1355 - mse: 0.0692\n",
            "Epoch 860: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3303 - accuracy: 0.8748 - mae: 0.1321 - mse: 0.0667 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1272 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 861/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3151 - accuracy: 0.8848 - mae: 0.1273 - mse: 0.0627\n",
            "Epoch 861: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3306 - accuracy: 0.8748 - mae: 0.1324 - mse: 0.0667 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1277 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 862/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8760 - mae: 0.1348 - mse: 0.0675\n",
            "Epoch 862: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3372 - accuracy: 0.8745 - mae: 0.1349 - mse: 0.0681 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1284 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 863/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3088 - accuracy: 0.8857 - mae: 0.1259 - mse: 0.0613\n",
            "Epoch 863: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3297 - accuracy: 0.8739 - mae: 0.1341 - mse: 0.0669 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1301 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 864/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8760 - mae: 0.1338 - mse: 0.0650\n",
            "Epoch 864: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3275 - accuracy: 0.8745 - mae: 0.1342 - mse: 0.0671 - val_loss: 0.3301 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 865/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3445 - accuracy: 0.8711 - mae: 0.1370 - mse: 0.0696\n",
            "Epoch 865: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3323 - accuracy: 0.8752 - mae: 0.1354 - mse: 0.0672 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 866/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3217 - accuracy: 0.8691 - mae: 0.1373 - mse: 0.0673\n",
            "Epoch 866: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3263 - accuracy: 0.8748 - mae: 0.1340 - mse: 0.0669 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1285 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 867/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8818 - mae: 0.1288 - mse: 0.0640\n",
            "Epoch 867: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3284 - accuracy: 0.8745 - mae: 0.1319 - mse: 0.0669 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1274 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 868/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8838 - mae: 0.1287 - mse: 0.0648\n",
            "Epoch 868: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3253 - accuracy: 0.8748 - mae: 0.1308 - mse: 0.0662 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1280 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 869/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3409 - accuracy: 0.8672 - mae: 0.1344 - mse: 0.0696\n",
            "Epoch 869: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3329 - accuracy: 0.8745 - mae: 0.1338 - mse: 0.0672 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1294 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 870/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3148 - accuracy: 0.8916 - mae: 0.1268 - mse: 0.0607\n",
            "Epoch 870: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3351 - accuracy: 0.8752 - mae: 0.1351 - mse: 0.0674 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 871/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8779 - mae: 0.1350 - mse: 0.0650\n",
            "Epoch 871: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3299 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0668 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1338 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 872/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3345 - accuracy: 0.8711 - mae: 0.1353 - mse: 0.0672\n",
            "Epoch 872: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3317 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0667 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1344 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 873/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8750 - mae: 0.1408 - mse: 0.0682\n",
            "Epoch 873: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3348 - accuracy: 0.8745 - mae: 0.1400 - mse: 0.0679 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1345 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 874/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.8739 - mae: 0.1377 - mse: 0.0668\n",
            "Epoch 874: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3259 - accuracy: 0.8739 - mae: 0.1377 - mse: 0.0668 - val_loss: 0.3251 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 875/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8691 - mae: 0.1399 - mse: 0.0686\n",
            "Epoch 875: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3307 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0671 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 876/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3316 - accuracy: 0.8779 - mae: 0.1325 - mse: 0.0656\n",
            "Epoch 876: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3352 - accuracy: 0.8748 - mae: 0.1348 - mse: 0.0672 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1286 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 877/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3164 - accuracy: 0.8857 - mae: 0.1290 - mse: 0.0631\n",
            "Epoch 877: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3299 - accuracy: 0.8745 - mae: 0.1319 - mse: 0.0671 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1266 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 878/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3346 - accuracy: 0.8750 - mae: 0.1284 - mse: 0.0667\n",
            "Epoch 878: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3338 - accuracy: 0.8745 - mae: 0.1317 - mse: 0.0675 - val_loss: 0.3234 - val_accuracy: 0.8744 - val_mae: 0.1276 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 879/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3151 - accuracy: 0.8789 - mae: 0.1304 - mse: 0.0650\n",
            "Epoch 879: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3259 - accuracy: 0.8745 - mae: 0.1325 - mse: 0.0664 - val_loss: 0.3232 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 880/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8770 - mae: 0.1318 - mse: 0.0655\n",
            "Epoch 880: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3318 - accuracy: 0.8745 - mae: 0.1353 - mse: 0.0673 - val_loss: 0.3243 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 881/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3145 - accuracy: 0.8809 - mae: 0.1357 - mse: 0.0644\n",
            "Epoch 881: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3296 - accuracy: 0.8748 - mae: 0.1403 - mse: 0.0673 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1367 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 882/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8721 - mae: 0.1408 - mse: 0.0674\n",
            "Epoch 882: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3374 - accuracy: 0.8748 - mae: 0.1422 - mse: 0.0680 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1372 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 883/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3176 - accuracy: 0.8799 - mae: 0.1399 - mse: 0.0643\n",
            "Epoch 883: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3324 - accuracy: 0.8739 - mae: 0.1417 - mse: 0.0677 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1344 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 884/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8662 - mae: 0.1420 - mse: 0.0712\n",
            "Epoch 884: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3326 - accuracy: 0.8742 - mae: 0.1382 - mse: 0.0674 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 885/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3291 - accuracy: 0.8652 - mae: 0.1370 - mse: 0.0690\n",
            "Epoch 885: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3261 - accuracy: 0.8748 - mae: 0.1357 - mse: 0.0668 - val_loss: 0.3236 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 886/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3267 - accuracy: 0.8760 - mae: 0.1367 - mse: 0.0669\n",
            "Epoch 886: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3302 - accuracy: 0.8748 - mae: 0.1348 - mse: 0.0668 - val_loss: 0.3229 - val_accuracy: 0.8744 - val_mae: 0.1294 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 887/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3097 - accuracy: 0.8809 - mae: 0.1285 - mse: 0.0632\n",
            "Epoch 887: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3279 - accuracy: 0.8739 - mae: 0.1337 - mse: 0.0669 - val_loss: 0.3224 - val_accuracy: 0.8744 - val_mae: 0.1282 - val_mse: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 888/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3234 - accuracy: 0.8789 - mae: 0.1325 - mse: 0.0655\n",
            "Epoch 888: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3302 - accuracy: 0.8748 - mae: 0.1336 - mse: 0.0671 - val_loss: 0.3229 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 889/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3144 - accuracy: 0.8887 - mae: 0.1279 - mse: 0.0615\n",
            "Epoch 889: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3305 - accuracy: 0.8745 - mae: 0.1357 - mse: 0.0673 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 890/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8809 - mae: 0.1358 - mse: 0.0645\n",
            "Epoch 890: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3312 - accuracy: 0.8745 - mae: 0.1382 - mse: 0.0671 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 891/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3457 - accuracy: 0.8613 - mae: 0.1439 - mse: 0.0712\n",
            "Epoch 891: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3325 - accuracy: 0.8745 - mae: 0.1396 - mse: 0.0671 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1352 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 892/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3514 - accuracy: 0.8633 - mae: 0.1463 - mse: 0.0725\n",
            "Epoch 892: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3297 - accuracy: 0.8742 - mae: 0.1393 - mse: 0.0674 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 893/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3242 - accuracy: 0.8760 - mae: 0.1368 - mse: 0.0664\n",
            "Epoch 893: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3294 - accuracy: 0.8748 - mae: 0.1375 - mse: 0.0670 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 894/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3165 - accuracy: 0.8760 - mae: 0.1322 - mse: 0.0654\n",
            "Epoch 894: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3299 - accuracy: 0.8742 - mae: 0.1346 - mse: 0.0669 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 895/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3395 - accuracy: 0.8760 - mae: 0.1363 - mse: 0.0677\n",
            "Epoch 895: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3351 - accuracy: 0.8742 - mae: 0.1332 - mse: 0.0670 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 896/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3289 - accuracy: 0.8779 - mae: 0.1316 - mse: 0.0660\n",
            "Epoch 896: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3287 - accuracy: 0.8745 - mae: 0.1343 - mse: 0.0671 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 897/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8838 - mae: 0.1302 - mse: 0.0640\n",
            "Epoch 897: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3344 - accuracy: 0.8739 - mae: 0.1348 - mse: 0.0675 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1330 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 898/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3065 - accuracy: 0.8848 - mae: 0.1307 - mse: 0.0612\n",
            "Epoch 898: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3285 - accuracy: 0.8736 - mae: 0.1365 - mse: 0.0671 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 899/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8770 - mae: 0.1367 - mse: 0.0665\n",
            "Epoch 899: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3315 - accuracy: 0.8748 - mae: 0.1365 - mse: 0.0670 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1330 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 900/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8809 - mae: 0.1339 - mse: 0.0634\n",
            "Epoch 900: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3251 - accuracy: 0.8739 - mae: 0.1387 - mse: 0.0667 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 901/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3164 - accuracy: 0.8779 - mae: 0.1363 - mse: 0.0647\n",
            "Epoch 901: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3243 - accuracy: 0.8739 - mae: 0.1371 - mse: 0.0667 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 902/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8701 - mae: 0.1364 - mse: 0.0681\n",
            "Epoch 902: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3306 - accuracy: 0.8755 - mae: 0.1344 - mse: 0.0669 - val_loss: 0.3239 - val_accuracy: 0.8744 - val_mae: 0.1284 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 903/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3224 - accuracy: 0.8770 - mae: 0.1328 - mse: 0.0654\n",
            "Epoch 903: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3259 - accuracy: 0.8745 - mae: 0.1333 - mse: 0.0665 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 904/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3382 - accuracy: 0.8672 - mae: 0.1382 - mse: 0.0690\n",
            "Epoch 904: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3255 - accuracy: 0.8745 - mae: 0.1346 - mse: 0.0664 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1307 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 905/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3324 - accuracy: 0.8750 - mae: 0.1368 - mse: 0.0673\n",
            "Epoch 905: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3319 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0672 - val_loss: 0.3252 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 906/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3444 - accuracy: 0.8711 - mae: 0.1389 - mse: 0.0701\n",
            "Epoch 906: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3281 - accuracy: 0.8752 - mae: 0.1379 - mse: 0.0669 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 907/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8652 - mae: 0.1386 - mse: 0.0704\n",
            "Epoch 907: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3306 - accuracy: 0.8739 - mae: 0.1375 - mse: 0.0673 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1313 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 908/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3030 - accuracy: 0.8857 - mae: 0.1296 - mse: 0.0616\n",
            "Epoch 908: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3321 - accuracy: 0.8748 - mae: 0.1353 - mse: 0.0674 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1297 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 909/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8896 - mae: 0.1295 - mse: 0.0610\n",
            "Epoch 909: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3266 - accuracy: 0.8748 - mae: 0.1345 - mse: 0.0666 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1291 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 910/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3240 - accuracy: 0.8750 - mae: 0.1336 - mse: 0.0658\n",
            "Epoch 910: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3304 - accuracy: 0.8752 - mae: 0.1339 - mse: 0.0669 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1284 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 911/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8799 - mae: 0.1295 - mse: 0.0646\n",
            "Epoch 911: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3332 - accuracy: 0.8752 - mae: 0.1328 - mse: 0.0671 - val_loss: 0.3298 - val_accuracy: 0.8744 - val_mae: 0.1282 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 912/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3216 - accuracy: 0.8838 - mae: 0.1294 - mse: 0.0642\n",
            "Epoch 912: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3354 - accuracy: 0.8736 - mae: 0.1331 - mse: 0.0678 - val_loss: 0.3308 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 913/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8799 - mae: 0.1299 - mse: 0.0638\n",
            "Epoch 913: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3275 - accuracy: 0.8752 - mae: 0.1346 - mse: 0.0670 - val_loss: 0.3302 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 914/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3259 - accuracy: 0.8779 - mae: 0.1347 - mse: 0.0666\n",
            "Epoch 914: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3291 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0674 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1330 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 915/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3083 - accuracy: 0.8809 - mae: 0.1339 - mse: 0.0636\n",
            "Epoch 915: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3278 - accuracy: 0.8748 - mae: 0.1371 - mse: 0.0668 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1323 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 916/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3331 - accuracy: 0.8672 - mae: 0.1401 - mse: 0.0693\n",
            "Epoch 916: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3259 - accuracy: 0.8745 - mae: 0.1363 - mse: 0.0668 - val_loss: 0.3282 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 917/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3167 - accuracy: 0.8760 - mae: 0.1338 - mse: 0.0651\n",
            "Epoch 917: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3280 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0670 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 918/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3014 - accuracy: 0.8984 - mae: 0.1273 - mse: 0.0576\n",
            "Epoch 918: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3317 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0671 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 919/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3000 - accuracy: 0.8896 - mae: 0.1285 - mse: 0.0603\n",
            "Epoch 919: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3315 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0673 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 920/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3147 - accuracy: 0.8740 - mae: 0.1332 - mse: 0.0649\n",
            "Epoch 920: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3280 - accuracy: 0.8742 - mae: 0.1378 - mse: 0.0671 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 921/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8643 - mae: 0.1414 - mse: 0.0701\n",
            "Epoch 921: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3268 - accuracy: 0.8739 - mae: 0.1381 - mse: 0.0671 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1359 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 922/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8809 - mae: 0.1388 - mse: 0.0655\n",
            "Epoch 922: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3284 - accuracy: 0.8748 - mae: 0.1398 - mse: 0.0669 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1350 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 923/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8740 - mae: 0.1366 - mse: 0.0671\n",
            "Epoch 923: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3279 - accuracy: 0.8739 - mae: 0.1383 - mse: 0.0665 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 924/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8896 - mae: 0.1342 - mse: 0.0628\n",
            "Epoch 924: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3356 - accuracy: 0.8748 - mae: 0.1368 - mse: 0.0676 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 925/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3458 - accuracy: 0.8623 - mae: 0.1370 - mse: 0.0714\n",
            "Epoch 925: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3236 - accuracy: 0.8745 - mae: 0.1317 - mse: 0.0661 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1268 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 926/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8789 - mae: 0.1289 - mse: 0.0656\n",
            "Epoch 926: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3379 - accuracy: 0.8742 - mae: 0.1322 - mse: 0.0676 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1289 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 927/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3332 - accuracy: 0.8672 - mae: 0.1358 - mse: 0.0697\n",
            "Epoch 927: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3280 - accuracy: 0.8742 - mae: 0.1340 - mse: 0.0669 - val_loss: 0.3269 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 928/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3224 - accuracy: 0.8809 - mae: 0.1302 - mse: 0.0644\n",
            "Epoch 928: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3289 - accuracy: 0.8748 - mae: 0.1355 - mse: 0.0669 - val_loss: 0.3265 - val_accuracy: 0.8744 - val_mae: 0.1305 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 929/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8721 - mae: 0.1346 - mse: 0.0671\n",
            "Epoch 929: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3265 - accuracy: 0.8742 - mae: 0.1348 - mse: 0.0666 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1310 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 930/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3317 - accuracy: 0.8691 - mae: 0.1365 - mse: 0.0676\n",
            "Epoch 930: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3283 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0667 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 931/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3225 - accuracy: 0.8750 - mae: 0.1326 - mse: 0.0664\n",
            "Epoch 931: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3250 - accuracy: 0.8748 - mae: 0.1365 - mse: 0.0668 - val_loss: 0.3241 - val_accuracy: 0.8744 - val_mae: 0.1313 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 932/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3512 - accuracy: 0.8711 - mae: 0.1424 - mse: 0.0705\n",
            "Epoch 932: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3317 - accuracy: 0.8752 - mae: 0.1367 - mse: 0.0674 - val_loss: 0.3232 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 933/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8643 - mae: 0.1413 - mse: 0.0715\n",
            "Epoch 933: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3314 - accuracy: 0.8742 - mae: 0.1359 - mse: 0.0672 - val_loss: 0.3234 - val_accuracy: 0.8744 - val_mae: 0.1296 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 934/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3112 - accuracy: 0.8779 - mae: 0.1318 - mse: 0.0641\n",
            "Epoch 934: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3280 - accuracy: 0.8745 - mae: 0.1351 - mse: 0.0669 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1305 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 935/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3206 - accuracy: 0.8799 - mae: 0.1340 - mse: 0.0651\n",
            "Epoch 935: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3288 - accuracy: 0.8748 - mae: 0.1363 - mse: 0.0669 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 936/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3428 - accuracy: 0.8682 - mae: 0.1423 - mse: 0.0703\n",
            "Epoch 936: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3275 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0670 - val_loss: 0.3268 - val_accuracy: 0.8744 - val_mae: 0.1333 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 937/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3211 - accuracy: 0.8809 - mae: 0.1350 - mse: 0.0647\n",
            "Epoch 937: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3297 - accuracy: 0.8748 - mae: 0.1374 - mse: 0.0672 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 938/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8877 - mae: 0.1307 - mse: 0.0614\n",
            "Epoch 938: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3294 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0668 - val_loss: 0.3254 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 939/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3150 - accuracy: 0.8877 - mae: 0.1318 - mse: 0.0627\n",
            "Epoch 939: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3291 - accuracy: 0.8748 - mae: 0.1372 - mse: 0.0669 - val_loss: 0.3245 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 940/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8760 - mae: 0.1342 - mse: 0.0654\n",
            "Epoch 940: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3316 - accuracy: 0.8752 - mae: 0.1363 - mse: 0.0674 - val_loss: 0.3242 - val_accuracy: 0.8744 - val_mae: 0.1302 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 941/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8691 - mae: 0.1368 - mse: 0.0690\n",
            "Epoch 941: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3280 - accuracy: 0.8748 - mae: 0.1362 - mse: 0.0671 - val_loss: 0.3244 - val_accuracy: 0.8744 - val_mae: 0.1309 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 942/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8604 - mae: 0.1439 - mse: 0.0738\n",
            "Epoch 942: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3253 - accuracy: 0.8742 - mae: 0.1365 - mse: 0.0665 - val_loss: 0.3240 - val_accuracy: 0.8744 - val_mae: 0.1309 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 943/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3350 - accuracy: 0.8701 - mae: 0.1395 - mse: 0.0693\n",
            "Epoch 943: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3335 - accuracy: 0.8742 - mae: 0.1377 - mse: 0.0679 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1320 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 944/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3222 - accuracy: 0.8799 - mae: 0.1364 - mse: 0.0655\n",
            "Epoch 944: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3303 - accuracy: 0.8748 - mae: 0.1385 - mse: 0.0671 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 945/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3076 - accuracy: 0.8936 - mae: 0.1331 - mse: 0.0606\n",
            "Epoch 945: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3347 - accuracy: 0.8755 - mae: 0.1401 - mse: 0.0679 - val_loss: 0.3286 - val_accuracy: 0.8744 - val_mae: 0.1339 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 946/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3470 - accuracy: 0.8672 - mae: 0.1423 - mse: 0.0712\n",
            "Epoch 946: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3322 - accuracy: 0.8748 - mae: 0.1386 - mse: 0.0677 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1332 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 947/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8721 - mae: 0.1367 - mse: 0.0660\n",
            "Epoch 947: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3289 - accuracy: 0.8739 - mae: 0.1374 - mse: 0.0670 - val_loss: 0.3270 - val_accuracy: 0.8731 - val_mae: 0.1310 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 948/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3463 - accuracy: 0.8594 - mae: 0.1407 - mse: 0.0713\n",
            "Epoch 948: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3232 - accuracy: 0.8748 - mae: 0.1343 - mse: 0.0660 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1292 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 949/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3039 - accuracy: 0.8857 - mae: 0.1289 - mse: 0.0615\n",
            "Epoch 949: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3267 - accuracy: 0.8745 - mae: 0.1330 - mse: 0.0666 - val_loss: 0.3251 - val_accuracy: 0.8731 - val_mae: 0.1270 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 950/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3622 - accuracy: 0.8555 - mae: 0.1425 - mse: 0.0755\n",
            "Epoch 950: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3315 - accuracy: 0.8742 - mae: 0.1335 - mse: 0.0676 - val_loss: 0.3253 - val_accuracy: 0.8731 - val_mae: 0.1268 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 951/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3329 - accuracy: 0.8730 - mae: 0.1316 - mse: 0.0675\n",
            "Epoch 951: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3320 - accuracy: 0.8745 - mae: 0.1328 - mse: 0.0673 - val_loss: 0.3255 - val_accuracy: 0.8731 - val_mae: 0.1265 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 952/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8945 - mae: 0.1235 - mse: 0.0589\n",
            "Epoch 952: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3254 - accuracy: 0.8739 - mae: 0.1311 - mse: 0.0666 - val_loss: 0.3250 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 953/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3095 - accuracy: 0.8857 - mae: 0.1287 - mse: 0.0626\n",
            "Epoch 953: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3256 - accuracy: 0.8742 - mae: 0.1336 - mse: 0.0668 - val_loss: 0.3246 - val_accuracy: 0.8744 - val_mae: 0.1290 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 954/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3459 - accuracy: 0.8643 - mae: 0.1431 - mse: 0.0713\n",
            "Epoch 954: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3267 - accuracy: 0.8748 - mae: 0.1336 - mse: 0.0663 - val_loss: 0.3246 - val_accuracy: 0.8744 - val_mae: 0.1283 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 955/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8672 - mae: 0.1344 - mse: 0.0693\n",
            "Epoch 955: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3280 - accuracy: 0.8748 - mae: 0.1328 - mse: 0.0668 - val_loss: 0.3249 - val_accuracy: 0.8744 - val_mae: 0.1282 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 956/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3302 - accuracy: 0.8770 - mae: 0.1323 - mse: 0.0667\n",
            "Epoch 956: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3309 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0673 - val_loss: 0.3254 - val_accuracy: 0.8744 - val_mae: 0.1289 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 957/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8770 - mae: 0.1335 - mse: 0.0661\n",
            "Epoch 957: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3268 - accuracy: 0.8742 - mae: 0.1341 - mse: 0.0668 - val_loss: 0.3260 - val_accuracy: 0.8744 - val_mae: 0.1305 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 958/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3130 - accuracy: 0.8838 - mae: 0.1333 - mse: 0.0629\n",
            "Epoch 958: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3298 - accuracy: 0.8736 - mae: 0.1366 - mse: 0.0672 - val_loss: 0.3265 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 959/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3099 - accuracy: 0.8887 - mae: 0.1300 - mse: 0.0614\n",
            "Epoch 959: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3327 - accuracy: 0.8748 - mae: 0.1361 - mse: 0.0673 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1311 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 960/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3148 - accuracy: 0.8828 - mae: 0.1304 - mse: 0.0629\n",
            "Epoch 960: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3285 - accuracy: 0.8742 - mae: 0.1362 - mse: 0.0669 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 961/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8691 - mae: 0.1366 - mse: 0.0676\n",
            "Epoch 961: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3312 - accuracy: 0.8748 - mae: 0.1379 - mse: 0.0675 - val_loss: 0.3313 - val_accuracy: 0.8731 - val_mae: 0.1331 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 962/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3014 - accuracy: 0.8857 - mae: 0.1305 - mse: 0.0603\n",
            "Epoch 962: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3313 - accuracy: 0.8748 - mae: 0.1371 - mse: 0.0667 - val_loss: 0.3318 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 963/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3502 - accuracy: 0.8643 - mae: 0.1396 - mse: 0.0719\n",
            "Epoch 963: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3299 - accuracy: 0.8748 - mae: 0.1367 - mse: 0.0674 - val_loss: 0.3319 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 964/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8672 - mae: 0.1406 - mse: 0.0704\n",
            "Epoch 964: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3338 - accuracy: 0.8742 - mae: 0.1375 - mse: 0.0676 - val_loss: 0.3301 - val_accuracy: 0.8731 - val_mae: 0.1308 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 965/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3038 - accuracy: 0.8896 - mae: 0.1280 - mse: 0.0603\n",
            "Epoch 965: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3314 - accuracy: 0.8739 - mae: 0.1352 - mse: 0.0673 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1285 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 966/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3389 - accuracy: 0.8750 - mae: 0.1347 - mse: 0.0685\n",
            "Epoch 966: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3277 - accuracy: 0.8742 - mae: 0.1336 - mse: 0.0671 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 967/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8721 - mae: 0.1345 - mse: 0.0684\n",
            "Epoch 967: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3350 - accuracy: 0.8745 - mae: 0.1354 - mse: 0.0678 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 968/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3659 - accuracy: 0.8506 - mae: 0.1471 - mse: 0.0764\n",
            "Epoch 968: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3279 - accuracy: 0.8748 - mae: 0.1375 - mse: 0.0668 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1331 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 969/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8770 - mae: 0.1359 - mse: 0.0668\n",
            "Epoch 969: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3293 - accuracy: 0.8742 - mae: 0.1376 - mse: 0.0670 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 970/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2881 - accuracy: 0.8965 - mae: 0.1275 - mse: 0.0572\n",
            "Epoch 970: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3270 - accuracy: 0.8745 - mae: 0.1365 - mse: 0.0667 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 971/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8701 - mae: 0.1359 - mse: 0.0682\n",
            "Epoch 971: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3259 - accuracy: 0.8752 - mae: 0.1360 - mse: 0.0666 - val_loss: 0.3302 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 972/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3222 - accuracy: 0.8779 - mae: 0.1329 - mse: 0.0646\n",
            "Epoch 972: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3248 - accuracy: 0.8745 - mae: 0.1353 - mse: 0.0664 - val_loss: 0.3304 - val_accuracy: 0.8744 - val_mae: 0.1320 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 973/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3189 - accuracy: 0.8760 - mae: 0.1315 - mse: 0.0645\n",
            "Epoch 973: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3277 - accuracy: 0.8748 - mae: 0.1367 - mse: 0.0668 - val_loss: 0.3291 - val_accuracy: 0.8744 - val_mae: 0.1298 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 974/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3465 - accuracy: 0.8584 - mae: 0.1419 - mse: 0.0729\n",
            "Epoch 974: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3285 - accuracy: 0.8742 - mae: 0.1341 - mse: 0.0671 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1280 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 975/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8721 - mae: 0.1359 - mse: 0.0679\n",
            "Epoch 975: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3199 - accuracy: 0.8745 - mae: 0.1326 - mse: 0.0658 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1251 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 976/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3560 - accuracy: 0.8604 - mae: 0.1373 - mse: 0.0732\n",
            "Epoch 976: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3299 - accuracy: 0.8748 - mae: 0.1304 - mse: 0.0669 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1239 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 977/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8672 - mae: 0.1338 - mse: 0.0712\n",
            "Epoch 977: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3281 - accuracy: 0.8745 - mae: 0.1291 - mse: 0.0669 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1258 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 978/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8965 - mae: 0.1205 - mse: 0.0586\n",
            "Epoch 978: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3289 - accuracy: 0.8748 - mae: 0.1319 - mse: 0.0671 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1306 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 979/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3363 - accuracy: 0.8730 - mae: 0.1380 - mse: 0.0685\n",
            "Epoch 979: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3289 - accuracy: 0.8748 - mae: 0.1371 - mse: 0.0671 - val_loss: 0.3293 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 980/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3428 - accuracy: 0.8691 - mae: 0.1428 - mse: 0.0698\n",
            "Epoch 980: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3267 - accuracy: 0.8742 - mae: 0.1400 - mse: 0.0667 - val_loss: 0.3298 - val_accuracy: 0.8731 - val_mae: 0.1371 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 981/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8604 - mae: 0.1438 - mse: 0.0700\n",
            "Epoch 981: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3240 - accuracy: 0.8742 - mae: 0.1406 - mse: 0.0663 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1345 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 982/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3193 - accuracy: 0.8828 - mae: 0.1352 - mse: 0.0644\n",
            "Epoch 982: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3321 - accuracy: 0.8739 - mae: 0.1382 - mse: 0.0675 - val_loss: 0.3271 - val_accuracy: 0.8744 - val_mae: 0.1306 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 983/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8779 - mae: 0.1312 - mse: 0.0632\n",
            "Epoch 983: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3256 - accuracy: 0.8742 - mae: 0.1341 - mse: 0.0663 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1286 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 984/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8799 - mae: 0.1294 - mse: 0.0641\n",
            "Epoch 984: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3231 - accuracy: 0.8745 - mae: 0.1317 - mse: 0.0659 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1297 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 985/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8770 - mae: 0.1320 - mse: 0.0655\n",
            "Epoch 985: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3305 - accuracy: 0.8745 - mae: 0.1347 - mse: 0.0673 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 986/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3549 - accuracy: 0.8604 - mae: 0.1393 - mse: 0.0722\n",
            "Epoch 986: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3343 - accuracy: 0.8742 - mae: 0.1354 - mse: 0.0673 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 987/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8828 - mae: 0.1289 - mse: 0.0623\n",
            "Epoch 987: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3290 - accuracy: 0.8739 - mae: 0.1341 - mse: 0.0667 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1291 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 988/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3214 - accuracy: 0.8691 - mae: 0.1339 - mse: 0.0673\n",
            "Epoch 988: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3278 - accuracy: 0.8748 - mae: 0.1339 - mse: 0.0667 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 989/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8750 - mae: 0.1354 - mse: 0.0672\n",
            "Epoch 989: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3304 - accuracy: 0.8742 - mae: 0.1351 - mse: 0.0673 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1304 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 990/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8818 - mae: 0.1377 - mse: 0.0652\n",
            "Epoch 990: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3292 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0669 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 991/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3240 - accuracy: 0.8691 - mae: 0.1393 - mse: 0.0676\n",
            "Epoch 991: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3231 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0665 - val_loss: 0.3298 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 992/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3108 - accuracy: 0.8887 - mae: 0.1339 - mse: 0.0625\n",
            "Epoch 992: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3245 - accuracy: 0.8745 - mae: 0.1366 - mse: 0.0664 - val_loss: 0.3305 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 993/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0668\n",
            "Epoch 993: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3258 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0668 - val_loss: 0.3303 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 994/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3251 - accuracy: 0.8740 - mae: 0.1365 - mse: 0.0673\n",
            "Epoch 994: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3275 - accuracy: 0.8742 - mae: 0.1363 - mse: 0.0671 - val_loss: 0.3308 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 995/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.8748 - mae: 0.1352 - mse: 0.0673\n",
            "Epoch 995: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3316 - accuracy: 0.8748 - mae: 0.1352 - mse: 0.0673 - val_loss: 0.3319 - val_accuracy: 0.8744 - val_mae: 0.1296 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 996/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3318 - accuracy: 0.8770 - mae: 0.1303 - mse: 0.0663\n",
            "Epoch 996: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3289 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0667 - val_loss: 0.3331 - val_accuracy: 0.8744 - val_mae: 0.1296 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 997/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3169 - accuracy: 0.8760 - mae: 0.1343 - mse: 0.0651\n",
            "Epoch 997: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3269 - accuracy: 0.8748 - mae: 0.1345 - mse: 0.0667 - val_loss: 0.3341 - val_accuracy: 0.8744 - val_mae: 0.1291 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 998/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8662 - mae: 0.1353 - mse: 0.0688\n",
            "Epoch 998: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3235 - accuracy: 0.8748 - mae: 0.1330 - mse: 0.0664 - val_loss: 0.3348 - val_accuracy: 0.8744 - val_mae: 0.1287 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 999/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3597 - accuracy: 0.8623 - mae: 0.1404 - mse: 0.0726\n",
            "Epoch 999: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3281 - accuracy: 0.8748 - mae: 0.1332 - mse: 0.0669 - val_loss: 0.3342 - val_accuracy: 0.8744 - val_mae: 0.1278 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1000/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8682 - mae: 0.1371 - mse: 0.0713\n",
            "Epoch 1000: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3385 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0678 - val_loss: 0.3332 - val_accuracy: 0.8744 - val_mae: 0.1282 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1001/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8691 - mae: 0.1335 - mse: 0.0679\n",
            "Epoch 1001: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3277 - accuracy: 0.8745 - mae: 0.1320 - mse: 0.0663 - val_loss: 0.3326 - val_accuracy: 0.8731 - val_mae: 0.1285 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1002/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3046 - accuracy: 0.8818 - mae: 0.1281 - mse: 0.0622\n",
            "Epoch 1002: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3287 - accuracy: 0.8742 - mae: 0.1338 - mse: 0.0670 - val_loss: 0.3327 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1003/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8740 - mae: 0.1285 - mse: 0.0650\n",
            "Epoch 1003: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3362 - accuracy: 0.8742 - mae: 0.1341 - mse: 0.0678 - val_loss: 0.3328 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1004/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3488 - accuracy: 0.8613 - mae: 0.1406 - mse: 0.0726\n",
            "Epoch 1004: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3311 - accuracy: 0.8742 - mae: 0.1359 - mse: 0.0672 - val_loss: 0.3316 - val_accuracy: 0.8731 - val_mae: 0.1313 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1005/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8828 - mae: 0.1318 - mse: 0.0640\n",
            "Epoch 1005: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3332 - accuracy: 0.8745 - mae: 0.1361 - mse: 0.0676 - val_loss: 0.3301 - val_accuracy: 0.8731 - val_mae: 0.1316 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1006/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3149 - accuracy: 0.8789 - mae: 0.1328 - mse: 0.0644\n",
            "Epoch 1006: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3301 - accuracy: 0.8748 - mae: 0.1362 - mse: 0.0670 - val_loss: 0.3299 - val_accuracy: 0.8731 - val_mae: 0.1323 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1007/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3104 - accuracy: 0.8867 - mae: 0.1336 - mse: 0.0628\n",
            "Epoch 1007: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3287 - accuracy: 0.8742 - mae: 0.1359 - mse: 0.0669 - val_loss: 0.3290 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1008/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3225 - accuracy: 0.8760 - mae: 0.1343 - mse: 0.0660\n",
            "Epoch 1008: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3295 - accuracy: 0.8748 - mae: 0.1351 - mse: 0.0671 - val_loss: 0.3292 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1009/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8809 - mae: 0.1297 - mse: 0.0635\n",
            "Epoch 1009: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3296 - accuracy: 0.8745 - mae: 0.1326 - mse: 0.0670 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1276 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1010/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3199 - accuracy: 0.8779 - mae: 0.1331 - mse: 0.0657\n",
            "Epoch 1010: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3275 - accuracy: 0.8742 - mae: 0.1328 - mse: 0.0668 - val_loss: 0.3288 - val_accuracy: 0.8731 - val_mae: 0.1274 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1011/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8740 - mae: 0.1295 - mse: 0.0661\n",
            "Epoch 1011: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3272 - accuracy: 0.8742 - mae: 0.1333 - mse: 0.0671 - val_loss: 0.3291 - val_accuracy: 0.8731 - val_mae: 0.1292 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1012/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3239 - accuracy: 0.8760 - mae: 0.1340 - mse: 0.0660\n",
            "Epoch 1012: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3285 - accuracy: 0.8745 - mae: 0.1343 - mse: 0.0669 - val_loss: 0.3302 - val_accuracy: 0.8731 - val_mae: 0.1312 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1013/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8760 - mae: 0.1352 - mse: 0.0659\n",
            "Epoch 1013: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3290 - accuracy: 0.8739 - mae: 0.1361 - mse: 0.0669 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1334 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1014/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8838 - mae: 0.1358 - mse: 0.0636\n",
            "Epoch 1014: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.3283 - accuracy: 0.8748 - mae: 0.1382 - mse: 0.0666 - val_loss: 0.3304 - val_accuracy: 0.8731 - val_mae: 0.1348 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1015/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3253 - accuracy: 0.8691 - mae: 0.1401 - mse: 0.0678\n",
            "Epoch 1015: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3248 - accuracy: 0.8748 - mae: 0.1388 - mse: 0.0667 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1322 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1016/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8809 - mae: 0.1351 - mse: 0.0643\n",
            "Epoch 1016: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.3261 - accuracy: 0.8745 - mae: 0.1352 - mse: 0.0662 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1297 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1017/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3229 - accuracy: 0.8721 - mae: 0.1364 - mse: 0.0662\n",
            "Epoch 1017: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3250 - accuracy: 0.8742 - mae: 0.1343 - mse: 0.0661 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1288 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1018/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8779 - mae: 0.1337 - mse: 0.0665\n",
            "Epoch 1018: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3265 - accuracy: 0.8752 - mae: 0.1340 - mse: 0.0670 - val_loss: 0.3304 - val_accuracy: 0.8744 - val_mae: 0.1273 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1019/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3707 - accuracy: 0.8555 - mae: 0.1453 - mse: 0.0760\n",
            "Epoch 1019: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3257 - accuracy: 0.8739 - mae: 0.1323 - mse: 0.0668 - val_loss: 0.3320 - val_accuracy: 0.8744 - val_mae: 0.1261 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1020/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3460 - accuracy: 0.8701 - mae: 0.1338 - mse: 0.0694\n",
            "Epoch 1020: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3277 - accuracy: 0.8745 - mae: 0.1294 - mse: 0.0667 - val_loss: 0.3333 - val_accuracy: 0.8744 - val_mae: 0.1253 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1021/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3072 - accuracy: 0.8848 - mae: 0.1256 - mse: 0.0625\n",
            "Epoch 1021: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3293 - accuracy: 0.8752 - mae: 0.1295 - mse: 0.0669 - val_loss: 0.3337 - val_accuracy: 0.8744 - val_mae: 0.1266 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1022/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3288 - accuracy: 0.8721 - mae: 0.1304 - mse: 0.0663\n",
            "Epoch 1022: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3257 - accuracy: 0.8742 - mae: 0.1310 - mse: 0.0666 - val_loss: 0.3336 - val_accuracy: 0.8744 - val_mae: 0.1288 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 1023/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3427 - accuracy: 0.8623 - mae: 0.1386 - mse: 0.0714\n",
            "Epoch 1023: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3273 - accuracy: 0.8748 - mae: 0.1331 - mse: 0.0668 - val_loss: 0.3330 - val_accuracy: 0.8744 - val_mae: 0.1298 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1024/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8740 - mae: 0.1321 - mse: 0.0668\n",
            "Epoch 1024: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3285 - accuracy: 0.8748 - mae: 0.1340 - mse: 0.0667 - val_loss: 0.3325 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1025/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3451 - accuracy: 0.8633 - mae: 0.1388 - mse: 0.0716\n",
            "Epoch 1025: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3273 - accuracy: 0.8745 - mae: 0.1342 - mse: 0.0669 - val_loss: 0.3316 - val_accuracy: 0.8744 - val_mae: 0.1300 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1026/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8691 - mae: 0.1363 - mse: 0.0673\n",
            "Epoch 1026: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3231 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0662 - val_loss: 0.3308 - val_accuracy: 0.8744 - val_mae: 0.1294 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1027/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8789 - mae: 0.1316 - mse: 0.0647\n",
            "Epoch 1027: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3309 - accuracy: 0.8748 - mae: 0.1352 - mse: 0.0669 - val_loss: 0.3310 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1028/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8750 - mae: 0.1376 - mse: 0.0669\n",
            "Epoch 1028: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3256 - accuracy: 0.8748 - mae: 0.1365 - mse: 0.0664 - val_loss: 0.3319 - val_accuracy: 0.8744 - val_mae: 0.1342 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1029/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8672 - mae: 0.1446 - mse: 0.0704\n",
            "Epoch 1029: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3336 - accuracy: 0.8748 - mae: 0.1396 - mse: 0.0671 - val_loss: 0.3326 - val_accuracy: 0.8744 - val_mae: 0.1366 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1030/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3398 - accuracy: 0.8652 - mae: 0.1429 - mse: 0.0700\n",
            "Epoch 1030: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3267 - accuracy: 0.8739 - mae: 0.1403 - mse: 0.0669 - val_loss: 0.3303 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1031/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8662 - mae: 0.1418 - mse: 0.0701\n",
            "Epoch 1031: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3288 - accuracy: 0.8748 - mae: 0.1381 - mse: 0.0667 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1306 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1032/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8740 - mae: 0.1337 - mse: 0.0667\n",
            "Epoch 1032: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3274 - accuracy: 0.8739 - mae: 0.1331 - mse: 0.0666 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1269 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1033/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3147 - accuracy: 0.8828 - mae: 0.1265 - mse: 0.0632\n",
            "Epoch 1033: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3290 - accuracy: 0.8748 - mae: 0.1313 - mse: 0.0673 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1265 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1034/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3381 - accuracy: 0.8682 - mae: 0.1342 - mse: 0.0694\n",
            "Epoch 1034: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3252 - accuracy: 0.8745 - mae: 0.1316 - mse: 0.0667 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1280 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1035/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3115 - accuracy: 0.8857 - mae: 0.1296 - mse: 0.0627\n",
            "Epoch 1035: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3333 - accuracy: 0.8745 - mae: 0.1330 - mse: 0.0675 - val_loss: 0.3274 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1036/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3363 - accuracy: 0.8672 - mae: 0.1379 - mse: 0.0694\n",
            "Epoch 1036: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3309 - accuracy: 0.8755 - mae: 0.1352 - mse: 0.0672 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1315 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1037/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3225 - accuracy: 0.8818 - mae: 0.1328 - mse: 0.0654\n",
            "Epoch 1037: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3274 - accuracy: 0.8752 - mae: 0.1366 - mse: 0.0669 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1331 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1038/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3217 - accuracy: 0.8760 - mae: 0.1368 - mse: 0.0655\n",
            "Epoch 1038: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3236 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0662 - val_loss: 0.3297 - val_accuracy: 0.8744 - val_mae: 0.1343 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1039/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3211 - accuracy: 0.8789 - mae: 0.1370 - mse: 0.0658\n",
            "Epoch 1039: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3243 - accuracy: 0.8745 - mae: 0.1386 - mse: 0.0667 - val_loss: 0.3299 - val_accuracy: 0.8744 - val_mae: 0.1341 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1040/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8721 - mae: 0.1374 - mse: 0.0664\n",
            "Epoch 1040: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3300 - accuracy: 0.8748 - mae: 0.1382 - mse: 0.0670 - val_loss: 0.3291 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1041/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3153 - accuracy: 0.8770 - mae: 0.1332 - mse: 0.0647\n",
            "Epoch 1041: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3230 - accuracy: 0.8745 - mae: 0.1351 - mse: 0.0664 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1295 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1042/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3458 - accuracy: 0.8662 - mae: 0.1386 - mse: 0.0709\n",
            "Epoch 1042: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3313 - accuracy: 0.8745 - mae: 0.1340 - mse: 0.0673 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1280 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1043/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8711 - mae: 0.1333 - mse: 0.0681\n",
            "Epoch 1043: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3266 - accuracy: 0.8742 - mae: 0.1321 - mse: 0.0667 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1276 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1044/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3346 - accuracy: 0.8691 - mae: 0.1339 - mse: 0.0687\n",
            "Epoch 1044: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3263 - accuracy: 0.8745 - mae: 0.1325 - mse: 0.0670 - val_loss: 0.3289 - val_accuracy: 0.8744 - val_mae: 0.1285 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1045/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8721 - mae: 0.1345 - mse: 0.0689\n",
            "Epoch 1045: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3343 - accuracy: 0.8739 - mae: 0.1330 - mse: 0.0674 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1299 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1046/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8770 - mae: 0.1308 - mse: 0.0634\n",
            "Epoch 1046: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3246 - accuracy: 0.8745 - mae: 0.1339 - mse: 0.0665 - val_loss: 0.3294 - val_accuracy: 0.8731 - val_mae: 0.1314 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1047/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3099 - accuracy: 0.8838 - mae: 0.1307 - mse: 0.0622\n",
            "Epoch 1047: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3269 - accuracy: 0.8736 - mae: 0.1363 - mse: 0.0669 - val_loss: 0.3304 - val_accuracy: 0.8731 - val_mae: 0.1348 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1048/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3499 - accuracy: 0.8623 - mae: 0.1447 - mse: 0.0715\n",
            "Epoch 1048: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3321 - accuracy: 0.8742 - mae: 0.1401 - mse: 0.0672 - val_loss: 0.3312 - val_accuracy: 0.8731 - val_mae: 0.1373 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1049/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3532 - accuracy: 0.8555 - mae: 0.1496 - mse: 0.0734\n",
            "Epoch 1049: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3300 - accuracy: 0.8745 - mae: 0.1430 - mse: 0.0673 - val_loss: 0.3303 - val_accuracy: 0.8731 - val_mae: 0.1361 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1050/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3332 - accuracy: 0.8701 - mae: 0.1446 - mse: 0.0687\n",
            "Epoch 1050: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3295 - accuracy: 0.8742 - mae: 0.1400 - mse: 0.0671 - val_loss: 0.3292 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1051/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8633 - mae: 0.1417 - mse: 0.0712\n",
            "Epoch 1051: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3287 - accuracy: 0.8739 - mae: 0.1362 - mse: 0.0669 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1052/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3095 - accuracy: 0.8809 - mae: 0.1303 - mse: 0.0632\n",
            "Epoch 1052: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3236 - accuracy: 0.8745 - mae: 0.1335 - mse: 0.0663 - val_loss: 0.3271 - val_accuracy: 0.8731 - val_mae: 0.1281 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1053/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3600 - accuracy: 0.8672 - mae: 0.1398 - mse: 0.0720\n",
            "Epoch 1053: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3288 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0667 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1284 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1054/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3211 - accuracy: 0.8779 - mae: 0.1346 - mse: 0.0656\n",
            "Epoch 1054: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3245 - accuracy: 0.8745 - mae: 0.1347 - mse: 0.0664 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1055/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8809 - mae: 0.1332 - mse: 0.0644\n",
            "Epoch 1055: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3277 - accuracy: 0.8748 - mae: 0.1365 - mse: 0.0668 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1327 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1056/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8740 - mae: 0.1412 - mse: 0.0677\n",
            "Epoch 1056: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3255 - accuracy: 0.8736 - mae: 0.1382 - mse: 0.0666 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1340 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1057/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3517 - accuracy: 0.8652 - mae: 0.1439 - mse: 0.0725\n",
            "Epoch 1057: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3284 - accuracy: 0.8742 - mae: 0.1388 - mse: 0.0672 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1339 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1058/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3216 - accuracy: 0.8682 - mae: 0.1370 - mse: 0.0674\n",
            "Epoch 1058: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3297 - accuracy: 0.8745 - mae: 0.1385 - mse: 0.0672 - val_loss: 0.3271 - val_accuracy: 0.8731 - val_mae: 0.1328 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1059/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2941 - accuracy: 0.8936 - mae: 0.1262 - mse: 0.0578\n",
            "Epoch 1059: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3295 - accuracy: 0.8742 - mae: 0.1367 - mse: 0.0670 - val_loss: 0.3270 - val_accuracy: 0.8744 - val_mae: 0.1303 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1060/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8701 - mae: 0.1372 - mse: 0.0690\n",
            "Epoch 1060: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3237 - accuracy: 0.8745 - mae: 0.1350 - mse: 0.0667 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1061/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3437 - accuracy: 0.8701 - mae: 0.1391 - mse: 0.0699\n",
            "Epoch 1061: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3325 - accuracy: 0.8742 - mae: 0.1354 - mse: 0.0675 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1304 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1062/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3191 - accuracy: 0.8721 - mae: 0.1341 - mse: 0.0667\n",
            "Epoch 1062: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3243 - accuracy: 0.8745 - mae: 0.1336 - mse: 0.0663 - val_loss: 0.3287 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1063/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3378 - accuracy: 0.8691 - mae: 0.1385 - mse: 0.0693\n",
            "Epoch 1063: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3231 - accuracy: 0.8752 - mae: 0.1336 - mse: 0.0661 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1274 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1064/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3240 - accuracy: 0.8799 - mae: 0.1283 - mse: 0.0645\n",
            "Epoch 1064: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3318 - accuracy: 0.8748 - mae: 0.1318 - mse: 0.0670 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1267 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1065/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8740 - mae: 0.1296 - mse: 0.0663\n",
            "Epoch 1065: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3322 - accuracy: 0.8742 - mae: 0.1326 - mse: 0.0672 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1292 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1066/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8809 - mae: 0.1317 - mse: 0.0648\n",
            "Epoch 1066: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3261 - accuracy: 0.8745 - mae: 0.1345 - mse: 0.0666 - val_loss: 0.3294 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1067/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8809 - mae: 0.1328 - mse: 0.0638\n",
            "Epoch 1067: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3228 - accuracy: 0.8748 - mae: 0.1353 - mse: 0.0661 - val_loss: 0.3284 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1068/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8662 - mae: 0.1405 - mse: 0.0703\n",
            "Epoch 1068: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3277 - accuracy: 0.8742 - mae: 0.1363 - mse: 0.0668 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1069/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3137 - accuracy: 0.8818 - mae: 0.1306 - mse: 0.0637\n",
            "Epoch 1069: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3258 - accuracy: 0.8752 - mae: 0.1361 - mse: 0.0669 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1318 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1070/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8770 - mae: 0.1377 - mse: 0.0670\n",
            "Epoch 1070: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3291 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0669 - val_loss: 0.3262 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1071/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3360 - accuracy: 0.8721 - mae: 0.1357 - mse: 0.0681\n",
            "Epoch 1071: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3333 - accuracy: 0.8745 - mae: 0.1382 - mse: 0.0674 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1072/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3053 - accuracy: 0.8828 - mae: 0.1326 - mse: 0.0624\n",
            "Epoch 1072: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3233 - accuracy: 0.8739 - mae: 0.1359 - mse: 0.0662 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1073/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3111 - accuracy: 0.8789 - mae: 0.1338 - mse: 0.0637\n",
            "Epoch 1073: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3268 - accuracy: 0.8748 - mae: 0.1340 - mse: 0.0663 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1272 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1074/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8799 - mae: 0.1304 - mse: 0.0652\n",
            "Epoch 1074: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3289 - accuracy: 0.8745 - mae: 0.1336 - mse: 0.0669 - val_loss: 0.3253 - val_accuracy: 0.8744 - val_mae: 0.1278 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1075/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8721 - mae: 0.1343 - mse: 0.0674\n",
            "Epoch 1075: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3297 - accuracy: 0.8745 - mae: 0.1347 - mse: 0.0671 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1293 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1076/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3605 - accuracy: 0.8594 - mae: 0.1420 - mse: 0.0729\n",
            "Epoch 1076: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3334 - accuracy: 0.8739 - mae: 0.1361 - mse: 0.0671 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1312 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1077/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8779 - mae: 0.1352 - mse: 0.0649\n",
            "Epoch 1077: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3277 - accuracy: 0.8742 - mae: 0.1366 - mse: 0.0668 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1324 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1078/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3291 - accuracy: 0.8799 - mae: 0.1353 - mse: 0.0651\n",
            "Epoch 1078: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3301 - accuracy: 0.8745 - mae: 0.1384 - mse: 0.0672 - val_loss: 0.3275 - val_accuracy: 0.8744 - val_mae: 0.1349 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1079/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8623 - mae: 0.1435 - mse: 0.0707\n",
            "Epoch 1079: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3313 - accuracy: 0.8742 - mae: 0.1408 - mse: 0.0676 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1334 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1080/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3112 - accuracy: 0.8857 - mae: 0.1309 - mse: 0.0626\n",
            "Epoch 1080: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3263 - accuracy: 0.8748 - mae: 0.1374 - mse: 0.0666 - val_loss: 0.3259 - val_accuracy: 0.8744 - val_mae: 0.1319 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1081/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3482 - accuracy: 0.8594 - mae: 0.1426 - mse: 0.0726\n",
            "Epoch 1081: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3246 - accuracy: 0.8748 - mae: 0.1359 - mse: 0.0662 - val_loss: 0.3258 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1082/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8604 - mae: 0.1458 - mse: 0.0736\n",
            "Epoch 1082: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3279 - accuracy: 0.8742 - mae: 0.1372 - mse: 0.0668 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1310 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1083/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8730 - mae: 0.1366 - mse: 0.0660\n",
            "Epoch 1083: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3260 - accuracy: 0.8752 - mae: 0.1355 - mse: 0.0664 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1084/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8623 - mae: 0.1418 - mse: 0.0722\n",
            "Epoch 1084: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3298 - accuracy: 0.8745 - mae: 0.1359 - mse: 0.0673 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1313 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1085/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8643 - mae: 0.1370 - mse: 0.0687\n",
            "Epoch 1085: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3289 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0667 - val_loss: 0.3272 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1086/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8740 - mae: 0.1391 - mse: 0.0677\n",
            "Epoch 1086: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3284 - accuracy: 0.8748 - mae: 0.1372 - mse: 0.0668 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1309 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1087/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3571 - accuracy: 0.8604 - mae: 0.1431 - mse: 0.0732\n",
            "Epoch 1087: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3265 - accuracy: 0.8748 - mae: 0.1351 - mse: 0.0668 - val_loss: 0.3266 - val_accuracy: 0.8744 - val_mae: 0.1307 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1088/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8672 - mae: 0.1392 - mse: 0.0696\n",
            "Epoch 1088: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3249 - accuracy: 0.8745 - mae: 0.1355 - mse: 0.0667 - val_loss: 0.3281 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1089/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8750 - mae: 0.1354 - mse: 0.0667\n",
            "Epoch 1089: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3283 - accuracy: 0.8748 - mae: 0.1383 - mse: 0.0670 - val_loss: 0.3307 - val_accuracy: 0.8744 - val_mae: 0.1357 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1090/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8770 - mae: 0.1368 - mse: 0.0659\n",
            "Epoch 1090: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3247 - accuracy: 0.8752 - mae: 0.1399 - mse: 0.0666 - val_loss: 0.3327 - val_accuracy: 0.8744 - val_mae: 0.1388 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 1091/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3370 - accuracy: 0.8652 - mae: 0.1468 - mse: 0.0700\n",
            "Epoch 1091: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3242 - accuracy: 0.8742 - mae: 0.1425 - mse: 0.0665 - val_loss: 0.3328 - val_accuracy: 0.8744 - val_mae: 0.1383 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 1092/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8760 - mae: 0.1401 - mse: 0.0668\n",
            "Epoch 1092: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3337 - accuracy: 0.8739 - mae: 0.1427 - mse: 0.0680 - val_loss: 0.3311 - val_accuracy: 0.8744 - val_mae: 0.1351 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1093/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8848 - mae: 0.1295 - mse: 0.0610\n",
            "Epoch 1093: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3272 - accuracy: 0.8745 - mae: 0.1389 - mse: 0.0671 - val_loss: 0.3286 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1094/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3447 - accuracy: 0.8613 - mae: 0.1420 - mse: 0.0723\n",
            "Epoch 1094: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3281 - accuracy: 0.8748 - mae: 0.1355 - mse: 0.0668 - val_loss: 0.3276 - val_accuracy: 0.8744 - val_mae: 0.1289 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1095/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3503 - accuracy: 0.8604 - mae: 0.1401 - mse: 0.0730\n",
            "Epoch 1095: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3332 - accuracy: 0.8745 - mae: 0.1358 - mse: 0.0677 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1304 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1096/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3499 - accuracy: 0.8584 - mae: 0.1420 - mse: 0.0728\n",
            "Epoch 1096: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3288 - accuracy: 0.8742 - mae: 0.1363 - mse: 0.0668 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1097/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8662 - mae: 0.1429 - mse: 0.0702\n",
            "Epoch 1097: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3321 - accuracy: 0.8748 - mae: 0.1373 - mse: 0.0674 - val_loss: 0.3279 - val_accuracy: 0.8744 - val_mae: 0.1304 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1098/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8711 - mae: 0.1361 - mse: 0.0679\n",
            "Epoch 1098: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3218 - accuracy: 0.8742 - mae: 0.1341 - mse: 0.0662 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1306 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1099/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3280 - accuracy: 0.8779 - mae: 0.1347 - mse: 0.0657\n",
            "Epoch 1099: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3309 - accuracy: 0.8742 - mae: 0.1356 - mse: 0.0668 - val_loss: 0.3277 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1100/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8809 - mae: 0.1337 - mse: 0.0659\n",
            "Epoch 1100: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3293 - accuracy: 0.8742 - mae: 0.1352 - mse: 0.0669 - val_loss: 0.3278 - val_accuracy: 0.8744 - val_mae: 0.1314 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1101/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8838 - mae: 0.1331 - mse: 0.0637\n",
            "Epoch 1101: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3257 - accuracy: 0.8742 - mae: 0.1353 - mse: 0.0664 - val_loss: 0.3285 - val_accuracy: 0.8744 - val_mae: 0.1320 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1102/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8770 - mae: 0.1328 - mse: 0.0650\n",
            "Epoch 1102: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3243 - accuracy: 0.8752 - mae: 0.1345 - mse: 0.0662 - val_loss: 0.3296 - val_accuracy: 0.8744 - val_mae: 0.1321 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1103/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3316 - accuracy: 0.8789 - mae: 0.1366 - mse: 0.0664\n",
            "Epoch 1103: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3263 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0667 - val_loss: 0.3304 - val_accuracy: 0.8744 - val_mae: 0.1317 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1104/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8643 - mae: 0.1393 - mse: 0.0702\n",
            "Epoch 1104: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3259 - accuracy: 0.8739 - mae: 0.1348 - mse: 0.0666 - val_loss: 0.3312 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1105/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3469 - accuracy: 0.8633 - mae: 0.1431 - mse: 0.0721\n",
            "Epoch 1105: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3268 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0668 - val_loss: 0.3319 - val_accuracy: 0.8744 - val_mae: 0.1336 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1106/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8662 - mae: 0.1391 - mse: 0.0693\n",
            "Epoch 1106: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3272 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0668 - val_loss: 0.3307 - val_accuracy: 0.8744 - val_mae: 0.1328 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1107/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3115 - accuracy: 0.8838 - mae: 0.1305 - mse: 0.0629\n",
            "Epoch 1107: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3264 - accuracy: 0.8745 - mae: 0.1364 - mse: 0.0665 - val_loss: 0.3292 - val_accuracy: 0.8744 - val_mae: 0.1329 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1108/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3089 - accuracy: 0.8887 - mae: 0.1332 - mse: 0.0614\n",
            "Epoch 1108: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3214 - accuracy: 0.8745 - mae: 0.1359 - mse: 0.0658 - val_loss: 0.3280 - val_accuracy: 0.8744 - val_mae: 0.1335 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1109/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3197 - accuracy: 0.8730 - mae: 0.1369 - mse: 0.0665\n",
            "Epoch 1109: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3277 - accuracy: 0.8748 - mae: 0.1381 - mse: 0.0669 - val_loss: 0.3264 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1110/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8721 - mae: 0.1372 - mse: 0.0687\n",
            "Epoch 1110: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3275 - accuracy: 0.8748 - mae: 0.1367 - mse: 0.0664 - val_loss: 0.3263 - val_accuracy: 0.8744 - val_mae: 0.1327 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1111/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3395 - accuracy: 0.8633 - mae: 0.1404 - mse: 0.0706\n",
            "Epoch 1111: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3271 - accuracy: 0.8745 - mae: 0.1356 - mse: 0.0660 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1311 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1112/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8711 - mae: 0.1413 - mse: 0.0699\n",
            "Epoch 1112: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3254 - accuracy: 0.8745 - mae: 0.1351 - mse: 0.0666 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1299 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1113/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0664\n",
            "Epoch 1113: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.3285 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0664 - val_loss: 0.3257 - val_accuracy: 0.8744 - val_mae: 0.1294 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1114/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3233 - accuracy: 0.8750 - mae: 0.1327 - mse: 0.0663\n",
            "Epoch 1114: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3261 - accuracy: 0.8745 - mae: 0.1338 - mse: 0.0665 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1298 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1115/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3222 - accuracy: 0.8779 - mae: 0.1324 - mse: 0.0653\n",
            "Epoch 1115: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3331 - accuracy: 0.8745 - mae: 0.1350 - mse: 0.0670 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1303 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1116/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8760 - mae: 0.1364 - mse: 0.0670\n",
            "Epoch 1116: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3329 - accuracy: 0.8748 - mae: 0.1363 - mse: 0.0672 - val_loss: 0.3276 - val_accuracy: 0.8731 - val_mae: 0.1310 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1117/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3207 - accuracy: 0.8740 - mae: 0.1342 - mse: 0.0656\n",
            "Epoch 1117: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3244 - accuracy: 0.8742 - mae: 0.1358 - mse: 0.0666 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1299 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1118/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8604 - mae: 0.1412 - mse: 0.0709\n",
            "Epoch 1118: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3258 - accuracy: 0.8745 - mae: 0.1352 - mse: 0.0667 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1119/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3205 - accuracy: 0.8779 - mae: 0.1351 - mse: 0.0655\n",
            "Epoch 1119: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3277 - accuracy: 0.8742 - mae: 0.1360 - mse: 0.0667 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1319 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1120/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2995 - accuracy: 0.8906 - mae: 0.1285 - mse: 0.0597\n",
            "Epoch 1120: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3268 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0667 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1329 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1121/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8779 - mae: 0.1386 - mse: 0.0668\n",
            "Epoch 1121: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3305 - accuracy: 0.8752 - mae: 0.1367 - mse: 0.0669 - val_loss: 0.3315 - val_accuracy: 0.8731 - val_mae: 0.1351 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1122/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8848 - mae: 0.1329 - mse: 0.0622\n",
            "Epoch 1122: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3279 - accuracy: 0.8745 - mae: 0.1390 - mse: 0.0670 - val_loss: 0.3303 - val_accuracy: 0.8731 - val_mae: 0.1346 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1123/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8711 - mae: 0.1386 - mse: 0.0671\n",
            "Epoch 1123: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3273 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0668 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1318 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1124/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3106 - accuracy: 0.8857 - mae: 0.1324 - mse: 0.0625\n",
            "Epoch 1124: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.3274 - accuracy: 0.8745 - mae: 0.1356 - mse: 0.0667 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1125/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3222 - accuracy: 0.8750 - mae: 0.1317 - mse: 0.0663\n",
            "Epoch 1125: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.3268 - accuracy: 0.8745 - mae: 0.1345 - mse: 0.0668 - val_loss: 0.3271 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1126/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8682 - mae: 0.1367 - mse: 0.0686\n",
            "Epoch 1126: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3252 - accuracy: 0.8748 - mae: 0.1350 - mse: 0.0666 - val_loss: 0.3278 - val_accuracy: 0.8731 - val_mae: 0.1318 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1127/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8633 - mae: 0.1436 - mse: 0.0727\n",
            "Epoch 1127: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3286 - accuracy: 0.8742 - mae: 0.1372 - mse: 0.0667 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1313 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1128/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8701 - mae: 0.1377 - mse: 0.0679\n",
            "Epoch 1128: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3270 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0666 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1285 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1129/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3335 - accuracy: 0.8701 - mae: 0.1357 - mse: 0.0688\n",
            "Epoch 1129: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3201 - accuracy: 0.8745 - mae: 0.1321 - mse: 0.0660 - val_loss: 0.3282 - val_accuracy: 0.8731 - val_mae: 0.1271 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1130/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8789 - mae: 0.1307 - mse: 0.0663\n",
            "Epoch 1130: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.3323 - accuracy: 0.8742 - mae: 0.1319 - mse: 0.0671 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1131/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3427 - accuracy: 0.8701 - mae: 0.1351 - mse: 0.0703\n",
            "Epoch 1131: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3258 - accuracy: 0.8745 - mae: 0.1323 - mse: 0.0663 - val_loss: 0.3280 - val_accuracy: 0.8731 - val_mae: 0.1283 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1132/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3409 - accuracy: 0.8604 - mae: 0.1357 - mse: 0.0713\n",
            "Epoch 1132: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3223 - accuracy: 0.8742 - mae: 0.1322 - mse: 0.0662 - val_loss: 0.3280 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1133/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3641 - accuracy: 0.8623 - mae: 0.1386 - mse: 0.0727\n",
            "Epoch 1133: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3275 - accuracy: 0.8742 - mae: 0.1320 - mse: 0.0663 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1276 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1134/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8779 - mae: 0.1277 - mse: 0.0638\n",
            "Epoch 1134: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3280 - accuracy: 0.8745 - mae: 0.1319 - mse: 0.0665 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1135/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3005 - accuracy: 0.8984 - mae: 0.1251 - mse: 0.0583\n",
            "Epoch 1135: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3288 - accuracy: 0.8745 - mae: 0.1342 - mse: 0.0668 - val_loss: 0.3301 - val_accuracy: 0.8731 - val_mae: 0.1319 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1136/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8701 - mae: 0.1412 - mse: 0.0700\n",
            "Epoch 1136: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3259 - accuracy: 0.8745 - mae: 0.1373 - mse: 0.0670 - val_loss: 0.3321 - val_accuracy: 0.8731 - val_mae: 0.1351 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1137/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3376 - accuracy: 0.8643 - mae: 0.1421 - mse: 0.0704\n",
            "Epoch 1137: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3269 - accuracy: 0.8745 - mae: 0.1397 - mse: 0.0669 - val_loss: 0.3328 - val_accuracy: 0.8731 - val_mae: 0.1353 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1138/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.8745 - mae: 0.1393 - mse: 0.0671\n",
            "Epoch 1138: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3292 - accuracy: 0.8745 - mae: 0.1393 - mse: 0.0671 - val_loss: 0.3320 - val_accuracy: 0.8731 - val_mae: 0.1331 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1139/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3260 - accuracy: 0.8740 - mae: 0.1372 - mse: 0.0666\n",
            "Epoch 1139: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3261 - accuracy: 0.8745 - mae: 0.1363 - mse: 0.0664 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1140/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8752 - mae: 0.1341 - mse: 0.0665\n",
            "Epoch 1140: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3270 - accuracy: 0.8752 - mae: 0.1341 - mse: 0.0665 - val_loss: 0.3290 - val_accuracy: 0.8731 - val_mae: 0.1274 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1141/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3364 - accuracy: 0.8760 - mae: 0.1311 - mse: 0.0674\n",
            "Epoch 1141: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3324 - accuracy: 0.8739 - mae: 0.1307 - mse: 0.0668 - val_loss: 0.3273 - val_accuracy: 0.8744 - val_mae: 0.1254 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1142/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3266 - accuracy: 0.8770 - mae: 0.1288 - mse: 0.0655\n",
            "Epoch 1142: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3282 - accuracy: 0.8748 - mae: 0.1308 - mse: 0.0667 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1267 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1143/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8750 - mae: 0.1296 - mse: 0.0656\n",
            "Epoch 1143: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3227 - accuracy: 0.8742 - mae: 0.1322 - mse: 0.0660 - val_loss: 0.3272 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1144/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3116 - accuracy: 0.8818 - mae: 0.1314 - mse: 0.0626\n",
            "Epoch 1144: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3254 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0668 - val_loss: 0.3280 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1145/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3109 - accuracy: 0.8789 - mae: 0.1342 - mse: 0.0639\n",
            "Epoch 1145: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3229 - accuracy: 0.8745 - mae: 0.1374 - mse: 0.0663 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1146/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8701 - mae: 0.1394 - mse: 0.0685\n",
            "Epoch 1146: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3262 - accuracy: 0.8755 - mae: 0.1364 - mse: 0.0665 - val_loss: 0.3277 - val_accuracy: 0.8731 - val_mae: 0.1318 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1147/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3150 - accuracy: 0.8848 - mae: 0.1340 - mse: 0.0631\n",
            "Epoch 1147: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3314 - accuracy: 0.8739 - mae: 0.1373 - mse: 0.0675 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1307 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1148/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8760 - mae: 0.1358 - mse: 0.0667\n",
            "Epoch 1148: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3232 - accuracy: 0.8748 - mae: 0.1341 - mse: 0.0662 - val_loss: 0.3255 - val_accuracy: 0.8744 - val_mae: 0.1298 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1149/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8770 - mae: 0.1337 - mse: 0.0649\n",
            "Epoch 1149: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3253 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0660 - val_loss: 0.3250 - val_accuracy: 0.8744 - val_mae: 0.1285 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1150/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3273 - accuracy: 0.8721 - mae: 0.1339 - mse: 0.0677\n",
            "Epoch 1150: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3244 - accuracy: 0.8748 - mae: 0.1323 - mse: 0.0662 - val_loss: 0.3248 - val_accuracy: 0.8744 - val_mae: 0.1282 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1151/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3054 - accuracy: 0.8867 - mae: 0.1279 - mse: 0.0611\n",
            "Epoch 1151: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3245 - accuracy: 0.8745 - mae: 0.1331 - mse: 0.0660 - val_loss: 0.3256 - val_accuracy: 0.8744 - val_mae: 0.1291 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1152/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8809 - mae: 0.1361 - mse: 0.0668\n",
            "Epoch 1152: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3279 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0668 - val_loss: 0.3267 - val_accuracy: 0.8744 - val_mae: 0.1308 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1153/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8740 - mae: 0.1364 - mse: 0.0669\n",
            "Epoch 1153: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3268 - accuracy: 0.8748 - mae: 0.1369 - mse: 0.0670 - val_loss: 0.3288 - val_accuracy: 0.8744 - val_mae: 0.1326 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1154/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2923 - accuracy: 0.8975 - mae: 0.1269 - mse: 0.0579\n",
            "Epoch 1154: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3261 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0665 - val_loss: 0.3283 - val_accuracy: 0.8744 - val_mae: 0.1325 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1155/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3275 - accuracy: 0.8789 - mae: 0.1326 - mse: 0.0655\n",
            "Epoch 1155: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3254 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0667 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1309 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1156/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3219 - accuracy: 0.8691 - mae: 0.1355 - mse: 0.0671\n",
            "Epoch 1156: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3233 - accuracy: 0.8745 - mae: 0.1340 - mse: 0.0659 - val_loss: 0.3253 - val_accuracy: 0.8731 - val_mae: 0.1276 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1157/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3135 - accuracy: 0.8770 - mae: 0.1297 - mse: 0.0646\n",
            "Epoch 1157: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3234 - accuracy: 0.8752 - mae: 0.1314 - mse: 0.0665 - val_loss: 0.3249 - val_accuracy: 0.8731 - val_mae: 0.1271 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1158/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8887 - mae: 0.1246 - mse: 0.0615\n",
            "Epoch 1158: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3292 - accuracy: 0.8745 - mae: 0.1326 - mse: 0.0670 - val_loss: 0.3251 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1159/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3516 - accuracy: 0.8574 - mae: 0.1434 - mse: 0.0739\n",
            "Epoch 1159: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3256 - accuracy: 0.8745 - mae: 0.1365 - mse: 0.0667 - val_loss: 0.3268 - val_accuracy: 0.8731 - val_mae: 0.1353 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1160/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8623 - mae: 0.1450 - mse: 0.0717\n",
            "Epoch 1160: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3277 - accuracy: 0.8742 - mae: 0.1396 - mse: 0.0670 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1386 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1161/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8643 - mae: 0.1427 - mse: 0.0687\n",
            "Epoch 1161: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3315 - accuracy: 0.8752 - mae: 0.1422 - mse: 0.0669 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1383 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1162/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3208 - accuracy: 0.8750 - mae: 0.1395 - mse: 0.0661\n",
            "Epoch 1162: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3206 - accuracy: 0.8761 - mae: 0.1395 - mse: 0.0659 - val_loss: 0.3280 - val_accuracy: 0.8731 - val_mae: 0.1335 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1163/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3045 - accuracy: 0.8867 - mae: 0.1318 - mse: 0.0617\n",
            "Epoch 1163: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3250 - accuracy: 0.8748 - mae: 0.1360 - mse: 0.0665 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1312 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1164/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3168 - accuracy: 0.8740 - mae: 0.1320 - mse: 0.0656\n",
            "Epoch 1164: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3247 - accuracy: 0.8742 - mae: 0.1339 - mse: 0.0663 - val_loss: 0.3300 - val_accuracy: 0.8731 - val_mae: 0.1314 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1165/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3318 - accuracy: 0.8701 - mae: 0.1375 - mse: 0.0689\n",
            "Epoch 1165: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3231 - accuracy: 0.8745 - mae: 0.1335 - mse: 0.0663 - val_loss: 0.3310 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1166/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3154 - accuracy: 0.8701 - mae: 0.1338 - mse: 0.0666\n",
            "Epoch 1166: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3262 - accuracy: 0.8748 - mae: 0.1351 - mse: 0.0665 - val_loss: 0.3314 - val_accuracy: 0.8731 - val_mae: 0.1319 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1167/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3149 - accuracy: 0.8799 - mae: 0.1296 - mse: 0.0640\n",
            "Epoch 1167: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3245 - accuracy: 0.8752 - mae: 0.1331 - mse: 0.0661 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1283 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1168/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3405 - accuracy: 0.8682 - mae: 0.1340 - mse: 0.0690\n",
            "Epoch 1168: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3282 - accuracy: 0.8745 - mae: 0.1302 - mse: 0.0662 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1252 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1169/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8730 - mae: 0.1273 - mse: 0.0658\n",
            "Epoch 1169: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3254 - accuracy: 0.8742 - mae: 0.1283 - mse: 0.0666 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1244 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1170/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3192 - accuracy: 0.8818 - mae: 0.1252 - mse: 0.0639\n",
            "Epoch 1170: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3305 - accuracy: 0.8745 - mae: 0.1287 - mse: 0.0669 - val_loss: 0.3290 - val_accuracy: 0.8731 - val_mae: 0.1255 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1171/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8691 - mae: 0.1317 - mse: 0.0691\n",
            "Epoch 1171: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3237 - accuracy: 0.8739 - mae: 0.1296 - mse: 0.0667 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1172/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8721 - mae: 0.1324 - mse: 0.0667\n",
            "Epoch 1172: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3268 - accuracy: 0.8736 - mae: 0.1333 - mse: 0.0667 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1313 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1173/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3441 - accuracy: 0.8604 - mae: 0.1429 - mse: 0.0721\n",
            "Epoch 1173: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3259 - accuracy: 0.8748 - mae: 0.1358 - mse: 0.0667 - val_loss: 0.3296 - val_accuracy: 0.8731 - val_mae: 0.1330 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1174/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8691 - mae: 0.1356 - mse: 0.0674\n",
            "Epoch 1174: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3244 - accuracy: 0.8745 - mae: 0.1352 - mse: 0.0660 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1336 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1175/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3068 - accuracy: 0.8857 - mae: 0.1300 - mse: 0.0613\n",
            "Epoch 1175: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3321 - accuracy: 0.8745 - mae: 0.1370 - mse: 0.0673 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1329 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1176/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8662 - mae: 0.1386 - mse: 0.0698\n",
            "Epoch 1176: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3229 - accuracy: 0.8742 - mae: 0.1355 - mse: 0.0664 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1332 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1177/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3153 - accuracy: 0.8779 - mae: 0.1341 - mse: 0.0649\n",
            "Epoch 1177: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3248 - accuracy: 0.8745 - mae: 0.1367 - mse: 0.0665 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1327 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1178/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3192 - accuracy: 0.8789 - mae: 0.1339 - mse: 0.0652\n",
            "Epoch 1178: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3244 - accuracy: 0.8739 - mae: 0.1362 - mse: 0.0666 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1308 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1179/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3205 - accuracy: 0.8711 - mae: 0.1335 - mse: 0.0667\n",
            "Epoch 1179: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3257 - accuracy: 0.8742 - mae: 0.1342 - mse: 0.0668 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1180/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8701 - mae: 0.1343 - mse: 0.0686\n",
            "Epoch 1180: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3240 - accuracy: 0.8752 - mae: 0.1332 - mse: 0.0663 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1181/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8779 - mae: 0.1326 - mse: 0.0668\n",
            "Epoch 1181: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3290 - accuracy: 0.8745 - mae: 0.1327 - mse: 0.0672 - val_loss: 0.3254 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1182/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3067 - accuracy: 0.8896 - mae: 0.1290 - mse: 0.0610\n",
            "Epoch 1182: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3248 - accuracy: 0.8748 - mae: 0.1338 - mse: 0.0663 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1308 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1183/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8711 - mae: 0.1356 - mse: 0.0680\n",
            "Epoch 1183: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3239 - accuracy: 0.8745 - mae: 0.1349 - mse: 0.0664 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1311 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1184/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3179 - accuracy: 0.8877 - mae: 0.1270 - mse: 0.0622\n",
            "Epoch 1184: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3323 - accuracy: 0.8742 - mae: 0.1347 - mse: 0.0672 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1185/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3095 - accuracy: 0.8857 - mae: 0.1297 - mse: 0.0619\n",
            "Epoch 1185: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3247 - accuracy: 0.8752 - mae: 0.1356 - mse: 0.0664 - val_loss: 0.3270 - val_accuracy: 0.8731 - val_mae: 0.1340 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1186/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3456 - accuracy: 0.8633 - mae: 0.1430 - mse: 0.0711\n",
            "Epoch 1186: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3270 - accuracy: 0.8748 - mae: 0.1384 - mse: 0.0667 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1344 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1187/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8730 - mae: 0.1402 - mse: 0.0664\n",
            "Epoch 1187: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3245 - accuracy: 0.8736 - mae: 0.1379 - mse: 0.0667 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1188/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3146 - accuracy: 0.8857 - mae: 0.1337 - mse: 0.0636\n",
            "Epoch 1188: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3215 - accuracy: 0.8742 - mae: 0.1356 - mse: 0.0662 - val_loss: 0.3269 - val_accuracy: 0.8731 - val_mae: 0.1321 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1189/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3265 - accuracy: 0.8740 - mae: 0.1355 - mse: 0.0670\n",
            "Epoch 1189: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3242 - accuracy: 0.8748 - mae: 0.1354 - mse: 0.0664 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1315 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1190/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3317 - accuracy: 0.8799 - mae: 0.1350 - mse: 0.0656\n",
            "Epoch 1190: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3295 - accuracy: 0.8742 - mae: 0.1354 - mse: 0.0669 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1302 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1191/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8848 - mae: 0.1303 - mse: 0.0625\n",
            "Epoch 1191: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3243 - accuracy: 0.8745 - mae: 0.1353 - mse: 0.0665 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1192/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8721 - mae: 0.1364 - mse: 0.0675\n",
            "Epoch 1192: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3240 - accuracy: 0.8742 - mae: 0.1356 - mse: 0.0664 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1320 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1193/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3361 - accuracy: 0.8691 - mae: 0.1393 - mse: 0.0685\n",
            "Epoch 1193: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3259 - accuracy: 0.8748 - mae: 0.1373 - mse: 0.0664 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1194/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8730 - mae: 0.1374 - mse: 0.0678\n",
            "Epoch 1194: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3278 - accuracy: 0.8745 - mae: 0.1367 - mse: 0.0667 - val_loss: 0.3263 - val_accuracy: 0.8731 - val_mae: 0.1319 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1195/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8701 - mae: 0.1385 - mse: 0.0680\n",
            "Epoch 1195: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3272 - accuracy: 0.8748 - mae: 0.1360 - mse: 0.0665 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1300 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1196/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8742 - mae: 0.1348 - mse: 0.0664\n",
            "Epoch 1196: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3254 - accuracy: 0.8742 - mae: 0.1348 - mse: 0.0664 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1197/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8745 - mae: 0.1354 - mse: 0.0669\n",
            "Epoch 1197: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.3312 - accuracy: 0.8745 - mae: 0.1354 - mse: 0.0669 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1295 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1198/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3270 - accuracy: 0.8743 - mae: 0.1340 - mse: 0.0671\n",
            "Epoch 1198: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 0.3257 - accuracy: 0.8752 - mae: 0.1341 - mse: 0.0668 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1199/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3267 - accuracy: 0.8740 - mae: 0.1337 - mse: 0.0668\n",
            "Epoch 1199: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.3243 - accuracy: 0.8752 - mae: 0.1333 - mse: 0.0662 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1272 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1200/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3207 - accuracy: 0.8766 - mae: 0.1311 - mse: 0.0653\n",
            "Epoch 1200: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.3239 - accuracy: 0.8745 - mae: 0.1320 - mse: 0.0661 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1261 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1201/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3249 - accuracy: 0.8743 - mae: 0.1322 - mse: 0.0666\n",
            "Epoch 1201: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.3255 - accuracy: 0.8748 - mae: 0.1320 - mse: 0.0666 - val_loss: 0.3264 - val_accuracy: 0.8731 - val_mae: 0.1279 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1202/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3294 - accuracy: 0.8730 - mae: 0.1345 - mse: 0.0674\n",
            "Epoch 1202: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.3261 - accuracy: 0.8748 - mae: 0.1337 - mse: 0.0666 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1203/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3210 - accuracy: 0.8750 - mae: 0.1330 - mse: 0.0658\n",
            "Epoch 1203: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 102ms/step - loss: 0.3217 - accuracy: 0.8748 - mae: 0.1332 - mse: 0.0659 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1291 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1204/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3231 - accuracy: 0.8737 - mae: 0.1325 - mse: 0.0660\n",
            "Epoch 1204: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.3222 - accuracy: 0.8745 - mae: 0.1324 - mse: 0.0657 - val_loss: 0.3294 - val_accuracy: 0.8731 - val_mae: 0.1292 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1205/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3230 - accuracy: 0.8750 - mae: 0.1328 - mse: 0.0662\n",
            "Epoch 1205: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.3229 - accuracy: 0.8748 - mae: 0.1328 - mse: 0.0663 - val_loss: 0.3303 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1206/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3293 - accuracy: 0.8734 - mae: 0.1337 - mse: 0.0671\n",
            "Epoch 1206: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.3272 - accuracy: 0.8745 - mae: 0.1329 - mse: 0.0666 - val_loss: 0.3299 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1207/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.8748 - mae: 0.1335 - mse: 0.0666\n",
            "Epoch 1207: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.3292 - accuracy: 0.8748 - mae: 0.1335 - mse: 0.0666 - val_loss: 0.3291 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1208/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8748 - mae: 0.1325 - mse: 0.0663\n",
            "Epoch 1208: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.3281 - accuracy: 0.8748 - mae: 0.1325 - mse: 0.0663 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1274 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1209/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3209 - accuracy: 0.8760 - mae: 0.1294 - mse: 0.0657\n",
            "Epoch 1209: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.3226 - accuracy: 0.8752 - mae: 0.1299 - mse: 0.0660 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1276 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1210/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.8739 - mae: 0.1315 - mse: 0.0662\n",
            "Epoch 1210: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.3252 - accuracy: 0.8739 - mae: 0.1315 - mse: 0.0662 - val_loss: 0.3298 - val_accuracy: 0.8731 - val_mae: 0.1296 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1211/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3264 - accuracy: 0.8737 - mae: 0.1337 - mse: 0.0661\n",
            "Epoch 1211: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.3269 - accuracy: 0.8739 - mae: 0.1339 - mse: 0.0662 - val_loss: 0.3308 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1212/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3344 - accuracy: 0.8743 - mae: 0.1363 - mse: 0.0668\n",
            "Epoch 1212: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.3327 - accuracy: 0.8748 - mae: 0.1360 - mse: 0.0665 - val_loss: 0.3314 - val_accuracy: 0.8731 - val_mae: 0.1330 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1213/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8748 - mae: 0.1355 - mse: 0.0663\n",
            "Epoch 1213: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.3234 - accuracy: 0.8748 - mae: 0.1355 - mse: 0.0663 - val_loss: 0.3311 - val_accuracy: 0.8731 - val_mae: 0.1315 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1214/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3277 - accuracy: 0.8750 - mae: 0.1350 - mse: 0.0668\n",
            "Epoch 1214: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 106ms/step - loss: 0.3290 - accuracy: 0.8748 - mae: 0.1351 - mse: 0.0670 - val_loss: 0.3315 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1215/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3229 - accuracy: 0.8753 - mae: 0.1341 - mse: 0.0659\n",
            "Epoch 1215: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.3230 - accuracy: 0.8748 - mae: 0.1342 - mse: 0.0659 - val_loss: 0.3328 - val_accuracy: 0.8731 - val_mae: 0.1320 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1216/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3265 - accuracy: 0.8730 - mae: 0.1365 - mse: 0.0672\n",
            "Epoch 1216: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.3245 - accuracy: 0.8748 - mae: 0.1361 - mse: 0.0667 - val_loss: 0.3326 - val_accuracy: 0.8731 - val_mae: 0.1311 - val_mse: 0.0684 - lr: 1.0000e-04\n",
            "Epoch 1217/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3268 - accuracy: 0.8757 - mae: 0.1340 - mse: 0.0664\n",
            "Epoch 1217: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.3295 - accuracy: 0.8745 - mae: 0.1346 - mse: 0.0670 - val_loss: 0.3311 - val_accuracy: 0.8731 - val_mae: 0.1296 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1218/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8742 - mae: 0.1327 - mse: 0.0662\n",
            "Epoch 1218: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.3217 - accuracy: 0.8742 - mae: 0.1327 - mse: 0.0662 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1296 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1219/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3254 - accuracy: 0.8747 - mae: 0.1348 - mse: 0.0665\n",
            "Epoch 1219: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 101ms/step - loss: 0.3262 - accuracy: 0.8739 - mae: 0.1352 - mse: 0.0668 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1316 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1220/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8739 - mae: 0.1371 - mse: 0.0661\n",
            "Epoch 1220: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.3219 - accuracy: 0.8739 - mae: 0.1371 - mse: 0.0661 - val_loss: 0.3269 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1221/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0664\n",
            "Epoch 1221: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3244 - accuracy: 0.8748 - mae: 0.1370 - mse: 0.0664 - val_loss: 0.3260 - val_accuracy: 0.8731 - val_mae: 0.1317 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1222/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3543 - accuracy: 0.8594 - mae: 0.1437 - mse: 0.0734\n",
            "Epoch 1222: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.3269 - accuracy: 0.8748 - mae: 0.1376 - mse: 0.0667 - val_loss: 0.3270 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1223/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0665\n",
            "Epoch 1223: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.3243 - accuracy: 0.8745 - mae: 0.1360 - mse: 0.0665 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1224/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3234 - accuracy: 0.8766 - mae: 0.1334 - mse: 0.0661\n",
            "Epoch 1224: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.3250 - accuracy: 0.8748 - mae: 0.1343 - mse: 0.0667 - val_loss: 0.3277 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1225/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8755 - mae: 0.1330 - mse: 0.0660\n",
            "Epoch 1225: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.3245 - accuracy: 0.8755 - mae: 0.1330 - mse: 0.0660 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1226/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3294 - accuracy: 0.8737 - mae: 0.1341 - mse: 0.0668\n",
            "Epoch 1226: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.3288 - accuracy: 0.8745 - mae: 0.1340 - mse: 0.0666 - val_loss: 0.3270 - val_accuracy: 0.8731 - val_mae: 0.1316 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1227/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8745 - mae: 0.1356 - mse: 0.0664\n",
            "Epoch 1227: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.3237 - accuracy: 0.8745 - mae: 0.1356 - mse: 0.0664 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1326 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1228/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3250 - accuracy: 0.8747 - mae: 0.1376 - mse: 0.0666\n",
            "Epoch 1228: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.3254 - accuracy: 0.8742 - mae: 0.1378 - mse: 0.0667 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1327 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1229/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3291 - accuracy: 0.8730 - mae: 0.1372 - mse: 0.0670\n",
            "Epoch 1229: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.3267 - accuracy: 0.8736 - mae: 0.1366 - mse: 0.0665 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1230/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.8742 - mae: 0.1357 - mse: 0.0662\n",
            "Epoch 1230: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.3222 - accuracy: 0.8742 - mae: 0.1357 - mse: 0.0662 - val_loss: 0.3264 - val_accuracy: 0.8731 - val_mae: 0.1300 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1231/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3247 - accuracy: 0.8753 - mae: 0.1333 - mse: 0.0663\n",
            "Epoch 1231: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.3237 - accuracy: 0.8758 - mae: 0.1332 - mse: 0.0661 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1232/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.8745 - mae: 0.1312 - mse: 0.0662\n",
            "Epoch 1232: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.3246 - accuracy: 0.8745 - mae: 0.1312 - mse: 0.0662 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1279 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1233/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3252 - accuracy: 0.8747 - mae: 0.1322 - mse: 0.0663\n",
            "Epoch 1233: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.3265 - accuracy: 0.8745 - mae: 0.1326 - mse: 0.0665 - val_loss: 0.3272 - val_accuracy: 0.8731 - val_mae: 0.1302 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1234/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3317 - accuracy: 0.8760 - mae: 0.1319 - mse: 0.0662\n",
            "Epoch 1234: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3287 - accuracy: 0.8745 - mae: 0.1354 - mse: 0.0669 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1331 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1235/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.8745 - mae: 0.1363 - mse: 0.0667\n",
            "Epoch 1235: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.3267 - accuracy: 0.8745 - mae: 0.1363 - mse: 0.0667 - val_loss: 0.3314 - val_accuracy: 0.8731 - val_mae: 0.1346 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 1236/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3300 - accuracy: 0.8652 - mae: 0.1421 - mse: 0.0693\n",
            "Epoch 1236: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3249 - accuracy: 0.8742 - mae: 0.1375 - mse: 0.0668 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1342 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1237/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.8755 - mae: 0.1384 - mse: 0.0666\n",
            "Epoch 1237: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.3266 - accuracy: 0.8755 - mae: 0.1384 - mse: 0.0666 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1333 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1238/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3228 - accuracy: 0.8747 - mae: 0.1358 - mse: 0.0662\n",
            "Epoch 1238: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 138ms/step - loss: 0.3235 - accuracy: 0.8742 - mae: 0.1360 - mse: 0.0664 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1239/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3303 - accuracy: 0.8724 - mae: 0.1356 - mse: 0.0677\n",
            "Epoch 1239: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.3272 - accuracy: 0.8739 - mae: 0.1346 - mse: 0.0670 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1240/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8711 - mae: 0.1329 - mse: 0.0672\n",
            "Epoch 1240: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3239 - accuracy: 0.8745 - mae: 0.1320 - mse: 0.0666 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1273 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1241/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8682 - mae: 0.1343 - mse: 0.0688\n",
            "Epoch 1241: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3267 - accuracy: 0.8755 - mae: 0.1314 - mse: 0.0667 - val_loss: 0.3257 - val_accuracy: 0.8731 - val_mae: 0.1262 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1242/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8672 - mae: 0.1336 - mse: 0.0694\n",
            "Epoch 1242: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3264 - accuracy: 0.8745 - mae: 0.1308 - mse: 0.0666 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1265 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1243/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8730 - mae: 0.1333 - mse: 0.0667\n",
            "Epoch 1243: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3236 - accuracy: 0.8742 - mae: 0.1312 - mse: 0.0663 - val_loss: 0.3268 - val_accuracy: 0.8731 - val_mae: 0.1281 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1244/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3347 - accuracy: 0.8730 - mae: 0.1324 - mse: 0.0677\n",
            "Epoch 1244: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3268 - accuracy: 0.8748 - mae: 0.1328 - mse: 0.0669 - val_loss: 0.3276 - val_accuracy: 0.8731 - val_mae: 0.1292 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1245/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8730 - mae: 0.1357 - mse: 0.0675\n",
            "Epoch 1245: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3232 - accuracy: 0.8742 - mae: 0.1331 - mse: 0.0663 - val_loss: 0.3288 - val_accuracy: 0.8731 - val_mae: 0.1285 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1246/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8809 - mae: 0.1274 - mse: 0.0637\n",
            "Epoch 1246: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3239 - accuracy: 0.8745 - mae: 0.1324 - mse: 0.0665 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1276 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1247/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3442 - accuracy: 0.8643 - mae: 0.1338 - mse: 0.0705\n",
            "Epoch 1247: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3259 - accuracy: 0.8748 - mae: 0.1313 - mse: 0.0664 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1275 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1248/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3378 - accuracy: 0.8662 - mae: 0.1368 - mse: 0.0700\n",
            "Epoch 1248: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3243 - accuracy: 0.8739 - mae: 0.1323 - mse: 0.0667 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1249/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8867 - mae: 0.1262 - mse: 0.0617\n",
            "Epoch 1249: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3281 - accuracy: 0.8739 - mae: 0.1324 - mse: 0.0668 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1294 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1250/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3557 - accuracy: 0.8662 - mae: 0.1380 - mse: 0.0707\n",
            "Epoch 1250: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3258 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0662 - val_loss: 0.3282 - val_accuracy: 0.8731 - val_mae: 0.1300 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1251/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3101 - accuracy: 0.8838 - mae: 0.1281 - mse: 0.0619\n",
            "Epoch 1251: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3207 - accuracy: 0.8748 - mae: 0.1334 - mse: 0.0658 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1252/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8770 - mae: 0.1338 - mse: 0.0663\n",
            "Epoch 1252: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3267 - accuracy: 0.8742 - mae: 0.1347 - mse: 0.0668 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1253/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3159 - accuracy: 0.8867 - mae: 0.1310 - mse: 0.0631\n",
            "Epoch 1253: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3275 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0666 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1254/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8662 - mae: 0.1405 - mse: 0.0711\n",
            "Epoch 1254: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3248 - accuracy: 0.8752 - mae: 0.1343 - mse: 0.0662 - val_loss: 0.3277 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1255/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3451 - accuracy: 0.8623 - mae: 0.1415 - mse: 0.0723\n",
            "Epoch 1255: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3273 - accuracy: 0.8748 - mae: 0.1357 - mse: 0.0666 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1256/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8691 - mae: 0.1386 - mse: 0.0696\n",
            "Epoch 1256: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3236 - accuracy: 0.8752 - mae: 0.1347 - mse: 0.0661 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1257/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3167 - accuracy: 0.8770 - mae: 0.1346 - mse: 0.0651\n",
            "Epoch 1257: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3219 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0658 - val_loss: 0.3271 - val_accuracy: 0.8731 - val_mae: 0.1296 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1258/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8740 - mae: 0.1339 - mse: 0.0661\n",
            "Epoch 1258: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3262 - accuracy: 0.8742 - mae: 0.1338 - mse: 0.0665 - val_loss: 0.3264 - val_accuracy: 0.8731 - val_mae: 0.1291 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1259/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3118 - accuracy: 0.8721 - mae: 0.1331 - mse: 0.0651\n",
            "Epoch 1259: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3245 - accuracy: 0.8748 - mae: 0.1353 - mse: 0.0666 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1260/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8633 - mae: 0.1390 - mse: 0.0699\n",
            "Epoch 1260: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3233 - accuracy: 0.8742 - mae: 0.1344 - mse: 0.0664 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1261/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8672 - mae: 0.1384 - mse: 0.0689\n",
            "Epoch 1261: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.3211 - accuracy: 0.8742 - mae: 0.1339 - mse: 0.0660 - val_loss: 0.3263 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1262/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8742 - mae: 0.1346 - mse: 0.0664\n",
            "Epoch 1262: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.3245 - accuracy: 0.8742 - mae: 0.1346 - mse: 0.0664 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1263/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3259 - accuracy: 0.8734 - mae: 0.1343 - mse: 0.0668\n",
            "Epoch 1263: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 136ms/step - loss: 0.3245 - accuracy: 0.8742 - mae: 0.1339 - mse: 0.0665 - val_loss: 0.3266 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1264/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3107 - accuracy: 0.8828 - mae: 0.1271 - mse: 0.0624\n",
            "Epoch 1264: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3249 - accuracy: 0.8742 - mae: 0.1350 - mse: 0.0663 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1298 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1265/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8691 - mae: 0.1387 - mse: 0.0704\n",
            "Epoch 1265: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3275 - accuracy: 0.8752 - mae: 0.1351 - mse: 0.0668 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1294 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1266/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3096 - accuracy: 0.8818 - mae: 0.1288 - mse: 0.0630\n",
            "Epoch 1266: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3247 - accuracy: 0.8742 - mae: 0.1342 - mse: 0.0668 - val_loss: 0.3268 - val_accuracy: 0.8731 - val_mae: 0.1282 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1267/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0672\n",
            "Epoch 1267: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 156ms/step - loss: 0.3300 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0672 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1284 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1268/1500\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.3278 - accuracy: 0.8757 - mae: 0.1335 - mse: 0.0661\n",
            "Epoch 1268: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.3290 - accuracy: 0.8742 - mae: 0.1340 - mse: 0.0666 - val_loss: 0.3251 - val_accuracy: 0.8731 - val_mae: 0.1296 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1269/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0662\n",
            "Epoch 1269: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.3219 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0662 - val_loss: 0.3248 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1270/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3644 - accuracy: 0.8584 - mae: 0.1445 - mse: 0.0746\n",
            "Epoch 1270: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3305 - accuracy: 0.8745 - mae: 0.1362 - mse: 0.0671 - val_loss: 0.3245 - val_accuracy: 0.8731 - val_mae: 0.1309 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1271/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8760 - mae: 0.1351 - mse: 0.0669\n",
            "Epoch 1271: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3281 - accuracy: 0.8752 - mae: 0.1355 - mse: 0.0668 - val_loss: 0.3238 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1272/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8760 - mae: 0.1371 - mse: 0.0669\n",
            "Epoch 1272: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3265 - accuracy: 0.8748 - mae: 0.1348 - mse: 0.0666 - val_loss: 0.3237 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1273/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3365 - accuracy: 0.8662 - mae: 0.1363 - mse: 0.0697\n",
            "Epoch 1273: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3228 - accuracy: 0.8742 - mae: 0.1338 - mse: 0.0661 - val_loss: 0.3241 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1274/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3208 - accuracy: 0.8750 - mae: 0.1335 - mse: 0.0664\n",
            "Epoch 1274: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3240 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0663 - val_loss: 0.3243 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1275/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3159 - accuracy: 0.8828 - mae: 0.1333 - mse: 0.0641\n",
            "Epoch 1275: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3279 - accuracy: 0.8748 - mae: 0.1349 - mse: 0.0669 - val_loss: 0.3249 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1276/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8672 - mae: 0.1384 - mse: 0.0698\n",
            "Epoch 1276: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3200 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0658 - val_loss: 0.3254 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1277/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8682 - mae: 0.1361 - mse: 0.0687\n",
            "Epoch 1277: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3247 - accuracy: 0.8745 - mae: 0.1336 - mse: 0.0665 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1278/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3230 - accuracy: 0.8721 - mae: 0.1317 - mse: 0.0661\n",
            "Epoch 1278: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3264 - accuracy: 0.8742 - mae: 0.1327 - mse: 0.0664 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1279 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1279/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8711 - mae: 0.1360 - mse: 0.0683\n",
            "Epoch 1279: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3214 - accuracy: 0.8742 - mae: 0.1319 - mse: 0.0658 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1283 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1280/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8828 - mae: 0.1266 - mse: 0.0620\n",
            "Epoch 1280: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3237 - accuracy: 0.8745 - mae: 0.1327 - mse: 0.0665 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1285 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1281/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3181 - accuracy: 0.8789 - mae: 0.1308 - mse: 0.0648\n",
            "Epoch 1281: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3229 - accuracy: 0.8742 - mae: 0.1324 - mse: 0.0663 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1281 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1282/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3295 - accuracy: 0.8652 - mae: 0.1340 - mse: 0.0691\n",
            "Epoch 1282: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3256 - accuracy: 0.8742 - mae: 0.1314 - mse: 0.0662 - val_loss: 0.3302 - val_accuracy: 0.8731 - val_mae: 0.1290 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1283/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3066 - accuracy: 0.8867 - mae: 0.1277 - mse: 0.0611\n",
            "Epoch 1283: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3247 - accuracy: 0.8745 - mae: 0.1323 - mse: 0.0663 - val_loss: 0.3309 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1284/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8682 - mae: 0.1353 - mse: 0.0682\n",
            "Epoch 1284: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3224 - accuracy: 0.8748 - mae: 0.1327 - mse: 0.0661 - val_loss: 0.3329 - val_accuracy: 0.8731 - val_mae: 0.1317 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1285/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3378 - accuracy: 0.8770 - mae: 0.1366 - mse: 0.0676\n",
            "Epoch 1285: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3293 - accuracy: 0.8742 - mae: 0.1363 - mse: 0.0670 - val_loss: 0.3331 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1286/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3272 - accuracy: 0.8721 - mae: 0.1371 - mse: 0.0673\n",
            "Epoch 1286: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3249 - accuracy: 0.8748 - mae: 0.1352 - mse: 0.0667 - val_loss: 0.3317 - val_accuracy: 0.8731 - val_mae: 0.1316 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1287/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8906 - mae: 0.1259 - mse: 0.0598\n",
            "Epoch 1287: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3260 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0663 - val_loss: 0.3300 - val_accuracy: 0.8731 - val_mae: 0.1303 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1288/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3226 - accuracy: 0.8779 - mae: 0.1332 - mse: 0.0648\n",
            "Epoch 1288: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3239 - accuracy: 0.8745 - mae: 0.1332 - mse: 0.0662 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1290 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1289/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8682 - mae: 0.1355 - mse: 0.0688\n",
            "Epoch 1289: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3243 - accuracy: 0.8742 - mae: 0.1327 - mse: 0.0662 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1290/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8701 - mae: 0.1324 - mse: 0.0670\n",
            "Epoch 1290: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3250 - accuracy: 0.8748 - mae: 0.1328 - mse: 0.0666 - val_loss: 0.3280 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1291/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8740 - mae: 0.1336 - mse: 0.0678\n",
            "Epoch 1291: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3196 - accuracy: 0.8748 - mae: 0.1320 - mse: 0.0659 - val_loss: 0.3276 - val_accuracy: 0.8731 - val_mae: 0.1284 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1292/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8564 - mae: 0.1398 - mse: 0.0730\n",
            "Epoch 1292: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3245 - accuracy: 0.8745 - mae: 0.1333 - mse: 0.0665 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1293/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3451 - accuracy: 0.8613 - mae: 0.1384 - mse: 0.0716\n",
            "Epoch 1293: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3270 - accuracy: 0.8748 - mae: 0.1331 - mse: 0.0663 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1294/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3252 - accuracy: 0.8760 - mae: 0.1302 - mse: 0.0656\n",
            "Epoch 1294: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3204 - accuracy: 0.8742 - mae: 0.1317 - mse: 0.0657 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1273 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1295/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3116 - accuracy: 0.8760 - mae: 0.1297 - mse: 0.0649\n",
            "Epoch 1295: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3267 - accuracy: 0.8748 - mae: 0.1323 - mse: 0.0666 - val_loss: 0.3254 - val_accuracy: 0.8731 - val_mae: 0.1284 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1296/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3265 - accuracy: 0.8633 - mae: 0.1335 - mse: 0.0690\n",
            "Epoch 1296: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3190 - accuracy: 0.8745 - mae: 0.1326 - mse: 0.0659 - val_loss: 0.3264 - val_accuracy: 0.8731 - val_mae: 0.1302 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1297/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3303 - accuracy: 0.8730 - mae: 0.1351 - mse: 0.0675\n",
            "Epoch 1297: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3254 - accuracy: 0.8748 - mae: 0.1345 - mse: 0.0666 - val_loss: 0.3274 - val_accuracy: 0.8731 - val_mae: 0.1318 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1298/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8770 - mae: 0.1326 - mse: 0.0652\n",
            "Epoch 1298: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3211 - accuracy: 0.8748 - mae: 0.1350 - mse: 0.0659 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1334 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1299/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3107 - accuracy: 0.8848 - mae: 0.1323 - mse: 0.0624\n",
            "Epoch 1299: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3263 - accuracy: 0.8748 - mae: 0.1363 - mse: 0.0665 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1347 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1300/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3008 - accuracy: 0.8857 - mae: 0.1302 - mse: 0.0606\n",
            "Epoch 1300: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3207 - accuracy: 0.8748 - mae: 0.1373 - mse: 0.0656 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1331 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1301/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8740 - mae: 0.1378 - mse: 0.0665\n",
            "Epoch 1301: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3227 - accuracy: 0.8745 - mae: 0.1368 - mse: 0.0663 - val_loss: 0.3269 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1302/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3431 - accuracy: 0.8555 - mae: 0.1412 - mse: 0.0733\n",
            "Epoch 1302: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3242 - accuracy: 0.8739 - mae: 0.1315 - mse: 0.0663 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1268 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1303/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3105 - accuracy: 0.8799 - mae: 0.1264 - mse: 0.0630\n",
            "Epoch 1303: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.3215 - accuracy: 0.8745 - mae: 0.1305 - mse: 0.0657 - val_loss: 0.3305 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1304/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3576 - accuracy: 0.8613 - mae: 0.1401 - mse: 0.0733\n",
            "Epoch 1304: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3244 - accuracy: 0.8755 - mae: 0.1330 - mse: 0.0664 - val_loss: 0.3338 - val_accuracy: 0.8731 - val_mae: 0.1321 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1305/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8770 - mae: 0.1326 - mse: 0.0639\n",
            "Epoch 1305: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3195 - accuracy: 0.8752 - mae: 0.1341 - mse: 0.0657 - val_loss: 0.3363 - val_accuracy: 0.8731 - val_mae: 0.1335 - val_mse: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 1306/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3439 - accuracy: 0.8760 - mae: 0.1385 - mse: 0.0694\n",
            "Epoch 1306: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3233 - accuracy: 0.8748 - mae: 0.1360 - mse: 0.0666 - val_loss: 0.3355 - val_accuracy: 0.8731 - val_mae: 0.1327 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1307/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2784 - accuracy: 0.9033 - mae: 0.1210 - mse: 0.0543\n",
            "Epoch 1307: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3268 - accuracy: 0.8748 - mae: 0.1359 - mse: 0.0667 - val_loss: 0.3328 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1308/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8748 - mae: 0.1336 - mse: 0.0662\n",
            "Epoch 1308: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3230 - accuracy: 0.8748 - mae: 0.1336 - mse: 0.0662 - val_loss: 0.3306 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1309/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3055 - accuracy: 0.8896 - mae: 0.1275 - mse: 0.0605\n",
            "Epoch 1309: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3227 - accuracy: 0.8745 - mae: 0.1322 - mse: 0.0659 - val_loss: 0.3288 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1310/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8604 - mae: 0.1388 - mse: 0.0712\n",
            "Epoch 1310: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.3250 - accuracy: 0.8748 - mae: 0.1329 - mse: 0.0662 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1311/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3450 - accuracy: 0.8662 - mae: 0.1402 - mse: 0.0713\n",
            "Epoch 1311: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3227 - accuracy: 0.8748 - mae: 0.1342 - mse: 0.0662 - val_loss: 0.3305 - val_accuracy: 0.8731 - val_mae: 0.1310 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1312/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3512 - accuracy: 0.8643 - mae: 0.1425 - mse: 0.0721\n",
            "Epoch 1312: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3230 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0659 - val_loss: 0.3331 - val_accuracy: 0.8731 - val_mae: 0.1318 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1313/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8779 - mae: 0.1345 - mse: 0.0655\n",
            "Epoch 1313: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.3219 - accuracy: 0.8748 - mae: 0.1344 - mse: 0.0660 - val_loss: 0.3318 - val_accuracy: 0.8731 - val_mae: 0.1309 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1314/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3219 - accuracy: 0.8809 - mae: 0.1323 - mse: 0.0648\n",
            "Epoch 1314: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3267 - accuracy: 0.8745 - mae: 0.1336 - mse: 0.0666 - val_loss: 0.3282 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1315/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3295 - accuracy: 0.8789 - mae: 0.1322 - mse: 0.0652\n",
            "Epoch 1315: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3288 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0665 - val_loss: 0.3249 - val_accuracy: 0.8731 - val_mae: 0.1283 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1316/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3397 - accuracy: 0.8691 - mae: 0.1383 - mse: 0.0694\n",
            "Epoch 1316: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3248 - accuracy: 0.8739 - mae: 0.1337 - mse: 0.0664 - val_loss: 0.3248 - val_accuracy: 0.8731 - val_mae: 0.1298 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 1317/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3419 - accuracy: 0.8721 - mae: 0.1370 - mse: 0.0685\n",
            "Epoch 1317: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3249 - accuracy: 0.8745 - mae: 0.1351 - mse: 0.0661 - val_loss: 0.3254 - val_accuracy: 0.8731 - val_mae: 0.1309 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1318/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8730 - mae: 0.1328 - mse: 0.0665\n",
            "Epoch 1318: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3219 - accuracy: 0.8742 - mae: 0.1338 - mse: 0.0661 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1302 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1319/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3626 - accuracy: 0.8525 - mae: 0.1416 - mse: 0.0747\n",
            "Epoch 1319: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3282 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0665 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1320/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8682 - mae: 0.1352 - mse: 0.0697\n",
            "Epoch 1320: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3233 - accuracy: 0.8745 - mae: 0.1319 - mse: 0.0663 - val_loss: 0.3272 - val_accuracy: 0.8731 - val_mae: 0.1300 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1321/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8701 - mae: 0.1369 - mse: 0.0686\n",
            "Epoch 1321: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3231 - accuracy: 0.8748 - mae: 0.1331 - mse: 0.0661 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1308 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1322/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3239 - accuracy: 0.8730 - mae: 0.1344 - mse: 0.0669\n",
            "Epoch 1322: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3233 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0663 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1323/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3457 - accuracy: 0.8633 - mae: 0.1384 - mse: 0.0715\n",
            "Epoch 1323: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3250 - accuracy: 0.8752 - mae: 0.1348 - mse: 0.0663 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1324/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3202 - accuracy: 0.8848 - mae: 0.1314 - mse: 0.0641\n",
            "Epoch 1324: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3250 - accuracy: 0.8748 - mae: 0.1351 - mse: 0.0663 - val_loss: 0.3303 - val_accuracy: 0.8731 - val_mae: 0.1323 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1325/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3239 - accuracy: 0.8701 - mae: 0.1365 - mse: 0.0670\n",
            "Epoch 1325: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3242 - accuracy: 0.8745 - mae: 0.1350 - mse: 0.0663 - val_loss: 0.3292 - val_accuracy: 0.8731 - val_mae: 0.1299 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1326/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2941 - accuracy: 0.8896 - mae: 0.1241 - mse: 0.0602\n",
            "Epoch 1326: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3184 - accuracy: 0.8752 - mae: 0.1323 - mse: 0.0657 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1277 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1327/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8721 - mae: 0.1359 - mse: 0.0680\n",
            "Epoch 1327: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3242 - accuracy: 0.8742 - mae: 0.1307 - mse: 0.0664 - val_loss: 0.3282 - val_accuracy: 0.8731 - val_mae: 0.1263 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1328/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3394 - accuracy: 0.8613 - mae: 0.1345 - mse: 0.0717\n",
            "Epoch 1328: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3223 - accuracy: 0.8748 - mae: 0.1293 - mse: 0.0661 - val_loss: 0.3278 - val_accuracy: 0.8731 - val_mae: 0.1273 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1329/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3273 - accuracy: 0.8750 - mae: 0.1300 - mse: 0.0667\n",
            "Epoch 1329: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3222 - accuracy: 0.8745 - mae: 0.1299 - mse: 0.0661 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1292 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1330/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3118 - accuracy: 0.8848 - mae: 0.1289 - mse: 0.0623\n",
            "Epoch 1330: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.3264 - accuracy: 0.8745 - mae: 0.1329 - mse: 0.0665 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1321 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1331/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3635 - accuracy: 0.8535 - mae: 0.1425 - mse: 0.0748\n",
            "Epoch 1331: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3276 - accuracy: 0.8748 - mae: 0.1356 - mse: 0.0664 - val_loss: 0.3301 - val_accuracy: 0.8731 - val_mae: 0.1344 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1332/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3492 - accuracy: 0.8623 - mae: 0.1456 - mse: 0.0720\n",
            "Epoch 1332: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3220 - accuracy: 0.8745 - mae: 0.1367 - mse: 0.0662 - val_loss: 0.3310 - val_accuracy: 0.8731 - val_mae: 0.1349 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1333/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8623 - mae: 0.1413 - mse: 0.0698\n",
            "Epoch 1333: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3204 - accuracy: 0.8748 - mae: 0.1372 - mse: 0.0661 - val_loss: 0.3308 - val_accuracy: 0.8731 - val_mae: 0.1342 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1334/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3104 - accuracy: 0.8799 - mae: 0.1346 - mse: 0.0634\n",
            "Epoch 1334: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3211 - accuracy: 0.8748 - mae: 0.1353 - mse: 0.0659 - val_loss: 0.3291 - val_accuracy: 0.8731 - val_mae: 0.1323 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1335/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8623 - mae: 0.1392 - mse: 0.0699\n",
            "Epoch 1335: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3205 - accuracy: 0.8752 - mae: 0.1349 - mse: 0.0658 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1309 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1336/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3273 - accuracy: 0.8711 - mae: 0.1342 - mse: 0.0669\n",
            "Epoch 1336: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3230 - accuracy: 0.8745 - mae: 0.1331 - mse: 0.0661 - val_loss: 0.3253 - val_accuracy: 0.8731 - val_mae: 0.1290 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1337/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3175 - accuracy: 0.8691 - mae: 0.1330 - mse: 0.0669\n",
            "Epoch 1337: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3194 - accuracy: 0.8752 - mae: 0.1318 - mse: 0.0658 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1338/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3298 - accuracy: 0.8662 - mae: 0.1336 - mse: 0.0687\n",
            "Epoch 1338: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3237 - accuracy: 0.8745 - mae: 0.1323 - mse: 0.0662 - val_loss: 0.3270 - val_accuracy: 0.8731 - val_mae: 0.1313 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1339/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3216 - accuracy: 0.8750 - mae: 0.1316 - mse: 0.0654\n",
            "Epoch 1339: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3264 - accuracy: 0.8755 - mae: 0.1346 - mse: 0.0665 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1339 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1340/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8809 - mae: 0.1363 - mse: 0.0646\n",
            "Epoch 1340: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3256 - accuracy: 0.8745 - mae: 0.1372 - mse: 0.0662 - val_loss: 0.3314 - val_accuracy: 0.8731 - val_mae: 0.1359 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1341/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3389 - accuracy: 0.8643 - mae: 0.1423 - mse: 0.0709\n",
            "Epoch 1341: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3198 - accuracy: 0.8748 - mae: 0.1380 - mse: 0.0659 - val_loss: 0.3316 - val_accuracy: 0.8731 - val_mae: 0.1346 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1342/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3516 - accuracy: 0.8584 - mae: 0.1439 - mse: 0.0723\n",
            "Epoch 1342: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3242 - accuracy: 0.8742 - mae: 0.1365 - mse: 0.0662 - val_loss: 0.3304 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1343/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8711 - mae: 0.1343 - mse: 0.0678\n",
            "Epoch 1343: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3222 - accuracy: 0.8745 - mae: 0.1321 - mse: 0.0662 - val_loss: 0.3301 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1344/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3143 - accuracy: 0.8730 - mae: 0.1276 - mse: 0.0651\n",
            "Epoch 1344: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3230 - accuracy: 0.8739 - mae: 0.1308 - mse: 0.0664 - val_loss: 0.3305 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1345/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3067 - accuracy: 0.8877 - mae: 0.1277 - mse: 0.0618\n",
            "Epoch 1345: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3172 - accuracy: 0.8742 - mae: 0.1299 - mse: 0.0656 - val_loss: 0.3310 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1346/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8662 - mae: 0.1351 - mse: 0.0694\n",
            "Epoch 1346: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3243 - accuracy: 0.8748 - mae: 0.1306 - mse: 0.0662 - val_loss: 0.3312 - val_accuracy: 0.8731 - val_mae: 0.1283 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1347/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2909 - accuracy: 0.8955 - mae: 0.1205 - mse: 0.0574\n",
            "Epoch 1347: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3279 - accuracy: 0.8748 - mae: 0.1317 - mse: 0.0667 - val_loss: 0.3321 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1348/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3412 - accuracy: 0.8633 - mae: 0.1373 - mse: 0.0712\n",
            "Epoch 1348: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3198 - accuracy: 0.8742 - mae: 0.1326 - mse: 0.0659 - val_loss: 0.3329 - val_accuracy: 0.8731 - val_mae: 0.1303 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1349/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8818 - mae: 0.1285 - mse: 0.0624\n",
            "Epoch 1349: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3267 - accuracy: 0.8745 - mae: 0.1335 - mse: 0.0668 - val_loss: 0.3332 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1350/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3253 - accuracy: 0.8789 - mae: 0.1337 - mse: 0.0649\n",
            "Epoch 1350: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3246 - accuracy: 0.8748 - mae: 0.1328 - mse: 0.0662 - val_loss: 0.3332 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1351/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8730 - mae: 0.1339 - mse: 0.0668\n",
            "Epoch 1351: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3238 - accuracy: 0.8742 - mae: 0.1338 - mse: 0.0663 - val_loss: 0.3323 - val_accuracy: 0.8731 - val_mae: 0.1314 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1352/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3381 - accuracy: 0.8760 - mae: 0.1347 - mse: 0.0674\n",
            "Epoch 1352: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3264 - accuracy: 0.8748 - mae: 0.1342 - mse: 0.0663 - val_loss: 0.3318 - val_accuracy: 0.8731 - val_mae: 0.1313 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1353/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8750 - mae: 0.1336 - mse: 0.0662\n",
            "Epoch 1353: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3265 - accuracy: 0.8748 - mae: 0.1344 - mse: 0.0664 - val_loss: 0.3315 - val_accuracy: 0.8731 - val_mae: 0.1309 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1354/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3104 - accuracy: 0.8867 - mae: 0.1311 - mse: 0.0620\n",
            "Epoch 1354: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3210 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0657 - val_loss: 0.3317 - val_accuracy: 0.8731 - val_mae: 0.1310 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1355/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8730 - mae: 0.1333 - mse: 0.0666\n",
            "Epoch 1355: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3174 - accuracy: 0.8742 - mae: 0.1333 - mse: 0.0657 - val_loss: 0.3325 - val_accuracy: 0.8731 - val_mae: 0.1328 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1356/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3489 - accuracy: 0.8633 - mae: 0.1426 - mse: 0.0717\n",
            "Epoch 1356: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3206 - accuracy: 0.8752 - mae: 0.1349 - mse: 0.0661 - val_loss: 0.3317 - val_accuracy: 0.8731 - val_mae: 0.1332 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1357/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3422 - accuracy: 0.8574 - mae: 0.1405 - mse: 0.0715\n",
            "Epoch 1357: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3211 - accuracy: 0.8742 - mae: 0.1342 - mse: 0.0659 - val_loss: 0.3302 - val_accuracy: 0.8731 - val_mae: 0.1317 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1358/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3141 - accuracy: 0.8887 - mae: 0.1311 - mse: 0.0621\n",
            "Epoch 1358: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3299 - accuracy: 0.8736 - mae: 0.1355 - mse: 0.0674 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1319 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1359/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3217 - accuracy: 0.8740 - mae: 0.1316 - mse: 0.0664\n",
            "Epoch 1359: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3245 - accuracy: 0.8752 - mae: 0.1347 - mse: 0.0663 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1345 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1360/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8721 - mae: 0.1397 - mse: 0.0680\n",
            "Epoch 1360: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3182 - accuracy: 0.8745 - mae: 0.1372 - mse: 0.0659 - val_loss: 0.3310 - val_accuracy: 0.8731 - val_mae: 0.1362 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1361/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3254 - accuracy: 0.8809 - mae: 0.1356 - mse: 0.0647\n",
            "Epoch 1361: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3265 - accuracy: 0.8742 - mae: 0.1378 - mse: 0.0664 - val_loss: 0.3309 - val_accuracy: 0.8731 - val_mae: 0.1346 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1362/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3279 - accuracy: 0.8584 - mae: 0.1393 - mse: 0.0695\n",
            "Epoch 1362: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3211 - accuracy: 0.8736 - mae: 0.1363 - mse: 0.0662 - val_loss: 0.3306 - val_accuracy: 0.8731 - val_mae: 0.1323 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1363/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3302 - accuracy: 0.8721 - mae: 0.1347 - mse: 0.0675\n",
            "Epoch 1363: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3225 - accuracy: 0.8742 - mae: 0.1338 - mse: 0.0660 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1294 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1364/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3267 - accuracy: 0.8750 - mae: 0.1301 - mse: 0.0665\n",
            "Epoch 1364: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3238 - accuracy: 0.8748 - mae: 0.1316 - mse: 0.0662 - val_loss: 0.3290 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1365/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3662 - accuracy: 0.8506 - mae: 0.1427 - mse: 0.0769\n",
            "Epoch 1365: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3243 - accuracy: 0.8742 - mae: 0.1328 - mse: 0.0665 - val_loss: 0.3282 - val_accuracy: 0.8731 - val_mae: 0.1302 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1366/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3213 - accuracy: 0.8770 - mae: 0.1324 - mse: 0.0659\n",
            "Epoch 1366: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3219 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0662 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1310 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1367/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3279 - accuracy: 0.8662 - mae: 0.1368 - mse: 0.0691\n",
            "Epoch 1367: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3281 - accuracy: 0.8752 - mae: 0.1359 - mse: 0.0672 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1332 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1368/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3071 - accuracy: 0.8828 - mae: 0.1318 - mse: 0.0624\n",
            "Epoch 1368: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3240 - accuracy: 0.8748 - mae: 0.1366 - mse: 0.0664 - val_loss: 0.3308 - val_accuracy: 0.8731 - val_mae: 0.1356 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1369/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8604 - mae: 0.1432 - mse: 0.0704\n",
            "Epoch 1369: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3242 - accuracy: 0.8736 - mae: 0.1388 - mse: 0.0664 - val_loss: 0.3322 - val_accuracy: 0.8731 - val_mae: 0.1368 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1370/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2958 - accuracy: 0.8857 - mae: 0.1325 - mse: 0.0603\n",
            "Epoch 1370: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3245 - accuracy: 0.8745 - mae: 0.1392 - mse: 0.0666 - val_loss: 0.3331 - val_accuracy: 0.8731 - val_mae: 0.1368 - val_mse: 0.0684 - lr: 1.0000e-04\n",
            "Epoch 1371/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3200 - accuracy: 0.8721 - mae: 0.1361 - mse: 0.0665\n",
            "Epoch 1371: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3250 - accuracy: 0.8745 - mae: 0.1383 - mse: 0.0659 - val_loss: 0.3324 - val_accuracy: 0.8731 - val_mae: 0.1354 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1372/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2932 - accuracy: 0.8867 - mae: 0.1290 - mse: 0.0604\n",
            "Epoch 1372: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3239 - accuracy: 0.8748 - mae: 0.1377 - mse: 0.0665 - val_loss: 0.3315 - val_accuracy: 0.8731 - val_mae: 0.1339 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1373/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8740 - mae: 0.1357 - mse: 0.0669\n",
            "Epoch 1373: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3228 - accuracy: 0.8739 - mae: 0.1358 - mse: 0.0666 - val_loss: 0.3307 - val_accuracy: 0.8731 - val_mae: 0.1327 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1374/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2950 - accuracy: 0.8887 - mae: 0.1286 - mse: 0.0598\n",
            "Epoch 1374: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3260 - accuracy: 0.8752 - mae: 0.1357 - mse: 0.0664 - val_loss: 0.3292 - val_accuracy: 0.8731 - val_mae: 0.1315 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1375/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8701 - mae: 0.1370 - mse: 0.0675\n",
            "Epoch 1375: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3232 - accuracy: 0.8752 - mae: 0.1342 - mse: 0.0664 - val_loss: 0.3280 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1376/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3357 - accuracy: 0.8730 - mae: 0.1334 - mse: 0.0681\n",
            "Epoch 1376: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3268 - accuracy: 0.8745 - mae: 0.1325 - mse: 0.0666 - val_loss: 0.3268 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1377/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8770 - mae: 0.1294 - mse: 0.0642\n",
            "Epoch 1377: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3262 - accuracy: 0.8752 - mae: 0.1328 - mse: 0.0664 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1291 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1378/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8721 - mae: 0.1374 - mse: 0.0690\n",
            "Epoch 1378: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3242 - accuracy: 0.8748 - mae: 0.1334 - mse: 0.0667 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1299 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1379/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8672 - mae: 0.1371 - mse: 0.0685\n",
            "Epoch 1379: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3247 - accuracy: 0.8742 - mae: 0.1330 - mse: 0.0660 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1380/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8789 - mae: 0.1339 - mse: 0.0646\n",
            "Epoch 1380: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3245 - accuracy: 0.8748 - mae: 0.1339 - mse: 0.0663 - val_loss: 0.3261 - val_accuracy: 0.8731 - val_mae: 0.1315 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1381/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8682 - mae: 0.1344 - mse: 0.0674\n",
            "Epoch 1381: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3237 - accuracy: 0.8745 - mae: 0.1355 - mse: 0.0664 - val_loss: 0.3272 - val_accuracy: 0.8731 - val_mae: 0.1338 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1382/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8779 - mae: 0.1339 - mse: 0.0654\n",
            "Epoch 1382: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3231 - accuracy: 0.8745 - mae: 0.1375 - mse: 0.0660 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1349 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1383/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8643 - mae: 0.1424 - mse: 0.0698\n",
            "Epoch 1383: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3227 - accuracy: 0.8745 - mae: 0.1371 - mse: 0.0664 - val_loss: 0.3276 - val_accuracy: 0.8731 - val_mae: 0.1332 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1384/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3319 - accuracy: 0.8711 - mae: 0.1401 - mse: 0.0679\n",
            "Epoch 1384: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3256 - accuracy: 0.8745 - mae: 0.1363 - mse: 0.0664 - val_loss: 0.3270 - val_accuracy: 0.8731 - val_mae: 0.1321 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1385/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3120 - accuracy: 0.8848 - mae: 0.1319 - mse: 0.0625\n",
            "Epoch 1385: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3261 - accuracy: 0.8745 - mae: 0.1345 - mse: 0.0665 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1312 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1386/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8770 - mae: 0.1319 - mse: 0.0653\n",
            "Epoch 1386: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3215 - accuracy: 0.8748 - mae: 0.1342 - mse: 0.0661 - val_loss: 0.3265 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1387/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3412 - accuracy: 0.8662 - mae: 0.1393 - mse: 0.0696\n",
            "Epoch 1387: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3232 - accuracy: 0.8742 - mae: 0.1335 - mse: 0.0661 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1291 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1388/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2886 - accuracy: 0.8936 - mae: 0.1246 - mse: 0.0579\n",
            "Epoch 1388: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3231 - accuracy: 0.8742 - mae: 0.1333 - mse: 0.0661 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1389/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8701 - mae: 0.1375 - mse: 0.0683\n",
            "Epoch 1389: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3226 - accuracy: 0.8745 - mae: 0.1339 - mse: 0.0659 - val_loss: 0.3264 - val_accuracy: 0.8731 - val_mae: 0.1312 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1390/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8730 - mae: 0.1362 - mse: 0.0674\n",
            "Epoch 1390: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3247 - accuracy: 0.8752 - mae: 0.1356 - mse: 0.0664 - val_loss: 0.3276 - val_accuracy: 0.8731 - val_mae: 0.1329 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1391/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3577 - accuracy: 0.8623 - mae: 0.1433 - mse: 0.0728\n",
            "Epoch 1391: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3243 - accuracy: 0.8748 - mae: 0.1361 - mse: 0.0663 - val_loss: 0.3277 - val_accuracy: 0.8731 - val_mae: 0.1323 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1392/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3108 - accuracy: 0.8896 - mae: 0.1325 - mse: 0.0622\n",
            "Epoch 1392: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3249 - accuracy: 0.8745 - mae: 0.1358 - mse: 0.0667 - val_loss: 0.3277 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1393/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3176 - accuracy: 0.8652 - mae: 0.1349 - mse: 0.0668\n",
            "Epoch 1393: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3229 - accuracy: 0.8745 - mae: 0.1333 - mse: 0.0657 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1295 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1394/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3209 - accuracy: 0.8701 - mae: 0.1324 - mse: 0.0675\n",
            "Epoch 1394: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3204 - accuracy: 0.8748 - mae: 0.1327 - mse: 0.0660 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1395/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8770 - mae: 0.1311 - mse: 0.0658\n",
            "Epoch 1395: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3256 - accuracy: 0.8739 - mae: 0.1327 - mse: 0.0668 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1275 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1396/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8818 - mae: 0.1323 - mse: 0.0652\n",
            "Epoch 1396: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3251 - accuracy: 0.8745 - mae: 0.1309 - mse: 0.0663 - val_loss: 0.3279 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1397/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8691 - mae: 0.1342 - mse: 0.0697\n",
            "Epoch 1397: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3239 - accuracy: 0.8752 - mae: 0.1310 - mse: 0.0663 - val_loss: 0.3277 - val_accuracy: 0.8731 - val_mae: 0.1293 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1398/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3278 - accuracy: 0.8789 - mae: 0.1317 - mse: 0.0652\n",
            "Epoch 1398: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3276 - accuracy: 0.8745 - mae: 0.1334 - mse: 0.0665 - val_loss: 0.3273 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1399/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3071 - accuracy: 0.8887 - mae: 0.1277 - mse: 0.0613\n",
            "Epoch 1399: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3225 - accuracy: 0.8752 - mae: 0.1337 - mse: 0.0660 - val_loss: 0.3266 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1400/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3010 - accuracy: 0.8867 - mae: 0.1290 - mse: 0.0614\n",
            "Epoch 1400: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3196 - accuracy: 0.8742 - mae: 0.1339 - mse: 0.0661 - val_loss: 0.3263 - val_accuracy: 0.8731 - val_mae: 0.1296 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1401/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8760 - mae: 0.1355 - mse: 0.0672\n",
            "Epoch 1401: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3241 - accuracy: 0.8745 - mae: 0.1328 - mse: 0.0667 - val_loss: 0.3254 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1402/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3088 - accuracy: 0.8857 - mae: 0.1272 - mse: 0.0626\n",
            "Epoch 1402: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3220 - accuracy: 0.8739 - mae: 0.1326 - mse: 0.0662 - val_loss: 0.3252 - val_accuracy: 0.8731 - val_mae: 0.1303 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1403/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8789 - mae: 0.1308 - mse: 0.0645\n",
            "Epoch 1403: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3290 - accuracy: 0.8745 - mae: 0.1348 - mse: 0.0665 - val_loss: 0.3254 - val_accuracy: 0.8731 - val_mae: 0.1318 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1404/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3223 - accuracy: 0.8799 - mae: 0.1346 - mse: 0.0654\n",
            "Epoch 1404: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3246 - accuracy: 0.8748 - mae: 0.1348 - mse: 0.0661 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1405/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8662 - mae: 0.1364 - mse: 0.0673\n",
            "Epoch 1405: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3214 - accuracy: 0.8752 - mae: 0.1346 - mse: 0.0655 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1406/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8584 - mae: 0.1394 - mse: 0.0717\n",
            "Epoch 1406: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3192 - accuracy: 0.8745 - mae: 0.1346 - mse: 0.0659 - val_loss: 0.3292 - val_accuracy: 0.8731 - val_mae: 0.1323 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1407/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3256 - accuracy: 0.8740 - mae: 0.1354 - mse: 0.0668\n",
            "Epoch 1407: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3237 - accuracy: 0.8752 - mae: 0.1344 - mse: 0.0659 - val_loss: 0.3310 - val_accuracy: 0.8731 - val_mae: 0.1315 - val_mse: 0.0677 - lr: 1.0000e-04\n",
            "Epoch 1408/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8760 - mae: 0.1320 - mse: 0.0652\n",
            "Epoch 1408: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3219 - accuracy: 0.8745 - mae: 0.1334 - mse: 0.0663 - val_loss: 0.3318 - val_accuracy: 0.8731 - val_mae: 0.1299 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1409/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3299 - accuracy: 0.8760 - mae: 0.1325 - mse: 0.0664\n",
            "Epoch 1409: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3253 - accuracy: 0.8752 - mae: 0.1319 - mse: 0.0664 - val_loss: 0.3301 - val_accuracy: 0.8731 - val_mae: 0.1287 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1410/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3298 - accuracy: 0.8750 - mae: 0.1292 - mse: 0.0677\n",
            "Epoch 1410: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3211 - accuracy: 0.8748 - mae: 0.1304 - mse: 0.0661 - val_loss: 0.3291 - val_accuracy: 0.8731 - val_mae: 0.1299 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1411/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2969 - accuracy: 0.8916 - mae: 0.1251 - mse: 0.0600\n",
            "Epoch 1411: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3214 - accuracy: 0.8748 - mae: 0.1332 - mse: 0.0663 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1307 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1412/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8682 - mae: 0.1335 - mse: 0.0680\n",
            "Epoch 1412: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3215 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0662 - val_loss: 0.3268 - val_accuracy: 0.8731 - val_mae: 0.1327 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1413/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8779 - mae: 0.1327 - mse: 0.0642\n",
            "Epoch 1413: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3198 - accuracy: 0.8745 - mae: 0.1350 - mse: 0.0657 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1325 - val_mse: 0.0670 - lr: 1.0000e-04\n",
            "Epoch 1414/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8828 - mae: 0.1338 - mse: 0.0644\n",
            "Epoch 1414: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3242 - accuracy: 0.8748 - mae: 0.1357 - mse: 0.0664 - val_loss: 0.3238 - val_accuracy: 0.8731 - val_mae: 0.1301 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1415/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3234 - accuracy: 0.8701 - mae: 0.1386 - mse: 0.0673\n",
            "Epoch 1415: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3209 - accuracy: 0.8748 - mae: 0.1336 - mse: 0.0660 - val_loss: 0.3230 - val_accuracy: 0.8731 - val_mae: 0.1274 - val_mse: 0.0666 - lr: 1.0000e-04\n",
            "Epoch 1416/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8779 - mae: 0.1276 - mse: 0.0640\n",
            "Epoch 1416: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3211 - accuracy: 0.8748 - mae: 0.1300 - mse: 0.0659 - val_loss: 0.3236 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1417/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3231 - accuracy: 0.8770 - mae: 0.1333 - mse: 0.0656\n",
            "Epoch 1417: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3228 - accuracy: 0.8748 - mae: 0.1335 - mse: 0.0662 - val_loss: 0.3247 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1418/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8760 - mae: 0.1378 - mse: 0.0670\n",
            "Epoch 1418: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3225 - accuracy: 0.8748 - mae: 0.1349 - mse: 0.0662 - val_loss: 0.3272 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1419/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8770 - mae: 0.1324 - mse: 0.0654\n",
            "Epoch 1419: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3225 - accuracy: 0.8748 - mae: 0.1357 - mse: 0.0664 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1311 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1420/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3392 - accuracy: 0.8613 - mae: 0.1396 - mse: 0.0707\n",
            "Epoch 1420: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3241 - accuracy: 0.8748 - mae: 0.1343 - mse: 0.0658 - val_loss: 0.3283 - val_accuracy: 0.8731 - val_mae: 0.1297 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1421/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3102 - accuracy: 0.8789 - mae: 0.1339 - mse: 0.0642\n",
            "Epoch 1421: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3193 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0658 - val_loss: 0.3281 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1422/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8740 - mae: 0.1338 - mse: 0.0673\n",
            "Epoch 1422: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3269 - accuracy: 0.8752 - mae: 0.1338 - mse: 0.0665 - val_loss: 0.3293 - val_accuracy: 0.8706 - val_mae: 0.1309 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1423/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8672 - mae: 0.1372 - mse: 0.0679\n",
            "Epoch 1423: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3219 - accuracy: 0.8745 - mae: 0.1349 - mse: 0.0659 - val_loss: 0.3301 - val_accuracy: 0.8706 - val_mae: 0.1321 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1424/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8662 - mae: 0.1428 - mse: 0.0702\n",
            "Epoch 1424: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3254 - accuracy: 0.8736 - mae: 0.1365 - mse: 0.0666 - val_loss: 0.3290 - val_accuracy: 0.8706 - val_mae: 0.1317 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1425/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8545 - mae: 0.1455 - mse: 0.0742\n",
            "Epoch 1425: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3231 - accuracy: 0.8748 - mae: 0.1345 - mse: 0.0660 - val_loss: 0.3271 - val_accuracy: 0.8706 - val_mae: 0.1296 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1426/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3139 - accuracy: 0.8760 - mae: 0.1322 - mse: 0.0643\n",
            "Epoch 1426: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3232 - accuracy: 0.8745 - mae: 0.1338 - mse: 0.0663 - val_loss: 0.3263 - val_accuracy: 0.8719 - val_mae: 0.1283 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1427/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3076 - accuracy: 0.8740 - mae: 0.1287 - mse: 0.0640\n",
            "Epoch 1427: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3224 - accuracy: 0.8742 - mae: 0.1319 - mse: 0.0659 - val_loss: 0.3256 - val_accuracy: 0.8731 - val_mae: 0.1274 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1428/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8789 - mae: 0.1288 - mse: 0.0638\n",
            "Epoch 1428: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3203 - accuracy: 0.8745 - mae: 0.1304 - mse: 0.0658 - val_loss: 0.3253 - val_accuracy: 0.8731 - val_mae: 0.1267 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1429/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3256 - accuracy: 0.8691 - mae: 0.1342 - mse: 0.0680\n",
            "Epoch 1429: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3258 - accuracy: 0.8739 - mae: 0.1312 - mse: 0.0666 - val_loss: 0.3244 - val_accuracy: 0.8731 - val_mae: 0.1276 - val_mse: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 1430/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8818 - mae: 0.1284 - mse: 0.0626\n",
            "Epoch 1430: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3199 - accuracy: 0.8752 - mae: 0.1316 - mse: 0.0656 - val_loss: 0.3245 - val_accuracy: 0.8731 - val_mae: 0.1288 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1431/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3283 - accuracy: 0.8779 - mae: 0.1309 - mse: 0.0651\n",
            "Epoch 1431: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3223 - accuracy: 0.8748 - mae: 0.1327 - mse: 0.0659 - val_loss: 0.3249 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1432/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8740 - mae: 0.1338 - mse: 0.0675\n",
            "Epoch 1432: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3249 - accuracy: 0.8745 - mae: 0.1339 - mse: 0.0665 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1433/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8701 - mae: 0.1355 - mse: 0.0689\n",
            "Epoch 1433: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3209 - accuracy: 0.8745 - mae: 0.1345 - mse: 0.0662 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1311 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1434/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3036 - accuracy: 0.8809 - mae: 0.1283 - mse: 0.0622\n",
            "Epoch 1434: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3209 - accuracy: 0.8748 - mae: 0.1338 - mse: 0.0656 - val_loss: 0.3308 - val_accuracy: 0.8731 - val_mae: 0.1319 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1435/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3075 - accuracy: 0.8867 - mae: 0.1278 - mse: 0.0618\n",
            "Epoch 1435: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3201 - accuracy: 0.8745 - mae: 0.1343 - mse: 0.0658 - val_loss: 0.3327 - val_accuracy: 0.8731 - val_mae: 0.1322 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1436/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3253 - accuracy: 0.8682 - mae: 0.1366 - mse: 0.0682\n",
            "Epoch 1436: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.3187 - accuracy: 0.8752 - mae: 0.1335 - mse: 0.0654 - val_loss: 0.3318 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1437/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3118 - accuracy: 0.8750 - mae: 0.1304 - mse: 0.0642\n",
            "Epoch 1437: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3219 - accuracy: 0.8742 - mae: 0.1323 - mse: 0.0659 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1291 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1438/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8750 - mae: 0.1348 - mse: 0.0662\n",
            "Epoch 1438: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3240 - accuracy: 0.8745 - mae: 0.1330 - mse: 0.0663 - val_loss: 0.3290 - val_accuracy: 0.8731 - val_mae: 0.1306 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1439/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0658\n",
            "Epoch 1439: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3227 - accuracy: 0.8745 - mae: 0.1341 - mse: 0.0658 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1333 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1440/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3459 - accuracy: 0.8643 - mae: 0.1433 - mse: 0.0721\n",
            "Epoch 1440: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3215 - accuracy: 0.8748 - mae: 0.1372 - mse: 0.0661 - val_loss: 0.3302 - val_accuracy: 0.8731 - val_mae: 0.1355 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1441/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8740 - mae: 0.1422 - mse: 0.0681\n",
            "Epoch 1441: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3187 - accuracy: 0.8748 - mae: 0.1388 - mse: 0.0659 - val_loss: 0.3302 - val_accuracy: 0.8731 - val_mae: 0.1364 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1442/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8613 - mae: 0.1432 - mse: 0.0697\n",
            "Epoch 1442: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3229 - accuracy: 0.8745 - mae: 0.1395 - mse: 0.0663 - val_loss: 0.3295 - val_accuracy: 0.8731 - val_mae: 0.1352 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1443/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3195 - accuracy: 0.8818 - mae: 0.1367 - mse: 0.0650\n",
            "Epoch 1443: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3236 - accuracy: 0.8748 - mae: 0.1390 - mse: 0.0664 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1336 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1444/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3111 - accuracy: 0.8867 - mae: 0.1337 - mse: 0.0620\n",
            "Epoch 1444: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3190 - accuracy: 0.8752 - mae: 0.1351 - mse: 0.0655 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1445/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8740 - mae: 0.1352 - mse: 0.0665\n",
            "Epoch 1445: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3199 - accuracy: 0.8742 - mae: 0.1337 - mse: 0.0662 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_mae: 0.1281 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1446/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3163 - accuracy: 0.8770 - mae: 0.1298 - mse: 0.0648\n",
            "Epoch 1446: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3201 - accuracy: 0.8752 - mae: 0.1300 - mse: 0.0655 - val_loss: 0.3296 - val_accuracy: 0.8731 - val_mae: 0.1265 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1447/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3413 - accuracy: 0.8633 - mae: 0.1339 - mse: 0.0714\n",
            "Epoch 1447: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3265 - accuracy: 0.8742 - mae: 0.1308 - mse: 0.0670 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1272 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1448/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3181 - accuracy: 0.8809 - mae: 0.1296 - mse: 0.0649\n",
            "Epoch 1448: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.3224 - accuracy: 0.8752 - mae: 0.1310 - mse: 0.0663 - val_loss: 0.3298 - val_accuracy: 0.8731 - val_mae: 0.1303 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1449/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3318 - accuracy: 0.8682 - mae: 0.1361 - mse: 0.0680\n",
            "Epoch 1449: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3206 - accuracy: 0.8748 - mae: 0.1337 - mse: 0.0658 - val_loss: 0.3298 - val_accuracy: 0.8731 - val_mae: 0.1324 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1450/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3502 - accuracy: 0.8535 - mae: 0.1441 - mse: 0.0742\n",
            "Epoch 1450: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.3195 - accuracy: 0.8748 - mae: 0.1348 - mse: 0.0658 - val_loss: 0.3293 - val_accuracy: 0.8731 - val_mae: 0.1321 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1451/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0649\n",
            "Epoch 1451: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3158 - accuracy: 0.8752 - mae: 0.1329 - mse: 0.0649 - val_loss: 0.3288 - val_accuracy: 0.8731 - val_mae: 0.1313 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1452/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8745 - mae: 0.1316 - mse: 0.0654\n",
            "Epoch 1452: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3177 - accuracy: 0.8745 - mae: 0.1316 - mse: 0.0654 - val_loss: 0.3285 - val_accuracy: 0.8731 - val_mae: 0.1292 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1453/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3469 - accuracy: 0.8662 - mae: 0.1329 - mse: 0.0697\n",
            "Epoch 1453: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3241 - accuracy: 0.8745 - mae: 0.1313 - mse: 0.0661 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1454/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3376 - accuracy: 0.8633 - mae: 0.1364 - mse: 0.0701\n",
            "Epoch 1454: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3262 - accuracy: 0.8742 - mae: 0.1306 - mse: 0.0665 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1286 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1455/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3374 - accuracy: 0.8584 - mae: 0.1367 - mse: 0.0709\n",
            "Epoch 1455: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3204 - accuracy: 0.8745 - mae: 0.1314 - mse: 0.0656 - val_loss: 0.3305 - val_accuracy: 0.8719 - val_mae: 0.1326 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1456/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8770 - mae: 0.1361 - mse: 0.0654\n",
            "Epoch 1456: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3229 - accuracy: 0.8745 - mae: 0.1365 - mse: 0.0662 - val_loss: 0.3325 - val_accuracy: 0.8719 - val_mae: 0.1360 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1457/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3191 - accuracy: 0.8789 - mae: 0.1351 - mse: 0.0647\n",
            "Epoch 1457: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3211 - accuracy: 0.8752 - mae: 0.1384 - mse: 0.0661 - val_loss: 0.3341 - val_accuracy: 0.8706 - val_mae: 0.1380 - val_mse: 0.0686 - lr: 1.0000e-04\n",
            "Epoch 1458/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3471 - accuracy: 0.8594 - mae: 0.1468 - mse: 0.0721\n",
            "Epoch 1458: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3310 - accuracy: 0.8742 - mae: 0.1422 - mse: 0.0674 - val_loss: 0.3330 - val_accuracy: 0.8706 - val_mae: 0.1383 - val_mse: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 1459/1500\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.8748 - mae: 0.1398 - mse: 0.0659\n",
            "Epoch 1459: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3208 - accuracy: 0.8748 - mae: 0.1398 - mse: 0.0659 - val_loss: 0.3294 - val_accuracy: 0.8706 - val_mae: 0.1348 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1460/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8643 - mae: 0.1401 - mse: 0.0695\n",
            "Epoch 1460: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3185 - accuracy: 0.8748 - mae: 0.1356 - mse: 0.0658 - val_loss: 0.3265 - val_accuracy: 0.8719 - val_mae: 0.1303 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1461/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3148 - accuracy: 0.8799 - mae: 0.1341 - mse: 0.0639\n",
            "Epoch 1461: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3247 - accuracy: 0.8742 - mae: 0.1325 - mse: 0.0658 - val_loss: 0.3258 - val_accuracy: 0.8731 - val_mae: 0.1278 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1462/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8789 - mae: 0.1300 - mse: 0.0647\n",
            "Epoch 1462: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.3149 - accuracy: 0.8745 - mae: 0.1313 - mse: 0.0656 - val_loss: 0.3264 - val_accuracy: 0.8731 - val_mae: 0.1290 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1463/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3210 - accuracy: 0.8730 - mae: 0.1360 - mse: 0.0669\n",
            "Epoch 1463: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3210 - accuracy: 0.8739 - mae: 0.1336 - mse: 0.0659 - val_loss: 0.3269 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1464/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2968 - accuracy: 0.8848 - mae: 0.1288 - mse: 0.0608\n",
            "Epoch 1464: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3202 - accuracy: 0.8748 - mae: 0.1346 - mse: 0.0658 - val_loss: 0.3269 - val_accuracy: 0.8731 - val_mae: 0.1308 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1465/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8643 - mae: 0.1406 - mse: 0.0707\n",
            "Epoch 1465: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3227 - accuracy: 0.8758 - mae: 0.1344 - mse: 0.0661 - val_loss: 0.3267 - val_accuracy: 0.8731 - val_mae: 0.1289 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1466/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8701 - mae: 0.1371 - mse: 0.0682\n",
            "Epoch 1466: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3177 - accuracy: 0.8742 - mae: 0.1322 - mse: 0.0657 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_mae: 0.1268 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "Epoch 1467/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8721 - mae: 0.1308 - mse: 0.0667\n",
            "Epoch 1467: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3193 - accuracy: 0.8755 - mae: 0.1293 - mse: 0.0655 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1261 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1468/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3437 - accuracy: 0.8623 - mae: 0.1347 - mse: 0.0706\n",
            "Epoch 1468: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3240 - accuracy: 0.8742 - mae: 0.1292 - mse: 0.0659 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1280 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1469/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8623 - mae: 0.1361 - mse: 0.0718\n",
            "Epoch 1469: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3226 - accuracy: 0.8748 - mae: 0.1318 - mse: 0.0662 - val_loss: 0.3310 - val_accuracy: 0.8719 - val_mae: 0.1293 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1470/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8711 - mae: 0.1318 - mse: 0.0660\n",
            "Epoch 1470: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3199 - accuracy: 0.8739 - mae: 0.1319 - mse: 0.0660 - val_loss: 0.3316 - val_accuracy: 0.8719 - val_mae: 0.1295 - val_mse: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 1471/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8760 - mae: 0.1308 - mse: 0.0655\n",
            "Epoch 1471: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3243 - accuracy: 0.8742 - mae: 0.1326 - mse: 0.0663 - val_loss: 0.3320 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1472/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3302 - accuracy: 0.8672 - mae: 0.1346 - mse: 0.0689\n",
            "Epoch 1472: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3252 - accuracy: 0.8739 - mae: 0.1342 - mse: 0.0665 - val_loss: 0.3333 - val_accuracy: 0.8731 - val_mae: 0.1321 - val_mse: 0.0682 - lr: 1.0000e-04\n",
            "Epoch 1473/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3113 - accuracy: 0.8779 - mae: 0.1301 - mse: 0.0635\n",
            "Epoch 1473: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3211 - accuracy: 0.8745 - mae: 0.1337 - mse: 0.0661 - val_loss: 0.3335 - val_accuracy: 0.8731 - val_mae: 0.1328 - val_mse: 0.0683 - lr: 1.0000e-04\n",
            "Epoch 1474/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3053 - accuracy: 0.8818 - mae: 0.1318 - mse: 0.0625\n",
            "Epoch 1474: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3187 - accuracy: 0.8745 - mae: 0.1344 - mse: 0.0655 - val_loss: 0.3326 - val_accuracy: 0.8731 - val_mae: 0.1329 - val_mse: 0.0681 - lr: 1.0000e-04\n",
            "Epoch 1475/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2967 - accuracy: 0.8906 - mae: 0.1272 - mse: 0.0601\n",
            "Epoch 1475: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3210 - accuracy: 0.8748 - mae: 0.1349 - mse: 0.0659 - val_loss: 0.3310 - val_accuracy: 0.8731 - val_mae: 0.1320 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1476/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3295 - accuracy: 0.8730 - mae: 0.1391 - mse: 0.0678\n",
            "Epoch 1476: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3232 - accuracy: 0.8748 - mae: 0.1347 - mse: 0.0662 - val_loss: 0.3297 - val_accuracy: 0.8731 - val_mae: 0.1311 - val_mse: 0.0676 - lr: 1.0000e-04\n",
            "Epoch 1477/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8867 - mae: 0.1255 - mse: 0.0612\n",
            "Epoch 1477: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3207 - accuracy: 0.8748 - mae: 0.1332 - mse: 0.0658 - val_loss: 0.3291 - val_accuracy: 0.8731 - val_mae: 0.1308 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1478/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3261 - accuracy: 0.8730 - mae: 0.1340 - mse: 0.0672\n",
            "Epoch 1478: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3220 - accuracy: 0.8752 - mae: 0.1334 - mse: 0.0661 - val_loss: 0.3291 - val_accuracy: 0.8731 - val_mae: 0.1314 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1479/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8730 - mae: 0.1374 - mse: 0.0670\n",
            "Epoch 1479: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3214 - accuracy: 0.8739 - mae: 0.1362 - mse: 0.0662 - val_loss: 0.3294 - val_accuracy: 0.8731 - val_mae: 0.1333 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1480/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8877 - mae: 0.1295 - mse: 0.0608\n",
            "Epoch 1480: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3201 - accuracy: 0.8745 - mae: 0.1369 - mse: 0.0659 - val_loss: 0.3290 - val_accuracy: 0.8731 - val_mae: 0.1337 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1481/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3358 - accuracy: 0.8730 - mae: 0.1408 - mse: 0.0691\n",
            "Epoch 1481: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.3242 - accuracy: 0.8742 - mae: 0.1378 - mse: 0.0669 - val_loss: 0.3259 - val_accuracy: 0.8731 - val_mae: 0.1330 - val_mse: 0.0671 - lr: 1.0000e-04\n",
            "Epoch 1482/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3139 - accuracy: 0.8779 - mae: 0.1357 - mse: 0.0646\n",
            "Epoch 1482: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3199 - accuracy: 0.8748 - mae: 0.1350 - mse: 0.0655 - val_loss: 0.3240 - val_accuracy: 0.8731 - val_mae: 0.1304 - val_mse: 0.0668 - lr: 1.0000e-04\n",
            "Epoch 1483/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3226 - accuracy: 0.8682 - mae: 0.1346 - mse: 0.0666\n",
            "Epoch 1483: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3169 - accuracy: 0.8745 - mae: 0.1329 - mse: 0.0652 - val_loss: 0.3229 - val_accuracy: 0.8731 - val_mae: 0.1275 - val_mse: 0.0665 - lr: 1.0000e-04\n",
            "Epoch 1484/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8711 - mae: 0.1326 - mse: 0.0668\n",
            "Epoch 1484: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3204 - accuracy: 0.8758 - mae: 0.1314 - mse: 0.0656 - val_loss: 0.3230 - val_accuracy: 0.8731 - val_mae: 0.1291 - val_mse: 0.0664 - lr: 1.0000e-04\n",
            "Epoch 1485/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8711 - mae: 0.1352 - mse: 0.0674\n",
            "Epoch 1485: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3186 - accuracy: 0.8752 - mae: 0.1347 - mse: 0.0656 - val_loss: 0.3262 - val_accuracy: 0.8731 - val_mae: 0.1339 - val_mse: 0.0669 - lr: 1.0000e-04\n",
            "Epoch 1486/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8750 - mae: 0.1417 - mse: 0.0677\n",
            "Epoch 1486: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3260 - accuracy: 0.8748 - mae: 0.1394 - mse: 0.0666 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1347 - val_mse: 0.0673 - lr: 1.0000e-04\n",
            "Epoch 1487/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3021 - accuracy: 0.8828 - mae: 0.1329 - mse: 0.0624\n",
            "Epoch 1487: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3223 - accuracy: 0.8745 - mae: 0.1388 - mse: 0.0664 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1328 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1488/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8643 - mae: 0.1398 - mse: 0.0696\n",
            "Epoch 1488: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.3231 - accuracy: 0.8742 - mae: 0.1361 - mse: 0.0662 - val_loss: 0.3289 - val_accuracy: 0.8731 - val_mae: 0.1305 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1489/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8721 - mae: 0.1355 - mse: 0.0685\n",
            "Epoch 1489: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3197 - accuracy: 0.8752 - mae: 0.1325 - mse: 0.0657 - val_loss: 0.3288 - val_accuracy: 0.8731 - val_mae: 0.1281 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1490/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8740 - mae: 0.1303 - mse: 0.0655\n",
            "Epoch 1490: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3248 - accuracy: 0.8742 - mae: 0.1315 - mse: 0.0663 - val_loss: 0.3288 - val_accuracy: 0.8731 - val_mae: 0.1268 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1491/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8799 - mae: 0.1290 - mse: 0.0653\n",
            "Epoch 1491: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3260 - accuracy: 0.8745 - mae: 0.1313 - mse: 0.0667 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_mae: 0.1260 - val_mse: 0.0674 - lr: 1.0000e-04\n",
            "Epoch 1492/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3059 - accuracy: 0.8818 - mae: 0.1252 - mse: 0.0615\n",
            "Epoch 1492: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3194 - accuracy: 0.8748 - mae: 0.1293 - mse: 0.0653 - val_loss: 0.3300 - val_accuracy: 0.8706 - val_mae: 0.1273 - val_mse: 0.0678 - lr: 1.0000e-04\n",
            "Epoch 1493/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3000 - accuracy: 0.8848 - mae: 0.1255 - mse: 0.0610\n",
            "Epoch 1493: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3212 - accuracy: 0.8755 - mae: 0.1305 - mse: 0.0659 - val_loss: 0.3333 - val_accuracy: 0.8706 - val_mae: 0.1301 - val_mse: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 1494/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3117 - accuracy: 0.8809 - mae: 0.1319 - mse: 0.0639\n",
            "Epoch 1494: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3226 - accuracy: 0.8739 - mae: 0.1333 - mse: 0.0664 - val_loss: 0.3369 - val_accuracy: 0.8706 - val_mae: 0.1332 - val_mse: 0.0692 - lr: 1.0000e-04\n",
            "Epoch 1495/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3074 - accuracy: 0.8799 - mae: 0.1330 - mse: 0.0633\n",
            "Epoch 1495: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3169 - accuracy: 0.8748 - mae: 0.1344 - mse: 0.0655 - val_loss: 0.3376 - val_accuracy: 0.8706 - val_mae: 0.1338 - val_mse: 0.0692 - lr: 1.0000e-04\n",
            "Epoch 1496/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3173 - accuracy: 0.8779 - mae: 0.1334 - mse: 0.0649\n",
            "Epoch 1496: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3211 - accuracy: 0.8755 - mae: 0.1353 - mse: 0.0660 - val_loss: 0.3377 - val_accuracy: 0.8706 - val_mae: 0.1328 - val_mse: 0.0691 - lr: 1.0000e-04\n",
            "Epoch 1497/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3463 - accuracy: 0.8662 - mae: 0.1402 - mse: 0.0715\n",
            "Epoch 1497: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.3224 - accuracy: 0.8748 - mae: 0.1334 - mse: 0.0662 - val_loss: 0.3352 - val_accuracy: 0.8706 - val_mae: 0.1303 - val_mse: 0.0687 - lr: 1.0000e-04\n",
            "Epoch 1498/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8711 - mae: 0.1325 - mse: 0.0669\n",
            "Epoch 1498: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3175 - accuracy: 0.8752 - mae: 0.1311 - mse: 0.0657 - val_loss: 0.3316 - val_accuracy: 0.8719 - val_mae: 0.1275 - val_mse: 0.0680 - lr: 1.0000e-04\n",
            "Epoch 1499/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3175 - accuracy: 0.8799 - mae: 0.1265 - mse: 0.0634\n",
            "Epoch 1499: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3220 - accuracy: 0.8742 - mae: 0.1297 - mse: 0.0659 - val_loss: 0.3287 - val_accuracy: 0.8731 - val_mae: 0.1259 - val_mse: 0.0675 - lr: 1.0000e-04\n",
            "Epoch 1500/1500\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8877 - mae: 0.1219 - mse: 0.0600\n",
            "Epoch 1500: val_loss did not improve from 0.32062\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3249 - accuracy: 0.8742 - mae: 0.1288 - mse: 0.0664 - val_loss: 0.3271 - val_accuracy: 0.8731 - val_mae: 0.1263 - val_mse: 0.0672 - lr: 1.0000e-04\n",
            "CPU times: user 2min 18s, sys: 7.3 s, total: 2min 25s\n",
            "Wall time: 3min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "CQZRdkOKfvnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "# plt.plot(hist.history['f1_metric'])\n",
        "# plt.plot(hist.history['val_f1_metric'])\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['accuracy'])\n",
        "\n",
        "plt.title(f'Model Loss and Accuracy: Fold {fold}')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'accuracy'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kQGQMtu6fvHH",
        "outputId": "f72da71c-a6c2-4ce1-8471-92d16d645139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'fold' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-9a074b7eeef2>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model Loss and Accuracy: Fold {fold}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fold' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.legend(['accuracy'], loc='upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "oOO9pVR-c_ef",
        "outputId": "9d2d47bd-288a-49bf-d45a-336d8307c922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d67c35ed000>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRgEBIGJQXM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}