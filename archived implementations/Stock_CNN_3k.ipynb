{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw_NyIyJlDmr",
        "outputId": "1dce1696-b13a-42b4-ff6c-aa22a1660bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5DQPqWulGhr",
        "outputId": "b7c74f54-4851-4c36-f553-1633ae5b3982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CNN Stock Prediction\n"
          ]
        }
      ],
      "source": [
        "%cd \"drive/MyDrive/CNN Stock Prediction\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ryu3DVmINch"
      },
      "source": [
        "#Load in X_train, X_label, y_train, y_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI_47pWIIT5S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "stock = 'IBM'\n",
        "\n",
        "train_features_path = f\"data/split/{stock}_train_feature_set.csv\"\n",
        "train_ft_df = pd.read_csv(train_features_path)\n",
        "\n",
        "train_labels_path = f\"data/split/{stock}_train_label_set.csv\"\n",
        "train_labels_df = pd.read_csv(train_labels_path)\n",
        "\n",
        "test_features_path = f\"data/split/{stock}_test_feature_set.csv\"\n",
        "test_ft_df = pd.read_csv(test_features_path)\n",
        "\n",
        "test_labels_path = f\"data/split/{stock}_test_label_set.csv\"\n",
        "test_labels_df = pd.read_csv(test_labels_path)\n",
        "\n",
        "dataframes = [train_ft_df, train_labels_df, test_ft_df, test_labels_df]\n",
        "\n",
        "cleaned_dfs = []\n",
        "for i in range(len(dataframes)):\n",
        "  df = dataframes[i]\n",
        "  cleaned_df = df.drop(['Unnamed: 0'], axis=1)\n",
        "  cleaned_df = cleaned_df.dropna()\n",
        "\n",
        "  cleaned_dfs.append(cleaned_df)\n",
        "\n",
        "X_train_all = cleaned_dfs[0]\n",
        "y_train_set = cleaned_dfs[1]\n",
        "X_test_all = cleaned_dfs[2]\n",
        "y_test = cleaned_dfs[3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACfwCXrIGbLT"
      },
      "source": [
        "Check for NAN Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mHJtKw5Gdkr",
        "outputId": "d2122d7c-5d02-456a-9f4d-6df5b49bb5d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X_train_all.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0ywNElLf2Tv",
        "outputId": "41563c50-4d39-4592-d6f7-af1558309f32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "y_train_set.isnull().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APITjVGPrn7w"
      },
      "source": [
        "DataFrame Sizes Before Choosing Best 225 Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYg0mPf0l5on",
        "outputId": "ddf8ae65-61c1-4cf6-d47b-8fb4aa011770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_all shape: (3115, 420)\n",
            "y_train_set labels shape: (3115, 1)\n",
            "X_test_all shape: (779, 420)\n",
            "y_test labels shape: (779, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train_all shape: {X_train_all.shape}\")\n",
        "print(f\"y_train_set labels shape: {y_train_set.shape}\")\n",
        "print(f\"X_test_all shape: {X_test_all.shape}\")\n",
        "print(f\"y_test labels shape: {y_test.shape}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCHQdaUJmYOE",
        "outputId": "868666ea-625e-4c04-949a-64daf45b53b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    2719\n",
              "2     201\n",
              "1     195\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# count train labels\n",
        "y_train_set.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q15xHZDul1fQ",
        "outputId": "87cdc00e-0b39-417d-e1f6-d84ae572ac9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    680\n",
              "2     50\n",
              "1     49\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# count test labels\n",
        "y_test.Label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F47Gb-7Oysg-"
      },
      "source": [
        "#Retrieve Data with Best Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pcD7dTV-wZlW",
        "outputId": "7d91a572-28d8-411c-f3e9-717e5063a3a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0\n",
              "0   RSI_ta_6\n",
              "1   RSI_ta_7\n",
              "2   RSI_ta_8\n",
              "3   RSI_ta_9\n",
              "4  RSI_ta_10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1bf4f0f-c874-4521-8681-44453c9537bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RSI_ta_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RSI_ta_7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RSI_ta_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RSI_ta_9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RSI_ta_10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1bf4f0f-c874-4521-8681-44453c9537bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1bf4f0f-c874-4521-8681-44453c9537bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1bf4f0f-c874-4521-8681-44453c9537bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4eac293b-cc87-4dde-854f-da78c29f9889\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4eac293b-cc87-4dde-854f-da78c29f9889')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4eac293b-cc87-4dde-854f-da78c29f9889 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 225,\n  \"fields\": [\n    {\n      \"column\": \"0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 225,\n        \"samples\": [\n          \"RSI_ta_15\",\n          \"CMF_ta_16\",\n          \"MFI_ta_12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data_path = f\"data/features/{stock}_selected_features.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "\n",
        "df.head() #(225, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "E-jka903y0Vv",
        "outputId": "fc7d4450-2580-49c1-f90e-eb03aabd8b92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [RSI_ta_6, RSI_ta_7, RSI_ta_8, RSI_ta_9, RSI_ta_10, RSI_ta_11, RSI_ta_12, RSI_ta_13, RSI_ta_14, RSI_ta_15, RSI_ta_16, RSI_ta_17, RSI_ta_18, RSI_ta_19, RSI_ta_20, WILLR_ta_6, WILLR_ta_7, WILLR_ta_8, WILLR_ta_9, WILLR_ta_10, WILLR_ta_11, WILLR_ta_12, WILLR_ta_13, WILLR_ta_14, WILLR_ta_15, WILLR_ta_16, WILLR_ta_17, WILLR_ta_18, WILLR_ta_19, WILLR_ta_20, TEMA_talib_6, CCI_ta_6, CCI_ta_7, CCI_ta_8, CCI_ta_9, CCI_ta_10, CCI_ta_11, CCI_ta_12, CCI_ta_13, CCI_ta_14, CCI_ta_15, CCI_ta_16, CCI_ta_17, CCI_ta_18, CCI_ta_19, CCI_ta_20, CMO_talib_6, CMO_talib_7, CMO_talib_8, CMO_talib_9, CMO_talib_10, CMO_talib_11, CMO_talib_12, CMO_talib_13, CMO_talib_14, CMO_talib_15, CMO_talib_16, CMO_talib_17, CMO_talib_18, CMO_talib_19, CMO_talib_20, MACD_ta_6, MACD_ta_7, MACD_ta_8, MACD_ta_9, MACD_ta_10, MACD_ta_11, MACD_ta_12, MACD_ta_13, MACD_ta_14, MACD_ta_15, MACD_ta_16, MACD_ta_17, MACD_ta_18, MACD_ta_19, MACD_ta_20, PPO_ta_6, PPO_ta_7, PPO_ta_8, PPO_ta_9, PPO_ta_10, PPO_ta_11, PPO_ta_12, PPO_ta_13, PPO_ta_14, PPO_ta_15, PPO_ta_16, PPO_ta_17, PPO_ta_18, PPO_ta_19, PPO_ta_20, ROC_ta_6, ROC_ta_7, ROC_ta_8, ROC_ta_9, ROC_ta_10, ROC_ta_11, ROC_ta_12, ROC_ta_13, ROC_ta_14, ...]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 225 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a314dea7-ee6e-4be2-b878-6c2d002740b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>0</th>\n",
              "      <th>RSI_ta_6</th>\n",
              "      <th>RSI_ta_7</th>\n",
              "      <th>RSI_ta_8</th>\n",
              "      <th>RSI_ta_9</th>\n",
              "      <th>RSI_ta_10</th>\n",
              "      <th>RSI_ta_11</th>\n",
              "      <th>RSI_ta_12</th>\n",
              "      <th>RSI_ta_13</th>\n",
              "      <th>RSI_ta_14</th>\n",
              "      <th>RSI_ta_15</th>\n",
              "      <th>...</th>\n",
              "      <th>AWSM_ta_7</th>\n",
              "      <th>AWSM_ta_8</th>\n",
              "      <th>AWSM_ta_9</th>\n",
              "      <th>AWSM_ta_10</th>\n",
              "      <th>AWSM_ta_11</th>\n",
              "      <th>AWSM_ta_12</th>\n",
              "      <th>AWSM_ta_13</th>\n",
              "      <th>AWSM_ta_14</th>\n",
              "      <th>AWSM_ta_15</th>\n",
              "      <th>AWSM_ta_16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 225 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a314dea7-ee6e-4be2-b878-6c2d002740b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a314dea7-ee6e-4be2-b878-6c2d002740b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a314dea7-ee6e-4be2-b878-6c2d002740b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# transpose dataframe\n",
        "max_accuracy_features = df.T\n",
        "\n",
        "headers = max_accuracy_features.iloc[0]\n",
        "features = pd.DataFrame(max_accuracy_features.values[1:], columns=headers) # best feature columns (0, 225) shape\n",
        "\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU4xkcMqp6fO"
      },
      "source": [
        "Best 225 Features in the Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWH46hF8y9Wj",
        "outputId": "25a98fea-2a7d-42d1-b45d-56162b0b1291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train Features: (3115, 225)\n"
          ]
        }
      ],
      "source": [
        "common_cols=list(set.intersection(set(X_train_all), set(features)))\n",
        "X_train_selected_features = X_train_all[common_cols]\n",
        "\n",
        "# rearrange to keep the original order of feature columns\n",
        "X_train_set = X_train_selected_features[list(features.columns)]\n",
        "\n",
        "print(\"Shape of Train Features:\", X_train_set.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2xrmQDmqHp8"
      },
      "source": [
        "Best 225 Features in the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9aiACaCqF4Z",
        "outputId": "cc851650-dbf8-4607-f329-009ef459583f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Test Features: (779, 225)\n"
          ]
        }
      ],
      "source": [
        "common_cols=list(set.intersection(set(X_test_all), set(features)))\n",
        "X_test_selected_features = X_test_all[common_cols]\n",
        "\n",
        "# rearrange to keep the original order of feature columns\n",
        "X_test = X_test_selected_features[list(features.columns)]\n",
        "\n",
        "print(\"Shape of Test Features:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xgWBXwLryBl",
        "outputId": "12c51151-faef-4097-b027-45de5d916a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train_set labels shape: (3115, 1)\n",
            "y_test labels shape: (779, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f\"y_train_set labels shape: {y_train_set.shape}\")\n",
        "print(f\"y_test labels shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "3I61029rmlh6",
        "outputId": "8cff47a9-e76e-43e7-fffd-25310f9c3a74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    RSI_ta_6   RSI_ta_7   RSI_ta_8   RSI_ta_9  RSI_ta_10  RSI_ta_11  \\\n",
              "0  47.990006  50.211632  51.454054  52.087298  52.338221  52.348572   \n",
              "1  44.355841  47.207888  49.284600  50.851197  52.066571  53.030537   \n",
              "2  41.146379  42.049716  42.535587  42.831382  43.045938  43.229699   \n",
              "3  89.481793  86.988204  84.629898  82.435110  80.416114  78.573461   \n",
              "4  53.802468  55.387964  56.244843  56.646624  56.766439  56.712363   \n",
              "\n",
              "   RSI_ta_12  RSI_ta_13  RSI_ta_14  RSI_ta_15  ...  AWSM_ta_7  AWSM_ta_8  \\\n",
              "0  52.208661  51.976951  51.691720  51.378208  ...   1.957143   2.946875   \n",
              "1  53.808399  54.444368  54.969293  55.405305  ...   2.039286   2.006875   \n",
              "2  43.404925  43.580505  43.759140  43.940813  ...   1.801786   1.860000   \n",
              "3  76.900160  75.385001  74.014888  72.776309  ...   3.569286   3.373125   \n",
              "4  56.552084  56.328474  56.069056  55.791714  ...   0.957857   1.864062   \n",
              "\n",
              "   AWSM_ta_9  AWSM_ta_10  AWSM_ta_11  AWSM_ta_12  AWSM_ta_13  AWSM_ta_14  \\\n",
              "0   3.311111     3.60475    3.541136    2.699167    2.237692    1.947500   \n",
              "1   1.962500     1.72275    1.410682    1.210625    1.625385    2.073036   \n",
              "2   1.925833     0.91575   -0.455909   -2.041875   -3.258654   -4.358036   \n",
              "3   3.186667     3.02725    2.717273    2.183958    1.481731    0.949821   \n",
              "4   2.710833     2.51600    3.494773    4.400000    5.243077    5.453750   \n",
              "\n",
              "   AWSM_ta_15  AWSM_ta_16  \n",
              "0    1.428000    1.217969  \n",
              "1    2.341333    2.697813  \n",
              "2   -5.328833   -5.831875  \n",
              "3    0.560667    0.000781  \n",
              "4    5.097167    4.422969  \n",
              "\n",
              "[5 rows x 225 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4f89ecd-7d20-49ed-ad30-ff594fb2aae8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RSI_ta_6</th>\n",
              "      <th>RSI_ta_7</th>\n",
              "      <th>RSI_ta_8</th>\n",
              "      <th>RSI_ta_9</th>\n",
              "      <th>RSI_ta_10</th>\n",
              "      <th>RSI_ta_11</th>\n",
              "      <th>RSI_ta_12</th>\n",
              "      <th>RSI_ta_13</th>\n",
              "      <th>RSI_ta_14</th>\n",
              "      <th>RSI_ta_15</th>\n",
              "      <th>...</th>\n",
              "      <th>AWSM_ta_7</th>\n",
              "      <th>AWSM_ta_8</th>\n",
              "      <th>AWSM_ta_9</th>\n",
              "      <th>AWSM_ta_10</th>\n",
              "      <th>AWSM_ta_11</th>\n",
              "      <th>AWSM_ta_12</th>\n",
              "      <th>AWSM_ta_13</th>\n",
              "      <th>AWSM_ta_14</th>\n",
              "      <th>AWSM_ta_15</th>\n",
              "      <th>AWSM_ta_16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47.990006</td>\n",
              "      <td>50.211632</td>\n",
              "      <td>51.454054</td>\n",
              "      <td>52.087298</td>\n",
              "      <td>52.338221</td>\n",
              "      <td>52.348572</td>\n",
              "      <td>52.208661</td>\n",
              "      <td>51.976951</td>\n",
              "      <td>51.691720</td>\n",
              "      <td>51.378208</td>\n",
              "      <td>...</td>\n",
              "      <td>1.957143</td>\n",
              "      <td>2.946875</td>\n",
              "      <td>3.311111</td>\n",
              "      <td>3.60475</td>\n",
              "      <td>3.541136</td>\n",
              "      <td>2.699167</td>\n",
              "      <td>2.237692</td>\n",
              "      <td>1.947500</td>\n",
              "      <td>1.428000</td>\n",
              "      <td>1.217969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.355841</td>\n",
              "      <td>47.207888</td>\n",
              "      <td>49.284600</td>\n",
              "      <td>50.851197</td>\n",
              "      <td>52.066571</td>\n",
              "      <td>53.030537</td>\n",
              "      <td>53.808399</td>\n",
              "      <td>54.444368</td>\n",
              "      <td>54.969293</td>\n",
              "      <td>55.405305</td>\n",
              "      <td>...</td>\n",
              "      <td>2.039286</td>\n",
              "      <td>2.006875</td>\n",
              "      <td>1.962500</td>\n",
              "      <td>1.72275</td>\n",
              "      <td>1.410682</td>\n",
              "      <td>1.210625</td>\n",
              "      <td>1.625385</td>\n",
              "      <td>2.073036</td>\n",
              "      <td>2.341333</td>\n",
              "      <td>2.697813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41.146379</td>\n",
              "      <td>42.049716</td>\n",
              "      <td>42.535587</td>\n",
              "      <td>42.831382</td>\n",
              "      <td>43.045938</td>\n",
              "      <td>43.229699</td>\n",
              "      <td>43.404925</td>\n",
              "      <td>43.580505</td>\n",
              "      <td>43.759140</td>\n",
              "      <td>43.940813</td>\n",
              "      <td>...</td>\n",
              "      <td>1.801786</td>\n",
              "      <td>1.860000</td>\n",
              "      <td>1.925833</td>\n",
              "      <td>0.91575</td>\n",
              "      <td>-0.455909</td>\n",
              "      <td>-2.041875</td>\n",
              "      <td>-3.258654</td>\n",
              "      <td>-4.358036</td>\n",
              "      <td>-5.328833</td>\n",
              "      <td>-5.831875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>89.481793</td>\n",
              "      <td>86.988204</td>\n",
              "      <td>84.629898</td>\n",
              "      <td>82.435110</td>\n",
              "      <td>80.416114</td>\n",
              "      <td>78.573461</td>\n",
              "      <td>76.900160</td>\n",
              "      <td>75.385001</td>\n",
              "      <td>74.014888</td>\n",
              "      <td>72.776309</td>\n",
              "      <td>...</td>\n",
              "      <td>3.569286</td>\n",
              "      <td>3.373125</td>\n",
              "      <td>3.186667</td>\n",
              "      <td>3.02725</td>\n",
              "      <td>2.717273</td>\n",
              "      <td>2.183958</td>\n",
              "      <td>1.481731</td>\n",
              "      <td>0.949821</td>\n",
              "      <td>0.560667</td>\n",
              "      <td>0.000781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53.802468</td>\n",
              "      <td>55.387964</td>\n",
              "      <td>56.244843</td>\n",
              "      <td>56.646624</td>\n",
              "      <td>56.766439</td>\n",
              "      <td>56.712363</td>\n",
              "      <td>56.552084</td>\n",
              "      <td>56.328474</td>\n",
              "      <td>56.069056</td>\n",
              "      <td>55.791714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.957857</td>\n",
              "      <td>1.864062</td>\n",
              "      <td>2.710833</td>\n",
              "      <td>2.51600</td>\n",
              "      <td>3.494773</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>5.243077</td>\n",
              "      <td>5.453750</td>\n",
              "      <td>5.097167</td>\n",
              "      <td>4.422969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 225 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4f89ecd-7d20-49ed-ad30-ff594fb2aae8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4f89ecd-7d20-49ed-ad30-ff594fb2aae8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4f89ecd-7d20-49ed-ad30-ff594fb2aae8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5cae6f0a-b3ac-4544-a75d-feff2b020d92\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cae6f0a-b3ac-4544-a75d-feff2b020d92')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5cae6f0a-b3ac-4544-a75d-feff2b020d92 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_set"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f8YuyCUkq69T",
        "outputId": "efb79b95-5018-469a-e8b5-14af0926f1de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label\n",
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96a0116d-7f08-4d6d-b950-d19d277015a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96a0116d-7f08-4d6d-b950-d19d277015a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96a0116d-7f08-4d6d-b950-d19d277015a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96a0116d-7f08-4d6d-b950-d19d277015a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7de66e14-c600-4516-b63d-0c26b4a32348\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7de66e14-c600-4516-b63d-0c26b4a32348')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7de66e14-c600-4516-b63d-0c26b4a32348 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_train_set",
              "summary": "{\n  \"name\": \"y_train_set\",\n  \"rows\": 3115,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "y_train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SgMyrMfqC4w",
        "outputId": "bbdfab60-ff32-45d5-f024-95dfdb18dc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test Class Distribution: \n",
            "[[  0 680]\n",
            " [  1  49]\n",
            " [  2  50]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"y_test Class Distribution: \")\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1URRvW8EnMXF"
      },
      "source": [
        "#Train and Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzUZVMO7rZMt",
        "outputId": "c10db91f-db7f-4e28-e5fe-04917cdfd6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (2180, 225)\n",
            "y_train shape: (2180, 1)\n",
            "X_val shape: (935, 225)\n",
            "y_val shape: (935, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split train into train and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_set, y_train_set, train_size=0.7,\n",
        "                                                    test_size=0.3, random_state=2, shuffle=True,\n",
        "                                                    stratify=y_train_set)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDlDMPXQp0nN",
        "outputId": "0174f9b6-03a6-4f90-9645-f322854a6f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_val Class Distribution: \n",
            "[[  0 816]\n",
            " [  1  59]\n",
            " [  2  60]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "print(\"y_val Class Distribution: \")\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE2rgnS2Ko1-",
        "outputId": "3a02035a-e8e1-4dd8-f8c0-c39df9cccf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train Class Distribution: \n",
            "[[   0 1903]\n",
            " [   1  136]\n",
            " [   2  141]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"y_train Class Distribution: \")\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osevTqf2bBtX"
      },
      "source": [
        "#Balance Classes on Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dILKrWWGbEYK",
        "outputId": "b03fec4a-f458-45ae-df66-47506d438bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaOFmErrecpk",
        "outputId": "8831f4a9-99ad-4a56-a320-d4dd478514c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Label Distribution:\n",
            "Class=0, n=1903 (87.294%)\n",
            "Class=2, n=141 (6.468%)\n",
            "Class=1, n=136 (6.239%)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "import imblearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "\n",
        "# encode labels for each class\n",
        "def sampleDistribution(y):\n",
        "  y = LabelEncoder().fit_transform(y)\n",
        "  counter = Counter(y)\n",
        "\n",
        "  for k,v in counter.items():\n",
        "    per = v / len(y) * 100\n",
        "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Training Set Label Distribution:\")\n",
        "sampleDistribution(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbI6yQ24mvjw"
      },
      "source": [
        "Oversampling the Minority Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvxgbQO6mx3Z"
      },
      "outputs": [],
      "source": [
        "# # from imblearn.over_sampling import SMOTE\n",
        "# from imblearn.under_sampling import TomekLinks\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# # oversample = RandomOverSampler(sampling_strategy=\"not majority\")\n",
        "# # # resample the dataset\n",
        "# # X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# sampleDistribution(y_train)\n",
        "\n",
        "# under = TomekLinks()\n",
        "\n",
        "# X_train, y_train = under.fit_resample(X_train, y_train)\n",
        "# sampleDistribution(y_train)\n",
        "\n",
        "# X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEwVh7dCOPEA"
      },
      "outputs": [],
      "source": [
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# sampleDistribution(y_train)\n",
        "\n",
        "# # define oversampling strategy\n",
        "# over = SMOTE()\n",
        "\n",
        "# X_train, y_train = over.fit_resample(X_train, y_train)\n",
        "# sampleDistribution(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr7KR6OcPn_E"
      },
      "source": [
        "Undersampling the Majority Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z3rNfboPmpJ"
      },
      "outputs": [],
      "source": [
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# # define undersample strategy\n",
        "# undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "\n",
        "# # fit and apply the transform\n",
        "# X_train_bal, y_train_bal = undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "# sampleDistribution(y_train_bal)\n",
        "\n",
        "# X_train = pd.DataFrame(X_train_bal, columns = X.columns) # feature columns\n",
        "# y_train = pd.DataFrame(y_train_bal, columns = y.columns) # undersampled label columns\n",
        "\n",
        "# X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pzPLRaAxVP0"
      },
      "source": [
        "Combined Oversampling and Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPZ02UEYUaTB"
      },
      "outputs": [],
      "source": [
        "# # from imblearn.under_sampling import RandomUnderSampler\n",
        "# # from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "\n",
        "# # resample all but the majority class\n",
        "# smote_tomek = SMOTETomek(sampling_strategy = 'not majority')\n",
        "\n",
        "# # resample the dataset\n",
        "# X_train, y_train = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "# sampleDistribution(y_train)\n",
        "\n",
        "# # X_train = pd.DataFrame(X_train_bal, columns = X.columns) # undersample/oversampled feature columns\n",
        "# # y_train = pd.DataFrame(y_train_bal, columns = y.columns) # undersample/oversampled label columns\n",
        "\n",
        "# X_train.shape\n",
        "# #y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq6KwzTyYDeP"
      },
      "source": [
        "Undersampling then Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwx4A9I4YWpG"
      },
      "outputs": [],
      "source": [
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# sampleDistribution(y_train)\n",
        "# # define undersampling strategy\n",
        "# under = RandomUnderSampler(sampling_strategy={0:1250})\n",
        "\n",
        "# X_train, y_train = under.fit_resample(X_train, y_train)\n",
        "# sampleDistribution(y_train)\n",
        "# # define oversampling strategy\n",
        "# over = RandomOverSampler(sampling_strategy = 'not majority')\n",
        "\n",
        "# X_train, y_train = over.fit_resample(X_train, y_train)\n",
        "\n",
        "# sampleDistribution(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjiKDOEO6yJc"
      },
      "source": [
        "Oversampling Using Smote Then Undersampling Using Tomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdsSVUMU614w"
      },
      "outputs": [],
      "source": [
        "# from imblearn.under_sampling import TomekLinks\n",
        "# # from imblearn.over_sampling import RandomOverSampler\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# sampleDistribution(y_train)\n",
        "\n",
        "# # define oversampling strategy\n",
        "# over = SMOTE()\n",
        "\n",
        "# X_train, y_train = over.fit_resample(X_train, y_train)\n",
        "# sampleDistribution(y_train)\n",
        "\n",
        "\n",
        "# # define undersampling strategy\n",
        "# under = TomekLinks()\n",
        "\n",
        "# X_train, y_train = under.fit_resample(X_train, y_train)\n",
        "# sampleDistribution(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUAwTFBgSt8Q"
      },
      "source": [
        "#Calculate Sample Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiHsUfmDSxQO",
        "outputId": "62ed35ac-38a3-4ccd-df45-927ea9723d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label\n",
            "1203      0\n",
            "77        0\n",
            "1056      0\n",
            "1641      0\n",
            "221       2\n",
            "926       0\n",
            "3032      0\n",
            "288       0\n",
            "2157      0\n",
            "641       0\n",
            "2893      0\n",
            "480       0\n",
            "1060      0\n",
            "22        0\n",
            "1288      0\n",
            "2893      0\n",
            "765       0\n",
            "765       0\n",
            "2032      0\n",
            "288       0\n",
            "411       0\n",
            "1151      0\n",
            "134       2\n",
            "2929      0\n",
            "1255      0\n",
            "2136      0\n",
            "991       0\n",
            "284       1\n",
            "940       0\n",
            "549       0\n",
            "[0.38185321 0.38185321 0.38185321 0.38185321 5.1536643  0.38185321\n",
            " 0.38185321 0.38185321 0.38185321 0.38185321 0.38185321 0.38185321\n",
            " 0.38185321 0.38185321 0.38185321 0.38185321 0.38185321 0.38185321\n",
            " 0.38185321 0.38185321 0.38185321 0.38185321 5.1536643  0.38185321\n",
            " 0.38185321 0.38185321 0.38185321 5.34313725 0.38185321 0.38185321]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# y_integers = np.argmax(y_train, axis=1) # compute_class_weight needs int labels\n",
        "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
        "# d_class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "y_int = y_train.Label.values\n",
        "y_integers = y_int.astype(int)  # compute_class_weight needs int labels\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
        "sample_weights = y_integers.copy().astype(float)\n",
        "for i in np.unique(y_integers):\n",
        "  sample_weights[sample_weights == i] = class_weights[i]\n",
        "\n",
        "rand_idx = np.random.randint(0, 100, 30)\n",
        "print(y_train.iloc[rand_idx])\n",
        "print(sample_weights[rand_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-_q9tGWKvfQ"
      },
      "source": [
        "# Setup Test Input Images (Normalizing + Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZC_PyIUg-S6d",
        "outputId": "a7811eb1-66da-4332-f799-88ce5dfe5351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n0 -> [1, 0, 0]\\n1 -> [0, 1, 0]\\n2 -> [0, 0, 1]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# min max scalar\n",
        "MM_SCALER = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "# One Hot Encode Labels\n",
        "\"\"\"\n",
        "0 -> [1, 0, 0]\n",
        "1 -> [0, 1, 0]\n",
        "2 -> [0, 0, 1]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piY-_WRgC8_T"
      },
      "source": [
        "###Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNZSAdE0_ahW"
      },
      "outputs": [],
      "source": [
        "X_train = MM_SCALER.fit_transform(X_train)\n",
        "X_val = MM_SCALER.transform(X_val)\n",
        "X_test = MM_SCALER.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyt39BRC_7l"
      },
      "source": [
        "###Reshape Data into 15x15 Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5hK0Qsm_gMI",
        "outputId": "bad4f936-5f78-406d-9d5e-fb11473276ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Images shape: (2180, 15, 15)\n",
            "X_val Images shape: (935, 15, 15)\n",
            "X_test Images shape: (779, 15, 15)\n"
          ]
        }
      ],
      "source": [
        "X_train_images = X_train.reshape(X_train.shape[0], 15, 15)\n",
        "X_val_images = X_val.reshape(X_val.shape[0], 15, 15)\n",
        "X_test_images = X_test.reshape(X_test.shape[0], 15, 15)\n",
        "\n",
        "print(f\"X_train Images shape: {X_train_images.shape}\")\n",
        "print(f\"X_val Images shape: {X_val_images.shape}\")\n",
        "print(f\"X_test Images shape: {X_test_images.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN4gqpiBDFb5"
      },
      "source": [
        "###Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqkTmyqQ8qn3",
        "outputId": "11f25be7-e606-41c5-da31-a1ab2502efe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2180, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "OHE = OneHotEncoder(sparse=False, categories='auto')\n",
        "\n",
        "y_train = y_train.to_numpy()\n",
        "y_val = y_val.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "y_train = OHE.fit_transform(y_train.reshape(-1, 1)) # Reshapes to a column vector\n",
        "y_val = OHE.transform(y_val.reshape(-1, 1))\n",
        "y_test = OHE.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpetb-kl_NTO",
        "outputId": "cc00e73f-160a-4eef-dc45-c82df83b35e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train images shape: (2180, 15, 15)\n",
            "y_train labels shape: (2180, 3)\n",
            "\n",
            "X_val images shape: (935, 15, 15)\n",
            "y_val labels shape: (935, 3)\n",
            "\n",
            "X_test images shape: (779, 15, 15)\n",
            "y_test labels shape: (779, 3)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train images shape: {X_train_images.shape}\")\n",
        "print(f\"y_train labels shape: {y_train.shape}\\n\")\n",
        "\n",
        "print(f\"X_val images shape: {X_val_images.shape}\")\n",
        "print(f\"y_val labels shape: {y_val.shape}\\n\")\n",
        "\n",
        "print(f\"X_test images shape: {X_test_images.shape}\")\n",
        "print(f\"y_test labels shape: {y_test.shape}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNRBdqU2F8K3"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urww_XpsE2hg"
      },
      "source": [
        "###CNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOsZVNF3E7p5",
        "outputId": "6102fc8d-c36a-4164-d905-59bc0480c387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPYb7Otse1dv"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"input_w\": 15,\n",
        "    \"input_h\": 15,\n",
        "    \"input_c\": 3,\n",
        "    \"num_classes\": 3,\n",
        "    \"batch_size\": 1024,\n",
        "    \"epochs\": 3000\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYy2LGUjE9Pc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# CNN model\n",
        "model = Sequential()\n",
        "# Conv2D\n",
        "model.add(Conv2D(filters = 20,\n",
        "                 kernel_size = 2,\n",
        "                 strides = 1,\n",
        "                 padding = 'valid',\n",
        "                 activation='relu',\n",
        "                 use_bias = True,\n",
        "                 kernel_regularizer=regularizers.l2(0.0),\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 input_shape=(params[\"input_w\"],\n",
        "                              params[\"input_h\"],\n",
        "                              params[\"input_c\"])\n",
        "                  ))\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.22))\n",
        "\n",
        "# Conv2D\n",
        "model.add(Conv2D(filters = 40,\n",
        "                 kernel_size = 2,\n",
        "                 strides = 2,\n",
        "                 padding = 'valid',\n",
        "                 activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(0.0),\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 ))\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense\n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.22))\n",
        "\n",
        "# Dense\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae', 'mse'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Model\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "jWRh6ojtKZtl",
        "outputId": "c61e4dca-49ac-46ee-e2a1-42d9c7eb57eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8MhU01rF2uJ"
      },
      "source": [
        "###Model Checkpoint Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yePB07frF1z0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
        "\n",
        "best_model_path = \"models/stock_cnn_best_model.h5\"\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
        "                   patience=100, min_delta=0.0001) # Stops the training early when validation loss stops improving, prevent overfitting\n",
        "\n",
        "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
        "                        min_delta=0.001, cooldown=1, min_lr=0.0001) # Adjusts Learning Rate on validation loss\n",
        "\n",
        "mcp = ModelCheckpoint(best_model_path, monitor='val_loss', verbose=1,\n",
        "                      save_best_only=True, save_weights_only=False, mode='min', save_freq=\"epoch\")  # val_f1_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0fhG2zSEP3g"
      },
      "source": [
        "###Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu1kIlt7Ed44"
      },
      "outputs": [],
      "source": [
        "# reshape images into 3 channels\n",
        "X_train_images = np.stack((X_train_images,)*3, axis=-1)\n",
        "X_val_images = np.stack((X_val_images,)*3, axis=-1)\n",
        "X_test_images = np.stack((X_test_images,)*3, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsFXZz1-ElNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a2158d-3606-49f1-cf17-aa8b2dbc03d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Images shape: (2180, 15, 15, 3)\n",
            "y_train labels shape: (2180, 3)\n",
            "\n",
            "X_val Images shape: (935, 15, 15, 3)\n",
            "y_val labels shape: (935, 3)\n",
            "\n",
            "X_test Images shape: (779, 15, 15, 3)\n",
            "y_test labels shape: (779, 3)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train Images shape: {X_train_images.shape}\")\n",
        "print(f\"y_train labels shape: {y_train.shape}\\n\")\n",
        "\n",
        "print(f\"X_val Images shape: {X_val_images.shape}\")\n",
        "print(f\"y_val labels shape: {y_val.shape}\\n\")\n",
        "\n",
        "print(f\"X_test Images shape: {X_test_images.shape}\")\n",
        "print(f\"y_test labels shape: {y_test.shape}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjfl1807FTw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adee6ca7-945a-48c8-a6c4-babee9484306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 1.0518 - accuracy: 0.3560 - mae: 0.4456 - mse: 0.2299\n",
            "Epoch 1: val_loss improved from inf to 1.14059, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 4s 772ms/step - loss: 1.0550 - accuracy: 0.3564 - mae: 0.4439 - mse: 0.2286 - val_loss: 1.1406 - val_accuracy: 0.1840 - val_mae: 0.4470 - val_mse: 0.2466 - lr: 0.0010\n",
            "Epoch 2/3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1751: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3408 - accuracy: 0.6683 - mae: 0.2214 - mse: 0.1433 - val_loss: 0.8006 - val_accuracy: 0.5647 - val_mae: 0.2693 - val_mse: 0.1857 - lr: 1.0000e-04\n",
            "Epoch 1752/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3451 - accuracy: 0.6694 - mae: 0.2216 - mse: 0.1425\n",
            "Epoch 1752: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 0.3475 - accuracy: 0.6688 - mae: 0.2222 - mse: 0.1427 - val_loss: 0.7963 - val_accuracy: 0.5615 - val_mae: 0.2685 - val_mse: 0.1849 - lr: 1.0000e-04\n",
            "Epoch 1753/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.6619 - mae: 0.2226 - mse: 0.1457\n",
            "Epoch 1753: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.3499 - accuracy: 0.6619 - mae: 0.2226 - mse: 0.1457 - val_loss: 0.7664 - val_accuracy: 0.5701 - val_mae: 0.2626 - val_mse: 0.1781 - lr: 1.0000e-04\n",
            "Epoch 1754/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3405 - accuracy: 0.6865 - mae: 0.2142 - mse: 0.1344\n",
            "Epoch 1754: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3383 - accuracy: 0.6849 - mae: 0.2136 - mse: 0.1340 - val_loss: 0.7211 - val_accuracy: 0.5989 - val_mae: 0.2528 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 1755/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3459 - accuracy: 0.6929 - mae: 0.2087 - mse: 0.1284\n",
            "Epoch 1755: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.3460 - accuracy: 0.6940 - mae: 0.2078 - mse: 0.1274 - val_loss: 0.6956 - val_accuracy: 0.6171 - val_mae: 0.2467 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 1756/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3462 - accuracy: 0.7104 - mae: 0.2015 - mse: 0.1221\n",
            "Epoch 1756: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3473 - accuracy: 0.7101 - mae: 0.2020 - mse: 0.1225 - val_loss: 0.7027 - val_accuracy: 0.6160 - val_mae: 0.2480 - val_mse: 0.1622 - lr: 1.0000e-04\n",
            "Epoch 1757/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.7216 - mae: 0.2020 - mse: 0.1239\n",
            "Epoch 1757: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.3501 - accuracy: 0.7216 - mae: 0.2020 - mse: 0.1239 - val_loss: 0.7275 - val_accuracy: 0.6043 - val_mae: 0.2534 - val_mse: 0.1682 - lr: 1.0000e-04\n",
            "Epoch 1758/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3620 - accuracy: 0.6968 - mae: 0.2076 - mse: 0.1287\n",
            "Epoch 1758: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3641 - accuracy: 0.6982 - mae: 0.2078 - mse: 0.1286 - val_loss: 0.7596 - val_accuracy: 0.5872 - val_mae: 0.2603 - val_mse: 0.1757 - lr: 1.0000e-04\n",
            "Epoch 1759/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3508 - accuracy: 0.6836 - mae: 0.2146 - mse: 0.1356\n",
            "Epoch 1759: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.3527 - accuracy: 0.6812 - mae: 0.2162 - mse: 0.1365 - val_loss: 0.7900 - val_accuracy: 0.5743 - val_mae: 0.2663 - val_mse: 0.1825 - lr: 1.0000e-04\n",
            "Epoch 1760/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.6693 - mae: 0.2210 - mse: 0.1422\n",
            "Epoch 1760: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.3499 - accuracy: 0.6693 - mae: 0.2210 - mse: 0.1422 - val_loss: 0.7856 - val_accuracy: 0.5797 - val_mae: 0.2656 - val_mse: 0.1817 - lr: 1.0000e-04\n",
            "Epoch 1761/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.6803 - mae: 0.2200 - mse: 0.1406\n",
            "Epoch 1761: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 0.3525 - accuracy: 0.6803 - mae: 0.2200 - mse: 0.1406 - val_loss: 0.7671 - val_accuracy: 0.5872 - val_mae: 0.2625 - val_mse: 0.1779 - lr: 1.0000e-04\n",
            "Epoch 1762/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3403 - accuracy: 0.6885 - mae: 0.2133 - mse: 0.1329\n",
            "Epoch 1762: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3384 - accuracy: 0.6876 - mae: 0.2133 - mse: 0.1326 - val_loss: 0.7459 - val_accuracy: 0.5957 - val_mae: 0.2583 - val_mse: 0.1731 - lr: 1.0000e-04\n",
            "Epoch 1763/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3286 - accuracy: 0.6865 - mae: 0.2124 - mse: 0.1325\n",
            "Epoch 1763: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3280 - accuracy: 0.6922 - mae: 0.2106 - mse: 0.1308 - val_loss: 0.7204 - val_accuracy: 0.6064 - val_mae: 0.2527 - val_mse: 0.1670 - lr: 1.0000e-04\n",
            "Epoch 1764/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.6945 - mae: 0.2082 - mse: 0.1277\n",
            "Epoch 1764: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.3419 - accuracy: 0.6945 - mae: 0.2082 - mse: 0.1277 - val_loss: 0.7194 - val_accuracy: 0.6107 - val_mae: 0.2523 - val_mse: 0.1666 - lr: 1.0000e-04\n",
            "Epoch 1765/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3443 - accuracy: 0.6992 - mae: 0.2060 - mse: 0.1265\n",
            "Epoch 1765: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3456 - accuracy: 0.6963 - mae: 0.2071 - mse: 0.1273 - val_loss: 0.7414 - val_accuracy: 0.5968 - val_mae: 0.2577 - val_mse: 0.1719 - lr: 1.0000e-04\n",
            "Epoch 1766/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3485 - accuracy: 0.6816 - mae: 0.2150 - mse: 0.1360\n",
            "Epoch 1766: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3472 - accuracy: 0.6830 - mae: 0.2138 - mse: 0.1350 - val_loss: 0.7583 - val_accuracy: 0.5893 - val_mae: 0.2615 - val_mse: 0.1758 - lr: 1.0000e-04\n",
            "Epoch 1767/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3434 - accuracy: 0.6816 - mae: 0.2159 - mse: 0.1346\n",
            "Epoch 1767: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3395 - accuracy: 0.6821 - mae: 0.2154 - mse: 0.1346 - val_loss: 0.7600 - val_accuracy: 0.5893 - val_mae: 0.2614 - val_mse: 0.1759 - lr: 1.0000e-04\n",
            "Epoch 1768/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.6849 - mae: 0.2142 - mse: 0.1352\n",
            "Epoch 1768: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.3491 - accuracy: 0.6849 - mae: 0.2142 - mse: 0.1352 - val_loss: 0.7471 - val_accuracy: 0.6011 - val_mae: 0.2580 - val_mse: 0.1724 - lr: 1.0000e-04\n",
            "Epoch 1769/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.6982 - mae: 0.2107 - mse: 0.1325\n",
            "Epoch 1769: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3431 - accuracy: 0.6982 - mae: 0.2107 - mse: 0.1325 - val_loss: 0.7396 - val_accuracy: 0.6064 - val_mae: 0.2553 - val_mse: 0.1702 - lr: 1.0000e-04\n",
            "Epoch 1770/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3553 - accuracy: 0.6992 - mae: 0.2067 - mse: 0.1271\n",
            "Epoch 1770: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.3542 - accuracy: 0.6982 - mae: 0.2068 - mse: 0.1275 - val_loss: 0.7279 - val_accuracy: 0.6128 - val_mae: 0.2524 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 1771/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.7041 - mae: 0.2055 - mse: 0.1267\n",
            "Epoch 1771: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3414 - accuracy: 0.7041 - mae: 0.2055 - mse: 0.1267 - val_loss: 0.7204 - val_accuracy: 0.6193 - val_mae: 0.2510 - val_mse: 0.1656 - lr: 1.0000e-04\n",
            "Epoch 1772/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3535 - accuracy: 0.7036 - mae: 0.2060 - mse: 0.1266\n",
            "Epoch 1772: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3544 - accuracy: 0.7050 - mae: 0.2058 - mse: 0.1264 - val_loss: 0.7330 - val_accuracy: 0.6139 - val_mae: 0.2543 - val_mse: 0.1687 - lr: 1.0000e-04\n",
            "Epoch 1773/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.7021 - mae: 0.2091 - mse: 0.1285\n",
            "Epoch 1773: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3517 - accuracy: 0.7023 - mae: 0.2096 - mse: 0.1292 - val_loss: 0.7660 - val_accuracy: 0.5957 - val_mae: 0.2623 - val_mse: 0.1767 - lr: 1.0000e-04\n",
            "Epoch 1774/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3386 - accuracy: 0.6831 - mae: 0.2150 - mse: 0.1356\n",
            "Epoch 1774: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.3447 - accuracy: 0.6817 - mae: 0.2161 - mse: 0.1369 - val_loss: 0.7971 - val_accuracy: 0.5722 - val_mae: 0.2698 - val_mse: 0.1841 - lr: 1.0000e-04\n",
            "Epoch 1775/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.6711 - mae: 0.2243 - mse: 0.1440\n",
            "Epoch 1775: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3434 - accuracy: 0.6711 - mae: 0.2243 - mse: 0.1440 - val_loss: 0.8025 - val_accuracy: 0.5647 - val_mae: 0.2711 - val_mse: 0.1854 - lr: 1.0000e-04\n",
            "Epoch 1776/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.6578 - mae: 0.2253 - mse: 0.1437\n",
            "Epoch 1776: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.3590 - accuracy: 0.6578 - mae: 0.2253 - mse: 0.1437 - val_loss: 0.7990 - val_accuracy: 0.5679 - val_mae: 0.2708 - val_mse: 0.1848 - lr: 1.0000e-04\n",
            "Epoch 1777/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.6670 - mae: 0.2224 - mse: 0.1413\n",
            "Epoch 1777: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3422 - accuracy: 0.6670 - mae: 0.2224 - mse: 0.1413 - val_loss: 0.7860 - val_accuracy: 0.5711 - val_mae: 0.2685 - val_mse: 0.1822 - lr: 1.0000e-04\n",
            "Epoch 1778/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3482 - accuracy: 0.6689 - mae: 0.2221 - mse: 0.1405\n",
            "Epoch 1778: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3474 - accuracy: 0.6725 - mae: 0.2209 - mse: 0.1395 - val_loss: 0.7690 - val_accuracy: 0.5765 - val_mae: 0.2648 - val_mse: 0.1785 - lr: 1.0000e-04\n",
            "Epoch 1779/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3515 - accuracy: 0.6802 - mae: 0.2199 - mse: 0.1391\n",
            "Epoch 1779: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.3451 - accuracy: 0.6826 - mae: 0.2179 - mse: 0.1374 - val_loss: 0.7422 - val_accuracy: 0.5893 - val_mae: 0.2587 - val_mse: 0.1721 - lr: 1.0000e-04\n",
            "Epoch 1780/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3448 - accuracy: 0.6899 - mae: 0.2129 - mse: 0.1316\n",
            "Epoch 1780: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.3469 - accuracy: 0.6954 - mae: 0.2110 - mse: 0.1301 - val_loss: 0.7190 - val_accuracy: 0.6053 - val_mae: 0.2530 - val_mse: 0.1664 - lr: 1.0000e-04\n",
            "Epoch 1781/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3491 - accuracy: 0.6948 - mae: 0.2077 - mse: 0.1255\n",
            "Epoch 1781: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3509 - accuracy: 0.6982 - mae: 0.2067 - mse: 0.1245 - val_loss: 0.7303 - val_accuracy: 0.6011 - val_mae: 0.2546 - val_mse: 0.1687 - lr: 1.0000e-04\n",
            "Epoch 1782/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3425 - accuracy: 0.6929 - mae: 0.2110 - mse: 0.1320\n",
            "Epoch 1782: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3437 - accuracy: 0.6922 - mae: 0.2105 - mse: 0.1317 - val_loss: 0.7579 - val_accuracy: 0.5893 - val_mae: 0.2602 - val_mse: 0.1751 - lr: 1.0000e-04\n",
            "Epoch 1783/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3431 - accuracy: 0.6855 - mae: 0.2150 - mse: 0.1358\n",
            "Epoch 1783: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3415 - accuracy: 0.6844 - mae: 0.2154 - mse: 0.1361 - val_loss: 0.7680 - val_accuracy: 0.5904 - val_mae: 0.2626 - val_mse: 0.1774 - lr: 1.0000e-04\n",
            "Epoch 1784/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3393 - accuracy: 0.6733 - mae: 0.2178 - mse: 0.1390\n",
            "Epoch 1784: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3392 - accuracy: 0.6761 - mae: 0.2171 - mse: 0.1381 - val_loss: 0.7523 - val_accuracy: 0.5947 - val_mae: 0.2589 - val_mse: 0.1736 - lr: 1.0000e-04\n",
            "Epoch 1785/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3431 - accuracy: 0.6885 - mae: 0.2112 - mse: 0.1317\n",
            "Epoch 1785: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3532 - accuracy: 0.6881 - mae: 0.2113 - mse: 0.1317 - val_loss: 0.7462 - val_accuracy: 0.5979 - val_mae: 0.2580 - val_mse: 0.1723 - lr: 1.0000e-04\n",
            "Epoch 1786/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3436 - accuracy: 0.6782 - mae: 0.2160 - mse: 0.1364\n",
            "Epoch 1786: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3435 - accuracy: 0.6817 - mae: 0.2145 - mse: 0.1355 - val_loss: 0.7569 - val_accuracy: 0.5925 - val_mae: 0.2622 - val_mse: 0.1754 - lr: 1.0000e-04\n",
            "Epoch 1787/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3496 - accuracy: 0.6768 - mae: 0.2173 - mse: 0.1368\n",
            "Epoch 1787: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.3554 - accuracy: 0.6766 - mae: 0.2180 - mse: 0.1371 - val_loss: 0.7703 - val_accuracy: 0.5893 - val_mae: 0.2666 - val_mse: 0.1789 - lr: 1.0000e-04\n",
            "Epoch 1788/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3493 - accuracy: 0.6753 - mae: 0.2245 - mse: 0.1435\n",
            "Epoch 1788: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3442 - accuracy: 0.6775 - mae: 0.2233 - mse: 0.1419 - val_loss: 0.7758 - val_accuracy: 0.5829 - val_mae: 0.2685 - val_mse: 0.1804 - lr: 1.0000e-04\n",
            "Epoch 1789/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3636 - accuracy: 0.6670 - mae: 0.2254 - mse: 0.1448\n",
            "Epoch 1789: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3589 - accuracy: 0.6693 - mae: 0.2237 - mse: 0.1433 - val_loss: 0.7560 - val_accuracy: 0.5936 - val_mae: 0.2641 - val_mse: 0.1757 - lr: 1.0000e-04\n",
            "Epoch 1790/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3491 - accuracy: 0.6875 - mae: 0.2176 - mse: 0.1352\n",
            "Epoch 1790: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3505 - accuracy: 0.6858 - mae: 0.2186 - mse: 0.1359 - val_loss: 0.7361 - val_accuracy: 0.6064 - val_mae: 0.2587 - val_mse: 0.1708 - lr: 1.0000e-04\n",
            "Epoch 1791/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3475 - accuracy: 0.6948 - mae: 0.2107 - mse: 0.1285\n",
            "Epoch 1791: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3456 - accuracy: 0.6945 - mae: 0.2108 - mse: 0.1287 - val_loss: 0.7200 - val_accuracy: 0.6139 - val_mae: 0.2541 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 1792/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3434 - accuracy: 0.7012 - mae: 0.2061 - mse: 0.1266\n",
            "Epoch 1792: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3396 - accuracy: 0.7018 - mae: 0.2051 - mse: 0.1256 - val_loss: 0.7064 - val_accuracy: 0.6225 - val_mae: 0.2498 - val_mse: 0.1632 - lr: 1.0000e-04\n",
            "Epoch 1793/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3499 - accuracy: 0.7227 - mae: 0.2003 - mse: 0.1197\n",
            "Epoch 1793: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3478 - accuracy: 0.7206 - mae: 0.2010 - mse: 0.1204 - val_loss: 0.7059 - val_accuracy: 0.6246 - val_mae: 0.2487 - val_mse: 0.1627 - lr: 1.0000e-04\n",
            "Epoch 1794/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3506 - accuracy: 0.7124 - mae: 0.2011 - mse: 0.1215\n",
            "Epoch 1794: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3502 - accuracy: 0.7069 - mae: 0.2032 - mse: 0.1233 - val_loss: 0.7127 - val_accuracy: 0.6225 - val_mae: 0.2494 - val_mse: 0.1641 - lr: 1.0000e-04\n",
            "Epoch 1795/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3471 - accuracy: 0.7104 - mae: 0.2042 - mse: 0.1250\n",
            "Epoch 1795: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3524 - accuracy: 0.7087 - mae: 0.2053 - mse: 0.1256 - val_loss: 0.7298 - val_accuracy: 0.6182 - val_mae: 0.2530 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 1796/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.7005 - mae: 0.2101 - mse: 0.1313\n",
            "Epoch 1796: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3702 - accuracy: 0.7005 - mae: 0.2101 - mse: 0.1313 - val_loss: 0.7696 - val_accuracy: 0.5893 - val_mae: 0.2629 - val_mse: 0.1777 - lr: 1.0000e-04\n",
            "Epoch 1797/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.6830 - mae: 0.2176 - mse: 0.1382\n",
            "Epoch 1797: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3421 - accuracy: 0.6830 - mae: 0.2176 - mse: 0.1382 - val_loss: 0.7852 - val_accuracy: 0.5786 - val_mae: 0.2671 - val_mse: 0.1815 - lr: 1.0000e-04\n",
            "Epoch 1798/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.6638 - mae: 0.2243 - mse: 0.1446\n",
            "Epoch 1798: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3602 - accuracy: 0.6638 - mae: 0.2243 - mse: 0.1446 - val_loss: 0.7839 - val_accuracy: 0.5818 - val_mae: 0.2674 - val_mse: 0.1812 - lr: 1.0000e-04\n",
            "Epoch 1799/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.6780 - mae: 0.2177 - mse: 0.1374\n",
            "Epoch 1799: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3434 - accuracy: 0.6780 - mae: 0.2177 - mse: 0.1374 - val_loss: 0.7591 - val_accuracy: 0.5968 - val_mae: 0.2619 - val_mse: 0.1754 - lr: 1.0000e-04\n",
            "Epoch 1800/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3373 - accuracy: 0.6831 - mae: 0.2148 - mse: 0.1341\n",
            "Epoch 1800: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3448 - accuracy: 0.6826 - mae: 0.2145 - mse: 0.1338 - val_loss: 0.7344 - val_accuracy: 0.6086 - val_mae: 0.2561 - val_mse: 0.1694 - lr: 1.0000e-04\n",
            "Epoch 1801/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.6982 - mae: 0.2104 - mse: 0.1300\n",
            "Epoch 1801: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3343 - accuracy: 0.6982 - mae: 0.2104 - mse: 0.1300 - val_loss: 0.7324 - val_accuracy: 0.6053 - val_mae: 0.2553 - val_mse: 0.1688 - lr: 1.0000e-04\n",
            "Epoch 1802/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.7005 - mae: 0.2089 - mse: 0.1274\n",
            "Epoch 1802: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.3480 - accuracy: 0.7005 - mae: 0.2089 - mse: 0.1274 - val_loss: 0.7254 - val_accuracy: 0.6107 - val_mae: 0.2531 - val_mse: 0.1669 - lr: 1.0000e-04\n",
            "Epoch 1803/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.7005 - mae: 0.2083 - mse: 0.1276\n",
            "Epoch 1803: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.3588 - accuracy: 0.7005 - mae: 0.2083 - mse: 0.1276 - val_loss: 0.7331 - val_accuracy: 0.6086 - val_mae: 0.2539 - val_mse: 0.1685 - lr: 1.0000e-04\n",
            "Epoch 1804/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.6904 - mae: 0.2101 - mse: 0.1301\n",
            "Epoch 1804: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.3420 - accuracy: 0.6904 - mae: 0.2101 - mse: 0.1301 - val_loss: 0.7513 - val_accuracy: 0.6000 - val_mae: 0.2573 - val_mse: 0.1727 - lr: 1.0000e-04\n",
            "Epoch 1805/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3413 - accuracy: 0.6880 - mae: 0.2114 - mse: 0.1325\n",
            "Epoch 1805: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.3390 - accuracy: 0.6853 - mae: 0.2125 - mse: 0.1332 - val_loss: 0.7597 - val_accuracy: 0.5957 - val_mae: 0.2588 - val_mse: 0.1746 - lr: 1.0000e-04\n",
            "Epoch 1806/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.6881 - mae: 0.2157 - mse: 0.1368\n",
            "Epoch 1806: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 190ms/step - loss: 0.3479 - accuracy: 0.6881 - mae: 0.2157 - mse: 0.1368 - val_loss: 0.7421 - val_accuracy: 0.6043 - val_mae: 0.2546 - val_mse: 0.1703 - lr: 1.0000e-04\n",
            "Epoch 1807/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3522 - accuracy: 0.6885 - mae: 0.2111 - mse: 0.1327\n",
            "Epoch 1807: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3459 - accuracy: 0.6927 - mae: 0.2092 - mse: 0.1310 - val_loss: 0.7125 - val_accuracy: 0.6182 - val_mae: 0.2470 - val_mse: 0.1629 - lr: 1.0000e-04\n",
            "Epoch 1808/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3354 - accuracy: 0.7080 - mae: 0.1991 - mse: 0.1214\n",
            "Epoch 1808: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3502 - accuracy: 0.7092 - mae: 0.1991 - mse: 0.1214 - val_loss: 0.7165 - val_accuracy: 0.6139 - val_mae: 0.2478 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 1809/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.7037 - mae: 0.2054 - mse: 0.1286\n",
            "Epoch 1809: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3462 - accuracy: 0.7037 - mae: 0.2054 - mse: 0.1286 - val_loss: 0.7623 - val_accuracy: 0.6011 - val_mae: 0.2590 - val_mse: 0.1750 - lr: 1.0000e-04\n",
            "Epoch 1810/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3365 - accuracy: 0.6865 - mae: 0.2148 - mse: 0.1378\n",
            "Epoch 1810: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3356 - accuracy: 0.6839 - mae: 0.2156 - mse: 0.1385 - val_loss: 0.7835 - val_accuracy: 0.5893 - val_mae: 0.2636 - val_mse: 0.1800 - lr: 1.0000e-04\n",
            "Epoch 1811/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3504 - accuracy: 0.6865 - mae: 0.2161 - mse: 0.1391\n",
            "Epoch 1811: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3503 - accuracy: 0.6835 - mae: 0.2173 - mse: 0.1396 - val_loss: 0.7698 - val_accuracy: 0.6000 - val_mae: 0.2609 - val_mse: 0.1769 - lr: 1.0000e-04\n",
            "Epoch 1812/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3344 - accuracy: 0.6934 - mae: 0.2104 - mse: 0.1341\n",
            "Epoch 1812: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3366 - accuracy: 0.6908 - mae: 0.2120 - mse: 0.1353 - val_loss: 0.7391 - val_accuracy: 0.6118 - val_mae: 0.2541 - val_mse: 0.1696 - lr: 1.0000e-04\n",
            "Epoch 1813/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3406 - accuracy: 0.7051 - mae: 0.2060 - mse: 0.1279\n",
            "Epoch 1813: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3435 - accuracy: 0.7037 - mae: 0.2067 - mse: 0.1282 - val_loss: 0.7165 - val_accuracy: 0.6278 - val_mae: 0.2489 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 1814/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3503 - accuracy: 0.7163 - mae: 0.2016 - mse: 0.1228\n",
            "Epoch 1814: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3485 - accuracy: 0.7161 - mae: 0.2012 - mse: 0.1222 - val_loss: 0.7215 - val_accuracy: 0.6214 - val_mae: 0.2505 - val_mse: 0.1653 - lr: 1.0000e-04\n",
            "Epoch 1815/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3518 - accuracy: 0.7041 - mae: 0.2069 - mse: 0.1266\n",
            "Epoch 1815: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3503 - accuracy: 0.7032 - mae: 0.2079 - mse: 0.1272 - val_loss: 0.7340 - val_accuracy: 0.6128 - val_mae: 0.2539 - val_mse: 0.1684 - lr: 1.0000e-04\n",
            "Epoch 1816/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3561 - accuracy: 0.7012 - mae: 0.2074 - mse: 0.1291\n",
            "Epoch 1816: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3557 - accuracy: 0.6977 - mae: 0.2097 - mse: 0.1311 - val_loss: 0.7278 - val_accuracy: 0.6160 - val_mae: 0.2525 - val_mse: 0.1669 - lr: 1.0000e-04\n",
            "Epoch 1817/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.7051 - mae: 0.2061 - mse: 0.1263\n",
            "Epoch 1817: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3399 - accuracy: 0.7069 - mae: 0.2049 - mse: 0.1255 - val_loss: 0.7085 - val_accuracy: 0.6278 - val_mae: 0.2477 - val_mse: 0.1623 - lr: 1.0000e-04\n",
            "Epoch 1818/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3407 - accuracy: 0.7139 - mae: 0.2003 - mse: 0.1228\n",
            "Epoch 1818: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3414 - accuracy: 0.7138 - mae: 0.1999 - mse: 0.1224 - val_loss: 0.7072 - val_accuracy: 0.6246 - val_mae: 0.2468 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 1819/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3369 - accuracy: 0.7158 - mae: 0.2014 - mse: 0.1229\n",
            "Epoch 1819: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3446 - accuracy: 0.7151 - mae: 0.2020 - mse: 0.1230 - val_loss: 0.7300 - val_accuracy: 0.6171 - val_mae: 0.2520 - val_mse: 0.1670 - lr: 1.0000e-04\n",
            "Epoch 1820/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3402 - accuracy: 0.7090 - mae: 0.2087 - mse: 0.1282\n",
            "Epoch 1820: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3417 - accuracy: 0.7106 - mae: 0.2075 - mse: 0.1274 - val_loss: 0.7728 - val_accuracy: 0.5936 - val_mae: 0.2622 - val_mse: 0.1774 - lr: 1.0000e-04\n",
            "Epoch 1821/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3412 - accuracy: 0.6821 - mae: 0.2176 - mse: 0.1388\n",
            "Epoch 1821: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.3436 - accuracy: 0.6826 - mae: 0.2171 - mse: 0.1385 - val_loss: 0.8071 - val_accuracy: 0.5733 - val_mae: 0.2701 - val_mse: 0.1858 - lr: 1.0000e-04\n",
            "Epoch 1822/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3478 - accuracy: 0.6562 - mae: 0.2262 - mse: 0.1478\n",
            "Epoch 1822: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3472 - accuracy: 0.6560 - mae: 0.2267 - mse: 0.1481 - val_loss: 0.8079 - val_accuracy: 0.5668 - val_mae: 0.2713 - val_mse: 0.1865 - lr: 1.0000e-04\n",
            "Epoch 1823/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3548 - accuracy: 0.6553 - mae: 0.2262 - mse: 0.1483\n",
            "Epoch 1823: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3519 - accuracy: 0.6537 - mae: 0.2258 - mse: 0.1479 - val_loss: 0.7641 - val_accuracy: 0.5882 - val_mae: 0.2626 - val_mse: 0.1767 - lr: 1.0000e-04\n",
            "Epoch 1824/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.6931 - mae: 0.2130 - mse: 0.1331\n",
            "Epoch 1824: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3360 - accuracy: 0.6931 - mae: 0.2130 - mse: 0.1331 - val_loss: 0.7166 - val_accuracy: 0.6160 - val_mae: 0.2519 - val_mse: 0.1655 - lr: 1.0000e-04\n",
            "Epoch 1825/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3599 - accuracy: 0.7012 - mae: 0.2093 - mse: 0.1291\n",
            "Epoch 1825: val_loss did not improve from 0.69555\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.3540 - accuracy: 0.7023 - mae: 0.2083 - mse: 0.1279 - val_loss: 0.6980 - val_accuracy: 0.6203 - val_mae: 0.2476 - val_mse: 0.1609 - lr: 1.0000e-04\n",
            "Epoch 1826/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.7151 - mae: 0.2005 - mse: 0.1212\n",
            "Epoch 1826: val_loss improved from 0.69555 to 0.69060, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 2s 954ms/step - loss: 0.3410 - accuracy: 0.7151 - mae: 0.2005 - mse: 0.1212 - val_loss: 0.6906 - val_accuracy: 0.6225 - val_mae: 0.2457 - val_mse: 0.1590 - lr: 1.0000e-04\n",
            "Epoch 1827/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.7119 - mae: 0.2011 - mse: 0.1221\n",
            "Epoch 1827: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.3376 - accuracy: 0.7119 - mae: 0.2011 - mse: 0.1221 - val_loss: 0.6943 - val_accuracy: 0.6203 - val_mae: 0.2459 - val_mse: 0.1597 - lr: 1.0000e-04\n",
            "Epoch 1828/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3467 - accuracy: 0.7144 - mae: 0.2000 - mse: 0.1217\n",
            "Epoch 1828: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.3556 - accuracy: 0.7142 - mae: 0.2003 - mse: 0.1218 - val_loss: 0.7305 - val_accuracy: 0.6064 - val_mae: 0.2534 - val_mse: 0.1681 - lr: 1.0000e-04\n",
            "Epoch 1829/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3327 - accuracy: 0.7026 - mae: 0.2066 - mse: 0.1268\n",
            "Epoch 1829: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3330 - accuracy: 0.6995 - mae: 0.2078 - mse: 0.1280 - val_loss: 0.7800 - val_accuracy: 0.5914 - val_mae: 0.2627 - val_mse: 0.1789 - lr: 1.0000e-04\n",
            "Epoch 1830/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3239 - accuracy: 0.7031 - mae: 0.2098 - mse: 0.1316\n",
            "Epoch 1830: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3295 - accuracy: 0.7000 - mae: 0.2109 - mse: 0.1329 - val_loss: 0.7871 - val_accuracy: 0.5904 - val_mae: 0.2631 - val_mse: 0.1801 - lr: 1.0000e-04\n",
            "Epoch 1831/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3519 - accuracy: 0.6904 - mae: 0.2140 - mse: 0.1364\n",
            "Epoch 1831: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3542 - accuracy: 0.6885 - mae: 0.2152 - mse: 0.1377 - val_loss: 0.7790 - val_accuracy: 0.5947 - val_mae: 0.2612 - val_mse: 0.1781 - lr: 1.0000e-04\n",
            "Epoch 1832/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3428 - accuracy: 0.6865 - mae: 0.2164 - mse: 0.1384\n",
            "Epoch 1832: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3418 - accuracy: 0.6904 - mae: 0.2144 - mse: 0.1365 - val_loss: 0.7619 - val_accuracy: 0.6043 - val_mae: 0.2580 - val_mse: 0.1744 - lr: 1.0000e-04\n",
            "Epoch 1833/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3264 - accuracy: 0.6934 - mae: 0.2111 - mse: 0.1322\n",
            "Epoch 1833: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3313 - accuracy: 0.6904 - mae: 0.2119 - mse: 0.1330 - val_loss: 0.7548 - val_accuracy: 0.6107 - val_mae: 0.2565 - val_mse: 0.1728 - lr: 1.0000e-04\n",
            "Epoch 1834/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3395 - accuracy: 0.6934 - mae: 0.2126 - mse: 0.1351\n",
            "Epoch 1834: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3454 - accuracy: 0.6968 - mae: 0.2116 - mse: 0.1344 - val_loss: 0.7574 - val_accuracy: 0.6096 - val_mae: 0.2573 - val_mse: 0.1733 - lr: 1.0000e-04\n",
            "Epoch 1835/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3486 - accuracy: 0.6860 - mae: 0.2142 - mse: 0.1362\n",
            "Epoch 1835: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3473 - accuracy: 0.6890 - mae: 0.2131 - mse: 0.1351 - val_loss: 0.7727 - val_accuracy: 0.6021 - val_mae: 0.2614 - val_mse: 0.1770 - lr: 1.0000e-04\n",
            "Epoch 1836/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3363 - accuracy: 0.6899 - mae: 0.2162 - mse: 0.1376\n",
            "Epoch 1836: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3337 - accuracy: 0.6894 - mae: 0.2163 - mse: 0.1372 - val_loss: 0.7710 - val_accuracy: 0.5989 - val_mae: 0.2612 - val_mse: 0.1766 - lr: 1.0000e-04\n",
            "Epoch 1837/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3418 - accuracy: 0.6797 - mae: 0.2146 - mse: 0.1367\n",
            "Epoch 1837: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3467 - accuracy: 0.6780 - mae: 0.2150 - mse: 0.1371 - val_loss: 0.7503 - val_accuracy: 0.6107 - val_mae: 0.2565 - val_mse: 0.1717 - lr: 1.0000e-04\n",
            "Epoch 1838/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3461 - accuracy: 0.6997 - mae: 0.2104 - mse: 0.1330\n",
            "Epoch 1838: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3467 - accuracy: 0.7028 - mae: 0.2090 - mse: 0.1318 - val_loss: 0.7406 - val_accuracy: 0.6139 - val_mae: 0.2545 - val_mse: 0.1696 - lr: 1.0000e-04\n",
            "Epoch 1839/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3430 - accuracy: 0.7080 - mae: 0.2050 - mse: 0.1268\n",
            "Epoch 1839: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3444 - accuracy: 0.7050 - mae: 0.2062 - mse: 0.1277 - val_loss: 0.7417 - val_accuracy: 0.6107 - val_mae: 0.2545 - val_mse: 0.1698 - lr: 1.0000e-04\n",
            "Epoch 1840/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3317 - accuracy: 0.7104 - mae: 0.2044 - mse: 0.1275\n",
            "Epoch 1840: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3382 - accuracy: 0.7092 - mae: 0.2056 - mse: 0.1283 - val_loss: 0.7463 - val_accuracy: 0.6032 - val_mae: 0.2552 - val_mse: 0.1709 - lr: 1.0000e-04\n",
            "Epoch 1841/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3510 - accuracy: 0.6890 - mae: 0.2124 - mse: 0.1347\n",
            "Epoch 1841: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3501 - accuracy: 0.6890 - mae: 0.2119 - mse: 0.1346 - val_loss: 0.7655 - val_accuracy: 0.5904 - val_mae: 0.2599 - val_mse: 0.1756 - lr: 1.0000e-04\n",
            "Epoch 1842/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3383 - accuracy: 0.6865 - mae: 0.2137 - mse: 0.1348\n",
            "Epoch 1842: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 0.3363 - accuracy: 0.6844 - mae: 0.2141 - mse: 0.1353 - val_loss: 0.7624 - val_accuracy: 0.5882 - val_mae: 0.2593 - val_mse: 0.1750 - lr: 1.0000e-04\n",
            "Epoch 1843/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3413 - accuracy: 0.6890 - mae: 0.2108 - mse: 0.1335\n",
            "Epoch 1843: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 0.3394 - accuracy: 0.6890 - mae: 0.2108 - mse: 0.1331 - val_loss: 0.7451 - val_accuracy: 0.5925 - val_mae: 0.2553 - val_mse: 0.1710 - lr: 1.0000e-04\n",
            "Epoch 1844/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3386 - accuracy: 0.7046 - mae: 0.2067 - mse: 0.1295\n",
            "Epoch 1844: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3380 - accuracy: 0.7041 - mae: 0.2067 - mse: 0.1296 - val_loss: 0.7296 - val_accuracy: 0.6107 - val_mae: 0.2513 - val_mse: 0.1671 - lr: 1.0000e-04\n",
            "Epoch 1845/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3281 - accuracy: 0.7036 - mae: 0.2025 - mse: 0.1249\n",
            "Epoch 1845: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3390 - accuracy: 0.7037 - mae: 0.2029 - mse: 0.1253 - val_loss: 0.7300 - val_accuracy: 0.6150 - val_mae: 0.2520 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 1846/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3459 - accuracy: 0.7017 - mae: 0.2080 - mse: 0.1290\n",
            "Epoch 1846: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3444 - accuracy: 0.7005 - mae: 0.2083 - mse: 0.1295 - val_loss: 0.7501 - val_accuracy: 0.5989 - val_mae: 0.2582 - val_mse: 0.1725 - lr: 1.0000e-04\n",
            "Epoch 1847/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.7000 - mae: 0.2135 - mse: 0.1334\n",
            "Epoch 1847: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.3424 - accuracy: 0.7000 - mae: 0.2135 - mse: 0.1334 - val_loss: 0.7567 - val_accuracy: 0.5882 - val_mae: 0.2603 - val_mse: 0.1743 - lr: 1.0000e-04\n",
            "Epoch 1848/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3498 - accuracy: 0.6904 - mae: 0.2141 - mse: 0.1343\n",
            "Epoch 1848: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.3503 - accuracy: 0.6899 - mae: 0.2148 - mse: 0.1344 - val_loss: 0.7699 - val_accuracy: 0.5914 - val_mae: 0.2637 - val_mse: 0.1778 - lr: 1.0000e-04\n",
            "Epoch 1849/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.6775 - mae: 0.2158 - mse: 0.1367\n",
            "Epoch 1849: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.3351 - accuracy: 0.6775 - mae: 0.2158 - mse: 0.1367 - val_loss: 0.7592 - val_accuracy: 0.5979 - val_mae: 0.2610 - val_mse: 0.1752 - lr: 1.0000e-04\n",
            "Epoch 1850/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3377 - accuracy: 0.6807 - mae: 0.2121 - mse: 0.1332\n",
            "Epoch 1850: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.3378 - accuracy: 0.6775 - mae: 0.2140 - mse: 0.1346 - val_loss: 0.7312 - val_accuracy: 0.6128 - val_mae: 0.2535 - val_mse: 0.1682 - lr: 1.0000e-04\n",
            "Epoch 1851/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.7119 - mae: 0.2033 - mse: 0.1253\n",
            "Epoch 1851: val_loss did not improve from 0.69060\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3245 - accuracy: 0.7119 - mae: 0.2033 - mse: 0.1253 - val_loss: 0.6951 - val_accuracy: 0.6278 - val_mae: 0.2438 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 1852/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.7289 - mae: 0.1953 - mse: 0.1168\n",
            "Epoch 1852: val_loss improved from 0.69060 to 0.68547, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 2s 922ms/step - loss: 0.3406 - accuracy: 0.7289 - mae: 0.1953 - mse: 0.1168 - val_loss: 0.6855 - val_accuracy: 0.6396 - val_mae: 0.2403 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 1853/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3557 - accuracy: 0.7275 - mae: 0.1955 - mse: 0.1172\n",
            "Epoch 1853: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3514 - accuracy: 0.7284 - mae: 0.1946 - mse: 0.1170 - val_loss: 0.7127 - val_accuracy: 0.6310 - val_mae: 0.2454 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 1854/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3248 - accuracy: 0.7266 - mae: 0.1960 - mse: 0.1195\n",
            "Epoch 1854: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3300 - accuracy: 0.7284 - mae: 0.1959 - mse: 0.1194 - val_loss: 0.7476 - val_accuracy: 0.6139 - val_mae: 0.2526 - val_mse: 0.1700 - lr: 1.0000e-04\n",
            "Epoch 1855/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3668 - accuracy: 0.6885 - mae: 0.2131 - mse: 0.1358\n",
            "Epoch 1855: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3625 - accuracy: 0.6908 - mae: 0.2120 - mse: 0.1349 - val_loss: 0.7892 - val_accuracy: 0.5872 - val_mae: 0.2621 - val_mse: 0.1802 - lr: 1.0000e-04\n",
            "Epoch 1856/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3512 - accuracy: 0.6768 - mae: 0.2177 - mse: 0.1421\n",
            "Epoch 1856: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3528 - accuracy: 0.6784 - mae: 0.2173 - mse: 0.1416 - val_loss: 0.7997 - val_accuracy: 0.5786 - val_mae: 0.2645 - val_mse: 0.1828 - lr: 1.0000e-04\n",
            "Epoch 1857/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3405 - accuracy: 0.6719 - mae: 0.2189 - mse: 0.1422\n",
            "Epoch 1857: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3370 - accuracy: 0.6780 - mae: 0.2161 - mse: 0.1395 - val_loss: 0.7922 - val_accuracy: 0.5840 - val_mae: 0.2628 - val_mse: 0.1811 - lr: 1.0000e-04\n",
            "Epoch 1858/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3359 - accuracy: 0.6743 - mae: 0.2155 - mse: 0.1401\n",
            "Epoch 1858: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3369 - accuracy: 0.6716 - mae: 0.2172 - mse: 0.1412 - val_loss: 0.7630 - val_accuracy: 0.6000 - val_mae: 0.2561 - val_mse: 0.1741 - lr: 1.0000e-04\n",
            "Epoch 1859/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3268 - accuracy: 0.7046 - mae: 0.2055 - mse: 0.1296\n",
            "Epoch 1859: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3360 - accuracy: 0.7028 - mae: 0.2067 - mse: 0.1301 - val_loss: 0.7312 - val_accuracy: 0.6203 - val_mae: 0.2484 - val_mse: 0.1663 - lr: 1.0000e-04\n",
            "Epoch 1860/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3334 - accuracy: 0.7129 - mae: 0.2012 - mse: 0.1239\n",
            "Epoch 1860: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3342 - accuracy: 0.7106 - mae: 0.2013 - mse: 0.1243 - val_loss: 0.7368 - val_accuracy: 0.6150 - val_mae: 0.2489 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 1861/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.7096 - mae: 0.2012 - mse: 0.1269\n",
            "Epoch 1861: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3385 - accuracy: 0.7096 - mae: 0.2012 - mse: 0.1269 - val_loss: 0.7487 - val_accuracy: 0.6086 - val_mae: 0.2515 - val_mse: 0.1701 - lr: 1.0000e-04\n",
            "Epoch 1862/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3350 - accuracy: 0.7134 - mae: 0.2013 - mse: 0.1238\n",
            "Epoch 1862: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3362 - accuracy: 0.7096 - mae: 0.2021 - mse: 0.1249 - val_loss: 0.7598 - val_accuracy: 0.5989 - val_mae: 0.2549 - val_mse: 0.1734 - lr: 1.0000e-04\n",
            "Epoch 1863/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3362 - accuracy: 0.6973 - mae: 0.2080 - mse: 0.1311\n",
            "Epoch 1863: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3353 - accuracy: 0.6972 - mae: 0.2078 - mse: 0.1311 - val_loss: 0.7579 - val_accuracy: 0.5979 - val_mae: 0.2554 - val_mse: 0.1736 - lr: 1.0000e-04\n",
            "Epoch 1864/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3608 - accuracy: 0.6909 - mae: 0.2081 - mse: 0.1318\n",
            "Epoch 1864: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.3611 - accuracy: 0.6894 - mae: 0.2091 - mse: 0.1323 - val_loss: 0.7590 - val_accuracy: 0.5979 - val_mae: 0.2566 - val_mse: 0.1742 - lr: 1.0000e-04\n",
            "Epoch 1865/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3422 - accuracy: 0.6787 - mae: 0.2136 - mse: 0.1378\n",
            "Epoch 1865: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3424 - accuracy: 0.6784 - mae: 0.2134 - mse: 0.1374 - val_loss: 0.7557 - val_accuracy: 0.5979 - val_mae: 0.2575 - val_mse: 0.1738 - lr: 1.0000e-04\n",
            "Epoch 1866/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3501 - accuracy: 0.6919 - mae: 0.2097 - mse: 0.1337\n",
            "Epoch 1866: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3492 - accuracy: 0.6908 - mae: 0.2104 - mse: 0.1341 - val_loss: 0.7323 - val_accuracy: 0.6096 - val_mae: 0.2540 - val_mse: 0.1687 - lr: 1.0000e-04\n",
            "Epoch 1867/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3360 - accuracy: 0.6875 - mae: 0.2094 - mse: 0.1297\n",
            "Epoch 1867: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3377 - accuracy: 0.6853 - mae: 0.2098 - mse: 0.1301 - val_loss: 0.7092 - val_accuracy: 0.6214 - val_mae: 0.2490 - val_mse: 0.1630 - lr: 1.0000e-04\n",
            "Epoch 1868/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3334 - accuracy: 0.7192 - mae: 0.1993 - mse: 0.1202\n",
            "Epoch 1868: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3378 - accuracy: 0.7161 - mae: 0.2008 - mse: 0.1216 - val_loss: 0.7048 - val_accuracy: 0.6267 - val_mae: 0.2483 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 1869/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3316 - accuracy: 0.7202 - mae: 0.2003 - mse: 0.1194\n",
            "Epoch 1869: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3356 - accuracy: 0.7188 - mae: 0.2014 - mse: 0.1203 - val_loss: 0.7097 - val_accuracy: 0.6118 - val_mae: 0.2509 - val_mse: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 1870/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3379 - accuracy: 0.6992 - mae: 0.2070 - mse: 0.1258\n",
            "Epoch 1870: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3388 - accuracy: 0.7032 - mae: 0.2059 - mse: 0.1250 - val_loss: 0.7389 - val_accuracy: 0.6043 - val_mae: 0.2582 - val_mse: 0.1711 - lr: 1.0000e-04\n",
            "Epoch 1871/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.6867 - mae: 0.2134 - mse: 0.1335\n",
            "Epoch 1871: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.3312 - accuracy: 0.6867 - mae: 0.2134 - mse: 0.1335 - val_loss: 0.7621 - val_accuracy: 0.5872 - val_mae: 0.2627 - val_mse: 0.1763 - lr: 1.0000e-04\n",
            "Epoch 1872/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.6858 - mae: 0.2137 - mse: 0.1346\n",
            "Epoch 1872: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.3394 - accuracy: 0.6858 - mae: 0.2137 - mse: 0.1346 - val_loss: 0.7535 - val_accuracy: 0.5925 - val_mae: 0.2602 - val_mse: 0.1740 - lr: 1.0000e-04\n",
            "Epoch 1873/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.7000 - mae: 0.2099 - mse: 0.1315\n",
            "Epoch 1873: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.3412 - accuracy: 0.7000 - mae: 0.2099 - mse: 0.1315 - val_loss: 0.7323 - val_accuracy: 0.6107 - val_mae: 0.2549 - val_mse: 0.1687 - lr: 1.0000e-04\n",
            "Epoch 1874/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.7023 - mae: 0.2055 - mse: 0.1270\n",
            "Epoch 1874: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3313 - accuracy: 0.7023 - mae: 0.2055 - mse: 0.1270 - val_loss: 0.7224 - val_accuracy: 0.6160 - val_mae: 0.2512 - val_mse: 0.1657 - lr: 1.0000e-04\n",
            "Epoch 1875/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.7142 - mae: 0.2025 - mse: 0.1240\n",
            "Epoch 1875: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3342 - accuracy: 0.7142 - mae: 0.2025 - mse: 0.1240 - val_loss: 0.7135 - val_accuracy: 0.6235 - val_mae: 0.2478 - val_mse: 0.1630 - lr: 1.0000e-04\n",
            "Epoch 1876/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3400 - accuracy: 0.7222 - mae: 0.2011 - mse: 0.1230\n",
            "Epoch 1876: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3377 - accuracy: 0.7220 - mae: 0.2004 - mse: 0.1225 - val_loss: 0.7130 - val_accuracy: 0.6267 - val_mae: 0.2473 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 1877/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.7188 - mae: 0.2010 - mse: 0.1214\n",
            "Epoch 1877: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.3467 - accuracy: 0.7188 - mae: 0.2010 - mse: 0.1214 - val_loss: 0.7269 - val_accuracy: 0.6128 - val_mae: 0.2505 - val_mse: 0.1662 - lr: 1.0000e-04\n",
            "Epoch 1878/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3285 - accuracy: 0.7051 - mae: 0.2038 - mse: 0.1269\n",
            "Epoch 1878: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.3265 - accuracy: 0.7060 - mae: 0.2030 - mse: 0.1261 - val_loss: 0.7376 - val_accuracy: 0.6128 - val_mae: 0.2521 - val_mse: 0.1684 - lr: 1.0000e-04\n",
            "Epoch 1879/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3243 - accuracy: 0.7007 - mae: 0.2049 - mse: 0.1279\n",
            "Epoch 1879: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 197ms/step - loss: 0.3253 - accuracy: 0.7000 - mae: 0.2048 - mse: 0.1279 - val_loss: 0.7413 - val_accuracy: 0.6182 - val_mae: 0.2517 - val_mse: 0.1688 - lr: 1.0000e-04\n",
            "Epoch 1880/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.7106 - mae: 0.2018 - mse: 0.1257\n",
            "Epoch 1880: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.3390 - accuracy: 0.7106 - mae: 0.2018 - mse: 0.1257 - val_loss: 0.7471 - val_accuracy: 0.6128 - val_mae: 0.2523 - val_mse: 0.1700 - lr: 1.0000e-04\n",
            "Epoch 1881/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3279 - accuracy: 0.7085 - mae: 0.2036 - mse: 0.1289\n",
            "Epoch 1881: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3286 - accuracy: 0.7078 - mae: 0.2033 - mse: 0.1288 - val_loss: 0.7424 - val_accuracy: 0.6150 - val_mae: 0.2508 - val_mse: 0.1688 - lr: 1.0000e-04\n",
            "Epoch 1882/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.6972 - mae: 0.2046 - mse: 0.1288\n",
            "Epoch 1882: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.3363 - accuracy: 0.6972 - mae: 0.2046 - mse: 0.1288 - val_loss: 0.7409 - val_accuracy: 0.6128 - val_mae: 0.2504 - val_mse: 0.1684 - lr: 1.0000e-04\n",
            "Epoch 1883/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3273 - accuracy: 0.7188 - mae: 0.2006 - mse: 0.1248\n",
            "Epoch 1883: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3260 - accuracy: 0.7216 - mae: 0.1994 - mse: 0.1238 - val_loss: 0.7399 - val_accuracy: 0.6160 - val_mae: 0.2506 - val_mse: 0.1683 - lr: 1.0000e-04\n",
            "Epoch 1884/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3328 - accuracy: 0.7046 - mae: 0.2009 - mse: 0.1250\n",
            "Epoch 1884: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3344 - accuracy: 0.7064 - mae: 0.2003 - mse: 0.1245 - val_loss: 0.7368 - val_accuracy: 0.6150 - val_mae: 0.2510 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 1885/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3284 - accuracy: 0.7124 - mae: 0.1973 - mse: 0.1216\n",
            "Epoch 1885: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3291 - accuracy: 0.7092 - mae: 0.1993 - mse: 0.1236 - val_loss: 0.7372 - val_accuracy: 0.6075 - val_mae: 0.2522 - val_mse: 0.1684 - lr: 1.0000e-04\n",
            "Epoch 1886/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3394 - accuracy: 0.7065 - mae: 0.2045 - mse: 0.1264\n",
            "Epoch 1886: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3405 - accuracy: 0.7064 - mae: 0.2044 - mse: 0.1266 - val_loss: 0.7300 - val_accuracy: 0.6107 - val_mae: 0.2517 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 1887/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3623 - accuracy: 0.7007 - mae: 0.2071 - mse: 0.1297\n",
            "Epoch 1887: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3541 - accuracy: 0.7032 - mae: 0.2052 - mse: 0.1284 - val_loss: 0.7350 - val_accuracy: 0.6107 - val_mae: 0.2537 - val_mse: 0.1687 - lr: 1.0000e-04\n",
            "Epoch 1888/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3514 - accuracy: 0.7012 - mae: 0.2083 - mse: 0.1306\n",
            "Epoch 1888: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3537 - accuracy: 0.6991 - mae: 0.2090 - mse: 0.1309 - val_loss: 0.7366 - val_accuracy: 0.6086 - val_mae: 0.2547 - val_mse: 0.1692 - lr: 1.0000e-04\n",
            "Epoch 1889/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3394 - accuracy: 0.6895 - mae: 0.2075 - mse: 0.1290\n",
            "Epoch 1889: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3386 - accuracy: 0.6899 - mae: 0.2083 - mse: 0.1296 - val_loss: 0.7396 - val_accuracy: 0.6021 - val_mae: 0.2560 - val_mse: 0.1701 - lr: 1.0000e-04\n",
            "Epoch 1890/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3281 - accuracy: 0.6978 - mae: 0.2082 - mse: 0.1290\n",
            "Epoch 1890: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3330 - accuracy: 0.7000 - mae: 0.2076 - mse: 0.1286 - val_loss: 0.7315 - val_accuracy: 0.6086 - val_mae: 0.2544 - val_mse: 0.1682 - lr: 1.0000e-04\n",
            "Epoch 1891/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3259 - accuracy: 0.7021 - mae: 0.2059 - mse: 0.1252\n",
            "Epoch 1891: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3257 - accuracy: 0.6986 - mae: 0.2067 - mse: 0.1256 - val_loss: 0.7287 - val_accuracy: 0.6118 - val_mae: 0.2538 - val_mse: 0.1675 - lr: 1.0000e-04\n",
            "Epoch 1892/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3429 - accuracy: 0.7002 - mae: 0.2058 - mse: 0.1268\n",
            "Epoch 1892: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3402 - accuracy: 0.7023 - mae: 0.2057 - mse: 0.1261 - val_loss: 0.7211 - val_accuracy: 0.6203 - val_mae: 0.2516 - val_mse: 0.1654 - lr: 1.0000e-04\n",
            "Epoch 1893/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3221 - accuracy: 0.6953 - mae: 0.2085 - mse: 0.1278\n",
            "Epoch 1893: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3291 - accuracy: 0.7005 - mae: 0.2062 - mse: 0.1261 - val_loss: 0.7152 - val_accuracy: 0.6235 - val_mae: 0.2491 - val_mse: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 1894/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3511 - accuracy: 0.7017 - mae: 0.2063 - mse: 0.1274\n",
            "Epoch 1894: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3471 - accuracy: 0.7018 - mae: 0.2058 - mse: 0.1273 - val_loss: 0.7307 - val_accuracy: 0.6075 - val_mae: 0.2516 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 1895/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3358 - accuracy: 0.6987 - mae: 0.2068 - mse: 0.1294\n",
            "Epoch 1895: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3313 - accuracy: 0.7009 - mae: 0.2062 - mse: 0.1290 - val_loss: 0.7235 - val_accuracy: 0.6139 - val_mae: 0.2491 - val_mse: 0.1652 - lr: 1.0000e-04\n",
            "Epoch 1896/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3211 - accuracy: 0.7129 - mae: 0.2000 - mse: 0.1229\n",
            "Epoch 1896: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3269 - accuracy: 0.7087 - mae: 0.2019 - mse: 0.1243 - val_loss: 0.7092 - val_accuracy: 0.6246 - val_mae: 0.2453 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 1897/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.7197 - mae: 0.1987 - mse: 0.1216\n",
            "Epoch 1897: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3286 - accuracy: 0.7197 - mae: 0.1987 - mse: 0.1216 - val_loss: 0.7042 - val_accuracy: 0.6310 - val_mae: 0.2440 - val_mse: 0.1602 - lr: 1.0000e-04\n",
            "Epoch 1898/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.7161 - mae: 0.1969 - mse: 0.1192\n",
            "Epoch 1898: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.3329 - accuracy: 0.7161 - mae: 0.1969 - mse: 0.1192 - val_loss: 0.6940 - val_accuracy: 0.6374 - val_mae: 0.2417 - val_mse: 0.1576 - lr: 1.0000e-04\n",
            "Epoch 1899/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.7220 - mae: 0.1959 - mse: 0.1182\n",
            "Epoch 1899: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.3496 - accuracy: 0.7220 - mae: 0.1959 - mse: 0.1182 - val_loss: 0.7043 - val_accuracy: 0.6267 - val_mae: 0.2455 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 1900/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.7188 - mae: 0.1969 - mse: 0.1192\n",
            "Epoch 1900: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.3255 - accuracy: 0.7188 - mae: 0.1969 - mse: 0.1192 - val_loss: 0.7262 - val_accuracy: 0.6096 - val_mae: 0.2518 - val_mse: 0.1664 - lr: 1.0000e-04\n",
            "Epoch 1901/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.7032 - mae: 0.2041 - mse: 0.1252\n",
            "Epoch 1901: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3288 - accuracy: 0.7032 - mae: 0.2041 - mse: 0.1252 - val_loss: 0.7460 - val_accuracy: 0.6032 - val_mae: 0.2574 - val_mse: 0.1713 - lr: 1.0000e-04\n",
            "Epoch 1902/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.6899 - mae: 0.2103 - mse: 0.1313\n",
            "Epoch 1902: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3389 - accuracy: 0.6899 - mae: 0.2103 - mse: 0.1313 - val_loss: 0.7622 - val_accuracy: 0.5936 - val_mae: 0.2612 - val_mse: 0.1750 - lr: 1.0000e-04\n",
            "Epoch 1903/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3405 - accuracy: 0.6958 - mae: 0.2122 - mse: 0.1323\n",
            "Epoch 1903: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3371 - accuracy: 0.6968 - mae: 0.2111 - mse: 0.1315 - val_loss: 0.7581 - val_accuracy: 0.5947 - val_mae: 0.2600 - val_mse: 0.1739 - lr: 1.0000e-04\n",
            "Epoch 1904/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3403 - accuracy: 0.6938 - mae: 0.2126 - mse: 0.1325\n",
            "Epoch 1904: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3402 - accuracy: 0.6931 - mae: 0.2123 - mse: 0.1321 - val_loss: 0.7451 - val_accuracy: 0.5989 - val_mae: 0.2563 - val_mse: 0.1705 - lr: 1.0000e-04\n",
            "Epoch 1905/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.6931 - mae: 0.2080 - mse: 0.1288\n",
            "Epoch 1905: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3409 - accuracy: 0.6931 - mae: 0.2080 - mse: 0.1288 - val_loss: 0.7276 - val_accuracy: 0.6150 - val_mae: 0.2514 - val_mse: 0.1662 - lr: 1.0000e-04\n",
            "Epoch 1906/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.7225 - mae: 0.1982 - mse: 0.1200\n",
            "Epoch 1906: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.3235 - accuracy: 0.7225 - mae: 0.1982 - mse: 0.1200 - val_loss: 0.7038 - val_accuracy: 0.6257 - val_mae: 0.2448 - val_mse: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 1907/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3472 - accuracy: 0.7192 - mae: 0.1972 - mse: 0.1193\n",
            "Epoch 1907: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3441 - accuracy: 0.7179 - mae: 0.1971 - mse: 0.1190 - val_loss: 0.7042 - val_accuracy: 0.6353 - val_mae: 0.2439 - val_mse: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 1908/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3279 - accuracy: 0.7168 - mae: 0.1976 - mse: 0.1196\n",
            "Epoch 1908: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3322 - accuracy: 0.7193 - mae: 0.1969 - mse: 0.1191 - val_loss: 0.7175 - val_accuracy: 0.6257 - val_mae: 0.2465 - val_mse: 0.1629 - lr: 1.0000e-04\n",
            "Epoch 1909/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3294 - accuracy: 0.7124 - mae: 0.1994 - mse: 0.1228\n",
            "Epoch 1909: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3327 - accuracy: 0.7087 - mae: 0.2011 - mse: 0.1244 - val_loss: 0.7500 - val_accuracy: 0.6064 - val_mae: 0.2543 - val_mse: 0.1707 - lr: 1.0000e-04\n",
            "Epoch 1910/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3349 - accuracy: 0.7056 - mae: 0.2025 - mse: 0.1263\n",
            "Epoch 1910: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3361 - accuracy: 0.6995 - mae: 0.2049 - mse: 0.1286 - val_loss: 0.7626 - val_accuracy: 0.6021 - val_mae: 0.2576 - val_mse: 0.1739 - lr: 1.0000e-04\n",
            "Epoch 1911/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3349 - accuracy: 0.6909 - mae: 0.2087 - mse: 0.1328\n",
            "Epoch 1911: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3422 - accuracy: 0.6908 - mae: 0.2090 - mse: 0.1331 - val_loss: 0.7544 - val_accuracy: 0.5957 - val_mae: 0.2564 - val_mse: 0.1723 - lr: 1.0000e-04\n",
            "Epoch 1912/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3383 - accuracy: 0.6929 - mae: 0.2100 - mse: 0.1329\n",
            "Epoch 1912: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3352 - accuracy: 0.6936 - mae: 0.2094 - mse: 0.1324 - val_loss: 0.7458 - val_accuracy: 0.6011 - val_mae: 0.2552 - val_mse: 0.1707 - lr: 1.0000e-04\n",
            "Epoch 1913/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3315 - accuracy: 0.7109 - mae: 0.2045 - mse: 0.1284\n",
            "Epoch 1913: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3371 - accuracy: 0.7073 - mae: 0.2059 - mse: 0.1291 - val_loss: 0.7405 - val_accuracy: 0.6053 - val_mae: 0.2545 - val_mse: 0.1697 - lr: 1.0000e-04\n",
            "Epoch 1914/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3298 - accuracy: 0.6978 - mae: 0.2090 - mse: 0.1306\n",
            "Epoch 1914: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.3251 - accuracy: 0.7023 - mae: 0.2065 - mse: 0.1287 - val_loss: 0.7417 - val_accuracy: 0.6043 - val_mae: 0.2541 - val_mse: 0.1697 - lr: 1.0000e-04\n",
            "Epoch 1915/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.6931 - mae: 0.2088 - mse: 0.1293\n",
            "Epoch 1915: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.3461 - accuracy: 0.6931 - mae: 0.2088 - mse: 0.1293 - val_loss: 0.7472 - val_accuracy: 0.6032 - val_mae: 0.2543 - val_mse: 0.1706 - lr: 1.0000e-04\n",
            "Epoch 1916/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3350 - accuracy: 0.7012 - mae: 0.2105 - mse: 0.1324\n",
            "Epoch 1916: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3360 - accuracy: 0.6995 - mae: 0.2105 - mse: 0.1327 - val_loss: 0.7499 - val_accuracy: 0.6021 - val_mae: 0.2541 - val_mse: 0.1710 - lr: 1.0000e-04\n",
            "Epoch 1917/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3403 - accuracy: 0.7046 - mae: 0.2063 - mse: 0.1283\n",
            "Epoch 1917: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3480 - accuracy: 0.7041 - mae: 0.2063 - mse: 0.1284 - val_loss: 0.7478 - val_accuracy: 0.6032 - val_mae: 0.2538 - val_mse: 0.1706 - lr: 1.0000e-04\n",
            "Epoch 1918/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3224 - accuracy: 0.6904 - mae: 0.2076 - mse: 0.1305\n",
            "Epoch 1918: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3239 - accuracy: 0.6904 - mae: 0.2073 - mse: 0.1300 - val_loss: 0.7526 - val_accuracy: 0.6000 - val_mae: 0.2556 - val_mse: 0.1720 - lr: 1.0000e-04\n",
            "Epoch 1919/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3334 - accuracy: 0.6914 - mae: 0.2064 - mse: 0.1303\n",
            "Epoch 1919: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3331 - accuracy: 0.6917 - mae: 0.2068 - mse: 0.1305 - val_loss: 0.7560 - val_accuracy: 0.6021 - val_mae: 0.2566 - val_mse: 0.1728 - lr: 1.0000e-04\n",
            "Epoch 1920/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3262 - accuracy: 0.6938 - mae: 0.2069 - mse: 0.1298\n",
            "Epoch 1920: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3299 - accuracy: 0.6945 - mae: 0.2063 - mse: 0.1295 - val_loss: 0.7536 - val_accuracy: 0.6000 - val_mae: 0.2557 - val_mse: 0.1721 - lr: 1.0000e-04\n",
            "Epoch 1921/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3302 - accuracy: 0.6982 - mae: 0.2079 - mse: 0.1311\n",
            "Epoch 1921: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3330 - accuracy: 0.6963 - mae: 0.2089 - mse: 0.1322 - val_loss: 0.7471 - val_accuracy: 0.6107 - val_mae: 0.2536 - val_mse: 0.1703 - lr: 1.0000e-04\n",
            "Epoch 1922/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3299 - accuracy: 0.7056 - mae: 0.2035 - mse: 0.1268\n",
            "Epoch 1922: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3287 - accuracy: 0.7083 - mae: 0.2030 - mse: 0.1259 - val_loss: 0.7359 - val_accuracy: 0.6182 - val_mae: 0.2504 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 1923/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3219 - accuracy: 0.7231 - mae: 0.1982 - mse: 0.1226\n",
            "Epoch 1923: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 209ms/step - loss: 0.3234 - accuracy: 0.7220 - mae: 0.1993 - mse: 0.1232 - val_loss: 0.7232 - val_accuracy: 0.6267 - val_mae: 0.2469 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 1924/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3317 - accuracy: 0.7236 - mae: 0.1963 - mse: 0.1201\n",
            "Epoch 1924: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3332 - accuracy: 0.7229 - mae: 0.1962 - mse: 0.1201 - val_loss: 0.7160 - val_accuracy: 0.6289 - val_mae: 0.2453 - val_mse: 0.1624 - lr: 1.0000e-04\n",
            "Epoch 1925/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.7289 - mae: 0.1952 - mse: 0.1196\n",
            "Epoch 1925: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3197 - accuracy: 0.7289 - mae: 0.1952 - mse: 0.1196 - val_loss: 0.7131 - val_accuracy: 0.6278 - val_mae: 0.2440 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 1926/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.7206 - mae: 0.1929 - mse: 0.1182\n",
            "Epoch 1926: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3285 - accuracy: 0.7206 - mae: 0.1929 - mse: 0.1182 - val_loss: 0.7228 - val_accuracy: 0.6203 - val_mae: 0.2458 - val_mse: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 1927/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3295 - accuracy: 0.7095 - mae: 0.1967 - mse: 0.1231\n",
            "Epoch 1927: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3297 - accuracy: 0.7092 - mae: 0.1967 - mse: 0.1229 - val_loss: 0.7351 - val_accuracy: 0.6171 - val_mae: 0.2485 - val_mse: 0.1665 - lr: 1.0000e-04\n",
            "Epoch 1928/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3289 - accuracy: 0.7153 - mae: 0.2004 - mse: 0.1252\n",
            "Epoch 1928: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3278 - accuracy: 0.7142 - mae: 0.2009 - mse: 0.1259 - val_loss: 0.7417 - val_accuracy: 0.6171 - val_mae: 0.2499 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 1929/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.7110 - mae: 0.2014 - mse: 0.1263\n",
            "Epoch 1929: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3370 - accuracy: 0.7110 - mae: 0.2014 - mse: 0.1263 - val_loss: 0.7392 - val_accuracy: 0.6203 - val_mae: 0.2500 - val_mse: 0.1675 - lr: 1.0000e-04\n",
            "Epoch 1930/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.7005 - mae: 0.2023 - mse: 0.1271\n",
            "Epoch 1930: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3290 - accuracy: 0.7005 - mae: 0.2023 - mse: 0.1271 - val_loss: 0.7269 - val_accuracy: 0.6235 - val_mae: 0.2479 - val_mse: 0.1647 - lr: 1.0000e-04\n",
            "Epoch 1931/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.7147 - mae: 0.1981 - mse: 0.1230\n",
            "Epoch 1931: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.3422 - accuracy: 0.7147 - mae: 0.1981 - mse: 0.1230 - val_loss: 0.7174 - val_accuracy: 0.6214 - val_mae: 0.2465 - val_mse: 0.1627 - lr: 1.0000e-04\n",
            "Epoch 1932/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.7138 - mae: 0.1981 - mse: 0.1216\n",
            "Epoch 1932: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.3283 - accuracy: 0.7138 - mae: 0.1981 - mse: 0.1216 - val_loss: 0.7081 - val_accuracy: 0.6235 - val_mae: 0.2454 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 1933/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3439 - accuracy: 0.7139 - mae: 0.1990 - mse: 0.1232\n",
            "Epoch 1933: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3476 - accuracy: 0.7138 - mae: 0.1994 - mse: 0.1233 - val_loss: 0.7091 - val_accuracy: 0.6214 - val_mae: 0.2465 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 1934/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3337 - accuracy: 0.7188 - mae: 0.1992 - mse: 0.1210\n",
            "Epoch 1934: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3338 - accuracy: 0.7179 - mae: 0.1994 - mse: 0.1213 - val_loss: 0.7349 - val_accuracy: 0.6096 - val_mae: 0.2524 - val_mse: 0.1679 - lr: 1.0000e-04\n",
            "Epoch 1935/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3294 - accuracy: 0.7148 - mae: 0.2012 - mse: 0.1241\n",
            "Epoch 1935: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3288 - accuracy: 0.7124 - mae: 0.2027 - mse: 0.1254 - val_loss: 0.7521 - val_accuracy: 0.6011 - val_mae: 0.2550 - val_mse: 0.1715 - lr: 1.0000e-04\n",
            "Epoch 1936/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3484 - accuracy: 0.6924 - mae: 0.2093 - mse: 0.1300\n",
            "Epoch 1936: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3477 - accuracy: 0.6945 - mae: 0.2084 - mse: 0.1298 - val_loss: 0.7487 - val_accuracy: 0.6053 - val_mae: 0.2541 - val_mse: 0.1707 - lr: 1.0000e-04\n",
            "Epoch 1937/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3271 - accuracy: 0.7119 - mae: 0.2015 - mse: 0.1260\n",
            "Epoch 1937: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3297 - accuracy: 0.7101 - mae: 0.2028 - mse: 0.1266 - val_loss: 0.7410 - val_accuracy: 0.6075 - val_mae: 0.2524 - val_mse: 0.1692 - lr: 1.0000e-04\n",
            "Epoch 1938/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3306 - accuracy: 0.6973 - mae: 0.2058 - mse: 0.1288\n",
            "Epoch 1938: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3278 - accuracy: 0.6972 - mae: 0.2054 - mse: 0.1286 - val_loss: 0.7274 - val_accuracy: 0.6075 - val_mae: 0.2488 - val_mse: 0.1659 - lr: 1.0000e-04\n",
            "Epoch 1939/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.7096 - mae: 0.2015 - mse: 0.1258\n",
            "Epoch 1939: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.3348 - accuracy: 0.7096 - mae: 0.2015 - mse: 0.1258 - val_loss: 0.7159 - val_accuracy: 0.6139 - val_mae: 0.2458 - val_mse: 0.1630 - lr: 1.0000e-04\n",
            "Epoch 1940/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3287 - accuracy: 0.7124 - mae: 0.1991 - mse: 0.1230\n",
            "Epoch 1940: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3335 - accuracy: 0.7128 - mae: 0.1986 - mse: 0.1230 - val_loss: 0.7170 - val_accuracy: 0.6160 - val_mae: 0.2464 - val_mse: 0.1634 - lr: 1.0000e-04\n",
            "Epoch 1941/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3309 - accuracy: 0.7153 - mae: 0.1980 - mse: 0.1235\n",
            "Epoch 1941: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3298 - accuracy: 0.7147 - mae: 0.1989 - mse: 0.1242 - val_loss: 0.7320 - val_accuracy: 0.6128 - val_mae: 0.2506 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 1942/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.7090 - mae: 0.2041 - mse: 0.1272\n",
            "Epoch 1942: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3429 - accuracy: 0.7069 - mae: 0.2053 - mse: 0.1283 - val_loss: 0.7265 - val_accuracy: 0.6139 - val_mae: 0.2498 - val_mse: 0.1662 - lr: 1.0000e-04\n",
            "Epoch 1943/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3396 - accuracy: 0.7075 - mae: 0.2016 - mse: 0.1252\n",
            "Epoch 1943: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3371 - accuracy: 0.7078 - mae: 0.2016 - mse: 0.1252 - val_loss: 0.7109 - val_accuracy: 0.6267 - val_mae: 0.2464 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 1944/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3284 - accuracy: 0.7188 - mae: 0.1986 - mse: 0.1210\n",
            "Epoch 1944: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3257 - accuracy: 0.7252 - mae: 0.1961 - mse: 0.1190 - val_loss: 0.6977 - val_accuracy: 0.6364 - val_mae: 0.2430 - val_mse: 0.1591 - lr: 1.0000e-04\n",
            "Epoch 1945/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3438 - accuracy: 0.7192 - mae: 0.1993 - mse: 0.1218\n",
            "Epoch 1945: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 185ms/step - loss: 0.3376 - accuracy: 0.7211 - mae: 0.1975 - mse: 0.1207 - val_loss: 0.7022 - val_accuracy: 0.6353 - val_mae: 0.2432 - val_mse: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 1946/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.7266 - mae: 0.1939 - mse: 0.1175\n",
            "Epoch 1946: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.3265 - accuracy: 0.7266 - mae: 0.1939 - mse: 0.1175 - val_loss: 0.7111 - val_accuracy: 0.6321 - val_mae: 0.2444 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 1947/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3426 - accuracy: 0.7168 - mae: 0.1985 - mse: 0.1225\n",
            "Epoch 1947: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3514 - accuracy: 0.7147 - mae: 0.1997 - mse: 0.1234 - val_loss: 0.7401 - val_accuracy: 0.6160 - val_mae: 0.2502 - val_mse: 0.1682 - lr: 1.0000e-04\n",
            "Epoch 1948/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3357 - accuracy: 0.7031 - mae: 0.2043 - mse: 0.1289\n",
            "Epoch 1948: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 0.3317 - accuracy: 0.7005 - mae: 0.2041 - mse: 0.1291 - val_loss: 0.7695 - val_accuracy: 0.6043 - val_mae: 0.2562 - val_mse: 0.1746 - lr: 1.0000e-04\n",
            "Epoch 1949/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.6945 - mae: 0.2087 - mse: 0.1327\n",
            "Epoch 1949: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3342 - accuracy: 0.6945 - mae: 0.2087 - mse: 0.1327 - val_loss: 0.7670 - val_accuracy: 0.6064 - val_mae: 0.2550 - val_mse: 0.1737 - lr: 1.0000e-04\n",
            "Epoch 1950/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.7073 - mae: 0.2042 - mse: 0.1269\n",
            "Epoch 1950: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 0.3225 - accuracy: 0.7073 - mae: 0.2042 - mse: 0.1269 - val_loss: 0.7472 - val_accuracy: 0.6150 - val_mae: 0.2500 - val_mse: 0.1687 - lr: 1.0000e-04\n",
            "Epoch 1951/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.7087 - mae: 0.2001 - mse: 0.1243\n",
            "Epoch 1951: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 0.3261 - accuracy: 0.7087 - mae: 0.2001 - mse: 0.1243 - val_loss: 0.7261 - val_accuracy: 0.6342 - val_mae: 0.2449 - val_mse: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 1952/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.7326 - mae: 0.1909 - mse: 0.1161\n",
            "Epoch 1952: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3295 - accuracy: 0.7326 - mae: 0.1909 - mse: 0.1161 - val_loss: 0.7189 - val_accuracy: 0.6342 - val_mae: 0.2431 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 1953/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3316 - accuracy: 0.7241 - mae: 0.1954 - mse: 0.1211\n",
            "Epoch 1953: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3326 - accuracy: 0.7271 - mae: 0.1938 - mse: 0.1199 - val_loss: 0.7333 - val_accuracy: 0.6321 - val_mae: 0.2463 - val_mse: 0.1655 - lr: 1.0000e-04\n",
            "Epoch 1954/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3425 - accuracy: 0.7046 - mae: 0.2003 - mse: 0.1267\n",
            "Epoch 1954: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3393 - accuracy: 0.7009 - mae: 0.2018 - mse: 0.1277 - val_loss: 0.7589 - val_accuracy: 0.6118 - val_mae: 0.2526 - val_mse: 0.1719 - lr: 1.0000e-04\n",
            "Epoch 1955/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.7119 - mae: 0.2012 - mse: 0.1266\n",
            "Epoch 1955: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 0.3131 - accuracy: 0.7119 - mae: 0.2012 - mse: 0.1266 - val_loss: 0.7437 - val_accuracy: 0.6086 - val_mae: 0.2497 - val_mse: 0.1686 - lr: 1.0000e-04\n",
            "Epoch 1956/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.7092 - mae: 0.2040 - mse: 0.1299\n",
            "Epoch 1956: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.3436 - accuracy: 0.7092 - mae: 0.2040 - mse: 0.1299 - val_loss: 0.7150 - val_accuracy: 0.6321 - val_mae: 0.2437 - val_mse: 0.1620 - lr: 1.0000e-04\n",
            "Epoch 1957/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.7312 - mae: 0.1923 - mse: 0.1168\n",
            "Epoch 1957: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.3219 - accuracy: 0.7312 - mae: 0.1923 - mse: 0.1168 - val_loss: 0.6890 - val_accuracy: 0.6460 - val_mae: 0.2381 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 1958/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.7229 - mae: 0.1920 - mse: 0.1156\n",
            "Epoch 1958: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3404 - accuracy: 0.7229 - mae: 0.1920 - mse: 0.1156 - val_loss: 0.6898 - val_accuracy: 0.6417 - val_mae: 0.2384 - val_mse: 0.1560 - lr: 1.0000e-04\n",
            "Epoch 1959/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.7303 - mae: 0.1915 - mse: 0.1149\n",
            "Epoch 1959: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.3387 - accuracy: 0.7303 - mae: 0.1915 - mse: 0.1149 - val_loss: 0.7133 - val_accuracy: 0.6342 - val_mae: 0.2440 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 1960/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.7206 - mae: 0.1959 - mse: 0.1187\n",
            "Epoch 1960: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.3247 - accuracy: 0.7206 - mae: 0.1959 - mse: 0.1187 - val_loss: 0.7290 - val_accuracy: 0.6225 - val_mae: 0.2477 - val_mse: 0.1655 - lr: 1.0000e-04\n",
            "Epoch 1961/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.7183 - mae: 0.1977 - mse: 0.1226\n",
            "Epoch 1961: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.3288 - accuracy: 0.7183 - mae: 0.1977 - mse: 0.1226 - val_loss: 0.7344 - val_accuracy: 0.6203 - val_mae: 0.2487 - val_mse: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 1962/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.7106 - mae: 0.2001 - mse: 0.1252\n",
            "Epoch 1962: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.3285 - accuracy: 0.7106 - mae: 0.2001 - mse: 0.1252 - val_loss: 0.7376 - val_accuracy: 0.6160 - val_mae: 0.2485 - val_mse: 0.1671 - lr: 1.0000e-04\n",
            "Epoch 1963/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.7064 - mae: 0.2023 - mse: 0.1269\n",
            "Epoch 1963: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3411 - accuracy: 0.7064 - mae: 0.2023 - mse: 0.1269 - val_loss: 0.7336 - val_accuracy: 0.6225 - val_mae: 0.2470 - val_mse: 0.1660 - lr: 1.0000e-04\n",
            "Epoch 1964/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3310 - accuracy: 0.7070 - mae: 0.2008 - mse: 0.1255\n",
            "Epoch 1964: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.3307 - accuracy: 0.7073 - mae: 0.1998 - mse: 0.1248 - val_loss: 0.7223 - val_accuracy: 0.6299 - val_mae: 0.2443 - val_mse: 0.1633 - lr: 1.0000e-04\n",
            "Epoch 1965/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3329 - accuracy: 0.7114 - mae: 0.1949 - mse: 0.1209\n",
            "Epoch 1965: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 0.3328 - accuracy: 0.7101 - mae: 0.1954 - mse: 0.1211 - val_loss: 0.7236 - val_accuracy: 0.6321 - val_mae: 0.2440 - val_mse: 0.1633 - lr: 1.0000e-04\n",
            "Epoch 1966/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3249 - accuracy: 0.7217 - mae: 0.1969 - mse: 0.1229\n",
            "Epoch 1966: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 0.3240 - accuracy: 0.7225 - mae: 0.1963 - mse: 0.1225 - val_loss: 0.7249 - val_accuracy: 0.6310 - val_mae: 0.2433 - val_mse: 0.1633 - lr: 1.0000e-04\n",
            "Epoch 1967/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3095 - accuracy: 0.7173 - mae: 0.1936 - mse: 0.1201\n",
            "Epoch 1967: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3111 - accuracy: 0.7161 - mae: 0.1943 - mse: 0.1204 - val_loss: 0.7264 - val_accuracy: 0.6310 - val_mae: 0.2426 - val_mse: 0.1633 - lr: 1.0000e-04\n",
            "Epoch 1968/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3345 - accuracy: 0.7144 - mae: 0.1973 - mse: 0.1251\n",
            "Epoch 1968: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3407 - accuracy: 0.7133 - mae: 0.1983 - mse: 0.1256 - val_loss: 0.7415 - val_accuracy: 0.6225 - val_mae: 0.2461 - val_mse: 0.1669 - lr: 1.0000e-04\n",
            "Epoch 1969/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3128 - accuracy: 0.7129 - mae: 0.1968 - mse: 0.1244\n",
            "Epoch 1969: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3175 - accuracy: 0.7096 - mae: 0.1988 - mse: 0.1263 - val_loss: 0.7542 - val_accuracy: 0.6118 - val_mae: 0.2500 - val_mse: 0.1703 - lr: 1.0000e-04\n",
            "Epoch 1970/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3323 - accuracy: 0.6987 - mae: 0.2027 - mse: 0.1288\n",
            "Epoch 1970: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3332 - accuracy: 0.7005 - mae: 0.2028 - mse: 0.1291 - val_loss: 0.7525 - val_accuracy: 0.6107 - val_mae: 0.2507 - val_mse: 0.1702 - lr: 1.0000e-04\n",
            "Epoch 1971/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3261 - accuracy: 0.7085 - mae: 0.2024 - mse: 0.1285\n",
            "Epoch 1971: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3250 - accuracy: 0.7106 - mae: 0.2015 - mse: 0.1278 - val_loss: 0.7405 - val_accuracy: 0.6139 - val_mae: 0.2489 - val_mse: 0.1676 - lr: 1.0000e-04\n",
            "Epoch 1972/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3341 - accuracy: 0.7095 - mae: 0.1989 - mse: 0.1243\n",
            "Epoch 1972: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3395 - accuracy: 0.7078 - mae: 0.2004 - mse: 0.1255 - val_loss: 0.7341 - val_accuracy: 0.6139 - val_mae: 0.2485 - val_mse: 0.1664 - lr: 1.0000e-04\n",
            "Epoch 1973/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3468 - accuracy: 0.7095 - mae: 0.2034 - mse: 0.1275\n",
            "Epoch 1973: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3411 - accuracy: 0.7101 - mae: 0.2026 - mse: 0.1269 - val_loss: 0.7419 - val_accuracy: 0.6118 - val_mae: 0.2514 - val_mse: 0.1685 - lr: 1.0000e-04\n",
            "Epoch 1974/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3376 - accuracy: 0.7104 - mae: 0.2036 - mse: 0.1283\n",
            "Epoch 1974: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3365 - accuracy: 0.7110 - mae: 0.2040 - mse: 0.1282 - val_loss: 0.7360 - val_accuracy: 0.6139 - val_mae: 0.2508 - val_mse: 0.1671 - lr: 1.0000e-04\n",
            "Epoch 1975/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3186 - accuracy: 0.7026 - mae: 0.2016 - mse: 0.1250\n",
            "Epoch 1975: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3203 - accuracy: 0.7009 - mae: 0.2019 - mse: 0.1252 - val_loss: 0.7245 - val_accuracy: 0.6193 - val_mae: 0.2484 - val_mse: 0.1642 - lr: 1.0000e-04\n",
            "Epoch 1976/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3242 - accuracy: 0.7095 - mae: 0.1968 - mse: 0.1208\n",
            "Epoch 1976: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3329 - accuracy: 0.7032 - mae: 0.1998 - mse: 0.1230 - val_loss: 0.7267 - val_accuracy: 0.6150 - val_mae: 0.2491 - val_mse: 0.1647 - lr: 1.0000e-04\n",
            "Epoch 1977/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3305 - accuracy: 0.7085 - mae: 0.2043 - mse: 0.1264\n",
            "Epoch 1977: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3272 - accuracy: 0.7106 - mae: 0.2030 - mse: 0.1255 - val_loss: 0.7376 - val_accuracy: 0.6118 - val_mae: 0.2512 - val_mse: 0.1671 - lr: 1.0000e-04\n",
            "Epoch 1978/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.7069 - mae: 0.2021 - mse: 0.1257\n",
            "Epoch 1978: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3286 - accuracy: 0.7069 - mae: 0.2021 - mse: 0.1257 - val_loss: 0.7346 - val_accuracy: 0.6139 - val_mae: 0.2501 - val_mse: 0.1661 - lr: 1.0000e-04\n",
            "Epoch 1979/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3336 - accuracy: 0.7109 - mae: 0.2013 - mse: 0.1251\n",
            "Epoch 1979: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3385 - accuracy: 0.7106 - mae: 0.2018 - mse: 0.1256 - val_loss: 0.7420 - val_accuracy: 0.6107 - val_mae: 0.2520 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 1980/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3276 - accuracy: 0.7124 - mae: 0.2006 - mse: 0.1236\n",
            "Epoch 1980: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3316 - accuracy: 0.7096 - mae: 0.2022 - mse: 0.1249 - val_loss: 0.7554 - val_accuracy: 0.6043 - val_mae: 0.2559 - val_mse: 0.1715 - lr: 1.0000e-04\n",
            "Epoch 1981/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3286 - accuracy: 0.7080 - mae: 0.2073 - mse: 0.1292\n",
            "Epoch 1981: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3288 - accuracy: 0.7096 - mae: 0.2060 - mse: 0.1284 - val_loss: 0.7549 - val_accuracy: 0.5968 - val_mae: 0.2563 - val_mse: 0.1716 - lr: 1.0000e-04\n",
            "Epoch 1982/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.7037 - mae: 0.2043 - mse: 0.1280\n",
            "Epoch 1982: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3296 - accuracy: 0.7037 - mae: 0.2043 - mse: 0.1280 - val_loss: 0.7446 - val_accuracy: 0.6011 - val_mae: 0.2541 - val_mse: 0.1693 - lr: 1.0000e-04\n",
            "Epoch 1983/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.6986 - mae: 0.2059 - mse: 0.1283\n",
            "Epoch 1983: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3345 - accuracy: 0.6986 - mae: 0.2059 - mse: 0.1283 - val_loss: 0.7288 - val_accuracy: 0.6107 - val_mae: 0.2504 - val_mse: 0.1657 - lr: 1.0000e-04\n",
            "Epoch 1984/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.7128 - mae: 0.1984 - mse: 0.1226\n",
            "Epoch 1984: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3166 - accuracy: 0.7128 - mae: 0.1984 - mse: 0.1226 - val_loss: 0.7067 - val_accuracy: 0.6257 - val_mae: 0.2443 - val_mse: 0.1601 - lr: 1.0000e-04\n",
            "Epoch 1985/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3381 - accuracy: 0.7173 - mae: 0.1957 - mse: 0.1188\n",
            "Epoch 1985: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3348 - accuracy: 0.7202 - mae: 0.1946 - mse: 0.1183 - val_loss: 0.6983 - val_accuracy: 0.6299 - val_mae: 0.2414 - val_mse: 0.1579 - lr: 1.0000e-04\n",
            "Epoch 1986/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3279 - accuracy: 0.7266 - mae: 0.1915 - mse: 0.1157\n",
            "Epoch 1986: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3315 - accuracy: 0.7284 - mae: 0.1914 - mse: 0.1153 - val_loss: 0.7127 - val_accuracy: 0.6278 - val_mae: 0.2444 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 1987/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3129 - accuracy: 0.7085 - mae: 0.1981 - mse: 0.1220\n",
            "Epoch 1987: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3158 - accuracy: 0.7101 - mae: 0.1968 - mse: 0.1211 - val_loss: 0.7494 - val_accuracy: 0.6053 - val_mae: 0.2520 - val_mse: 0.1698 - lr: 1.0000e-04\n",
            "Epoch 1988/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.6986 - mae: 0.2053 - mse: 0.1312\n",
            "Epoch 1988: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3285 - accuracy: 0.6986 - mae: 0.2053 - mse: 0.1312 - val_loss: 0.7925 - val_accuracy: 0.5882 - val_mae: 0.2603 - val_mse: 0.1793 - lr: 1.0000e-04\n",
            "Epoch 1989/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.6858 - mae: 0.2166 - mse: 0.1406\n",
            "Epoch 1989: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3379 - accuracy: 0.6858 - mae: 0.2166 - mse: 0.1406 - val_loss: 0.8032 - val_accuracy: 0.5872 - val_mae: 0.2614 - val_mse: 0.1812 - lr: 1.0000e-04\n",
            "Epoch 1990/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.6862 - mae: 0.2097 - mse: 0.1363\n",
            "Epoch 1990: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.3235 - accuracy: 0.6862 - mae: 0.2097 - mse: 0.1363 - val_loss: 0.7731 - val_accuracy: 0.6032 - val_mae: 0.2542 - val_mse: 0.1739 - lr: 1.0000e-04\n",
            "Epoch 1991/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.6950 - mae: 0.2061 - mse: 0.1310\n",
            "Epoch 1991: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3348 - accuracy: 0.6950 - mae: 0.2061 - mse: 0.1310 - val_loss: 0.7369 - val_accuracy: 0.6299 - val_mae: 0.2455 - val_mse: 0.1650 - lr: 1.0000e-04\n",
            "Epoch 1992/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.7257 - mae: 0.1942 - mse: 0.1215\n",
            "Epoch 1992: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3256 - accuracy: 0.7257 - mae: 0.1942 - mse: 0.1215 - val_loss: 0.7285 - val_accuracy: 0.6374 - val_mae: 0.2429 - val_mse: 0.1626 - lr: 1.0000e-04\n",
            "Epoch 1993/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3312 - accuracy: 0.7158 - mae: 0.1949 - mse: 0.1217\n",
            "Epoch 1993: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3292 - accuracy: 0.7193 - mae: 0.1938 - mse: 0.1206 - val_loss: 0.7258 - val_accuracy: 0.6406 - val_mae: 0.2418 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 1994/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3416 - accuracy: 0.7295 - mae: 0.1923 - mse: 0.1197\n",
            "Epoch 1994: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3342 - accuracy: 0.7330 - mae: 0.1902 - mse: 0.1180 - val_loss: 0.7240 - val_accuracy: 0.6385 - val_mae: 0.2415 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 1995/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3273 - accuracy: 0.7236 - mae: 0.1943 - mse: 0.1210\n",
            "Epoch 1995: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3280 - accuracy: 0.7229 - mae: 0.1942 - mse: 0.1210 - val_loss: 0.7197 - val_accuracy: 0.6385 - val_mae: 0.2406 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 1996/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3303 - accuracy: 0.7339 - mae: 0.1905 - mse: 0.1181\n",
            "Epoch 1996: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3309 - accuracy: 0.7326 - mae: 0.1912 - mse: 0.1187 - val_loss: 0.7239 - val_accuracy: 0.6321 - val_mae: 0.2422 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 1997/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3269 - accuracy: 0.7197 - mae: 0.1943 - mse: 0.1206\n",
            "Epoch 1997: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3259 - accuracy: 0.7188 - mae: 0.1944 - mse: 0.1210 - val_loss: 0.7299 - val_accuracy: 0.6278 - val_mae: 0.2444 - val_mse: 0.1634 - lr: 1.0000e-04\n",
            "Epoch 1998/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3268 - accuracy: 0.7158 - mae: 0.1959 - mse: 0.1220\n",
            "Epoch 1998: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3264 - accuracy: 0.7147 - mae: 0.1968 - mse: 0.1227 - val_loss: 0.7319 - val_accuracy: 0.6267 - val_mae: 0.2453 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 1999/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3270 - accuracy: 0.7202 - mae: 0.1955 - mse: 0.1228\n",
            "Epoch 1999: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3267 - accuracy: 0.7179 - mae: 0.1968 - mse: 0.1237 - val_loss: 0.7222 - val_accuracy: 0.6321 - val_mae: 0.2434 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2000/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.7197 - mae: 0.1957 - mse: 0.1221\n",
            "Epoch 2000: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3325 - accuracy: 0.7197 - mae: 0.1957 - mse: 0.1221 - val_loss: 0.7155 - val_accuracy: 0.6332 - val_mae: 0.2424 - val_mse: 0.1604 - lr: 1.0000e-04\n",
            "Epoch 2001/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3276 - accuracy: 0.7236 - mae: 0.1939 - mse: 0.1201\n",
            "Epoch 2001: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3243 - accuracy: 0.7234 - mae: 0.1938 - mse: 0.1199 - val_loss: 0.7123 - val_accuracy: 0.6310 - val_mae: 0.2416 - val_mse: 0.1595 - lr: 1.0000e-04\n",
            "Epoch 2002/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3166 - accuracy: 0.7314 - mae: 0.1897 - mse: 0.1154\n",
            "Epoch 2002: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3239 - accuracy: 0.7307 - mae: 0.1899 - mse: 0.1156 - val_loss: 0.7176 - val_accuracy: 0.6332 - val_mae: 0.2427 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2003/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3299 - accuracy: 0.7246 - mae: 0.1965 - mse: 0.1211\n",
            "Epoch 2003: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3323 - accuracy: 0.7206 - mae: 0.1977 - mse: 0.1223 - val_loss: 0.7410 - val_accuracy: 0.6182 - val_mae: 0.2483 - val_mse: 0.1661 - lr: 1.0000e-04\n",
            "Epoch 2004/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3137 - accuracy: 0.7246 - mae: 0.1971 - mse: 0.1212\n",
            "Epoch 2004: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3145 - accuracy: 0.7225 - mae: 0.1977 - mse: 0.1221 - val_loss: 0.7450 - val_accuracy: 0.6171 - val_mae: 0.2489 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 2005/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3323 - accuracy: 0.7275 - mae: 0.1954 - mse: 0.1214\n",
            "Epoch 2005: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3311 - accuracy: 0.7261 - mae: 0.1964 - mse: 0.1218 - val_loss: 0.7397 - val_accuracy: 0.6171 - val_mae: 0.2479 - val_mse: 0.1657 - lr: 1.0000e-04\n",
            "Epoch 2006/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3163 - accuracy: 0.7188 - mae: 0.1958 - mse: 0.1193\n",
            "Epoch 2006: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3217 - accuracy: 0.7138 - mae: 0.1972 - mse: 0.1210 - val_loss: 0.7281 - val_accuracy: 0.6150 - val_mae: 0.2464 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2007/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3455 - accuracy: 0.7144 - mae: 0.1998 - mse: 0.1222\n",
            "Epoch 2007: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3403 - accuracy: 0.7161 - mae: 0.1982 - mse: 0.1213 - val_loss: 0.7276 - val_accuracy: 0.6139 - val_mae: 0.2471 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 2008/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3362 - accuracy: 0.7153 - mae: 0.1990 - mse: 0.1235\n",
            "Epoch 2008: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3328 - accuracy: 0.7161 - mae: 0.1980 - mse: 0.1231 - val_loss: 0.7228 - val_accuracy: 0.6203 - val_mae: 0.2465 - val_mse: 0.1629 - lr: 1.0000e-04\n",
            "Epoch 2009/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3315 - accuracy: 0.7178 - mae: 0.1979 - mse: 0.1215\n",
            "Epoch 2009: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3254 - accuracy: 0.7211 - mae: 0.1962 - mse: 0.1198 - val_loss: 0.7167 - val_accuracy: 0.6246 - val_mae: 0.2446 - val_mse: 0.1614 - lr: 1.0000e-04\n",
            "Epoch 2010/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.7225 - mae: 0.1944 - mse: 0.1195\n",
            "Epoch 2010: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 202ms/step - loss: 0.3324 - accuracy: 0.7225 - mae: 0.1944 - mse: 0.1195 - val_loss: 0.7173 - val_accuracy: 0.6289 - val_mae: 0.2440 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 2011/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3334 - accuracy: 0.7358 - mae: 0.1948 - mse: 0.1193\n",
            "Epoch 2011: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.3351 - accuracy: 0.7335 - mae: 0.1945 - mse: 0.1191 - val_loss: 0.7351 - val_accuracy: 0.6182 - val_mae: 0.2482 - val_mse: 0.1660 - lr: 1.0000e-04\n",
            "Epoch 2012/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3130 - accuracy: 0.7173 - mae: 0.1985 - mse: 0.1236\n",
            "Epoch 2012: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3150 - accuracy: 0.7202 - mae: 0.1975 - mse: 0.1230 - val_loss: 0.7573 - val_accuracy: 0.6053 - val_mae: 0.2526 - val_mse: 0.1712 - lr: 1.0000e-04\n",
            "Epoch 2013/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3284 - accuracy: 0.7041 - mae: 0.2035 - mse: 0.1301\n",
            "Epoch 2013: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 208ms/step - loss: 0.3260 - accuracy: 0.7087 - mae: 0.2016 - mse: 0.1286 - val_loss: 0.7669 - val_accuracy: 0.6053 - val_mae: 0.2540 - val_mse: 0.1733 - lr: 1.0000e-04\n",
            "Epoch 2014/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.6931 - mae: 0.2056 - mse: 0.1312\n",
            "Epoch 2014: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.3269 - accuracy: 0.6931 - mae: 0.2056 - mse: 0.1312 - val_loss: 0.7661 - val_accuracy: 0.6075 - val_mae: 0.2531 - val_mse: 0.1729 - lr: 1.0000e-04\n",
            "Epoch 2015/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.7041 - mae: 0.2028 - mse: 0.1300\n",
            "Epoch 2015: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3231 - accuracy: 0.7041 - mae: 0.2028 - mse: 0.1300 - val_loss: 0.7632 - val_accuracy: 0.6043 - val_mae: 0.2515 - val_mse: 0.1721 - lr: 1.0000e-04\n",
            "Epoch 2016/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3211 - accuracy: 0.7051 - mae: 0.1982 - mse: 0.1272\n",
            "Epoch 2016: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3242 - accuracy: 0.7028 - mae: 0.1993 - mse: 0.1278 - val_loss: 0.7541 - val_accuracy: 0.6043 - val_mae: 0.2496 - val_mse: 0.1701 - lr: 1.0000e-04\n",
            "Epoch 2017/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3412 - accuracy: 0.7002 - mae: 0.2036 - mse: 0.1306\n",
            "Epoch 2017: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.3424 - accuracy: 0.6977 - mae: 0.2046 - mse: 0.1314 - val_loss: 0.7454 - val_accuracy: 0.6096 - val_mae: 0.2485 - val_mse: 0.1685 - lr: 1.0000e-04\n",
            "Epoch 2018/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.7096 - mae: 0.1964 - mse: 0.1246\n",
            "Epoch 2018: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3090 - accuracy: 0.7096 - mae: 0.1964 - mse: 0.1246 - val_loss: 0.7308 - val_accuracy: 0.6160 - val_mae: 0.2462 - val_mse: 0.1654 - lr: 1.0000e-04\n",
            "Epoch 2019/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.7101 - mae: 0.1997 - mse: 0.1268\n",
            "Epoch 2019: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.3308 - accuracy: 0.7101 - mae: 0.1997 - mse: 0.1268 - val_loss: 0.7159 - val_accuracy: 0.6289 - val_mae: 0.2440 - val_mse: 0.1622 - lr: 1.0000e-04\n",
            "Epoch 2020/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.7128 - mae: 0.1983 - mse: 0.1234\n",
            "Epoch 2020: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3417 - accuracy: 0.7128 - mae: 0.1983 - mse: 0.1234 - val_loss: 0.7056 - val_accuracy: 0.6299 - val_mae: 0.2426 - val_mse: 0.1599 - lr: 1.0000e-04\n",
            "Epoch 2021/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3163 - accuracy: 0.7285 - mae: 0.1913 - mse: 0.1170\n",
            "Epoch 2021: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 0.3183 - accuracy: 0.7326 - mae: 0.1909 - mse: 0.1165 - val_loss: 0.7158 - val_accuracy: 0.6171 - val_mae: 0.2458 - val_mse: 0.1626 - lr: 1.0000e-04\n",
            "Epoch 2022/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3232 - accuracy: 0.7236 - mae: 0.1947 - mse: 0.1197\n",
            "Epoch 2022: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3232 - accuracy: 0.7206 - mae: 0.1962 - mse: 0.1211 - val_loss: 0.7371 - val_accuracy: 0.6086 - val_mae: 0.2512 - val_mse: 0.1679 - lr: 1.0000e-04\n",
            "Epoch 2023/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3411 - accuracy: 0.7021 - mae: 0.2055 - mse: 0.1301\n",
            "Epoch 2023: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3376 - accuracy: 0.7032 - mae: 0.2053 - mse: 0.1295 - val_loss: 0.7413 - val_accuracy: 0.6043 - val_mae: 0.2525 - val_mse: 0.1690 - lr: 1.0000e-04\n",
            "Epoch 2024/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3331 - accuracy: 0.7075 - mae: 0.2053 - mse: 0.1301\n",
            "Epoch 2024: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3322 - accuracy: 0.7060 - mae: 0.2058 - mse: 0.1307 - val_loss: 0.7287 - val_accuracy: 0.6128 - val_mae: 0.2494 - val_mse: 0.1657 - lr: 1.0000e-04\n",
            "Epoch 2025/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3291 - accuracy: 0.7080 - mae: 0.2006 - mse: 0.1244\n",
            "Epoch 2025: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3301 - accuracy: 0.7055 - mae: 0.2014 - mse: 0.1255 - val_loss: 0.7078 - val_accuracy: 0.6310 - val_mae: 0.2440 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2026/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3490 - accuracy: 0.7114 - mae: 0.1993 - mse: 0.1232\n",
            "Epoch 2026: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3491 - accuracy: 0.7115 - mae: 0.1988 - mse: 0.1227 - val_loss: 0.7056 - val_accuracy: 0.6342 - val_mae: 0.2433 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2027/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3361 - accuracy: 0.7192 - mae: 0.1989 - mse: 0.1212\n",
            "Epoch 2027: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3289 - accuracy: 0.7211 - mae: 0.1980 - mse: 0.1205 - val_loss: 0.7088 - val_accuracy: 0.6321 - val_mae: 0.2437 - val_mse: 0.1599 - lr: 1.0000e-04\n",
            "Epoch 2028/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3332 - accuracy: 0.7217 - mae: 0.1981 - mse: 0.1207\n",
            "Epoch 2028: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3262 - accuracy: 0.7234 - mae: 0.1967 - mse: 0.1196 - val_loss: 0.7044 - val_accuracy: 0.6364 - val_mae: 0.2419 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2029/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3326 - accuracy: 0.7310 - mae: 0.1936 - mse: 0.1167\n",
            "Epoch 2029: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3314 - accuracy: 0.7284 - mae: 0.1945 - mse: 0.1179 - val_loss: 0.6951 - val_accuracy: 0.6460 - val_mae: 0.2389 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2030/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3471 - accuracy: 0.7261 - mae: 0.1929 - mse: 0.1178\n",
            "Epoch 2030: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3437 - accuracy: 0.7298 - mae: 0.1909 - mse: 0.1163 - val_loss: 0.6931 - val_accuracy: 0.6460 - val_mae: 0.2377 - val_mse: 0.1552 - lr: 1.0000e-04\n",
            "Epoch 2031/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3353 - accuracy: 0.7285 - mae: 0.1911 - mse: 0.1164\n",
            "Epoch 2031: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3354 - accuracy: 0.7307 - mae: 0.1904 - mse: 0.1155 - val_loss: 0.7157 - val_accuracy: 0.6374 - val_mae: 0.2428 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 2032/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3215 - accuracy: 0.7153 - mae: 0.1958 - mse: 0.1211\n",
            "Epoch 2032: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3214 - accuracy: 0.7193 - mae: 0.1952 - mse: 0.1200 - val_loss: 0.7502 - val_accuracy: 0.6182 - val_mae: 0.2500 - val_mse: 0.1690 - lr: 1.0000e-04\n",
            "Epoch 2033/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3339 - accuracy: 0.6997 - mae: 0.2042 - mse: 0.1301\n",
            "Epoch 2033: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3281 - accuracy: 0.7028 - mae: 0.2025 - mse: 0.1290 - val_loss: 0.7743 - val_accuracy: 0.6011 - val_mae: 0.2542 - val_mse: 0.1743 - lr: 1.0000e-04\n",
            "Epoch 2034/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3253 - accuracy: 0.6880 - mae: 0.2069 - mse: 0.1350\n",
            "Epoch 2034: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3206 - accuracy: 0.6927 - mae: 0.2053 - mse: 0.1337 - val_loss: 0.7538 - val_accuracy: 0.6128 - val_mae: 0.2490 - val_mse: 0.1694 - lr: 1.0000e-04\n",
            "Epoch 2035/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3064 - accuracy: 0.7227 - mae: 0.1964 - mse: 0.1241\n",
            "Epoch 2035: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3065 - accuracy: 0.7239 - mae: 0.1954 - mse: 0.1233 - val_loss: 0.7195 - val_accuracy: 0.6342 - val_mae: 0.2404 - val_mse: 0.1609 - lr: 1.0000e-04\n",
            "Epoch 2036/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3222 - accuracy: 0.7202 - mae: 0.1918 - mse: 0.1201\n",
            "Epoch 2036: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3236 - accuracy: 0.7183 - mae: 0.1928 - mse: 0.1209 - val_loss: 0.7011 - val_accuracy: 0.6471 - val_mae: 0.2358 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2037/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.7362 - mae: 0.1855 - mse: 0.1145\n",
            "Epoch 2037: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3099 - accuracy: 0.7362 - mae: 0.1855 - mse: 0.1145 - val_loss: 0.6865 - val_accuracy: 0.6503 - val_mae: 0.2326 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2038/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3190 - accuracy: 0.7432 - mae: 0.1827 - mse: 0.1105\n",
            "Epoch 2038: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.3250 - accuracy: 0.7422 - mae: 0.1842 - mse: 0.1116 - val_loss: 0.6888 - val_accuracy: 0.6492 - val_mae: 0.2339 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2039/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.7440 - mae: 0.1852 - mse: 0.1130\n",
            "Epoch 2039: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.3172 - accuracy: 0.7440 - mae: 0.1852 - mse: 0.1130 - val_loss: 0.7059 - val_accuracy: 0.6406 - val_mae: 0.2394 - val_mse: 0.1581 - lr: 1.0000e-04\n",
            "Epoch 2040/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.7330 - mae: 0.1907 - mse: 0.1163\n",
            "Epoch 2040: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3251 - accuracy: 0.7330 - mae: 0.1907 - mse: 0.1163 - val_loss: 0.7186 - val_accuracy: 0.6353 - val_mae: 0.2433 - val_mse: 0.1614 - lr: 1.0000e-04\n",
            "Epoch 2041/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3361 - accuracy: 0.7031 - mae: 0.1995 - mse: 0.1252\n",
            "Epoch 2041: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3351 - accuracy: 0.7087 - mae: 0.1984 - mse: 0.1239 - val_loss: 0.7334 - val_accuracy: 0.6289 - val_mae: 0.2476 - val_mse: 0.1652 - lr: 1.0000e-04\n",
            "Epoch 2042/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.7101 - mae: 0.2031 - mse: 0.1282\n",
            "Epoch 2042: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3398 - accuracy: 0.7101 - mae: 0.2031 - mse: 0.1282 - val_loss: 0.7443 - val_accuracy: 0.6214 - val_mae: 0.2505 - val_mse: 0.1681 - lr: 1.0000e-04\n",
            "Epoch 2043/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.7096 - mae: 0.2012 - mse: 0.1264\n",
            "Epoch 2043: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3228 - accuracy: 0.7096 - mae: 0.2012 - mse: 0.1264 - val_loss: 0.7378 - val_accuracy: 0.6278 - val_mae: 0.2490 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 2044/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3295 - accuracy: 0.7031 - mae: 0.2021 - mse: 0.1267\n",
            "Epoch 2044: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3287 - accuracy: 0.7023 - mae: 0.2030 - mse: 0.1272 - val_loss: 0.7113 - val_accuracy: 0.6364 - val_mae: 0.2428 - val_mse: 0.1605 - lr: 1.0000e-04\n",
            "Epoch 2045/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3278 - accuracy: 0.7139 - mae: 0.1939 - mse: 0.1201\n",
            "Epoch 2045: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3302 - accuracy: 0.7124 - mae: 0.1944 - mse: 0.1208 - val_loss: 0.6917 - val_accuracy: 0.6417 - val_mae: 0.2381 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2046/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.7399 - mae: 0.1860 - mse: 0.1119\n",
            "Epoch 2046: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3204 - accuracy: 0.7399 - mae: 0.1860 - mse: 0.1119 - val_loss: 0.6926 - val_accuracy: 0.6439 - val_mae: 0.2387 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2047/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.7202 - mae: 0.1951 - mse: 0.1192\n",
            "Epoch 2047: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.3448 - accuracy: 0.7202 - mae: 0.1951 - mse: 0.1192 - val_loss: 0.7209 - val_accuracy: 0.6267 - val_mae: 0.2464 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2048/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3332 - accuracy: 0.7031 - mae: 0.2005 - mse: 0.1244\n",
            "Epoch 2048: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3361 - accuracy: 0.7028 - mae: 0.2005 - mse: 0.1246 - val_loss: 0.7668 - val_accuracy: 0.5947 - val_mae: 0.2576 - val_mse: 0.1748 - lr: 1.0000e-04\n",
            "Epoch 2049/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3162 - accuracy: 0.6865 - mae: 0.2100 - mse: 0.1362\n",
            "Epoch 2049: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 211ms/step - loss: 0.3143 - accuracy: 0.6867 - mae: 0.2102 - mse: 0.1361 - val_loss: 0.7865 - val_accuracy: 0.5904 - val_mae: 0.2620 - val_mse: 0.1796 - lr: 1.0000e-04\n",
            "Epoch 2050/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3264 - accuracy: 0.6958 - mae: 0.2088 - mse: 0.1346\n",
            "Epoch 2050: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3208 - accuracy: 0.6968 - mae: 0.2078 - mse: 0.1339 - val_loss: 0.7595 - val_accuracy: 0.6086 - val_mae: 0.2558 - val_mse: 0.1732 - lr: 1.0000e-04\n",
            "Epoch 2051/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3193 - accuracy: 0.6948 - mae: 0.2051 - mse: 0.1295\n",
            "Epoch 2051: val_loss did not improve from 0.68547\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3199 - accuracy: 0.6972 - mae: 0.2044 - mse: 0.1289 - val_loss: 0.7115 - val_accuracy: 0.6289 - val_mae: 0.2444 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 2052/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3101 - accuracy: 0.7222 - mae: 0.1951 - mse: 0.1191\n",
            "Epoch 2052: val_loss improved from 0.68547 to 0.68051, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 1s 465ms/step - loss: 0.3097 - accuracy: 0.7266 - mae: 0.1930 - mse: 0.1173 - val_loss: 0.6805 - val_accuracy: 0.6460 - val_mae: 0.2357 - val_mse: 0.1537 - lr: 1.0000e-04\n",
            "Epoch 2053/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3420 - accuracy: 0.7437 - mae: 0.1880 - mse: 0.1131\n",
            "Epoch 2053: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3364 - accuracy: 0.7495 - mae: 0.1858 - mse: 0.1113 - val_loss: 0.6837 - val_accuracy: 0.6460 - val_mae: 0.2350 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 2054/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3198 - accuracy: 0.7490 - mae: 0.1814 - mse: 0.1084\n",
            "Epoch 2054: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3232 - accuracy: 0.7459 - mae: 0.1831 - mse: 0.1095 - val_loss: 0.7110 - val_accuracy: 0.6353 - val_mae: 0.2403 - val_mse: 0.1602 - lr: 1.0000e-04\n",
            "Epoch 2055/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3366 - accuracy: 0.7188 - mae: 0.1950 - mse: 0.1221\n",
            "Epoch 2055: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3327 - accuracy: 0.7197 - mae: 0.1940 - mse: 0.1214 - val_loss: 0.7503 - val_accuracy: 0.6128 - val_mae: 0.2485 - val_mse: 0.1692 - lr: 1.0000e-04\n",
            "Epoch 2056/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3371 - accuracy: 0.7070 - mae: 0.2019 - mse: 0.1289\n",
            "Epoch 2056: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3370 - accuracy: 0.7078 - mae: 0.2018 - mse: 0.1293 - val_loss: 0.7765 - val_accuracy: 0.6000 - val_mae: 0.2541 - val_mse: 0.1752 - lr: 1.0000e-04\n",
            "Epoch 2057/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3257 - accuracy: 0.6938 - mae: 0.2056 - mse: 0.1330\n",
            "Epoch 2057: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3235 - accuracy: 0.6959 - mae: 0.2046 - mse: 0.1323 - val_loss: 0.7748 - val_accuracy: 0.6064 - val_mae: 0.2542 - val_mse: 0.1748 - lr: 1.0000e-04\n",
            "Epoch 2058/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.7147 - mae: 0.2007 - mse: 0.1280\n",
            "Epoch 2058: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.3130 - accuracy: 0.7147 - mae: 0.2007 - mse: 0.1280 - val_loss: 0.7428 - val_accuracy: 0.6246 - val_mae: 0.2478 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 2059/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3370 - accuracy: 0.7051 - mae: 0.2000 - mse: 0.1266\n",
            "Epoch 2059: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3316 - accuracy: 0.7078 - mae: 0.1987 - mse: 0.1255 - val_loss: 0.7048 - val_accuracy: 0.6439 - val_mae: 0.2394 - val_mse: 0.1581 - lr: 1.0000e-04\n",
            "Epoch 2060/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3143 - accuracy: 0.7451 - mae: 0.1843 - mse: 0.1110\n",
            "Epoch 2060: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3154 - accuracy: 0.7450 - mae: 0.1846 - mse: 0.1111 - val_loss: 0.6853 - val_accuracy: 0.6503 - val_mae: 0.2347 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2061/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.7459 - mae: 0.1854 - mse: 0.1103\n",
            "Epoch 2061: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.3336 - accuracy: 0.7459 - mae: 0.1854 - mse: 0.1103 - val_loss: 0.6919 - val_accuracy: 0.6481 - val_mae: 0.2360 - val_mse: 0.1546 - lr: 1.0000e-04\n",
            "Epoch 2062/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3291 - accuracy: 0.7417 - mae: 0.1853 - mse: 0.1123\n",
            "Epoch 2062: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3252 - accuracy: 0.7450 - mae: 0.1841 - mse: 0.1115 - val_loss: 0.7176 - val_accuracy: 0.6417 - val_mae: 0.2416 - val_mse: 0.1605 - lr: 1.0000e-04\n",
            "Epoch 2063/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3240 - accuracy: 0.7236 - mae: 0.1917 - mse: 0.1178\n",
            "Epoch 2063: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3206 - accuracy: 0.7252 - mae: 0.1907 - mse: 0.1171 - val_loss: 0.7450 - val_accuracy: 0.6278 - val_mae: 0.2471 - val_mse: 0.1666 - lr: 1.0000e-04\n",
            "Epoch 2064/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3339 - accuracy: 0.7100 - mae: 0.1982 - mse: 0.1265\n",
            "Epoch 2064: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3323 - accuracy: 0.7101 - mae: 0.1982 - mse: 0.1260 - val_loss: 0.7572 - val_accuracy: 0.6235 - val_mae: 0.2489 - val_mse: 0.1690 - lr: 1.0000e-04\n",
            "Epoch 2065/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3157 - accuracy: 0.7222 - mae: 0.1966 - mse: 0.1240\n",
            "Epoch 2065: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3135 - accuracy: 0.7216 - mae: 0.1967 - mse: 0.1242 - val_loss: 0.7469 - val_accuracy: 0.6278 - val_mae: 0.2454 - val_mse: 0.1661 - lr: 1.0000e-04\n",
            "Epoch 2066/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3227 - accuracy: 0.7358 - mae: 0.1903 - mse: 0.1202\n",
            "Epoch 2066: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.3236 - accuracy: 0.7317 - mae: 0.1928 - mse: 0.1223 - val_loss: 0.7210 - val_accuracy: 0.6385 - val_mae: 0.2390 - val_mse: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 2067/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3234 - accuracy: 0.7383 - mae: 0.1870 - mse: 0.1152\n",
            "Epoch 2067: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.3243 - accuracy: 0.7399 - mae: 0.1863 - mse: 0.1146 - val_loss: 0.7013 - val_accuracy: 0.6492 - val_mae: 0.2348 - val_mse: 0.1555 - lr: 1.0000e-04\n",
            "Epoch 2068/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3097 - accuracy: 0.7373 - mae: 0.1844 - mse: 0.1125\n",
            "Epoch 2068: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3138 - accuracy: 0.7367 - mae: 0.1850 - mse: 0.1134 - val_loss: 0.7131 - val_accuracy: 0.6342 - val_mae: 0.2387 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 2069/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3350 - accuracy: 0.7229 - mae: 0.1911 - mse: 0.1189\n",
            "Epoch 2069: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3350 - accuracy: 0.7229 - mae: 0.1911 - mse: 0.1189 - val_loss: 0.7394 - val_accuracy: 0.6193 - val_mae: 0.2462 - val_mse: 0.1658 - lr: 1.0000e-04\n",
            "Epoch 2070/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3188 - accuracy: 0.7134 - mae: 0.1983 - mse: 0.1255\n",
            "Epoch 2070: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3197 - accuracy: 0.7106 - mae: 0.1991 - mse: 0.1260 - val_loss: 0.7677 - val_accuracy: 0.6043 - val_mae: 0.2534 - val_mse: 0.1730 - lr: 1.0000e-04\n",
            "Epoch 2071/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.6991 - mae: 0.2032 - mse: 0.1298\n",
            "Epoch 2071: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3298 - accuracy: 0.6991 - mae: 0.2032 - mse: 0.1298 - val_loss: 0.7785 - val_accuracy: 0.5957 - val_mae: 0.2564 - val_mse: 0.1757 - lr: 1.0000e-04\n",
            "Epoch 2072/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3182 - accuracy: 0.6958 - mae: 0.2032 - mse: 0.1308\n",
            "Epoch 2072: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3170 - accuracy: 0.6940 - mae: 0.2039 - mse: 0.1311 - val_loss: 0.7652 - val_accuracy: 0.6043 - val_mae: 0.2533 - val_mse: 0.1724 - lr: 1.0000e-04\n",
            "Epoch 2073/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3264 - accuracy: 0.7114 - mae: 0.2017 - mse: 0.1258\n",
            "Epoch 2073: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3249 - accuracy: 0.7133 - mae: 0.2003 - mse: 0.1248 - val_loss: 0.7387 - val_accuracy: 0.6246 - val_mae: 0.2473 - val_mse: 0.1660 - lr: 1.0000e-04\n",
            "Epoch 2074/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.7110 - mae: 0.1973 - mse: 0.1233\n",
            "Epoch 2074: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3168 - accuracy: 0.7110 - mae: 0.1973 - mse: 0.1233 - val_loss: 0.7165 - val_accuracy: 0.6364 - val_mae: 0.2422 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2075/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3178 - accuracy: 0.7295 - mae: 0.1897 - mse: 0.1150\n",
            "Epoch 2075: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3284 - accuracy: 0.7289 - mae: 0.1909 - mse: 0.1156 - val_loss: 0.6999 - val_accuracy: 0.6406 - val_mae: 0.2385 - val_mse: 0.1567 - lr: 1.0000e-04\n",
            "Epoch 2076/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3225 - accuracy: 0.7437 - mae: 0.1870 - mse: 0.1116\n",
            "Epoch 2076: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3194 - accuracy: 0.7394 - mae: 0.1881 - mse: 0.1129 - val_loss: 0.7087 - val_accuracy: 0.6396 - val_mae: 0.2414 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2077/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3102 - accuracy: 0.7188 - mae: 0.1955 - mse: 0.1195\n",
            "Epoch 2077: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3125 - accuracy: 0.7234 - mae: 0.1938 - mse: 0.1184 - val_loss: 0.7067 - val_accuracy: 0.6396 - val_mae: 0.2410 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 2078/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3164 - accuracy: 0.7251 - mae: 0.1942 - mse: 0.1193\n",
            "Epoch 2078: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3216 - accuracy: 0.7252 - mae: 0.1937 - mse: 0.1189 - val_loss: 0.7329 - val_accuracy: 0.6235 - val_mae: 0.2473 - val_mse: 0.1653 - lr: 1.0000e-04\n",
            "Epoch 2079/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3173 - accuracy: 0.7212 - mae: 0.1965 - mse: 0.1224\n",
            "Epoch 2079: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3164 - accuracy: 0.7211 - mae: 0.1961 - mse: 0.1222 - val_loss: 0.7662 - val_accuracy: 0.5989 - val_mae: 0.2551 - val_mse: 0.1732 - lr: 1.0000e-04\n",
            "Epoch 2080/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3302 - accuracy: 0.6958 - mae: 0.2069 - mse: 0.1336\n",
            "Epoch 2080: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3277 - accuracy: 0.6913 - mae: 0.2087 - mse: 0.1352 - val_loss: 0.7696 - val_accuracy: 0.5947 - val_mae: 0.2561 - val_mse: 0.1739 - lr: 1.0000e-04\n",
            "Epoch 2081/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3274 - accuracy: 0.7031 - mae: 0.2052 - mse: 0.1303\n",
            "Epoch 2081: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3246 - accuracy: 0.7037 - mae: 0.2049 - mse: 0.1299 - val_loss: 0.7405 - val_accuracy: 0.6235 - val_mae: 0.2497 - val_mse: 0.1669 - lr: 1.0000e-04\n",
            "Epoch 2082/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3216 - accuracy: 0.7119 - mae: 0.1979 - mse: 0.1215\n",
            "Epoch 2082: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3216 - accuracy: 0.7115 - mae: 0.1986 - mse: 0.1221 - val_loss: 0.7168 - val_accuracy: 0.6449 - val_mae: 0.2434 - val_mse: 0.1605 - lr: 1.0000e-04\n",
            "Epoch 2083/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3273 - accuracy: 0.7388 - mae: 0.1896 - mse: 0.1145\n",
            "Epoch 2083: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.3259 - accuracy: 0.7353 - mae: 0.1910 - mse: 0.1157 - val_loss: 0.7024 - val_accuracy: 0.6535 - val_mae: 0.2388 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 2084/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3306 - accuracy: 0.7236 - mae: 0.1902 - mse: 0.1150\n",
            "Epoch 2084: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3282 - accuracy: 0.7248 - mae: 0.1892 - mse: 0.1149 - val_loss: 0.6941 - val_accuracy: 0.6535 - val_mae: 0.2363 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Epoch 2085/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3254 - accuracy: 0.7300 - mae: 0.1866 - mse: 0.1129\n",
            "Epoch 2085: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3255 - accuracy: 0.7330 - mae: 0.1856 - mse: 0.1118 - val_loss: 0.7058 - val_accuracy: 0.6471 - val_mae: 0.2386 - val_mse: 0.1571 - lr: 1.0000e-04\n",
            "Epoch 2086/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3412 - accuracy: 0.7339 - mae: 0.1895 - mse: 0.1164\n",
            "Epoch 2086: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3396 - accuracy: 0.7339 - mae: 0.1892 - mse: 0.1161 - val_loss: 0.7463 - val_accuracy: 0.6332 - val_mae: 0.2471 - val_mse: 0.1666 - lr: 1.0000e-04\n",
            "Epoch 2087/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3254 - accuracy: 0.7017 - mae: 0.2032 - mse: 0.1293\n",
            "Epoch 2087: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3258 - accuracy: 0.7037 - mae: 0.2022 - mse: 0.1288 - val_loss: 0.7867 - val_accuracy: 0.6011 - val_mae: 0.2552 - val_mse: 0.1759 - lr: 1.0000e-04\n",
            "Epoch 2088/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3274 - accuracy: 0.6958 - mae: 0.2078 - mse: 0.1361\n",
            "Epoch 2088: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3258 - accuracy: 0.6986 - mae: 0.2063 - mse: 0.1349 - val_loss: 0.7991 - val_accuracy: 0.5968 - val_mae: 0.2572 - val_mse: 0.1784 - lr: 1.0000e-04\n",
            "Epoch 2089/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3267 - accuracy: 0.6914 - mae: 0.2088 - mse: 0.1374\n",
            "Epoch 2089: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3265 - accuracy: 0.6950 - mae: 0.2075 - mse: 0.1365 - val_loss: 0.7755 - val_accuracy: 0.6150 - val_mae: 0.2513 - val_mse: 0.1727 - lr: 1.0000e-04\n",
            "Epoch 2090/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3132 - accuracy: 0.7056 - mae: 0.1982 - mse: 0.1275\n",
            "Epoch 2090: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3128 - accuracy: 0.7037 - mae: 0.1993 - mse: 0.1283 - val_loss: 0.7320 - val_accuracy: 0.6364 - val_mae: 0.2408 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 2091/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3223 - accuracy: 0.7310 - mae: 0.1889 - mse: 0.1184\n",
            "Epoch 2091: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3241 - accuracy: 0.7312 - mae: 0.1890 - mse: 0.1183 - val_loss: 0.7009 - val_accuracy: 0.6492 - val_mae: 0.2328 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2092/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3274 - accuracy: 0.7373 - mae: 0.1848 - mse: 0.1141\n",
            "Epoch 2092: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3250 - accuracy: 0.7376 - mae: 0.1848 - mse: 0.1141 - val_loss: 0.6954 - val_accuracy: 0.6567 - val_mae: 0.2314 - val_mse: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 2093/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3288 - accuracy: 0.7344 - mae: 0.1844 - mse: 0.1122\n",
            "Epoch 2093: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.3282 - accuracy: 0.7339 - mae: 0.1845 - mse: 0.1127 - val_loss: 0.7034 - val_accuracy: 0.6535 - val_mae: 0.2340 - val_mse: 0.1550 - lr: 1.0000e-04\n",
            "Epoch 2094/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3098 - accuracy: 0.7417 - mae: 0.1830 - mse: 0.1112\n",
            "Epoch 2094: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3109 - accuracy: 0.7408 - mae: 0.1832 - mse: 0.1117 - val_loss: 0.7129 - val_accuracy: 0.6439 - val_mae: 0.2372 - val_mse: 0.1577 - lr: 1.0000e-04\n",
            "Epoch 2095/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.7261 - mae: 0.1893 - mse: 0.1164\n",
            "Epoch 2095: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.3252 - accuracy: 0.7261 - mae: 0.1893 - mse: 0.1164 - val_loss: 0.7276 - val_accuracy: 0.6396 - val_mae: 0.2412 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 2096/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3207 - accuracy: 0.7368 - mae: 0.1896 - mse: 0.1172\n",
            "Epoch 2096: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3221 - accuracy: 0.7317 - mae: 0.1911 - mse: 0.1189 - val_loss: 0.7297 - val_accuracy: 0.6364 - val_mae: 0.2427 - val_mse: 0.1627 - lr: 1.0000e-04\n",
            "Epoch 2097/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3175 - accuracy: 0.7217 - mae: 0.1957 - mse: 0.1234\n",
            "Epoch 2097: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3178 - accuracy: 0.7275 - mae: 0.1932 - mse: 0.1209 - val_loss: 0.7268 - val_accuracy: 0.6321 - val_mae: 0.2428 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2098/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.7252 - mae: 0.1933 - mse: 0.1202\n",
            "Epoch 2098: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3211 - accuracy: 0.7252 - mae: 0.1933 - mse: 0.1202 - val_loss: 0.7437 - val_accuracy: 0.6278 - val_mae: 0.2469 - val_mse: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 2099/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.7119 - mae: 0.1994 - mse: 0.1263\n",
            "Epoch 2099: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3213 - accuracy: 0.7119 - mae: 0.1994 - mse: 0.1263 - val_loss: 0.7529 - val_accuracy: 0.6193 - val_mae: 0.2497 - val_mse: 0.1693 - lr: 1.0000e-04\n",
            "Epoch 2100/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.7014 - mae: 0.2007 - mse: 0.1258\n",
            "Epoch 2100: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3147 - accuracy: 0.7014 - mae: 0.2007 - mse: 0.1258 - val_loss: 0.7600 - val_accuracy: 0.6128 - val_mae: 0.2514 - val_mse: 0.1710 - lr: 1.0000e-04\n",
            "Epoch 2101/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3183 - accuracy: 0.6992 - mae: 0.2016 - mse: 0.1284\n",
            "Epoch 2101: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3145 - accuracy: 0.7032 - mae: 0.1999 - mse: 0.1268 - val_loss: 0.7524 - val_accuracy: 0.6193 - val_mae: 0.2493 - val_mse: 0.1689 - lr: 1.0000e-04\n",
            "Epoch 2102/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3075 - accuracy: 0.7124 - mae: 0.1957 - mse: 0.1236\n",
            "Epoch 2102: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3120 - accuracy: 0.7119 - mae: 0.1963 - mse: 0.1237 - val_loss: 0.7372 - val_accuracy: 0.6246 - val_mae: 0.2451 - val_mse: 0.1649 - lr: 1.0000e-04\n",
            "Epoch 2103/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.7225 - mae: 0.1929 - mse: 0.1197\n",
            "Epoch 2103: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3215 - accuracy: 0.7225 - mae: 0.1929 - mse: 0.1197 - val_loss: 0.7352 - val_accuracy: 0.6278 - val_mae: 0.2437 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 2104/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3362 - accuracy: 0.7129 - mae: 0.1979 - mse: 0.1245\n",
            "Epoch 2104: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3346 - accuracy: 0.7142 - mae: 0.1966 - mse: 0.1234 - val_loss: 0.7339 - val_accuracy: 0.6299 - val_mae: 0.2430 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2105/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3165 - accuracy: 0.7358 - mae: 0.1902 - mse: 0.1171\n",
            "Epoch 2105: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.3179 - accuracy: 0.7335 - mae: 0.1912 - mse: 0.1182 - val_loss: 0.7398 - val_accuracy: 0.6257 - val_mae: 0.2445 - val_mse: 0.1650 - lr: 1.0000e-04\n",
            "Epoch 2106/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3265 - accuracy: 0.7236 - mae: 0.1960 - mse: 0.1228\n",
            "Epoch 2106: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3238 - accuracy: 0.7216 - mae: 0.1961 - mse: 0.1236 - val_loss: 0.7334 - val_accuracy: 0.6257 - val_mae: 0.2435 - val_mse: 0.1636 - lr: 1.0000e-04\n",
            "Epoch 2107/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3296 - accuracy: 0.7202 - mae: 0.1926 - mse: 0.1220\n",
            "Epoch 2107: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3285 - accuracy: 0.7211 - mae: 0.1924 - mse: 0.1220 - val_loss: 0.7196 - val_accuracy: 0.6353 - val_mae: 0.2413 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 2108/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3165 - accuracy: 0.7295 - mae: 0.1895 - mse: 0.1164\n",
            "Epoch 2108: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3165 - accuracy: 0.7275 - mae: 0.1903 - mse: 0.1168 - val_loss: 0.7105 - val_accuracy: 0.6417 - val_mae: 0.2399 - val_mse: 0.1589 - lr: 1.0000e-04\n",
            "Epoch 2109/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3369 - accuracy: 0.7373 - mae: 0.1898 - mse: 0.1158\n",
            "Epoch 2109: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3351 - accuracy: 0.7321 - mae: 0.1904 - mse: 0.1166 - val_loss: 0.7108 - val_accuracy: 0.6385 - val_mae: 0.2407 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2110/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3103 - accuracy: 0.7349 - mae: 0.1863 - mse: 0.1122\n",
            "Epoch 2110: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3156 - accuracy: 0.7298 - mae: 0.1889 - mse: 0.1143 - val_loss: 0.7126 - val_accuracy: 0.6364 - val_mae: 0.2413 - val_mse: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 2111/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3205 - accuracy: 0.7329 - mae: 0.1899 - mse: 0.1165\n",
            "Epoch 2111: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3193 - accuracy: 0.7317 - mae: 0.1906 - mse: 0.1168 - val_loss: 0.7197 - val_accuracy: 0.6342 - val_mae: 0.2431 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 2112/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3300 - accuracy: 0.7222 - mae: 0.1947 - mse: 0.1204\n",
            "Epoch 2112: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3267 - accuracy: 0.7239 - mae: 0.1938 - mse: 0.1199 - val_loss: 0.7197 - val_accuracy: 0.6374 - val_mae: 0.2429 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 2113/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3167 - accuracy: 0.7217 - mae: 0.1946 - mse: 0.1206\n",
            "Epoch 2113: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3155 - accuracy: 0.7234 - mae: 0.1941 - mse: 0.1204 - val_loss: 0.7107 - val_accuracy: 0.6439 - val_mae: 0.2403 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2114/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3340 - accuracy: 0.7354 - mae: 0.1892 - mse: 0.1142\n",
            "Epoch 2114: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3317 - accuracy: 0.7339 - mae: 0.1903 - mse: 0.1154 - val_loss: 0.7019 - val_accuracy: 0.6449 - val_mae: 0.2384 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2115/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3358 - accuracy: 0.7251 - mae: 0.1904 - mse: 0.1178\n",
            "Epoch 2115: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3336 - accuracy: 0.7257 - mae: 0.1905 - mse: 0.1183 - val_loss: 0.6950 - val_accuracy: 0.6439 - val_mae: 0.2372 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2116/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3302 - accuracy: 0.7158 - mae: 0.1943 - mse: 0.1201\n",
            "Epoch 2116: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3261 - accuracy: 0.7202 - mae: 0.1917 - mse: 0.1181 - val_loss: 0.6960 - val_accuracy: 0.6449 - val_mae: 0.2375 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2117/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3132 - accuracy: 0.7432 - mae: 0.1855 - mse: 0.1113\n",
            "Epoch 2117: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3126 - accuracy: 0.7413 - mae: 0.1861 - mse: 0.1122 - val_loss: 0.7070 - val_accuracy: 0.6417 - val_mae: 0.2398 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2118/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3303 - accuracy: 0.7319 - mae: 0.1893 - mse: 0.1168\n",
            "Epoch 2118: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3251 - accuracy: 0.7289 - mae: 0.1900 - mse: 0.1170 - val_loss: 0.7099 - val_accuracy: 0.6353 - val_mae: 0.2405 - val_mse: 0.1591 - lr: 1.0000e-04\n",
            "Epoch 2119/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3042 - accuracy: 0.7246 - mae: 0.1893 - mse: 0.1152\n",
            "Epoch 2119: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3044 - accuracy: 0.7280 - mae: 0.1879 - mse: 0.1138 - val_loss: 0.7130 - val_accuracy: 0.6374 - val_mae: 0.2413 - val_mse: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 2120/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3200 - accuracy: 0.7261 - mae: 0.1907 - mse: 0.1172\n",
            "Epoch 2120: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3169 - accuracy: 0.7271 - mae: 0.1905 - mse: 0.1170 - val_loss: 0.7277 - val_accuracy: 0.6321 - val_mae: 0.2444 - val_mse: 0.1632 - lr: 1.0000e-04\n",
            "Epoch 2121/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3102 - accuracy: 0.7173 - mae: 0.1941 - mse: 0.1208\n",
            "Epoch 2121: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 212ms/step - loss: 0.3147 - accuracy: 0.7174 - mae: 0.1945 - mse: 0.1212 - val_loss: 0.7367 - val_accuracy: 0.6246 - val_mae: 0.2457 - val_mse: 0.1650 - lr: 1.0000e-04\n",
            "Epoch 2122/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.7115 - mae: 0.1986 - mse: 0.1245\n",
            "Epoch 2122: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3364 - accuracy: 0.7115 - mae: 0.1986 - mse: 0.1245 - val_loss: 0.7540 - val_accuracy: 0.6160 - val_mae: 0.2494 - val_mse: 0.1691 - lr: 1.0000e-04\n",
            "Epoch 2123/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.7037 - mae: 0.2010 - mse: 0.1279\n",
            "Epoch 2123: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.3235 - accuracy: 0.7037 - mae: 0.2010 - mse: 0.1279 - val_loss: 0.7624 - val_accuracy: 0.6107 - val_mae: 0.2513 - val_mse: 0.1713 - lr: 1.0000e-04\n",
            "Epoch 2124/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.7128 - mae: 0.1981 - mse: 0.1262\n",
            "Epoch 2124: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.3152 - accuracy: 0.7128 - mae: 0.1981 - mse: 0.1262 - val_loss: 0.7593 - val_accuracy: 0.6139 - val_mae: 0.2505 - val_mse: 0.1707 - lr: 1.0000e-04\n",
            "Epoch 2125/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.7133 - mae: 0.1982 - mse: 0.1261\n",
            "Epoch 2125: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.3221 - accuracy: 0.7133 - mae: 0.1982 - mse: 0.1261 - val_loss: 0.7519 - val_accuracy: 0.6128 - val_mae: 0.2486 - val_mse: 0.1689 - lr: 1.0000e-04\n",
            "Epoch 2126/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3241 - accuracy: 0.7070 - mae: 0.1975 - mse: 0.1266\n",
            "Epoch 2126: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3291 - accuracy: 0.7037 - mae: 0.1988 - mse: 0.1276 - val_loss: 0.7489 - val_accuracy: 0.6150 - val_mae: 0.2483 - val_mse: 0.1685 - lr: 1.0000e-04\n",
            "Epoch 2127/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.7028 - mae: 0.2015 - mse: 0.1291\n",
            "Epoch 2127: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3286 - accuracy: 0.7028 - mae: 0.2015 - mse: 0.1291 - val_loss: 0.7366 - val_accuracy: 0.6214 - val_mae: 0.2465 - val_mse: 0.1661 - lr: 1.0000e-04\n",
            "Epoch 2128/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.7106 - mae: 0.1985 - mse: 0.1247\n",
            "Epoch 2128: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3201 - accuracy: 0.7106 - mae: 0.1985 - mse: 0.1247 - val_loss: 0.7098 - val_accuracy: 0.6342 - val_mae: 0.2408 - val_mse: 0.1597 - lr: 1.0000e-04\n",
            "Epoch 2129/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3305 - accuracy: 0.7271 - mae: 0.1918 - mse: 0.1181\n",
            "Epoch 2129: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.3316 - accuracy: 0.7298 - mae: 0.1914 - mse: 0.1177 - val_loss: 0.7003 - val_accuracy: 0.6364 - val_mae: 0.2387 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2130/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.7275 - mae: 0.1885 - mse: 0.1147\n",
            "Epoch 2130: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.3259 - accuracy: 0.7275 - mae: 0.1885 - mse: 0.1147 - val_loss: 0.7081 - val_accuracy: 0.6353 - val_mae: 0.2406 - val_mse: 0.1592 - lr: 1.0000e-04\n",
            "Epoch 2131/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3218 - accuracy: 0.7319 - mae: 0.1908 - mse: 0.1172\n",
            "Epoch 2131: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3234 - accuracy: 0.7289 - mae: 0.1912 - mse: 0.1177 - val_loss: 0.7284 - val_accuracy: 0.6321 - val_mae: 0.2459 - val_mse: 0.1642 - lr: 1.0000e-04\n",
            "Epoch 2132/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3264 - accuracy: 0.7173 - mae: 0.1971 - mse: 0.1222\n",
            "Epoch 2132: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3292 - accuracy: 0.7142 - mae: 0.1986 - mse: 0.1236 - val_loss: 0.7385 - val_accuracy: 0.6257 - val_mae: 0.2484 - val_mse: 0.1665 - lr: 1.0000e-04\n",
            "Epoch 2133/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3123 - accuracy: 0.7134 - mae: 0.2002 - mse: 0.1250\n",
            "Epoch 2133: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3148 - accuracy: 0.7138 - mae: 0.1994 - mse: 0.1241 - val_loss: 0.7401 - val_accuracy: 0.6246 - val_mae: 0.2489 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 2134/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3073 - accuracy: 0.7168 - mae: 0.1951 - mse: 0.1198\n",
            "Epoch 2134: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3080 - accuracy: 0.7138 - mae: 0.1974 - mse: 0.1218 - val_loss: 0.7405 - val_accuracy: 0.6214 - val_mae: 0.2488 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 2135/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3376 - accuracy: 0.7109 - mae: 0.2001 - mse: 0.1246\n",
            "Epoch 2135: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3320 - accuracy: 0.7133 - mae: 0.1993 - mse: 0.1238 - val_loss: 0.7224 - val_accuracy: 0.6289 - val_mae: 0.2441 - val_mse: 0.1623 - lr: 1.0000e-04\n",
            "Epoch 2136/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3339 - accuracy: 0.7222 - mae: 0.1955 - mse: 0.1199\n",
            "Epoch 2136: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3306 - accuracy: 0.7229 - mae: 0.1949 - mse: 0.1193 - val_loss: 0.7080 - val_accuracy: 0.6374 - val_mae: 0.2405 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 2137/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3073 - accuracy: 0.7168 - mae: 0.1931 - mse: 0.1176\n",
            "Epoch 2137: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3066 - accuracy: 0.7170 - mae: 0.1926 - mse: 0.1174 - val_loss: 0.6942 - val_accuracy: 0.6417 - val_mae: 0.2373 - val_mse: 0.1555 - lr: 1.0000e-04\n",
            "Epoch 2138/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3157 - accuracy: 0.7339 - mae: 0.1897 - mse: 0.1145\n",
            "Epoch 2138: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.3171 - accuracy: 0.7372 - mae: 0.1879 - mse: 0.1129 - val_loss: 0.7001 - val_accuracy: 0.6460 - val_mae: 0.2385 - val_mse: 0.1568 - lr: 1.0000e-04\n",
            "Epoch 2139/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3021 - accuracy: 0.7344 - mae: 0.1883 - mse: 0.1148\n",
            "Epoch 2139: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3046 - accuracy: 0.7344 - mae: 0.1886 - mse: 0.1148 - val_loss: 0.7264 - val_accuracy: 0.6246 - val_mae: 0.2435 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2140/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3179 - accuracy: 0.7139 - mae: 0.1956 - mse: 0.1218\n",
            "Epoch 2140: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3127 - accuracy: 0.7147 - mae: 0.1951 - mse: 0.1217 - val_loss: 0.7400 - val_accuracy: 0.6225 - val_mae: 0.2457 - val_mse: 0.1656 - lr: 1.0000e-04\n",
            "Epoch 2141/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3011 - accuracy: 0.7266 - mae: 0.1904 - mse: 0.1175\n",
            "Epoch 2141: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3073 - accuracy: 0.7248 - mae: 0.1919 - mse: 0.1191 - val_loss: 0.7342 - val_accuracy: 0.6342 - val_mae: 0.2438 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 2142/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3220 - accuracy: 0.7124 - mae: 0.1952 - mse: 0.1239\n",
            "Epoch 2142: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3183 - accuracy: 0.7142 - mae: 0.1946 - mse: 0.1235 - val_loss: 0.7337 - val_accuracy: 0.6406 - val_mae: 0.2432 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2143/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3201 - accuracy: 0.7163 - mae: 0.1959 - mse: 0.1226\n",
            "Epoch 2143: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3228 - accuracy: 0.7206 - mae: 0.1946 - mse: 0.1212 - val_loss: 0.7279 - val_accuracy: 0.6471 - val_mae: 0.2415 - val_mse: 0.1618 - lr: 1.0000e-04\n",
            "Epoch 2144/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3212 - accuracy: 0.7231 - mae: 0.1923 - mse: 0.1197\n",
            "Epoch 2144: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.3185 - accuracy: 0.7239 - mae: 0.1924 - mse: 0.1195 - val_loss: 0.7287 - val_accuracy: 0.6406 - val_mae: 0.2421 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 2145/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7378 - mae: 0.1917 - mse: 0.1170\n",
            "Epoch 2145: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3099 - accuracy: 0.7353 - mae: 0.1926 - mse: 0.1183 - val_loss: 0.7182 - val_accuracy: 0.6385 - val_mae: 0.2396 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2146/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3057 - accuracy: 0.7388 - mae: 0.1874 - mse: 0.1152\n",
            "Epoch 2146: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3037 - accuracy: 0.7404 - mae: 0.1866 - mse: 0.1142 - val_loss: 0.7075 - val_accuracy: 0.6449 - val_mae: 0.2366 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 2147/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3203 - accuracy: 0.7378 - mae: 0.1862 - mse: 0.1143\n",
            "Epoch 2147: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3207 - accuracy: 0.7372 - mae: 0.1862 - mse: 0.1146 - val_loss: 0.7026 - val_accuracy: 0.6492 - val_mae: 0.2350 - val_mse: 0.1549 - lr: 1.0000e-04\n",
            "Epoch 2148/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.7486 - mae: 0.1844 - mse: 0.1125\n",
            "Epoch 2148: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 0.3367 - accuracy: 0.7486 - mae: 0.1844 - mse: 0.1125 - val_loss: 0.7151 - val_accuracy: 0.6439 - val_mae: 0.2380 - val_mse: 0.1580 - lr: 1.0000e-04\n",
            "Epoch 2149/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3222 - accuracy: 0.7378 - mae: 0.1893 - mse: 0.1174\n",
            "Epoch 2149: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3207 - accuracy: 0.7385 - mae: 0.1890 - mse: 0.1173 - val_loss: 0.7317 - val_accuracy: 0.6417 - val_mae: 0.2415 - val_mse: 0.1620 - lr: 1.0000e-04\n",
            "Epoch 2150/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.7376 - mae: 0.1867 - mse: 0.1166\n",
            "Epoch 2150: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3065 - accuracy: 0.7376 - mae: 0.1867 - mse: 0.1166 - val_loss: 0.7286 - val_accuracy: 0.6481 - val_mae: 0.2398 - val_mse: 0.1611 - lr: 1.0000e-04\n",
            "Epoch 2151/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.7427 - mae: 0.1871 - mse: 0.1164\n",
            "Epoch 2151: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.3259 - accuracy: 0.7427 - mae: 0.1871 - mse: 0.1164 - val_loss: 0.7187 - val_accuracy: 0.6524 - val_mae: 0.2367 - val_mse: 0.1586 - lr: 1.0000e-04\n",
            "Epoch 2152/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.7450 - mae: 0.1847 - mse: 0.1138\n",
            "Epoch 2152: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3203 - accuracy: 0.7450 - mae: 0.1847 - mse: 0.1138 - val_loss: 0.7189 - val_accuracy: 0.6545 - val_mae: 0.2363 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2153/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.7482 - mae: 0.1830 - mse: 0.1127\n",
            "Epoch 2153: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3090 - accuracy: 0.7482 - mae: 0.1830 - mse: 0.1127 - val_loss: 0.7292 - val_accuracy: 0.6535 - val_mae: 0.2382 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2154/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.7284 - mae: 0.1907 - mse: 0.1200\n",
            "Epoch 2154: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3335 - accuracy: 0.7284 - mae: 0.1907 - mse: 0.1200 - val_loss: 0.7446 - val_accuracy: 0.6364 - val_mae: 0.2428 - val_mse: 0.1648 - lr: 1.0000e-04\n",
            "Epoch 2155/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3253 - accuracy: 0.7271 - mae: 0.1923 - mse: 0.1212\n",
            "Epoch 2155: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.3221 - accuracy: 0.7307 - mae: 0.1908 - mse: 0.1195 - val_loss: 0.7460 - val_accuracy: 0.6342 - val_mae: 0.2446 - val_mse: 0.1659 - lr: 1.0000e-04\n",
            "Epoch 2156/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3133 - accuracy: 0.7188 - mae: 0.1944 - mse: 0.1223\n",
            "Epoch 2156: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3148 - accuracy: 0.7179 - mae: 0.1946 - mse: 0.1228 - val_loss: 0.7479 - val_accuracy: 0.6321 - val_mae: 0.2460 - val_mse: 0.1668 - lr: 1.0000e-04\n",
            "Epoch 2157/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.7188 - mae: 0.1931 - mse: 0.1214\n",
            "Epoch 2157: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3156 - accuracy: 0.7188 - mae: 0.1931 - mse: 0.1214 - val_loss: 0.7433 - val_accuracy: 0.6299 - val_mae: 0.2457 - val_mse: 0.1660 - lr: 1.0000e-04\n",
            "Epoch 2158/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3208 - accuracy: 0.7109 - mae: 0.1988 - mse: 0.1248\n",
            "Epoch 2158: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3211 - accuracy: 0.7110 - mae: 0.1982 - mse: 0.1246 - val_loss: 0.7392 - val_accuracy: 0.6374 - val_mae: 0.2448 - val_mse: 0.1649 - lr: 1.0000e-04\n",
            "Epoch 2159/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3150 - accuracy: 0.7241 - mae: 0.1956 - mse: 0.1222\n",
            "Epoch 2159: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3173 - accuracy: 0.7202 - mae: 0.1974 - mse: 0.1236 - val_loss: 0.7325 - val_accuracy: 0.6406 - val_mae: 0.2429 - val_mse: 0.1631 - lr: 1.0000e-04\n",
            "Epoch 2160/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3243 - accuracy: 0.7227 - mae: 0.1934 - mse: 0.1206\n",
            "Epoch 2160: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3247 - accuracy: 0.7261 - mae: 0.1926 - mse: 0.1194 - val_loss: 0.7230 - val_accuracy: 0.6428 - val_mae: 0.2409 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2161/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3107 - accuracy: 0.7261 - mae: 0.1905 - mse: 0.1170\n",
            "Epoch 2161: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3065 - accuracy: 0.7248 - mae: 0.1908 - mse: 0.1175 - val_loss: 0.7093 - val_accuracy: 0.6513 - val_mae: 0.2379 - val_mse: 0.1579 - lr: 1.0000e-04\n",
            "Epoch 2162/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3281 - accuracy: 0.7251 - mae: 0.1902 - mse: 0.1168\n",
            "Epoch 2162: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3276 - accuracy: 0.7266 - mae: 0.1904 - mse: 0.1167 - val_loss: 0.6906 - val_accuracy: 0.6524 - val_mae: 0.2339 - val_mse: 0.1537 - lr: 1.0000e-04\n",
            "Epoch 2163/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3041 - accuracy: 0.7490 - mae: 0.1817 - mse: 0.1083\n",
            "Epoch 2163: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2998 - accuracy: 0.7514 - mae: 0.1807 - mse: 0.1076 - val_loss: 0.6882 - val_accuracy: 0.6524 - val_mae: 0.2335 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2164/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3049 - accuracy: 0.7266 - mae: 0.1846 - mse: 0.1112\n",
            "Epoch 2164: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3109 - accuracy: 0.7257 - mae: 0.1861 - mse: 0.1126 - val_loss: 0.6874 - val_accuracy: 0.6481 - val_mae: 0.2327 - val_mse: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 2165/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3222 - accuracy: 0.7485 - mae: 0.1836 - mse: 0.1103\n",
            "Epoch 2165: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3209 - accuracy: 0.7477 - mae: 0.1829 - mse: 0.1096 - val_loss: 0.7019 - val_accuracy: 0.6439 - val_mae: 0.2355 - val_mse: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 2166/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3099 - accuracy: 0.7368 - mae: 0.1855 - mse: 0.1140\n",
            "Epoch 2166: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3112 - accuracy: 0.7390 - mae: 0.1851 - mse: 0.1136 - val_loss: 0.7251 - val_accuracy: 0.6342 - val_mae: 0.2406 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 2167/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3137 - accuracy: 0.7163 - mae: 0.1922 - mse: 0.1192\n",
            "Epoch 2167: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3160 - accuracy: 0.7170 - mae: 0.1927 - mse: 0.1196 - val_loss: 0.7438 - val_accuracy: 0.6278 - val_mae: 0.2446 - val_mse: 0.1662 - lr: 1.0000e-04\n",
            "Epoch 2168/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3337 - accuracy: 0.7070 - mae: 0.1997 - mse: 0.1273\n",
            "Epoch 2168: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3305 - accuracy: 0.7069 - mae: 0.1993 - mse: 0.1272 - val_loss: 0.7513 - val_accuracy: 0.6267 - val_mae: 0.2461 - val_mse: 0.1679 - lr: 1.0000e-04\n",
            "Epoch 2169/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3120 - accuracy: 0.7134 - mae: 0.1959 - mse: 0.1236\n",
            "Epoch 2169: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3128 - accuracy: 0.7165 - mae: 0.1947 - mse: 0.1228 - val_loss: 0.7498 - val_accuracy: 0.6278 - val_mae: 0.2457 - val_mse: 0.1674 - lr: 1.0000e-04\n",
            "Epoch 2170/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3131 - accuracy: 0.6982 - mae: 0.2015 - mse: 0.1286\n",
            "Epoch 2170: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3126 - accuracy: 0.7060 - mae: 0.1980 - mse: 0.1256 - val_loss: 0.7582 - val_accuracy: 0.6278 - val_mae: 0.2475 - val_mse: 0.1691 - lr: 1.0000e-04\n",
            "Epoch 2171/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3360 - accuracy: 0.7036 - mae: 0.2011 - mse: 0.1298\n",
            "Epoch 2171: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.3336 - accuracy: 0.7032 - mae: 0.2013 - mse: 0.1298 - val_loss: 0.7659 - val_accuracy: 0.6182 - val_mae: 0.2495 - val_mse: 0.1711 - lr: 1.0000e-04\n",
            "Epoch 2172/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3306 - accuracy: 0.7114 - mae: 0.1997 - mse: 0.1287\n",
            "Epoch 2172: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3314 - accuracy: 0.7101 - mae: 0.1997 - mse: 0.1288 - val_loss: 0.7480 - val_accuracy: 0.6257 - val_mae: 0.2459 - val_mse: 0.1671 - lr: 1.0000e-04\n",
            "Epoch 2173/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3182 - accuracy: 0.7100 - mae: 0.1968 - mse: 0.1259\n",
            "Epoch 2173: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3227 - accuracy: 0.7073 - mae: 0.1977 - mse: 0.1265 - val_loss: 0.7233 - val_accuracy: 0.6439 - val_mae: 0.2410 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 2174/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3038 - accuracy: 0.7417 - mae: 0.1866 - mse: 0.1153\n",
            "Epoch 2174: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3084 - accuracy: 0.7413 - mae: 0.1871 - mse: 0.1155 - val_loss: 0.7127 - val_accuracy: 0.6503 - val_mae: 0.2389 - val_mse: 0.1589 - lr: 1.0000e-04\n",
            "Epoch 2175/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3197 - accuracy: 0.7354 - mae: 0.1875 - mse: 0.1156\n",
            "Epoch 2175: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3210 - accuracy: 0.7335 - mae: 0.1888 - mse: 0.1167 - val_loss: 0.7194 - val_accuracy: 0.6471 - val_mae: 0.2401 - val_mse: 0.1602 - lr: 1.0000e-04\n",
            "Epoch 2176/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3097 - accuracy: 0.7314 - mae: 0.1904 - mse: 0.1177\n",
            "Epoch 2176: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3097 - accuracy: 0.7339 - mae: 0.1892 - mse: 0.1168 - val_loss: 0.7226 - val_accuracy: 0.6449 - val_mae: 0.2403 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 2177/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3289 - accuracy: 0.7212 - mae: 0.1935 - mse: 0.1208\n",
            "Epoch 2177: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3248 - accuracy: 0.7206 - mae: 0.1935 - mse: 0.1207 - val_loss: 0.7228 - val_accuracy: 0.6439 - val_mae: 0.2402 - val_mse: 0.1609 - lr: 1.0000e-04\n",
            "Epoch 2178/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.7303 - mae: 0.1896 - mse: 0.1182\n",
            "Epoch 2178: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3142 - accuracy: 0.7303 - mae: 0.1896 - mse: 0.1182 - val_loss: 0.7111 - val_accuracy: 0.6503 - val_mae: 0.2375 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2179/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3063 - accuracy: 0.7353 - mae: 0.1864 - mse: 0.1152\n",
            "Epoch 2179: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3063 - accuracy: 0.7353 - mae: 0.1864 - mse: 0.1152 - val_loss: 0.7133 - val_accuracy: 0.6503 - val_mae: 0.2372 - val_mse: 0.1587 - lr: 1.0000e-04\n",
            "Epoch 2180/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.7188 - mae: 0.1916 - mse: 0.1205\n",
            "Epoch 2180: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3266 - accuracy: 0.7188 - mae: 0.1916 - mse: 0.1205 - val_loss: 0.7390 - val_accuracy: 0.6342 - val_mae: 0.2426 - val_mse: 0.1645 - lr: 1.0000e-04\n",
            "Epoch 2181/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3136 - accuracy: 0.7148 - mae: 0.1955 - mse: 0.1257\n",
            "Epoch 2181: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3180 - accuracy: 0.7106 - mae: 0.1973 - mse: 0.1269 - val_loss: 0.7718 - val_accuracy: 0.6139 - val_mae: 0.2500 - val_mse: 0.1718 - lr: 1.0000e-04\n",
            "Epoch 2182/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3055 - accuracy: 0.7109 - mae: 0.1972 - mse: 0.1278\n",
            "Epoch 2182: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3111 - accuracy: 0.7110 - mae: 0.1980 - mse: 0.1286 - val_loss: 0.7739 - val_accuracy: 0.6203 - val_mae: 0.2499 - val_mse: 0.1719 - lr: 1.0000e-04\n",
            "Epoch 2183/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.7106 - mae: 0.2011 - mse: 0.1301\n",
            "Epoch 2183: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.3285 - accuracy: 0.7106 - mae: 0.2011 - mse: 0.1301 - val_loss: 0.7543 - val_accuracy: 0.6278 - val_mae: 0.2453 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 2184/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.7115 - mae: 0.1960 - mse: 0.1250\n",
            "Epoch 2184: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3213 - accuracy: 0.7115 - mae: 0.1960 - mse: 0.1250 - val_loss: 0.7296 - val_accuracy: 0.6385 - val_mae: 0.2403 - val_mse: 0.1618 - lr: 1.0000e-04\n",
            "Epoch 2185/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.7326 - mae: 0.1882 - mse: 0.1169\n",
            "Epoch 2185: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.3106 - accuracy: 0.7326 - mae: 0.1882 - mse: 0.1169 - val_loss: 0.7233 - val_accuracy: 0.6321 - val_mae: 0.2396 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 2186/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.7317 - mae: 0.1887 - mse: 0.1171\n",
            "Epoch 2186: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3216 - accuracy: 0.7317 - mae: 0.1887 - mse: 0.1171 - val_loss: 0.7209 - val_accuracy: 0.6364 - val_mae: 0.2395 - val_mse: 0.1601 - lr: 1.0000e-04\n",
            "Epoch 2187/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3285 - accuracy: 0.7295 - mae: 0.1896 - mse: 0.1173\n",
            "Epoch 2187: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3272 - accuracy: 0.7280 - mae: 0.1898 - mse: 0.1175 - val_loss: 0.7144 - val_accuracy: 0.6374 - val_mae: 0.2391 - val_mse: 0.1590 - lr: 1.0000e-04\n",
            "Epoch 2188/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3161 - accuracy: 0.7412 - mae: 0.1850 - mse: 0.1137\n",
            "Epoch 2188: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3115 - accuracy: 0.7431 - mae: 0.1838 - mse: 0.1126 - val_loss: 0.7037 - val_accuracy: 0.6364 - val_mae: 0.2383 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2189/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3154 - accuracy: 0.7427 - mae: 0.1865 - mse: 0.1133\n",
            "Epoch 2189: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3196 - accuracy: 0.7445 - mae: 0.1861 - mse: 0.1131 - val_loss: 0.7150 - val_accuracy: 0.6289 - val_mae: 0.2414 - val_mse: 0.1602 - lr: 1.0000e-04\n",
            "Epoch 2190/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3163 - accuracy: 0.7319 - mae: 0.1905 - mse: 0.1176\n",
            "Epoch 2190: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.3148 - accuracy: 0.7349 - mae: 0.1896 - mse: 0.1169 - val_loss: 0.7493 - val_accuracy: 0.6235 - val_mae: 0.2487 - val_mse: 0.1681 - lr: 1.0000e-04\n",
            "Epoch 2191/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3234 - accuracy: 0.7061 - mae: 0.2008 - mse: 0.1266\n",
            "Epoch 2191: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3244 - accuracy: 0.7078 - mae: 0.2006 - mse: 0.1265 - val_loss: 0.7699 - val_accuracy: 0.6118 - val_mae: 0.2531 - val_mse: 0.1729 - lr: 1.0000e-04\n",
            "Epoch 2192/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3152 - accuracy: 0.7095 - mae: 0.2003 - mse: 0.1270\n",
            "Epoch 2192: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3159 - accuracy: 0.7073 - mae: 0.2018 - mse: 0.1285 - val_loss: 0.7653 - val_accuracy: 0.6011 - val_mae: 0.2526 - val_mse: 0.1721 - lr: 1.0000e-04\n",
            "Epoch 2193/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3123 - accuracy: 0.7046 - mae: 0.1983 - mse: 0.1267\n",
            "Epoch 2193: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3163 - accuracy: 0.7037 - mae: 0.1992 - mse: 0.1273 - val_loss: 0.7479 - val_accuracy: 0.6107 - val_mae: 0.2486 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 2194/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3119 - accuracy: 0.7202 - mae: 0.1950 - mse: 0.1228\n",
            "Epoch 2194: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3116 - accuracy: 0.7193 - mae: 0.1950 - mse: 0.1229 - val_loss: 0.7312 - val_accuracy: 0.6299 - val_mae: 0.2442 - val_mse: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 2195/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3178 - accuracy: 0.7095 - mae: 0.1942 - mse: 0.1211\n",
            "Epoch 2195: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3180 - accuracy: 0.7106 - mae: 0.1936 - mse: 0.1208 - val_loss: 0.7106 - val_accuracy: 0.6396 - val_mae: 0.2384 - val_mse: 0.1583 - lr: 1.0000e-04\n",
            "Epoch 2196/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3050 - accuracy: 0.7441 - mae: 0.1827 - mse: 0.1114\n",
            "Epoch 2196: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3048 - accuracy: 0.7413 - mae: 0.1837 - mse: 0.1117 - val_loss: 0.6972 - val_accuracy: 0.6492 - val_mae: 0.2342 - val_mse: 0.1547 - lr: 1.0000e-04\n",
            "Epoch 2197/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3015 - accuracy: 0.7466 - mae: 0.1807 - mse: 0.1090\n",
            "Epoch 2197: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3022 - accuracy: 0.7417 - mae: 0.1829 - mse: 0.1105 - val_loss: 0.6909 - val_accuracy: 0.6535 - val_mae: 0.2318 - val_mse: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 2198/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3122 - accuracy: 0.7393 - mae: 0.1829 - mse: 0.1116\n",
            "Epoch 2198: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3131 - accuracy: 0.7422 - mae: 0.1815 - mse: 0.1106 - val_loss: 0.6940 - val_accuracy: 0.6545 - val_mae: 0.2320 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2199/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3026 - accuracy: 0.7412 - mae: 0.1811 - mse: 0.1103\n",
            "Epoch 2199: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3056 - accuracy: 0.7417 - mae: 0.1811 - mse: 0.1103 - val_loss: 0.7184 - val_accuracy: 0.6439 - val_mae: 0.2380 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2200/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3154 - accuracy: 0.7324 - mae: 0.1885 - mse: 0.1161\n",
            "Epoch 2200: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3174 - accuracy: 0.7312 - mae: 0.1890 - mse: 0.1170 - val_loss: 0.7440 - val_accuracy: 0.6364 - val_mae: 0.2442 - val_mse: 0.1654 - lr: 1.0000e-04\n",
            "Epoch 2201/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3044 - accuracy: 0.7285 - mae: 0.1912 - mse: 0.1189\n",
            "Epoch 2201: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3044 - accuracy: 0.7266 - mae: 0.1923 - mse: 0.1200 - val_loss: 0.7502 - val_accuracy: 0.6278 - val_mae: 0.2461 - val_mse: 0.1671 - lr: 1.0000e-04\n",
            "Epoch 2202/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3244 - accuracy: 0.7183 - mae: 0.1973 - mse: 0.1254\n",
            "Epoch 2202: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3227 - accuracy: 0.7193 - mae: 0.1963 - mse: 0.1244 - val_loss: 0.7364 - val_accuracy: 0.6321 - val_mae: 0.2434 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 2203/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3197 - accuracy: 0.7222 - mae: 0.1953 - mse: 0.1215\n",
            "Epoch 2203: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3194 - accuracy: 0.7216 - mae: 0.1954 - mse: 0.1216 - val_loss: 0.7308 - val_accuracy: 0.6278 - val_mae: 0.2421 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2204/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3268 - accuracy: 0.7266 - mae: 0.1898 - mse: 0.1186\n",
            "Epoch 2204: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3211 - accuracy: 0.7298 - mae: 0.1881 - mse: 0.1171 - val_loss: 0.7242 - val_accuracy: 0.6364 - val_mae: 0.2410 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2205/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.7349 - mae: 0.1871 - mse: 0.1160\n",
            "Epoch 2205: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.3078 - accuracy: 0.7349 - mae: 0.1871 - mse: 0.1160 - val_loss: 0.7080 - val_accuracy: 0.6332 - val_mae: 0.2380 - val_mse: 0.1575 - lr: 1.0000e-04\n",
            "Epoch 2206/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.7385 - mae: 0.1862 - mse: 0.1135\n",
            "Epoch 2206: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3173 - accuracy: 0.7385 - mae: 0.1862 - mse: 0.1135 - val_loss: 0.7008 - val_accuracy: 0.6374 - val_mae: 0.2370 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2207/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.7344 - mae: 0.1847 - mse: 0.1117\n",
            "Epoch 2207: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3231 - accuracy: 0.7344 - mae: 0.1847 - mse: 0.1117 - val_loss: 0.7125 - val_accuracy: 0.6332 - val_mae: 0.2397 - val_mse: 0.1590 - lr: 1.0000e-04\n",
            "Epoch 2208/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3115 - accuracy: 0.7378 - mae: 0.1869 - mse: 0.1141\n",
            "Epoch 2208: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3098 - accuracy: 0.7399 - mae: 0.1860 - mse: 0.1136 - val_loss: 0.7185 - val_accuracy: 0.6460 - val_mae: 0.2400 - val_mse: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 2209/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3004 - accuracy: 0.7363 - mae: 0.1844 - mse: 0.1122\n",
            "Epoch 2209: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3024 - accuracy: 0.7339 - mae: 0.1859 - mse: 0.1138 - val_loss: 0.7260 - val_accuracy: 0.6428 - val_mae: 0.2407 - val_mse: 0.1614 - lr: 1.0000e-04\n",
            "Epoch 2210/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3290 - accuracy: 0.7183 - mae: 0.1934 - mse: 0.1210\n",
            "Epoch 2210: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3245 - accuracy: 0.7202 - mae: 0.1921 - mse: 0.1201 - val_loss: 0.7302 - val_accuracy: 0.6332 - val_mae: 0.2416 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2211/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.7362 - mae: 0.1882 - mse: 0.1166\n",
            "Epoch 2211: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3201 - accuracy: 0.7362 - mae: 0.1882 - mse: 0.1166 - val_loss: 0.7374 - val_accuracy: 0.6342 - val_mae: 0.2432 - val_mse: 0.1642 - lr: 1.0000e-04\n",
            "Epoch 2212/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7144 - mae: 0.1938 - mse: 0.1229\n",
            "Epoch 2212: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3062 - accuracy: 0.7156 - mae: 0.1928 - mse: 0.1216 - val_loss: 0.7455 - val_accuracy: 0.6225 - val_mae: 0.2449 - val_mse: 0.1659 - lr: 1.0000e-04\n",
            "Epoch 2213/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3138 - accuracy: 0.7188 - mae: 0.1942 - mse: 0.1226\n",
            "Epoch 2213: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 0.3133 - accuracy: 0.7206 - mae: 0.1936 - mse: 0.1216 - val_loss: 0.7555 - val_accuracy: 0.6203 - val_mae: 0.2466 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 2214/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3187 - accuracy: 0.7158 - mae: 0.1980 - mse: 0.1271\n",
            "Epoch 2214: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 0.3209 - accuracy: 0.7179 - mae: 0.1977 - mse: 0.1269 - val_loss: 0.7607 - val_accuracy: 0.6182 - val_mae: 0.2478 - val_mse: 0.1692 - lr: 1.0000e-04\n",
            "Epoch 2215/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3068 - accuracy: 0.7178 - mae: 0.1949 - mse: 0.1247\n",
            "Epoch 2215: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3038 - accuracy: 0.7193 - mae: 0.1935 - mse: 0.1234 - val_loss: 0.7541 - val_accuracy: 0.6278 - val_mae: 0.2459 - val_mse: 0.1676 - lr: 1.0000e-04\n",
            "Epoch 2216/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3071 - accuracy: 0.7363 - mae: 0.1894 - mse: 0.1191\n",
            "Epoch 2216: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3081 - accuracy: 0.7339 - mae: 0.1907 - mse: 0.1203 - val_loss: 0.7353 - val_accuracy: 0.6396 - val_mae: 0.2409 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2217/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3184 - accuracy: 0.7300 - mae: 0.1889 - mse: 0.1196\n",
            "Epoch 2217: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3168 - accuracy: 0.7317 - mae: 0.1881 - mse: 0.1188 - val_loss: 0.7125 - val_accuracy: 0.6481 - val_mae: 0.2355 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2218/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7437 - mae: 0.1801 - mse: 0.1096\n",
            "Epoch 2218: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3057 - accuracy: 0.7468 - mae: 0.1792 - mse: 0.1089 - val_loss: 0.7053 - val_accuracy: 0.6524 - val_mae: 0.2338 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2219/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3191 - accuracy: 0.7456 - mae: 0.1825 - mse: 0.1118\n",
            "Epoch 2219: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3215 - accuracy: 0.7431 - mae: 0.1832 - mse: 0.1124 - val_loss: 0.7129 - val_accuracy: 0.6449 - val_mae: 0.2363 - val_mse: 0.1577 - lr: 1.0000e-04\n",
            "Epoch 2220/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3105 - accuracy: 0.7310 - mae: 0.1872 - mse: 0.1159\n",
            "Epoch 2220: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3099 - accuracy: 0.7317 - mae: 0.1870 - mse: 0.1156 - val_loss: 0.7311 - val_accuracy: 0.6332 - val_mae: 0.2419 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2221/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3385 - accuracy: 0.7139 - mae: 0.1951 - mse: 0.1236\n",
            "Epoch 2221: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3399 - accuracy: 0.7124 - mae: 0.1959 - mse: 0.1242 - val_loss: 0.7516 - val_accuracy: 0.6225 - val_mae: 0.2485 - val_mse: 0.1681 - lr: 1.0000e-04\n",
            "Epoch 2222/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3033 - accuracy: 0.7153 - mae: 0.1967 - mse: 0.1239\n",
            "Epoch 2222: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3006 - accuracy: 0.7151 - mae: 0.1966 - mse: 0.1237 - val_loss: 0.7536 - val_accuracy: 0.6107 - val_mae: 0.2502 - val_mse: 0.1688 - lr: 1.0000e-04\n",
            "Epoch 2223/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2974 - accuracy: 0.7300 - mae: 0.1929 - mse: 0.1194\n",
            "Epoch 2223: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2972 - accuracy: 0.7339 - mae: 0.1913 - mse: 0.1182 - val_loss: 0.7347 - val_accuracy: 0.6203 - val_mae: 0.2459 - val_mse: 0.1642 - lr: 1.0000e-04\n",
            "Epoch 2224/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3246 - accuracy: 0.7251 - mae: 0.1925 - mse: 0.1190\n",
            "Epoch 2224: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3222 - accuracy: 0.7234 - mae: 0.1928 - mse: 0.1190 - val_loss: 0.7302 - val_accuracy: 0.6246 - val_mae: 0.2441 - val_mse: 0.1630 - lr: 1.0000e-04\n",
            "Epoch 2225/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3088 - accuracy: 0.7227 - mae: 0.1910 - mse: 0.1180\n",
            "Epoch 2225: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3073 - accuracy: 0.7257 - mae: 0.1898 - mse: 0.1170 - val_loss: 0.7227 - val_accuracy: 0.6332 - val_mae: 0.2415 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2226/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3115 - accuracy: 0.7354 - mae: 0.1884 - mse: 0.1163\n",
            "Epoch 2226: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3099 - accuracy: 0.7381 - mae: 0.1880 - mse: 0.1157 - val_loss: 0.7161 - val_accuracy: 0.6417 - val_mae: 0.2394 - val_mse: 0.1592 - lr: 1.0000e-04\n",
            "Epoch 2227/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3136 - accuracy: 0.7266 - mae: 0.1915 - mse: 0.1192\n",
            "Epoch 2227: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3089 - accuracy: 0.7330 - mae: 0.1885 - mse: 0.1166 - val_loss: 0.7096 - val_accuracy: 0.6503 - val_mae: 0.2371 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2228/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3185 - accuracy: 0.7490 - mae: 0.1858 - mse: 0.1134\n",
            "Epoch 2228: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3174 - accuracy: 0.7472 - mae: 0.1865 - mse: 0.1141 - val_loss: 0.7082 - val_accuracy: 0.6503 - val_mae: 0.2361 - val_mse: 0.1568 - lr: 1.0000e-04\n",
            "Epoch 2229/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3002 - accuracy: 0.7446 - mae: 0.1810 - mse: 0.1107\n",
            "Epoch 2229: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.3001 - accuracy: 0.7454 - mae: 0.1811 - mse: 0.1105 - val_loss: 0.7021 - val_accuracy: 0.6513 - val_mae: 0.2339 - val_mse: 0.1552 - lr: 1.0000e-04\n",
            "Epoch 2230/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2969 - accuracy: 0.7461 - mae: 0.1828 - mse: 0.1130\n",
            "Epoch 2230: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2922 - accuracy: 0.7486 - mae: 0.1805 - mse: 0.1115 - val_loss: 0.6931 - val_accuracy: 0.6642 - val_mae: 0.2308 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2231/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3240 - accuracy: 0.7422 - mae: 0.1823 - mse: 0.1114\n",
            "Epoch 2231: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3217 - accuracy: 0.7427 - mae: 0.1823 - mse: 0.1115 - val_loss: 0.6954 - val_accuracy: 0.6567 - val_mae: 0.2307 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2232/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3109 - accuracy: 0.7500 - mae: 0.1782 - mse: 0.1082\n",
            "Epoch 2232: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 212ms/step - loss: 0.3146 - accuracy: 0.7509 - mae: 0.1779 - mse: 0.1082 - val_loss: 0.7141 - val_accuracy: 0.6364 - val_mae: 0.2348 - val_mse: 0.1574 - lr: 1.0000e-04\n",
            "Epoch 2233/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3259 - accuracy: 0.7329 - mae: 0.1879 - mse: 0.1167\n",
            "Epoch 2233: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3234 - accuracy: 0.7335 - mae: 0.1876 - mse: 0.1166 - val_loss: 0.7501 - val_accuracy: 0.6257 - val_mae: 0.2442 - val_mse: 0.1662 - lr: 1.0000e-04\n",
            "Epoch 2234/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.7206 - mae: 0.1945 - mse: 0.1265\n",
            "Epoch 2234: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3204 - accuracy: 0.7206 - mae: 0.1945 - mse: 0.1265 - val_loss: 0.7543 - val_accuracy: 0.6214 - val_mae: 0.2465 - val_mse: 0.1676 - lr: 1.0000e-04\n",
            "Epoch 2235/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3224 - accuracy: 0.7109 - mae: 0.1958 - mse: 0.1252\n",
            "Epoch 2235: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.3206 - accuracy: 0.7115 - mae: 0.1962 - mse: 0.1255 - val_loss: 0.7263 - val_accuracy: 0.6481 - val_mae: 0.2406 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2236/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.7372 - mae: 0.1872 - mse: 0.1140\n",
            "Epoch 2236: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.3117 - accuracy: 0.7372 - mae: 0.1872 - mse: 0.1140 - val_loss: 0.7053 - val_accuracy: 0.6642 - val_mae: 0.2348 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2237/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.7537 - mae: 0.1802 - mse: 0.1082\n",
            "Epoch 2237: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 221ms/step - loss: 0.3069 - accuracy: 0.7537 - mae: 0.1802 - mse: 0.1082 - val_loss: 0.7017 - val_accuracy: 0.6663 - val_mae: 0.2328 - val_mse: 0.1540 - lr: 1.0000e-04\n",
            "Epoch 2238/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.7408 - mae: 0.1818 - mse: 0.1115\n",
            "Epoch 2238: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3232 - accuracy: 0.7408 - mae: 0.1818 - mse: 0.1115 - val_loss: 0.7078 - val_accuracy: 0.6599 - val_mae: 0.2344 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2239/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.7385 - mae: 0.1821 - mse: 0.1122\n",
            "Epoch 2239: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 0.3179 - accuracy: 0.7385 - mae: 0.1821 - mse: 0.1122 - val_loss: 0.7279 - val_accuracy: 0.6439 - val_mae: 0.2398 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2240/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.7298 - mae: 0.1874 - mse: 0.1172\n",
            "Epoch 2240: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3026 - accuracy: 0.7298 - mae: 0.1874 - mse: 0.1172 - val_loss: 0.7631 - val_accuracy: 0.6214 - val_mae: 0.2482 - val_mse: 0.1696 - lr: 1.0000e-04\n",
            "Epoch 2241/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.7055 - mae: 0.1989 - mse: 0.1289\n",
            "Epoch 2241: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3136 - accuracy: 0.7055 - mae: 0.1989 - mse: 0.1289 - val_loss: 0.7562 - val_accuracy: 0.6182 - val_mae: 0.2466 - val_mse: 0.1680 - lr: 1.0000e-04\n",
            "Epoch 2242/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7144 - mae: 0.1955 - mse: 0.1253\n",
            "Epoch 2242: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3073 - accuracy: 0.7174 - mae: 0.1940 - mse: 0.1240 - val_loss: 0.7316 - val_accuracy: 0.6278 - val_mae: 0.2407 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2243/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3181 - accuracy: 0.7212 - mae: 0.1906 - mse: 0.1197\n",
            "Epoch 2243: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3141 - accuracy: 0.7243 - mae: 0.1891 - mse: 0.1184 - val_loss: 0.7199 - val_accuracy: 0.6481 - val_mae: 0.2377 - val_mse: 0.1589 - lr: 1.0000e-04\n",
            "Epoch 2244/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3136 - accuracy: 0.7354 - mae: 0.1871 - mse: 0.1143\n",
            "Epoch 2244: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3146 - accuracy: 0.7335 - mae: 0.1871 - mse: 0.1147 - val_loss: 0.7240 - val_accuracy: 0.6471 - val_mae: 0.2382 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2245/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2990 - accuracy: 0.7397 - mae: 0.1846 - mse: 0.1132\n",
            "Epoch 2245: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3047 - accuracy: 0.7381 - mae: 0.1855 - mse: 0.1142 - val_loss: 0.7388 - val_accuracy: 0.6342 - val_mae: 0.2425 - val_mse: 0.1632 - lr: 1.0000e-04\n",
            "Epoch 2246/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3192 - accuracy: 0.7251 - mae: 0.1908 - mse: 0.1183\n",
            "Epoch 2246: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3217 - accuracy: 0.7239 - mae: 0.1914 - mse: 0.1193 - val_loss: 0.7636 - val_accuracy: 0.6171 - val_mae: 0.2487 - val_mse: 0.1693 - lr: 1.0000e-04\n",
            "Epoch 2247/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3284 - accuracy: 0.7075 - mae: 0.1991 - mse: 0.1274\n",
            "Epoch 2247: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3269 - accuracy: 0.7110 - mae: 0.1979 - mse: 0.1261 - val_loss: 0.7747 - val_accuracy: 0.6075 - val_mae: 0.2518 - val_mse: 0.1723 - lr: 1.0000e-04\n",
            "Epoch 2248/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2921 - accuracy: 0.7139 - mae: 0.1986 - mse: 0.1263\n",
            "Epoch 2248: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2982 - accuracy: 0.7142 - mae: 0.1988 - mse: 0.1265 - val_loss: 0.7699 - val_accuracy: 0.6139 - val_mae: 0.2502 - val_mse: 0.1710 - lr: 1.0000e-04\n",
            "Epoch 2249/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.7037 - mae: 0.2016 - mse: 0.1287\n",
            "Epoch 2249: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 0.3257 - accuracy: 0.7037 - mae: 0.2016 - mse: 0.1287 - val_loss: 0.7568 - val_accuracy: 0.6278 - val_mae: 0.2471 - val_mse: 0.1677 - lr: 1.0000e-04\n",
            "Epoch 2250/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3032 - accuracy: 0.7124 - mae: 0.1951 - mse: 0.1225\n",
            "Epoch 2250: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3007 - accuracy: 0.7147 - mae: 0.1943 - mse: 0.1218 - val_loss: 0.7207 - val_accuracy: 0.6460 - val_mae: 0.2387 - val_mse: 0.1592 - lr: 1.0000e-04\n",
            "Epoch 2251/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3307 - accuracy: 0.7378 - mae: 0.1859 - mse: 0.1126\n",
            "Epoch 2251: val_loss did not improve from 0.68051\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3276 - accuracy: 0.7339 - mae: 0.1870 - mse: 0.1137 - val_loss: 0.6944 - val_accuracy: 0.6631 - val_mae: 0.2320 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2252/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3053 - accuracy: 0.7505 - mae: 0.1778 - mse: 0.1065\n",
            "Epoch 2252: val_loss improved from 0.68051 to 0.66903, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 1s 455ms/step - loss: 0.3055 - accuracy: 0.7440 - mae: 0.1799 - mse: 0.1083 - val_loss: 0.6690 - val_accuracy: 0.6770 - val_mae: 0.2253 - val_mse: 0.1464 - lr: 1.0000e-04\n",
            "Epoch 2253/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2969 - accuracy: 0.7622 - mae: 0.1725 - mse: 0.1018\n",
            "Epoch 2253: val_loss improved from 0.66903 to 0.66434, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 1s 197ms/step - loss: 0.3028 - accuracy: 0.7610 - mae: 0.1733 - mse: 0.1022 - val_loss: 0.6643 - val_accuracy: 0.6759 - val_mae: 0.2237 - val_mse: 0.1452 - lr: 1.0000e-04\n",
            "Epoch 2254/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3374 - accuracy: 0.7554 - mae: 0.1780 - mse: 0.1069\n",
            "Epoch 2254: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3309 - accuracy: 0.7546 - mae: 0.1776 - mse: 0.1066 - val_loss: 0.6922 - val_accuracy: 0.6631 - val_mae: 0.2310 - val_mse: 0.1523 - lr: 1.0000e-04\n",
            "Epoch 2255/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3121 - accuracy: 0.7412 - mae: 0.1806 - mse: 0.1097\n",
            "Epoch 2255: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3127 - accuracy: 0.7394 - mae: 0.1816 - mse: 0.1105 - val_loss: 0.7197 - val_accuracy: 0.6449 - val_mae: 0.2375 - val_mse: 0.1591 - lr: 1.0000e-04\n",
            "Epoch 2256/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2975 - accuracy: 0.7334 - mae: 0.1873 - mse: 0.1168\n",
            "Epoch 2256: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2974 - accuracy: 0.7339 - mae: 0.1871 - mse: 0.1165 - val_loss: 0.7362 - val_accuracy: 0.6353 - val_mae: 0.2405 - val_mse: 0.1627 - lr: 1.0000e-04\n",
            "Epoch 2257/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.7216 - mae: 0.1886 - mse: 0.1193\n",
            "Epoch 2257: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 0.3137 - accuracy: 0.7216 - mae: 0.1886 - mse: 0.1193 - val_loss: 0.7439 - val_accuracy: 0.6385 - val_mae: 0.2414 - val_mse: 0.1641 - lr: 1.0000e-04\n",
            "Epoch 2258/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3112 - accuracy: 0.7168 - mae: 0.1911 - mse: 0.1207\n",
            "Epoch 2258: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3104 - accuracy: 0.7183 - mae: 0.1907 - mse: 0.1204 - val_loss: 0.7420 - val_accuracy: 0.6406 - val_mae: 0.2410 - val_mse: 0.1636 - lr: 1.0000e-04\n",
            "Epoch 2259/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3266 - accuracy: 0.7197 - mae: 0.1933 - mse: 0.1234\n",
            "Epoch 2259: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 221ms/step - loss: 0.3263 - accuracy: 0.7243 - mae: 0.1913 - mse: 0.1215 - val_loss: 0.7377 - val_accuracy: 0.6374 - val_mae: 0.2405 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2260/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.7321 - mae: 0.1886 - mse: 0.1168\n",
            "Epoch 2260: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3020 - accuracy: 0.7321 - mae: 0.1886 - mse: 0.1168 - val_loss: 0.7449 - val_accuracy: 0.6310 - val_mae: 0.2425 - val_mse: 0.1646 - lr: 1.0000e-04\n",
            "Epoch 2261/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3286 - accuracy: 0.7246 - mae: 0.1891 - mse: 0.1190\n",
            "Epoch 2261: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.3276 - accuracy: 0.7257 - mae: 0.1889 - mse: 0.1188 - val_loss: 0.7697 - val_accuracy: 0.6118 - val_mae: 0.2491 - val_mse: 0.1707 - lr: 1.0000e-04\n",
            "Epoch 2262/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.7078 - mae: 0.1996 - mse: 0.1292\n",
            "Epoch 2262: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3178 - accuracy: 0.7078 - mae: 0.1996 - mse: 0.1292 - val_loss: 0.7761 - val_accuracy: 0.6096 - val_mae: 0.2510 - val_mse: 0.1722 - lr: 1.0000e-04\n",
            "Epoch 2263/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.7046 - mae: 0.2000 - mse: 0.1299\n",
            "Epoch 2263: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3126 - accuracy: 0.7046 - mae: 0.2000 - mse: 0.1299 - val_loss: 0.7720 - val_accuracy: 0.6150 - val_mae: 0.2499 - val_mse: 0.1711 - lr: 1.0000e-04\n",
            "Epoch 2264/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.7193 - mae: 0.1936 - mse: 0.1224\n",
            "Epoch 2264: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.3049 - accuracy: 0.7193 - mae: 0.1936 - mse: 0.1224 - val_loss: 0.7398 - val_accuracy: 0.6342 - val_mae: 0.2430 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 2265/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.7381 - mae: 0.1878 - mse: 0.1156\n",
            "Epoch 2265: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.3105 - accuracy: 0.7381 - mae: 0.1878 - mse: 0.1156 - val_loss: 0.7134 - val_accuracy: 0.6428 - val_mae: 0.2375 - val_mse: 0.1581 - lr: 1.0000e-04\n",
            "Epoch 2266/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.7422 - mae: 0.1821 - mse: 0.1117\n",
            "Epoch 2266: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3058 - accuracy: 0.7422 - mae: 0.1821 - mse: 0.1117 - val_loss: 0.6955 - val_accuracy: 0.6449 - val_mae: 0.2336 - val_mse: 0.1541 - lr: 1.0000e-04\n",
            "Epoch 2267/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3107 - accuracy: 0.7407 - mae: 0.1840 - mse: 0.1118\n",
            "Epoch 2267: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.3096 - accuracy: 0.7445 - mae: 0.1825 - mse: 0.1103 - val_loss: 0.6965 - val_accuracy: 0.6481 - val_mae: 0.2339 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2268/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.7463 - mae: 0.1820 - mse: 0.1105\n",
            "Epoch 2268: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3043 - accuracy: 0.7463 - mae: 0.1820 - mse: 0.1105 - val_loss: 0.7193 - val_accuracy: 0.6364 - val_mae: 0.2395 - val_mse: 0.1599 - lr: 1.0000e-04\n",
            "Epoch 2269/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.7321 - mae: 0.1884 - mse: 0.1177\n",
            "Epoch 2269: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.3075 - accuracy: 0.7321 - mae: 0.1884 - mse: 0.1177 - val_loss: 0.7458 - val_accuracy: 0.6289 - val_mae: 0.2455 - val_mse: 0.1659 - lr: 1.0000e-04\n",
            "Epoch 2270/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3053 - accuracy: 0.7153 - mae: 0.1945 - mse: 0.1229\n",
            "Epoch 2270: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3110 - accuracy: 0.7147 - mae: 0.1955 - mse: 0.1235 - val_loss: 0.7491 - val_accuracy: 0.6267 - val_mae: 0.2459 - val_mse: 0.1664 - lr: 1.0000e-04\n",
            "Epoch 2271/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.7156 - mae: 0.1947 - mse: 0.1228\n",
            "Epoch 2271: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 0.3089 - accuracy: 0.7156 - mae: 0.1947 - mse: 0.1228 - val_loss: 0.7441 - val_accuracy: 0.6342 - val_mae: 0.2445 - val_mse: 0.1650 - lr: 1.0000e-04\n",
            "Epoch 2272/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.7422 - mae: 0.1879 - mse: 0.1161\n",
            "Epoch 2272: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3046 - accuracy: 0.7422 - mae: 0.1879 - mse: 0.1161 - val_loss: 0.7295 - val_accuracy: 0.6396 - val_mae: 0.2409 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 2273/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.7372 - mae: 0.1901 - mse: 0.1179\n",
            "Epoch 2273: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.3204 - accuracy: 0.7372 - mae: 0.1901 - mse: 0.1179 - val_loss: 0.7085 - val_accuracy: 0.6503 - val_mae: 0.2357 - val_mse: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 2274/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3032 - accuracy: 0.7524 - mae: 0.1789 - mse: 0.1078\n",
            "Epoch 2274: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3055 - accuracy: 0.7482 - mae: 0.1811 - mse: 0.1094 - val_loss: 0.6939 - val_accuracy: 0.6599 - val_mae: 0.2315 - val_mse: 0.1523 - lr: 1.0000e-04\n",
            "Epoch 2275/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.7509 - mae: 0.1783 - mse: 0.1071\n",
            "Epoch 2275: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.3154 - accuracy: 0.7509 - mae: 0.1783 - mse: 0.1071 - val_loss: 0.6995 - val_accuracy: 0.6599 - val_mae: 0.2318 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2276/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.7367 - mae: 0.1815 - mse: 0.1110\n",
            "Epoch 2276: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.3125 - accuracy: 0.7367 - mae: 0.1815 - mse: 0.1110 - val_loss: 0.7177 - val_accuracy: 0.6513 - val_mae: 0.2354 - val_mse: 0.1570 - lr: 1.0000e-04\n",
            "Epoch 2277/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.7505 - mae: 0.1823 - mse: 0.1116\n",
            "Epoch 2277: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3085 - accuracy: 0.7505 - mae: 0.1823 - mse: 0.1116 - val_loss: 0.7247 - val_accuracy: 0.6492 - val_mae: 0.2366 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2278/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3086 - accuracy: 0.7485 - mae: 0.1798 - mse: 0.1096\n",
            "Epoch 2278: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3080 - accuracy: 0.7463 - mae: 0.1811 - mse: 0.1108 - val_loss: 0.7244 - val_accuracy: 0.6481 - val_mae: 0.2365 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2279/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3003 - accuracy: 0.7427 - mae: 0.1821 - mse: 0.1120\n",
            "Epoch 2279: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3006 - accuracy: 0.7468 - mae: 0.1810 - mse: 0.1106 - val_loss: 0.7203 - val_accuracy: 0.6492 - val_mae: 0.2358 - val_mse: 0.1577 - lr: 1.0000e-04\n",
            "Epoch 2280/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3104 - accuracy: 0.7461 - mae: 0.1828 - mse: 0.1121\n",
            "Epoch 2280: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3115 - accuracy: 0.7450 - mae: 0.1824 - mse: 0.1123 - val_loss: 0.7346 - val_accuracy: 0.6417 - val_mae: 0.2399 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 2281/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.7239 - mae: 0.1896 - mse: 0.1188\n",
            "Epoch 2281: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.3121 - accuracy: 0.7239 - mae: 0.1896 - mse: 0.1188 - val_loss: 0.7459 - val_accuracy: 0.6342 - val_mae: 0.2429 - val_mse: 0.1644 - lr: 1.0000e-04\n",
            "Epoch 2282/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3222 - accuracy: 0.7222 - mae: 0.1909 - mse: 0.1194\n",
            "Epoch 2282: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3222 - accuracy: 0.7202 - mae: 0.1922 - mse: 0.1208 - val_loss: 0.7577 - val_accuracy: 0.6246 - val_mae: 0.2457 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 2283/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3117 - accuracy: 0.7319 - mae: 0.1871 - mse: 0.1157\n",
            "Epoch 2283: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3090 - accuracy: 0.7321 - mae: 0.1868 - mse: 0.1155 - val_loss: 0.7464 - val_accuracy: 0.6310 - val_mae: 0.2435 - val_mse: 0.1647 - lr: 1.0000e-04\n",
            "Epoch 2284/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3146 - accuracy: 0.7295 - mae: 0.1885 - mse: 0.1184\n",
            "Epoch 2284: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.3224 - accuracy: 0.7294 - mae: 0.1891 - mse: 0.1194 - val_loss: 0.7435 - val_accuracy: 0.6310 - val_mae: 0.2429 - val_mse: 0.1642 - lr: 1.0000e-04\n",
            "Epoch 2285/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.7266 - mae: 0.1896 - mse: 0.1196\n",
            "Epoch 2285: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.3043 - accuracy: 0.7266 - mae: 0.1896 - mse: 0.1196 - val_loss: 0.7564 - val_accuracy: 0.6246 - val_mae: 0.2461 - val_mse: 0.1674 - lr: 1.0000e-04\n",
            "Epoch 2286/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.7147 - mae: 0.1958 - mse: 0.1243\n",
            "Epoch 2286: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3165 - accuracy: 0.7147 - mae: 0.1958 - mse: 0.1243 - val_loss: 0.7633 - val_accuracy: 0.6246 - val_mae: 0.2483 - val_mse: 0.1693 - lr: 1.0000e-04\n",
            "Epoch 2287/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.7161 - mae: 0.1942 - mse: 0.1231\n",
            "Epoch 2287: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3057 - accuracy: 0.7161 - mae: 0.1942 - mse: 0.1231 - val_loss: 0.7545 - val_accuracy: 0.6278 - val_mae: 0.2470 - val_mse: 0.1676 - lr: 1.0000e-04\n",
            "Epoch 2288/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.7197 - mae: 0.1943 - mse: 0.1226\n",
            "Epoch 2288: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.3027 - accuracy: 0.7197 - mae: 0.1943 - mse: 0.1226 - val_loss: 0.7455 - val_accuracy: 0.6299 - val_mae: 0.2445 - val_mse: 0.1654 - lr: 1.0000e-04\n",
            "Epoch 2289/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3059 - accuracy: 0.7207 - mae: 0.1929 - mse: 0.1216\n",
            "Epoch 2289: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3066 - accuracy: 0.7206 - mae: 0.1931 - mse: 0.1215 - val_loss: 0.7417 - val_accuracy: 0.6342 - val_mae: 0.2422 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 2290/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.7216 - mae: 0.1929 - mse: 0.1217\n",
            "Epoch 2290: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3231 - accuracy: 0.7216 - mae: 0.1929 - mse: 0.1217 - val_loss: 0.7445 - val_accuracy: 0.6310 - val_mae: 0.2416 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 2291/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.7220 - mae: 0.1923 - mse: 0.1227\n",
            "Epoch 2291: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3150 - accuracy: 0.7220 - mae: 0.1923 - mse: 0.1227 - val_loss: 0.7379 - val_accuracy: 0.6385 - val_mae: 0.2395 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2292/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3183 - accuracy: 0.7275 - mae: 0.1893 - mse: 0.1208\n",
            "Epoch 2292: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 217ms/step - loss: 0.3190 - accuracy: 0.7261 - mae: 0.1904 - mse: 0.1215 - val_loss: 0.7137 - val_accuracy: 0.6513 - val_mae: 0.2333 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2293/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3130 - accuracy: 0.7344 - mae: 0.1824 - mse: 0.1115\n",
            "Epoch 2293: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3166 - accuracy: 0.7362 - mae: 0.1829 - mse: 0.1119 - val_loss: 0.7041 - val_accuracy: 0.6599 - val_mae: 0.2310 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2294/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.7569 - mae: 0.1791 - mse: 0.1092\n",
            "Epoch 2294: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3151 - accuracy: 0.7569 - mae: 0.1791 - mse: 0.1092 - val_loss: 0.7231 - val_accuracy: 0.6492 - val_mae: 0.2364 - val_mse: 0.1580 - lr: 1.0000e-04\n",
            "Epoch 2295/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2956 - accuracy: 0.7358 - mae: 0.1848 - mse: 0.1152\n",
            "Epoch 2295: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 186ms/step - loss: 0.2950 - accuracy: 0.7344 - mae: 0.1860 - mse: 0.1156 - val_loss: 0.7402 - val_accuracy: 0.6364 - val_mae: 0.2418 - val_mse: 0.1627 - lr: 1.0000e-04\n",
            "Epoch 2296/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3123 - accuracy: 0.7256 - mae: 0.1910 - mse: 0.1207\n",
            "Epoch 2296: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3093 - accuracy: 0.7280 - mae: 0.1891 - mse: 0.1189 - val_loss: 0.7373 - val_accuracy: 0.6449 - val_mae: 0.2418 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2297/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.7239 - mae: 0.1911 - mse: 0.1187\n",
            "Epoch 2297: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3207 - accuracy: 0.7239 - mae: 0.1911 - mse: 0.1187 - val_loss: 0.7319 - val_accuracy: 0.6503 - val_mae: 0.2409 - val_mse: 0.1614 - lr: 1.0000e-04\n",
            "Epoch 2298/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3121 - accuracy: 0.7310 - mae: 0.1885 - mse: 0.1182\n",
            "Epoch 2298: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3051 - accuracy: 0.7321 - mae: 0.1867 - mse: 0.1170 - val_loss: 0.7198 - val_accuracy: 0.6513 - val_mae: 0.2380 - val_mse: 0.1589 - lr: 1.0000e-04\n",
            "Epoch 2299/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3027 - accuracy: 0.7471 - mae: 0.1827 - mse: 0.1113\n",
            "Epoch 2299: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3003 - accuracy: 0.7472 - mae: 0.1819 - mse: 0.1110 - val_loss: 0.7027 - val_accuracy: 0.6535 - val_mae: 0.2338 - val_mse: 0.1550 - lr: 1.0000e-04\n",
            "Epoch 2300/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3120 - accuracy: 0.7544 - mae: 0.1792 - mse: 0.1082\n",
            "Epoch 2300: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3081 - accuracy: 0.7550 - mae: 0.1785 - mse: 0.1076 - val_loss: 0.6943 - val_accuracy: 0.6578 - val_mae: 0.2313 - val_mse: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 2301/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2909 - accuracy: 0.7544 - mae: 0.1759 - mse: 0.1065\n",
            "Epoch 2301: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2977 - accuracy: 0.7537 - mae: 0.1766 - mse: 0.1068 - val_loss: 0.6953 - val_accuracy: 0.6503 - val_mae: 0.2304 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2302/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3124 - accuracy: 0.7466 - mae: 0.1784 - mse: 0.1087\n",
            "Epoch 2302: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3101 - accuracy: 0.7454 - mae: 0.1788 - mse: 0.1095 - val_loss: 0.7156 - val_accuracy: 0.6449 - val_mae: 0.2338 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2303/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2987 - accuracy: 0.7456 - mae: 0.1796 - mse: 0.1108\n",
            "Epoch 2303: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2979 - accuracy: 0.7472 - mae: 0.1790 - mse: 0.1109 - val_loss: 0.7255 - val_accuracy: 0.6406 - val_mae: 0.2352 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2304/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3238 - accuracy: 0.7393 - mae: 0.1834 - mse: 0.1162\n",
            "Epoch 2304: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3241 - accuracy: 0.7376 - mae: 0.1840 - mse: 0.1165 - val_loss: 0.7398 - val_accuracy: 0.6417 - val_mae: 0.2385 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2305/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3044 - accuracy: 0.7334 - mae: 0.1875 - mse: 0.1187\n",
            "Epoch 2305: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3075 - accuracy: 0.7326 - mae: 0.1878 - mse: 0.1187 - val_loss: 0.7594 - val_accuracy: 0.6310 - val_mae: 0.2431 - val_mse: 0.1672 - lr: 1.0000e-04\n",
            "Epoch 2306/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.7220 - mae: 0.1888 - mse: 0.1211\n",
            "Epoch 2306: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.2912 - accuracy: 0.7220 - mae: 0.1888 - mse: 0.1211 - val_loss: 0.7621 - val_accuracy: 0.6267 - val_mae: 0.2437 - val_mse: 0.1677 - lr: 1.0000e-04\n",
            "Epoch 2307/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3135 - accuracy: 0.7310 - mae: 0.1884 - mse: 0.1202\n",
            "Epoch 2307: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3139 - accuracy: 0.7275 - mae: 0.1900 - mse: 0.1218 - val_loss: 0.7440 - val_accuracy: 0.6342 - val_mae: 0.2398 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2308/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3067 - accuracy: 0.7300 - mae: 0.1881 - mse: 0.1188\n",
            "Epoch 2308: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3105 - accuracy: 0.7312 - mae: 0.1877 - mse: 0.1186 - val_loss: 0.7249 - val_accuracy: 0.6417 - val_mae: 0.2364 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2309/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3081 - accuracy: 0.7378 - mae: 0.1870 - mse: 0.1162\n",
            "Epoch 2309: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3074 - accuracy: 0.7404 - mae: 0.1852 - mse: 0.1150 - val_loss: 0.7290 - val_accuracy: 0.6449 - val_mae: 0.2391 - val_mse: 0.1609 - lr: 1.0000e-04\n",
            "Epoch 2310/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2994 - accuracy: 0.7437 - mae: 0.1862 - mse: 0.1154\n",
            "Epoch 2310: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2994 - accuracy: 0.7431 - mae: 0.1863 - mse: 0.1158 - val_loss: 0.7311 - val_accuracy: 0.6385 - val_mae: 0.2407 - val_mse: 0.1618 - lr: 1.0000e-04\n",
            "Epoch 2311/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2989 - accuracy: 0.7363 - mae: 0.1886 - mse: 0.1162\n",
            "Epoch 2311: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2995 - accuracy: 0.7394 - mae: 0.1869 - mse: 0.1149 - val_loss: 0.7280 - val_accuracy: 0.6374 - val_mae: 0.2403 - val_mse: 0.1612 - lr: 1.0000e-04\n",
            "Epoch 2312/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3115 - accuracy: 0.7363 - mae: 0.1887 - mse: 0.1179\n",
            "Epoch 2312: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3102 - accuracy: 0.7358 - mae: 0.1883 - mse: 0.1173 - val_loss: 0.7297 - val_accuracy: 0.6364 - val_mae: 0.2410 - val_mse: 0.1617 - lr: 1.0000e-04\n",
            "Epoch 2313/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3003 - accuracy: 0.7310 - mae: 0.1898 - mse: 0.1188\n",
            "Epoch 2313: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.3032 - accuracy: 0.7294 - mae: 0.1913 - mse: 0.1197 - val_loss: 0.7235 - val_accuracy: 0.6406 - val_mae: 0.2399 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2314/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.7271 - mae: 0.1885 - mse: 0.1174\n",
            "Epoch 2314: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.3117 - accuracy: 0.7271 - mae: 0.1885 - mse: 0.1174 - val_loss: 0.7186 - val_accuracy: 0.6428 - val_mae: 0.2389 - val_mse: 0.1590 - lr: 1.0000e-04\n",
            "Epoch 2315/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3124 - accuracy: 0.7329 - mae: 0.1872 - mse: 0.1146\n",
            "Epoch 2315: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3099 - accuracy: 0.7349 - mae: 0.1863 - mse: 0.1141 - val_loss: 0.7231 - val_accuracy: 0.6406 - val_mae: 0.2395 - val_mse: 0.1598 - lr: 1.0000e-04\n",
            "Epoch 2316/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.7294 - mae: 0.1858 - mse: 0.1162\n",
            "Epoch 2316: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3026 - accuracy: 0.7294 - mae: 0.1858 - mse: 0.1162 - val_loss: 0.7253 - val_accuracy: 0.6406 - val_mae: 0.2392 - val_mse: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 2317/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.7358 - mae: 0.1861 - mse: 0.1152\n",
            "Epoch 2317: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.3024 - accuracy: 0.7358 - mae: 0.1861 - mse: 0.1152 - val_loss: 0.7241 - val_accuracy: 0.6428 - val_mae: 0.2387 - val_mse: 0.1596 - lr: 1.0000e-04\n",
            "Epoch 2318/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7354 - mae: 0.1869 - mse: 0.1154\n",
            "Epoch 2318: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.3073 - accuracy: 0.7335 - mae: 0.1868 - mse: 0.1156 - val_loss: 0.7110 - val_accuracy: 0.6460 - val_mae: 0.2354 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 2319/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.7399 - mae: 0.1817 - mse: 0.1128\n",
            "Epoch 2319: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.2958 - accuracy: 0.7399 - mae: 0.1817 - mse: 0.1128 - val_loss: 0.6936 - val_accuracy: 0.6599 - val_mae: 0.2314 - val_mse: 0.1522 - lr: 1.0000e-04\n",
            "Epoch 2320/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.7482 - mae: 0.1819 - mse: 0.1110\n",
            "Epoch 2320: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.3069 - accuracy: 0.7482 - mae: 0.1819 - mse: 0.1110 - val_loss: 0.6863 - val_accuracy: 0.6684 - val_mae: 0.2296 - val_mse: 0.1503 - lr: 1.0000e-04\n",
            "Epoch 2321/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3054 - accuracy: 0.7573 - mae: 0.1766 - mse: 0.1075\n",
            "Epoch 2321: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3102 - accuracy: 0.7537 - mae: 0.1779 - mse: 0.1086 - val_loss: 0.6995 - val_accuracy: 0.6642 - val_mae: 0.2330 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2322/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3064 - accuracy: 0.7388 - mae: 0.1812 - mse: 0.1100\n",
            "Epoch 2322: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3043 - accuracy: 0.7367 - mae: 0.1820 - mse: 0.1108 - val_loss: 0.7119 - val_accuracy: 0.6471 - val_mae: 0.2367 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2323/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3019 - accuracy: 0.7378 - mae: 0.1861 - mse: 0.1134\n",
            "Epoch 2323: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.3027 - accuracy: 0.7404 - mae: 0.1853 - mse: 0.1130 - val_loss: 0.7142 - val_accuracy: 0.6492 - val_mae: 0.2374 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2324/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2978 - accuracy: 0.7451 - mae: 0.1839 - mse: 0.1109\n",
            "Epoch 2324: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.2994 - accuracy: 0.7459 - mae: 0.1834 - mse: 0.1107 - val_loss: 0.7219 - val_accuracy: 0.6449 - val_mae: 0.2387 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 2325/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2971 - accuracy: 0.7417 - mae: 0.1863 - mse: 0.1136\n",
            "Epoch 2325: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2960 - accuracy: 0.7408 - mae: 0.1856 - mse: 0.1134 - val_loss: 0.7273 - val_accuracy: 0.6471 - val_mae: 0.2385 - val_mse: 0.1595 - lr: 1.0000e-04\n",
            "Epoch 2326/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3063 - accuracy: 0.7358 - mae: 0.1867 - mse: 0.1149\n",
            "Epoch 2326: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3037 - accuracy: 0.7362 - mae: 0.1862 - mse: 0.1148 - val_loss: 0.7230 - val_accuracy: 0.6481 - val_mae: 0.2360 - val_mse: 0.1579 - lr: 1.0000e-04\n",
            "Epoch 2327/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3058 - accuracy: 0.7422 - mae: 0.1820 - mse: 0.1121\n",
            "Epoch 2327: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3091 - accuracy: 0.7422 - mae: 0.1821 - mse: 0.1125 - val_loss: 0.7205 - val_accuracy: 0.6460 - val_mae: 0.2345 - val_mse: 0.1570 - lr: 1.0000e-04\n",
            "Epoch 2328/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3077 - accuracy: 0.7466 - mae: 0.1801 - mse: 0.1106\n",
            "Epoch 2328: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3042 - accuracy: 0.7463 - mae: 0.1806 - mse: 0.1110 - val_loss: 0.7233 - val_accuracy: 0.6503 - val_mae: 0.2344 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2329/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2867 - accuracy: 0.7451 - mae: 0.1791 - mse: 0.1110\n",
            "Epoch 2329: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2930 - accuracy: 0.7463 - mae: 0.1798 - mse: 0.1108 - val_loss: 0.7192 - val_accuracy: 0.6524 - val_mae: 0.2333 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2330/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2954 - accuracy: 0.7407 - mae: 0.1800 - mse: 0.1116\n",
            "Epoch 2330: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2974 - accuracy: 0.7404 - mae: 0.1808 - mse: 0.1126 - val_loss: 0.7312 - val_accuracy: 0.6439 - val_mae: 0.2360 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 2331/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2946 - accuracy: 0.7354 - mae: 0.1816 - mse: 0.1134\n",
            "Epoch 2331: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2977 - accuracy: 0.7372 - mae: 0.1818 - mse: 0.1135 - val_loss: 0.7351 - val_accuracy: 0.6417 - val_mae: 0.2371 - val_mse: 0.1597 - lr: 1.0000e-04\n",
            "Epoch 2332/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2948 - accuracy: 0.7427 - mae: 0.1829 - mse: 0.1140\n",
            "Epoch 2332: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2974 - accuracy: 0.7394 - mae: 0.1838 - mse: 0.1147 - val_loss: 0.7387 - val_accuracy: 0.6460 - val_mae: 0.2381 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2333/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2837 - accuracy: 0.7490 - mae: 0.1795 - mse: 0.1107\n",
            "Epoch 2333: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2861 - accuracy: 0.7468 - mae: 0.1807 - mse: 0.1115 - val_loss: 0.7347 - val_accuracy: 0.6481 - val_mae: 0.2366 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2334/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3129 - accuracy: 0.7422 - mae: 0.1807 - mse: 0.1122\n",
            "Epoch 2334: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3141 - accuracy: 0.7404 - mae: 0.1812 - mse: 0.1126 - val_loss: 0.7425 - val_accuracy: 0.6417 - val_mae: 0.2385 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 2335/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3030 - accuracy: 0.7368 - mae: 0.1846 - mse: 0.1166\n",
            "Epoch 2335: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.3011 - accuracy: 0.7367 - mae: 0.1846 - mse: 0.1165 - val_loss: 0.7460 - val_accuracy: 0.6385 - val_mae: 0.2393 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 2336/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2930 - accuracy: 0.7334 - mae: 0.1847 - mse: 0.1156\n",
            "Epoch 2336: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2929 - accuracy: 0.7339 - mae: 0.1841 - mse: 0.1153 - val_loss: 0.7317 - val_accuracy: 0.6460 - val_mae: 0.2358 - val_mse: 0.1589 - lr: 1.0000e-04\n",
            "Epoch 2337/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3082 - accuracy: 0.7397 - mae: 0.1849 - mse: 0.1158\n",
            "Epoch 2337: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3023 - accuracy: 0.7417 - mae: 0.1838 - mse: 0.1149 - val_loss: 0.7139 - val_accuracy: 0.6578 - val_mae: 0.2313 - val_mse: 0.1550 - lr: 1.0000e-04\n",
            "Epoch 2338/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2940 - accuracy: 0.7563 - mae: 0.1779 - mse: 0.1100\n",
            "Epoch 2338: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2916 - accuracy: 0.7601 - mae: 0.1766 - mse: 0.1087 - val_loss: 0.6918 - val_accuracy: 0.6717 - val_mae: 0.2251 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2339/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3061 - accuracy: 0.7559 - mae: 0.1750 - mse: 0.1051\n",
            "Epoch 2339: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.3020 - accuracy: 0.7583 - mae: 0.1734 - mse: 0.1042 - val_loss: 0.6884 - val_accuracy: 0.6749 - val_mae: 0.2241 - val_mse: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 2340/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.7587 - mae: 0.1706 - mse: 0.1037\n",
            "Epoch 2340: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.2900 - accuracy: 0.7587 - mae: 0.1706 - mse: 0.1037 - val_loss: 0.7023 - val_accuracy: 0.6674 - val_mae: 0.2275 - val_mse: 0.1520 - lr: 1.0000e-04\n",
            "Epoch 2341/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3201 - accuracy: 0.7544 - mae: 0.1805 - mse: 0.1104\n",
            "Epoch 2341: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3170 - accuracy: 0.7569 - mae: 0.1790 - mse: 0.1093 - val_loss: 0.7305 - val_accuracy: 0.6481 - val_mae: 0.2338 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2342/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.7440 - mae: 0.1848 - mse: 0.1170\n",
            "Epoch 2342: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3194 - accuracy: 0.7440 - mae: 0.1848 - mse: 0.1170 - val_loss: 0.7634 - val_accuracy: 0.6289 - val_mae: 0.2417 - val_mse: 0.1662 - lr: 1.0000e-04\n",
            "Epoch 2343/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.7243 - mae: 0.1901 - mse: 0.1225\n",
            "Epoch 2343: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.3060 - accuracy: 0.7243 - mae: 0.1901 - mse: 0.1225 - val_loss: 0.7821 - val_accuracy: 0.6235 - val_mae: 0.2462 - val_mse: 0.1707 - lr: 1.0000e-04\n",
            "Epoch 2344/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.7151 - mae: 0.1946 - mse: 0.1272\n",
            "Epoch 2344: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3049 - accuracy: 0.7151 - mae: 0.1946 - mse: 0.1272 - val_loss: 0.7713 - val_accuracy: 0.6289 - val_mae: 0.2438 - val_mse: 0.1682 - lr: 1.0000e-04\n",
            "Epoch 2345/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2992 - accuracy: 0.7275 - mae: 0.1883 - mse: 0.1201\n",
            "Epoch 2345: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3009 - accuracy: 0.7280 - mae: 0.1887 - mse: 0.1203 - val_loss: 0.7403 - val_accuracy: 0.6449 - val_mae: 0.2366 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2346/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.7427 - mae: 0.1802 - mse: 0.1119\n",
            "Epoch 2346: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3075 - accuracy: 0.7427 - mae: 0.1802 - mse: 0.1119 - val_loss: 0.7282 - val_accuracy: 0.6513 - val_mae: 0.2340 - val_mse: 0.1581 - lr: 1.0000e-04\n",
            "Epoch 2347/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3094 - accuracy: 0.7383 - mae: 0.1813 - mse: 0.1127\n",
            "Epoch 2347: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3091 - accuracy: 0.7344 - mae: 0.1826 - mse: 0.1134 - val_loss: 0.7448 - val_accuracy: 0.6353 - val_mae: 0.2384 - val_mse: 0.1624 - lr: 1.0000e-04\n",
            "Epoch 2348/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.7193 - mae: 0.1896 - mse: 0.1192\n",
            "Epoch 2348: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.3077 - accuracy: 0.7193 - mae: 0.1896 - mse: 0.1192 - val_loss: 0.7532 - val_accuracy: 0.6342 - val_mae: 0.2414 - val_mse: 0.1650 - lr: 1.0000e-04\n",
            "Epoch 2349/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.7339 - mae: 0.1862 - mse: 0.1177\n",
            "Epoch 2349: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.2956 - accuracy: 0.7339 - mae: 0.1862 - mse: 0.1177 - val_loss: 0.7501 - val_accuracy: 0.6321 - val_mae: 0.2417 - val_mse: 0.1648 - lr: 1.0000e-04\n",
            "Epoch 2350/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2951 - accuracy: 0.7271 - mae: 0.1890 - mse: 0.1194\n",
            "Epoch 2350: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 186ms/step - loss: 0.2952 - accuracy: 0.7271 - mae: 0.1892 - mse: 0.1193 - val_loss: 0.7287 - val_accuracy: 0.6374 - val_mae: 0.2373 - val_mse: 0.1602 - lr: 1.0000e-04\n",
            "Epoch 2351/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2925 - accuracy: 0.7422 - mae: 0.1801 - mse: 0.1109\n",
            "Epoch 2351: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2942 - accuracy: 0.7399 - mae: 0.1817 - mse: 0.1119 - val_loss: 0.7076 - val_accuracy: 0.6460 - val_mae: 0.2322 - val_mse: 0.1552 - lr: 1.0000e-04\n",
            "Epoch 2352/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3063 - accuracy: 0.7471 - mae: 0.1806 - mse: 0.1121\n",
            "Epoch 2352: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3063 - accuracy: 0.7445 - mae: 0.1814 - mse: 0.1127 - val_loss: 0.6905 - val_accuracy: 0.6610 - val_mae: 0.2273 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2353/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2960 - accuracy: 0.7524 - mae: 0.1749 - mse: 0.1059\n",
            "Epoch 2353: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2993 - accuracy: 0.7528 - mae: 0.1748 - mse: 0.1061 - val_loss: 0.6891 - val_accuracy: 0.6663 - val_mae: 0.2265 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2354/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3117 - accuracy: 0.7563 - mae: 0.1762 - mse: 0.1064\n",
            "Epoch 2354: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3139 - accuracy: 0.7573 - mae: 0.1761 - mse: 0.1063 - val_loss: 0.7098 - val_accuracy: 0.6545 - val_mae: 0.2317 - val_mse: 0.1550 - lr: 1.0000e-04\n",
            "Epoch 2355/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2933 - accuracy: 0.7402 - mae: 0.1800 - mse: 0.1107\n",
            "Epoch 2355: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2926 - accuracy: 0.7422 - mae: 0.1788 - mse: 0.1098 - val_loss: 0.7391 - val_accuracy: 0.6460 - val_mae: 0.2387 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2356/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2974 - accuracy: 0.7319 - mae: 0.1871 - mse: 0.1191\n",
            "Epoch 2356: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2983 - accuracy: 0.7298 - mae: 0.1877 - mse: 0.1197 - val_loss: 0.7509 - val_accuracy: 0.6439 - val_mae: 0.2411 - val_mse: 0.1644 - lr: 1.0000e-04\n",
            "Epoch 2357/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3108 - accuracy: 0.7349 - mae: 0.1859 - mse: 0.1178\n",
            "Epoch 2357: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3105 - accuracy: 0.7349 - mae: 0.1857 - mse: 0.1177 - val_loss: 0.7486 - val_accuracy: 0.6396 - val_mae: 0.2403 - val_mse: 0.1637 - lr: 1.0000e-04\n",
            "Epoch 2358/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2965 - accuracy: 0.7363 - mae: 0.1860 - mse: 0.1171\n",
            "Epoch 2358: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2998 - accuracy: 0.7362 - mae: 0.1864 - mse: 0.1171 - val_loss: 0.7378 - val_accuracy: 0.6460 - val_mae: 0.2376 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2359/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3043 - accuracy: 0.7358 - mae: 0.1846 - mse: 0.1156\n",
            "Epoch 2359: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3035 - accuracy: 0.7385 - mae: 0.1828 - mse: 0.1144 - val_loss: 0.7326 - val_accuracy: 0.6481 - val_mae: 0.2360 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2360/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2974 - accuracy: 0.7495 - mae: 0.1804 - mse: 0.1112\n",
            "Epoch 2360: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2955 - accuracy: 0.7477 - mae: 0.1810 - mse: 0.1122 - val_loss: 0.7269 - val_accuracy: 0.6513 - val_mae: 0.2340 - val_mse: 0.1576 - lr: 1.0000e-04\n",
            "Epoch 2361/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2857 - accuracy: 0.7427 - mae: 0.1801 - mse: 0.1116\n",
            "Epoch 2361: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2837 - accuracy: 0.7459 - mae: 0.1784 - mse: 0.1099 - val_loss: 0.7103 - val_accuracy: 0.6642 - val_mae: 0.2293 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2362/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3047 - accuracy: 0.7529 - mae: 0.1792 - mse: 0.1101\n",
            "Epoch 2362: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3006 - accuracy: 0.7537 - mae: 0.1780 - mse: 0.1093 - val_loss: 0.7062 - val_accuracy: 0.6684 - val_mae: 0.2279 - val_mse: 0.1521 - lr: 1.0000e-04\n",
            "Epoch 2363/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3163 - accuracy: 0.7598 - mae: 0.1784 - mse: 0.1101\n",
            "Epoch 2363: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3137 - accuracy: 0.7633 - mae: 0.1769 - mse: 0.1093 - val_loss: 0.7048 - val_accuracy: 0.6695 - val_mae: 0.2280 - val_mse: 0.1521 - lr: 1.0000e-04\n",
            "Epoch 2364/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2967 - accuracy: 0.7651 - mae: 0.1726 - mse: 0.1065\n",
            "Epoch 2364: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2962 - accuracy: 0.7633 - mae: 0.1739 - mse: 0.1072 - val_loss: 0.7133 - val_accuracy: 0.6578 - val_mae: 0.2305 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2365/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3193 - accuracy: 0.7456 - mae: 0.1810 - mse: 0.1125\n",
            "Epoch 2365: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.3175 - accuracy: 0.7454 - mae: 0.1811 - mse: 0.1126 - val_loss: 0.7287 - val_accuracy: 0.6481 - val_mae: 0.2341 - val_mse: 0.1578 - lr: 1.0000e-04\n",
            "Epoch 2366/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3040 - accuracy: 0.7446 - mae: 0.1806 - mse: 0.1127\n",
            "Epoch 2366: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3029 - accuracy: 0.7431 - mae: 0.1808 - mse: 0.1131 - val_loss: 0.7377 - val_accuracy: 0.6492 - val_mae: 0.2356 - val_mse: 0.1597 - lr: 1.0000e-04\n",
            "Epoch 2367/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2971 - accuracy: 0.7388 - mae: 0.1823 - mse: 0.1143\n",
            "Epoch 2367: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2950 - accuracy: 0.7376 - mae: 0.1822 - mse: 0.1141 - val_loss: 0.7326 - val_accuracy: 0.6567 - val_mae: 0.2341 - val_mse: 0.1583 - lr: 1.0000e-04\n",
            "Epoch 2368/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.7440 - mae: 0.1809 - mse: 0.1130\n",
            "Epoch 2368: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3034 - accuracy: 0.7440 - mae: 0.1809 - mse: 0.1130 - val_loss: 0.7307 - val_accuracy: 0.6524 - val_mae: 0.2338 - val_mse: 0.1578 - lr: 1.0000e-04\n",
            "Epoch 2369/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2876 - accuracy: 0.7588 - mae: 0.1761 - mse: 0.1082\n",
            "Epoch 2369: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.2917 - accuracy: 0.7573 - mae: 0.1768 - mse: 0.1088 - val_loss: 0.7420 - val_accuracy: 0.6439 - val_mae: 0.2367 - val_mse: 0.1605 - lr: 1.0000e-04\n",
            "Epoch 2370/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2969 - accuracy: 0.7285 - mae: 0.1859 - mse: 0.1171\n",
            "Epoch 2370: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.2952 - accuracy: 0.7298 - mae: 0.1852 - mse: 0.1166 - val_loss: 0.7525 - val_accuracy: 0.6406 - val_mae: 0.2393 - val_mse: 0.1630 - lr: 1.0000e-04\n",
            "Epoch 2371/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.7436 - mae: 0.1837 - mse: 0.1138\n",
            "Epoch 2371: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.3046 - accuracy: 0.7436 - mae: 0.1837 - mse: 0.1138 - val_loss: 0.7513 - val_accuracy: 0.6439 - val_mae: 0.2390 - val_mse: 0.1627 - lr: 1.0000e-04\n",
            "Epoch 2372/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.7330 - mae: 0.1865 - mse: 0.1182\n",
            "Epoch 2372: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3125 - accuracy: 0.7330 - mae: 0.1865 - mse: 0.1182 - val_loss: 0.7476 - val_accuracy: 0.6439 - val_mae: 0.2388 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 2373/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.7376 - mae: 0.1843 - mse: 0.1140\n",
            "Epoch 2373: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3023 - accuracy: 0.7376 - mae: 0.1843 - mse: 0.1140 - val_loss: 0.7426 - val_accuracy: 0.6513 - val_mae: 0.2379 - val_mse: 0.1611 - lr: 1.0000e-04\n",
            "Epoch 2374/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.7372 - mae: 0.1845 - mse: 0.1156\n",
            "Epoch 2374: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.2972 - accuracy: 0.7372 - mae: 0.1845 - mse: 0.1156 - val_loss: 0.7343 - val_accuracy: 0.6535 - val_mae: 0.2358 - val_mse: 0.1591 - lr: 1.0000e-04\n",
            "Epoch 2375/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.7436 - mae: 0.1843 - mse: 0.1150\n",
            "Epoch 2375: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3070 - accuracy: 0.7436 - mae: 0.1843 - mse: 0.1150 - val_loss: 0.7213 - val_accuracy: 0.6535 - val_mae: 0.2329 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2376/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.7486 - mae: 0.1803 - mse: 0.1097\n",
            "Epoch 2376: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.3123 - accuracy: 0.7486 - mae: 0.1803 - mse: 0.1097 - val_loss: 0.7185 - val_accuracy: 0.6567 - val_mae: 0.2325 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 2377/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3007 - accuracy: 0.7339 - mae: 0.1842 - mse: 0.1140\n",
            "Epoch 2377: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 202ms/step - loss: 0.3036 - accuracy: 0.7376 - mae: 0.1829 - mse: 0.1129 - val_loss: 0.7382 - val_accuracy: 0.6449 - val_mae: 0.2375 - val_mse: 0.1609 - lr: 1.0000e-04\n",
            "Epoch 2378/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2935 - accuracy: 0.7305 - mae: 0.1851 - mse: 0.1163\n",
            "Epoch 2378: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2968 - accuracy: 0.7307 - mae: 0.1851 - mse: 0.1163 - val_loss: 0.7624 - val_accuracy: 0.6364 - val_mae: 0.2427 - val_mse: 0.1665 - lr: 1.0000e-04\n",
            "Epoch 2379/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.7206 - mae: 0.1926 - mse: 0.1237\n",
            "Epoch 2379: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 0.3140 - accuracy: 0.7206 - mae: 0.1926 - mse: 0.1237 - val_loss: 0.7699 - val_accuracy: 0.6332 - val_mae: 0.2441 - val_mse: 0.1681 - lr: 1.0000e-04\n",
            "Epoch 2380/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3043 - accuracy: 0.7256 - mae: 0.1892 - mse: 0.1190\n",
            "Epoch 2380: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3039 - accuracy: 0.7248 - mae: 0.1897 - mse: 0.1196 - val_loss: 0.7555 - val_accuracy: 0.6385 - val_mae: 0.2408 - val_mse: 0.1648 - lr: 1.0000e-04\n",
            "Epoch 2381/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3154 - accuracy: 0.7178 - mae: 0.1905 - mse: 0.1215\n",
            "Epoch 2381: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3137 - accuracy: 0.7188 - mae: 0.1896 - mse: 0.1208 - val_loss: 0.7343 - val_accuracy: 0.6439 - val_mae: 0.2363 - val_mse: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 2382/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3020 - accuracy: 0.7275 - mae: 0.1872 - mse: 0.1171\n",
            "Epoch 2382: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2979 - accuracy: 0.7303 - mae: 0.1858 - mse: 0.1159 - val_loss: 0.7131 - val_accuracy: 0.6599 - val_mae: 0.2315 - val_mse: 0.1549 - lr: 1.0000e-04\n",
            "Epoch 2383/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2977 - accuracy: 0.7515 - mae: 0.1768 - mse: 0.1074\n",
            "Epoch 2383: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2954 - accuracy: 0.7537 - mae: 0.1755 - mse: 0.1061 - val_loss: 0.6948 - val_accuracy: 0.6706 - val_mae: 0.2268 - val_mse: 0.1503 - lr: 1.0000e-04\n",
            "Epoch 2384/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3172 - accuracy: 0.7622 - mae: 0.1758 - mse: 0.1049\n",
            "Epoch 2384: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3164 - accuracy: 0.7628 - mae: 0.1760 - mse: 0.1050 - val_loss: 0.7001 - val_accuracy: 0.6674 - val_mae: 0.2282 - val_mse: 0.1516 - lr: 1.0000e-04\n",
            "Epoch 2385/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2995 - accuracy: 0.7563 - mae: 0.1763 - mse: 0.1087\n",
            "Epoch 2385: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2981 - accuracy: 0.7592 - mae: 0.1755 - mse: 0.1078 - val_loss: 0.7132 - val_accuracy: 0.6610 - val_mae: 0.2316 - val_mse: 0.1548 - lr: 1.0000e-04\n",
            "Epoch 2386/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7358 - mae: 0.1811 - mse: 0.1129\n",
            "Epoch 2386: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3062 - accuracy: 0.7358 - mae: 0.1808 - mse: 0.1123 - val_loss: 0.7288 - val_accuracy: 0.6503 - val_mae: 0.2354 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2387/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3034 - accuracy: 0.7446 - mae: 0.1825 - mse: 0.1132\n",
            "Epoch 2387: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3101 - accuracy: 0.7440 - mae: 0.1826 - mse: 0.1133 - val_loss: 0.7488 - val_accuracy: 0.6396 - val_mae: 0.2399 - val_mse: 0.1632 - lr: 1.0000e-04\n",
            "Epoch 2388/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2903 - accuracy: 0.7417 - mae: 0.1837 - mse: 0.1141\n",
            "Epoch 2388: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2909 - accuracy: 0.7353 - mae: 0.1859 - mse: 0.1162 - val_loss: 0.7623 - val_accuracy: 0.6332 - val_mae: 0.2428 - val_mse: 0.1663 - lr: 1.0000e-04\n",
            "Epoch 2389/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3200 - accuracy: 0.7212 - mae: 0.1909 - mse: 0.1235\n",
            "Epoch 2389: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3160 - accuracy: 0.7248 - mae: 0.1886 - mse: 0.1213 - val_loss: 0.7509 - val_accuracy: 0.6364 - val_mae: 0.2405 - val_mse: 0.1638 - lr: 1.0000e-04\n",
            "Epoch 2390/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3060 - accuracy: 0.7251 - mae: 0.1883 - mse: 0.1195\n",
            "Epoch 2390: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3097 - accuracy: 0.7216 - mae: 0.1900 - mse: 0.1211 - val_loss: 0.7431 - val_accuracy: 0.6460 - val_mae: 0.2386 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2391/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3127 - accuracy: 0.7261 - mae: 0.1888 - mse: 0.1197\n",
            "Epoch 2391: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3136 - accuracy: 0.7266 - mae: 0.1891 - mse: 0.1203 - val_loss: 0.7373 - val_accuracy: 0.6492 - val_mae: 0.2374 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2392/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3061 - accuracy: 0.7295 - mae: 0.1847 - mse: 0.1152\n",
            "Epoch 2392: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3061 - accuracy: 0.7294 - mae: 0.1845 - mse: 0.1150 - val_loss: 0.7280 - val_accuracy: 0.6471 - val_mae: 0.2355 - val_mse: 0.1587 - lr: 1.0000e-04\n",
            "Epoch 2393/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3119 - accuracy: 0.7310 - mae: 0.1861 - mse: 0.1175\n",
            "Epoch 2393: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3098 - accuracy: 0.7339 - mae: 0.1848 - mse: 0.1162 - val_loss: 0.7275 - val_accuracy: 0.6417 - val_mae: 0.2356 - val_mse: 0.1586 - lr: 1.0000e-04\n",
            "Epoch 2394/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2965 - accuracy: 0.7422 - mae: 0.1818 - mse: 0.1136\n",
            "Epoch 2394: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2975 - accuracy: 0.7417 - mae: 0.1828 - mse: 0.1144 - val_loss: 0.7252 - val_accuracy: 0.6406 - val_mae: 0.2353 - val_mse: 0.1581 - lr: 1.0000e-04\n",
            "Epoch 2395/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3051 - accuracy: 0.7344 - mae: 0.1823 - mse: 0.1127\n",
            "Epoch 2395: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.3044 - accuracy: 0.7335 - mae: 0.1829 - mse: 0.1130 - val_loss: 0.7170 - val_accuracy: 0.6524 - val_mae: 0.2333 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2396/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.7482 - mae: 0.1786 - mse: 0.1098\n",
            "Epoch 2396: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.3019 - accuracy: 0.7482 - mae: 0.1786 - mse: 0.1098 - val_loss: 0.7074 - val_accuracy: 0.6599 - val_mae: 0.2308 - val_mse: 0.1538 - lr: 1.0000e-04\n",
            "Epoch 2397/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.7482 - mae: 0.1793 - mse: 0.1104\n",
            "Epoch 2397: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3048 - accuracy: 0.7482 - mae: 0.1793 - mse: 0.1104 - val_loss: 0.7040 - val_accuracy: 0.6620 - val_mae: 0.2295 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2398/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.7564 - mae: 0.1757 - mse: 0.1081\n",
            "Epoch 2398: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3001 - accuracy: 0.7564 - mae: 0.1757 - mse: 0.1081 - val_loss: 0.7072 - val_accuracy: 0.6652 - val_mae: 0.2294 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2399/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3029 - accuracy: 0.7681 - mae: 0.1717 - mse: 0.1036\n",
            "Epoch 2399: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3072 - accuracy: 0.7624 - mae: 0.1747 - mse: 0.1060 - val_loss: 0.7229 - val_accuracy: 0.6610 - val_mae: 0.2322 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2400/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.7596 - mae: 0.1780 - mse: 0.1090\n",
            "Epoch 2400: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.2936 - accuracy: 0.7596 - mae: 0.1780 - mse: 0.1090 - val_loss: 0.7301 - val_accuracy: 0.6578 - val_mae: 0.2334 - val_mse: 0.1577 - lr: 1.0000e-04\n",
            "Epoch 2401/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3059 - accuracy: 0.7456 - mae: 0.1790 - mse: 0.1103\n",
            "Epoch 2401: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 0.3060 - accuracy: 0.7431 - mae: 0.1805 - mse: 0.1113 - val_loss: 0.7224 - val_accuracy: 0.6620 - val_mae: 0.2315 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 2402/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3120 - accuracy: 0.7432 - mae: 0.1799 - mse: 0.1116\n",
            "Epoch 2402: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 211ms/step - loss: 0.3067 - accuracy: 0.7468 - mae: 0.1779 - mse: 0.1099 - val_loss: 0.7214 - val_accuracy: 0.6674 - val_mae: 0.2312 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2403/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.7468 - mae: 0.1785 - mse: 0.1105\n",
            "Epoch 2403: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3095 - accuracy: 0.7468 - mae: 0.1785 - mse: 0.1105 - val_loss: 0.7292 - val_accuracy: 0.6599 - val_mae: 0.2333 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2404/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.7450 - mae: 0.1802 - mse: 0.1125\n",
            "Epoch 2404: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.2983 - accuracy: 0.7450 - mae: 0.1802 - mse: 0.1125 - val_loss: 0.7378 - val_accuracy: 0.6545 - val_mae: 0.2352 - val_mse: 0.1592 - lr: 1.0000e-04\n",
            "Epoch 2405/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2956 - accuracy: 0.7480 - mae: 0.1815 - mse: 0.1132\n",
            "Epoch 2405: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 211ms/step - loss: 0.2969 - accuracy: 0.7468 - mae: 0.1814 - mse: 0.1130 - val_loss: 0.7438 - val_accuracy: 0.6513 - val_mae: 0.2368 - val_mse: 0.1607 - lr: 1.0000e-04\n",
            "Epoch 2406/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2935 - accuracy: 0.7344 - mae: 0.1850 - mse: 0.1150\n",
            "Epoch 2406: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2983 - accuracy: 0.7298 - mae: 0.1865 - mse: 0.1167 - val_loss: 0.7396 - val_accuracy: 0.6513 - val_mae: 0.2361 - val_mse: 0.1599 - lr: 1.0000e-04\n",
            "Epoch 2407/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2989 - accuracy: 0.7393 - mae: 0.1822 - mse: 0.1139\n",
            "Epoch 2407: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2981 - accuracy: 0.7417 - mae: 0.1808 - mse: 0.1125 - val_loss: 0.7354 - val_accuracy: 0.6513 - val_mae: 0.2360 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2408/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3008 - accuracy: 0.7354 - mae: 0.1810 - mse: 0.1124\n",
            "Epoch 2408: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2975 - accuracy: 0.7317 - mae: 0.1823 - mse: 0.1137 - val_loss: 0.7260 - val_accuracy: 0.6513 - val_mae: 0.2348 - val_mse: 0.1580 - lr: 1.0000e-04\n",
            "Epoch 2409/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2933 - accuracy: 0.7471 - mae: 0.1799 - mse: 0.1123\n",
            "Epoch 2409: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2971 - accuracy: 0.7491 - mae: 0.1800 - mse: 0.1123 - val_loss: 0.7046 - val_accuracy: 0.6610 - val_mae: 0.2302 - val_mse: 0.1533 - lr: 1.0000e-04\n",
            "Epoch 2410/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3055 - accuracy: 0.7461 - mae: 0.1786 - mse: 0.1104\n",
            "Epoch 2410: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.3178 - accuracy: 0.7376 - mae: 0.1818 - mse: 0.1127 - val_loss: 0.7068 - val_accuracy: 0.6556 - val_mae: 0.2315 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2411/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3113 - accuracy: 0.7422 - mae: 0.1805 - mse: 0.1123\n",
            "Epoch 2411: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3119 - accuracy: 0.7413 - mae: 0.1812 - mse: 0.1121 - val_loss: 0.7302 - val_accuracy: 0.6428 - val_mae: 0.2379 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2412/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3047 - accuracy: 0.7266 - mae: 0.1895 - mse: 0.1190\n",
            "Epoch 2412: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3021 - accuracy: 0.7280 - mae: 0.1882 - mse: 0.1179 - val_loss: 0.7459 - val_accuracy: 0.6332 - val_mae: 0.2416 - val_mse: 0.1645 - lr: 1.0000e-04\n",
            "Epoch 2413/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2933 - accuracy: 0.7261 - mae: 0.1900 - mse: 0.1204\n",
            "Epoch 2413: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2976 - accuracy: 0.7271 - mae: 0.1894 - mse: 0.1200 - val_loss: 0.7473 - val_accuracy: 0.6342 - val_mae: 0.2413 - val_mse: 0.1645 - lr: 1.0000e-04\n",
            "Epoch 2414/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3026 - accuracy: 0.7183 - mae: 0.1920 - mse: 0.1214\n",
            "Epoch 2414: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3019 - accuracy: 0.7202 - mae: 0.1905 - mse: 0.1204 - val_loss: 0.7482 - val_accuracy: 0.6332 - val_mae: 0.2416 - val_mse: 0.1647 - lr: 1.0000e-04\n",
            "Epoch 2415/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3217 - accuracy: 0.7119 - mae: 0.1956 - mse: 0.1255\n",
            "Epoch 2415: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3226 - accuracy: 0.7128 - mae: 0.1947 - mse: 0.1249 - val_loss: 0.7534 - val_accuracy: 0.6353 - val_mae: 0.2428 - val_mse: 0.1658 - lr: 1.0000e-04\n",
            "Epoch 2416/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3047 - accuracy: 0.7212 - mae: 0.1913 - mse: 0.1228\n",
            "Epoch 2416: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3074 - accuracy: 0.7179 - mae: 0.1932 - mse: 0.1241 - val_loss: 0.7412 - val_accuracy: 0.6417 - val_mae: 0.2403 - val_mse: 0.1630 - lr: 1.0000e-04\n",
            "Epoch 2417/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3070 - accuracy: 0.7236 - mae: 0.1879 - mse: 0.1177\n",
            "Epoch 2417: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3089 - accuracy: 0.7211 - mae: 0.1891 - mse: 0.1187 - val_loss: 0.7188 - val_accuracy: 0.6471 - val_mae: 0.2356 - val_mse: 0.1578 - lr: 1.0000e-04\n",
            "Epoch 2418/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3078 - accuracy: 0.7412 - mae: 0.1821 - mse: 0.1117\n",
            "Epoch 2418: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3080 - accuracy: 0.7376 - mae: 0.1837 - mse: 0.1130 - val_loss: 0.6986 - val_accuracy: 0.6567 - val_mae: 0.2308 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2419/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2861 - accuracy: 0.7583 - mae: 0.1738 - mse: 0.1037\n",
            "Epoch 2419: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2853 - accuracy: 0.7541 - mae: 0.1754 - mse: 0.1046 - val_loss: 0.6779 - val_accuracy: 0.6642 - val_mae: 0.2251 - val_mse: 0.1477 - lr: 1.0000e-04\n",
            "Epoch 2420/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2888 - accuracy: 0.7725 - mae: 0.1692 - mse: 0.1005\n",
            "Epoch 2420: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.2884 - accuracy: 0.7693 - mae: 0.1700 - mse: 0.1008 - val_loss: 0.6707 - val_accuracy: 0.6684 - val_mae: 0.2222 - val_mse: 0.1455 - lr: 1.0000e-04\n",
            "Epoch 2421/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2878 - accuracy: 0.7700 - mae: 0.1706 - mse: 0.1002\n",
            "Epoch 2421: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2878 - accuracy: 0.7720 - mae: 0.1695 - mse: 0.0995 - val_loss: 0.6774 - val_accuracy: 0.6663 - val_mae: 0.2231 - val_mse: 0.1468 - lr: 1.0000e-04\n",
            "Epoch 2422/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3023 - accuracy: 0.7583 - mae: 0.1719 - mse: 0.1029\n",
            "Epoch 2422: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.3024 - accuracy: 0.7560 - mae: 0.1726 - mse: 0.1037 - val_loss: 0.7007 - val_accuracy: 0.6545 - val_mae: 0.2290 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2423/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.7528 - mae: 0.1750 - mse: 0.1075\n",
            "Epoch 2423: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3073 - accuracy: 0.7528 - mae: 0.1750 - mse: 0.1075 - val_loss: 0.7364 - val_accuracy: 0.6310 - val_mae: 0.2393 - val_mse: 0.1620 - lr: 1.0000e-04\n",
            "Epoch 2424/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.7294 - mae: 0.1926 - mse: 0.1213\n",
            "Epoch 2424: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.3079 - accuracy: 0.7294 - mae: 0.1926 - mse: 0.1213 - val_loss: 0.7839 - val_accuracy: 0.6118 - val_mae: 0.2523 - val_mse: 0.1737 - lr: 1.0000e-04\n",
            "Epoch 2425/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.7018 - mae: 0.2002 - mse: 0.1311\n",
            "Epoch 2425: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3187 - accuracy: 0.7018 - mae: 0.2002 - mse: 0.1311 - val_loss: 0.7813 - val_accuracy: 0.6107 - val_mae: 0.2533 - val_mse: 0.1735 - lr: 1.0000e-04\n",
            "Epoch 2426/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.7055 - mae: 0.2006 - mse: 0.1302\n",
            "Epoch 2426: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3085 - accuracy: 0.7055 - mae: 0.2006 - mse: 0.1302 - val_loss: 0.7457 - val_accuracy: 0.6257 - val_mae: 0.2462 - val_mse: 0.1656 - lr: 1.0000e-04\n",
            "Epoch 2427/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3112 - accuracy: 0.7168 - mae: 0.1954 - mse: 0.1230\n",
            "Epoch 2427: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.3089 - accuracy: 0.7174 - mae: 0.1956 - mse: 0.1228 - val_loss: 0.6960 - val_accuracy: 0.6524 - val_mae: 0.2343 - val_mse: 0.1536 - lr: 1.0000e-04\n",
            "Epoch 2428/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.7500 - mae: 0.1827 - mse: 0.1098\n",
            "Epoch 2428: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3189 - accuracy: 0.7500 - mae: 0.1827 - mse: 0.1098 - val_loss: 0.6704 - val_accuracy: 0.6674 - val_mae: 0.2265 - val_mse: 0.1467 - lr: 1.0000e-04\n",
            "Epoch 2429/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.7642 - mae: 0.1718 - mse: 0.0996\n",
            "Epoch 2429: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 0.3042 - accuracy: 0.7642 - mae: 0.1718 - mse: 0.0996 - val_loss: 0.6817 - val_accuracy: 0.6695 - val_mae: 0.2274 - val_mse: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 2430/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2975 - accuracy: 0.7588 - mae: 0.1761 - mse: 0.1062\n",
            "Epoch 2430: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.3036 - accuracy: 0.7592 - mae: 0.1757 - mse: 0.1060 - val_loss: 0.7096 - val_accuracy: 0.6567 - val_mae: 0.2322 - val_mse: 0.1548 - lr: 1.0000e-04\n",
            "Epoch 2431/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3018 - accuracy: 0.7412 - mae: 0.1838 - mse: 0.1161\n",
            "Epoch 2431: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3059 - accuracy: 0.7381 - mae: 0.1851 - mse: 0.1166 - val_loss: 0.7470 - val_accuracy: 0.6310 - val_mae: 0.2403 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2432/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2986 - accuracy: 0.7168 - mae: 0.1890 - mse: 0.1214\n",
            "Epoch 2432: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 199ms/step - loss: 0.2970 - accuracy: 0.7174 - mae: 0.1892 - mse: 0.1215 - val_loss: 0.7594 - val_accuracy: 0.6267 - val_mae: 0.2430 - val_mse: 0.1661 - lr: 1.0000e-04\n",
            "Epoch 2433/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3153 - accuracy: 0.7080 - mae: 0.1948 - mse: 0.1246\n",
            "Epoch 2433: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.3130 - accuracy: 0.7096 - mae: 0.1942 - mse: 0.1240 - val_loss: 0.7442 - val_accuracy: 0.6342 - val_mae: 0.2398 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2434/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3014 - accuracy: 0.7324 - mae: 0.1843 - mse: 0.1158\n",
            "Epoch 2434: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2978 - accuracy: 0.7326 - mae: 0.1845 - mse: 0.1154 - val_loss: 0.7165 - val_accuracy: 0.6610 - val_mae: 0.2331 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2435/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3000 - accuracy: 0.7456 - mae: 0.1791 - mse: 0.1107\n",
            "Epoch 2435: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3057 - accuracy: 0.7431 - mae: 0.1801 - mse: 0.1110 - val_loss: 0.6961 - val_accuracy: 0.6684 - val_mae: 0.2279 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2436/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3026 - accuracy: 0.7549 - mae: 0.1743 - mse: 0.1057\n",
            "Epoch 2436: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.3031 - accuracy: 0.7550 - mae: 0.1746 - mse: 0.1056 - val_loss: 0.7036 - val_accuracy: 0.6631 - val_mae: 0.2301 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2437/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2983 - accuracy: 0.7529 - mae: 0.1781 - mse: 0.1088\n",
            "Epoch 2437: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2968 - accuracy: 0.7509 - mae: 0.1790 - mse: 0.1097 - val_loss: 0.7189 - val_accuracy: 0.6588 - val_mae: 0.2331 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2438/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3012 - accuracy: 0.7422 - mae: 0.1829 - mse: 0.1123\n",
            "Epoch 2438: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2995 - accuracy: 0.7427 - mae: 0.1822 - mse: 0.1120 - val_loss: 0.7239 - val_accuracy: 0.6556 - val_mae: 0.2337 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2439/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2883 - accuracy: 0.7549 - mae: 0.1781 - mse: 0.1088\n",
            "Epoch 2439: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2892 - accuracy: 0.7537 - mae: 0.1784 - mse: 0.1092 - val_loss: 0.7224 - val_accuracy: 0.6524 - val_mae: 0.2332 - val_mse: 0.1568 - lr: 1.0000e-04\n",
            "Epoch 2440/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.7482 - mae: 0.1782 - mse: 0.1113\n",
            "Epoch 2440: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2925 - accuracy: 0.7482 - mae: 0.1782 - mse: 0.1113 - val_loss: 0.7135 - val_accuracy: 0.6610 - val_mae: 0.2308 - val_mse: 0.1547 - lr: 1.0000e-04\n",
            "Epoch 2441/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2893 - accuracy: 0.7578 - mae: 0.1754 - mse: 0.1076\n",
            "Epoch 2441: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2897 - accuracy: 0.7560 - mae: 0.1758 - mse: 0.1082 - val_loss: 0.6981 - val_accuracy: 0.6631 - val_mae: 0.2270 - val_mse: 0.1509 - lr: 1.0000e-04\n",
            "Epoch 2442/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2952 - accuracy: 0.7471 - mae: 0.1760 - mse: 0.1076\n",
            "Epoch 2442: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2986 - accuracy: 0.7495 - mae: 0.1765 - mse: 0.1082 - val_loss: 0.6928 - val_accuracy: 0.6706 - val_mae: 0.2254 - val_mse: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 2443/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.7743 - mae: 0.1689 - mse: 0.1015\n",
            "Epoch 2443: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.2927 - accuracy: 0.7743 - mae: 0.1689 - mse: 0.1015 - val_loss: 0.7038 - val_accuracy: 0.6674 - val_mae: 0.2277 - val_mse: 0.1516 - lr: 1.0000e-04\n",
            "Epoch 2444/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3038 - accuracy: 0.7549 - mae: 0.1767 - mse: 0.1078\n",
            "Epoch 2444: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3002 - accuracy: 0.7555 - mae: 0.1759 - mse: 0.1074 - val_loss: 0.7119 - val_accuracy: 0.6695 - val_mae: 0.2292 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2445/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3126 - accuracy: 0.7471 - mae: 0.1781 - mse: 0.1091\n",
            "Epoch 2445: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.3146 - accuracy: 0.7486 - mae: 0.1781 - mse: 0.1085 - val_loss: 0.7211 - val_accuracy: 0.6674 - val_mae: 0.2313 - val_mse: 0.1553 - lr: 1.0000e-04\n",
            "Epoch 2446/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2903 - accuracy: 0.7549 - mae: 0.1765 - mse: 0.1074\n",
            "Epoch 2446: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2896 - accuracy: 0.7541 - mae: 0.1768 - mse: 0.1080 - val_loss: 0.7309 - val_accuracy: 0.6610 - val_mae: 0.2343 - val_mse: 0.1579 - lr: 1.0000e-04\n",
            "Epoch 2447/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2886 - accuracy: 0.7461 - mae: 0.1773 - mse: 0.1089\n",
            "Epoch 2447: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2895 - accuracy: 0.7459 - mae: 0.1777 - mse: 0.1090 - val_loss: 0.7250 - val_accuracy: 0.6599 - val_mae: 0.2336 - val_mse: 0.1569 - lr: 1.0000e-04\n",
            "Epoch 2448/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3010 - accuracy: 0.7354 - mae: 0.1811 - mse: 0.1130\n",
            "Epoch 2448: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3020 - accuracy: 0.7367 - mae: 0.1809 - mse: 0.1124 - val_loss: 0.7200 - val_accuracy: 0.6535 - val_mae: 0.2329 - val_mse: 0.1560 - lr: 1.0000e-04\n",
            "Epoch 2449/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3104 - accuracy: 0.7329 - mae: 0.1838 - mse: 0.1144\n",
            "Epoch 2449: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3097 - accuracy: 0.7335 - mae: 0.1829 - mse: 0.1139 - val_loss: 0.7306 - val_accuracy: 0.6417 - val_mae: 0.2355 - val_mse: 0.1586 - lr: 1.0000e-04\n",
            "Epoch 2450/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2885 - accuracy: 0.7407 - mae: 0.1827 - mse: 0.1135\n",
            "Epoch 2450: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.2871 - accuracy: 0.7436 - mae: 0.1810 - mse: 0.1122 - val_loss: 0.7376 - val_accuracy: 0.6374 - val_mae: 0.2373 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2451/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2966 - accuracy: 0.7329 - mae: 0.1870 - mse: 0.1171\n",
            "Epoch 2451: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2961 - accuracy: 0.7312 - mae: 0.1870 - mse: 0.1172 - val_loss: 0.7328 - val_accuracy: 0.6556 - val_mae: 0.2357 - val_mse: 0.1588 - lr: 1.0000e-04\n",
            "Epoch 2452/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2935 - accuracy: 0.7393 - mae: 0.1832 - mse: 0.1135\n",
            "Epoch 2452: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.2953 - accuracy: 0.7413 - mae: 0.1826 - mse: 0.1128 - val_loss: 0.7230 - val_accuracy: 0.6717 - val_mae: 0.2323 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2453/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.7399 - mae: 0.1809 - mse: 0.1127\n",
            "Epoch 2453: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3091 - accuracy: 0.7399 - mae: 0.1809 - mse: 0.1127 - val_loss: 0.7231 - val_accuracy: 0.6620 - val_mae: 0.2320 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2454/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.7477 - mae: 0.1787 - mse: 0.1098\n",
            "Epoch 2454: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.3032 - accuracy: 0.7477 - mae: 0.1787 - mse: 0.1098 - val_loss: 0.7292 - val_accuracy: 0.6492 - val_mae: 0.2334 - val_mse: 0.1571 - lr: 1.0000e-04\n",
            "Epoch 2455/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.7486 - mae: 0.1822 - mse: 0.1126\n",
            "Epoch 2455: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3049 - accuracy: 0.7486 - mae: 0.1822 - mse: 0.1126 - val_loss: 0.7281 - val_accuracy: 0.6460 - val_mae: 0.2325 - val_mse: 0.1567 - lr: 1.0000e-04\n",
            "Epoch 2456/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.7431 - mae: 0.1791 - mse: 0.1109\n",
            "Epoch 2456: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3035 - accuracy: 0.7431 - mae: 0.1791 - mse: 0.1109 - val_loss: 0.7248 - val_accuracy: 0.6503 - val_mae: 0.2315 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2457/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.7367 - mae: 0.1822 - mse: 0.1159\n",
            "Epoch 2457: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.3252 - accuracy: 0.7367 - mae: 0.1822 - mse: 0.1159 - val_loss: 0.7363 - val_accuracy: 0.6406 - val_mae: 0.2350 - val_mse: 0.1591 - lr: 1.0000e-04\n",
            "Epoch 2458/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2983 - accuracy: 0.7378 - mae: 0.1835 - mse: 0.1149\n",
            "Epoch 2458: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.2938 - accuracy: 0.7394 - mae: 0.1827 - mse: 0.1148 - val_loss: 0.7227 - val_accuracy: 0.6481 - val_mae: 0.2322 - val_mse: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 2459/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.7541 - mae: 0.1767 - mse: 0.1089\n",
            "Epoch 2459: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.2899 - accuracy: 0.7541 - mae: 0.1767 - mse: 0.1089 - val_loss: 0.6969 - val_accuracy: 0.6652 - val_mae: 0.2259 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2460/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2785 - accuracy: 0.7646 - mae: 0.1698 - mse: 0.1033\n",
            "Epoch 2460: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2812 - accuracy: 0.7651 - mae: 0.1697 - mse: 0.1029 - val_loss: 0.6837 - val_accuracy: 0.6674 - val_mae: 0.2218 - val_mse: 0.1466 - lr: 1.0000e-04\n",
            "Epoch 2461/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2972 - accuracy: 0.7593 - mae: 0.1677 - mse: 0.0999\n",
            "Epoch 2461: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2954 - accuracy: 0.7610 - mae: 0.1682 - mse: 0.1002 - val_loss: 0.6921 - val_accuracy: 0.6674 - val_mae: 0.2234 - val_mse: 0.1486 - lr: 1.0000e-04\n",
            "Epoch 2462/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3042 - accuracy: 0.7568 - mae: 0.1724 - mse: 0.1054\n",
            "Epoch 2462: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.3032 - accuracy: 0.7560 - mae: 0.1742 - mse: 0.1066 - val_loss: 0.7038 - val_accuracy: 0.6663 - val_mae: 0.2262 - val_mse: 0.1515 - lr: 1.0000e-04\n",
            "Epoch 2463/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3051 - accuracy: 0.7568 - mae: 0.1758 - mse: 0.1076\n",
            "Epoch 2463: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3091 - accuracy: 0.7550 - mae: 0.1770 - mse: 0.1084 - val_loss: 0.7131 - val_accuracy: 0.6642 - val_mae: 0.2291 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Epoch 2464/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3054 - accuracy: 0.7515 - mae: 0.1780 - mse: 0.1108\n",
            "Epoch 2464: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.3038 - accuracy: 0.7472 - mae: 0.1792 - mse: 0.1117 - val_loss: 0.7214 - val_accuracy: 0.6556 - val_mae: 0.2319 - val_mse: 0.1567 - lr: 1.0000e-04\n",
            "Epoch 2465/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2913 - accuracy: 0.7544 - mae: 0.1769 - mse: 0.1088\n",
            "Epoch 2465: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2882 - accuracy: 0.7578 - mae: 0.1757 - mse: 0.1080 - val_loss: 0.7182 - val_accuracy: 0.6578 - val_mae: 0.2313 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2466/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2923 - accuracy: 0.7500 - mae: 0.1791 - mse: 0.1115\n",
            "Epoch 2466: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2909 - accuracy: 0.7505 - mae: 0.1786 - mse: 0.1111 - val_loss: 0.7101 - val_accuracy: 0.6610 - val_mae: 0.2296 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 2467/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2952 - accuracy: 0.7529 - mae: 0.1769 - mse: 0.1089\n",
            "Epoch 2467: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2942 - accuracy: 0.7523 - mae: 0.1770 - mse: 0.1089 - val_loss: 0.7027 - val_accuracy: 0.6684 - val_mae: 0.2278 - val_mse: 0.1519 - lr: 1.0000e-04\n",
            "Epoch 2468/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2880 - accuracy: 0.7559 - mae: 0.1748 - mse: 0.1063\n",
            "Epoch 2468: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2959 - accuracy: 0.7569 - mae: 0.1740 - mse: 0.1056 - val_loss: 0.7109 - val_accuracy: 0.6674 - val_mae: 0.2288 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2469/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3068 - accuracy: 0.7305 - mae: 0.1840 - mse: 0.1158\n",
            "Epoch 2469: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3038 - accuracy: 0.7335 - mae: 0.1827 - mse: 0.1148 - val_loss: 0.7335 - val_accuracy: 0.6567 - val_mae: 0.2337 - val_mse: 0.1586 - lr: 1.0000e-04\n",
            "Epoch 2470/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2977 - accuracy: 0.7358 - mae: 0.1814 - mse: 0.1145\n",
            "Epoch 2470: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2951 - accuracy: 0.7376 - mae: 0.1809 - mse: 0.1140 - val_loss: 0.7355 - val_accuracy: 0.6556 - val_mae: 0.2349 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2471/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2969 - accuracy: 0.7397 - mae: 0.1817 - mse: 0.1143\n",
            "Epoch 2471: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2999 - accuracy: 0.7390 - mae: 0.1813 - mse: 0.1136 - val_loss: 0.7288 - val_accuracy: 0.6599 - val_mae: 0.2340 - val_mse: 0.1582 - lr: 1.0000e-04\n",
            "Epoch 2472/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2807 - accuracy: 0.7378 - mae: 0.1801 - mse: 0.1131\n",
            "Epoch 2472: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2834 - accuracy: 0.7376 - mae: 0.1812 - mse: 0.1139 - val_loss: 0.7205 - val_accuracy: 0.6631 - val_mae: 0.2325 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2473/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.7514 - mae: 0.1787 - mse: 0.1096\n",
            "Epoch 2473: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 217ms/step - loss: 0.2828 - accuracy: 0.7514 - mae: 0.1787 - mse: 0.1096 - val_loss: 0.7035 - val_accuracy: 0.6684 - val_mae: 0.2288 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2474/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2940 - accuracy: 0.7466 - mae: 0.1786 - mse: 0.1102\n",
            "Epoch 2474: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2945 - accuracy: 0.7450 - mae: 0.1789 - mse: 0.1108 - val_loss: 0.6928 - val_accuracy: 0.6706 - val_mae: 0.2256 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2475/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2955 - accuracy: 0.7593 - mae: 0.1740 - mse: 0.1058\n",
            "Epoch 2475: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2959 - accuracy: 0.7573 - mae: 0.1748 - mse: 0.1070 - val_loss: 0.6902 - val_accuracy: 0.6684 - val_mae: 0.2245 - val_mse: 0.1492 - lr: 1.0000e-04\n",
            "Epoch 2476/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.7606 - mae: 0.1732 - mse: 0.1056\n",
            "Epoch 2476: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 0.3098 - accuracy: 0.7606 - mae: 0.1732 - mse: 0.1056 - val_loss: 0.6854 - val_accuracy: 0.6695 - val_mae: 0.2235 - val_mse: 0.1481 - lr: 1.0000e-04\n",
            "Epoch 2477/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2995 - accuracy: 0.7554 - mae: 0.1709 - mse: 0.1045\n",
            "Epoch 2477: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.2989 - accuracy: 0.7541 - mae: 0.1716 - mse: 0.1054 - val_loss: 0.6819 - val_accuracy: 0.6759 - val_mae: 0.2229 - val_mse: 0.1473 - lr: 1.0000e-04\n",
            "Epoch 2478/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2901 - accuracy: 0.7490 - mae: 0.1765 - mse: 0.1085\n",
            "Epoch 2478: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.2918 - accuracy: 0.7523 - mae: 0.1758 - mse: 0.1080 - val_loss: 0.6817 - val_accuracy: 0.6727 - val_mae: 0.2230 - val_mse: 0.1473 - lr: 1.0000e-04\n",
            "Epoch 2479/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3024 - accuracy: 0.7642 - mae: 0.1722 - mse: 0.1039\n",
            "Epoch 2479: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.2990 - accuracy: 0.7638 - mae: 0.1724 - mse: 0.1040 - val_loss: 0.6962 - val_accuracy: 0.6663 - val_mae: 0.2264 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2480/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.7532 - mae: 0.1728 - mse: 0.1043\n",
            "Epoch 2480: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.2993 - accuracy: 0.7532 - mae: 0.1728 - mse: 0.1043 - val_loss: 0.7139 - val_accuracy: 0.6556 - val_mae: 0.2306 - val_mse: 0.1548 - lr: 1.0000e-04\n",
            "Epoch 2481/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.7317 - mae: 0.1825 - mse: 0.1141\n",
            "Epoch 2481: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3099 - accuracy: 0.7317 - mae: 0.1825 - mse: 0.1141 - val_loss: 0.7300 - val_accuracy: 0.6471 - val_mae: 0.2344 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2482/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.7399 - mae: 0.1802 - mse: 0.1127\n",
            "Epoch 2482: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.2907 - accuracy: 0.7399 - mae: 0.1802 - mse: 0.1127 - val_loss: 0.7342 - val_accuracy: 0.6492 - val_mae: 0.2350 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2483/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.7385 - mae: 0.1812 - mse: 0.1136\n",
            "Epoch 2483: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2942 - accuracy: 0.7385 - mae: 0.1812 - mse: 0.1136 - val_loss: 0.7394 - val_accuracy: 0.6481 - val_mae: 0.2359 - val_mse: 0.1602 - lr: 1.0000e-04\n",
            "Epoch 2484/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2949 - accuracy: 0.7461 - mae: 0.1821 - mse: 0.1137\n",
            "Epoch 2484: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.2977 - accuracy: 0.7431 - mae: 0.1834 - mse: 0.1150 - val_loss: 0.7366 - val_accuracy: 0.6481 - val_mae: 0.2355 - val_mse: 0.1596 - lr: 1.0000e-04\n",
            "Epoch 2485/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.7472 - mae: 0.1797 - mse: 0.1117\n",
            "Epoch 2485: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 0.2905 - accuracy: 0.7472 - mae: 0.1797 - mse: 0.1117 - val_loss: 0.7266 - val_accuracy: 0.6524 - val_mae: 0.2334 - val_mse: 0.1574 - lr: 1.0000e-04\n",
            "Epoch 2486/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.7358 - mae: 0.1804 - mse: 0.1122\n",
            "Epoch 2486: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.2854 - accuracy: 0.7358 - mae: 0.1804 - mse: 0.1122 - val_loss: 0.7144 - val_accuracy: 0.6513 - val_mae: 0.2304 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2487/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2968 - accuracy: 0.7588 - mae: 0.1741 - mse: 0.1070\n",
            "Epoch 2487: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2970 - accuracy: 0.7550 - mae: 0.1759 - mse: 0.1087 - val_loss: 0.7113 - val_accuracy: 0.6610 - val_mae: 0.2298 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2488/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2894 - accuracy: 0.7412 - mae: 0.1778 - mse: 0.1098\n",
            "Epoch 2488: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2921 - accuracy: 0.7436 - mae: 0.1773 - mse: 0.1094 - val_loss: 0.7112 - val_accuracy: 0.6599 - val_mae: 0.2296 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2489/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3052 - accuracy: 0.7422 - mae: 0.1787 - mse: 0.1097\n",
            "Epoch 2489: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3047 - accuracy: 0.7436 - mae: 0.1779 - mse: 0.1092 - val_loss: 0.7266 - val_accuracy: 0.6460 - val_mae: 0.2328 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2490/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2866 - accuracy: 0.7451 - mae: 0.1784 - mse: 0.1115\n",
            "Epoch 2490: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.2875 - accuracy: 0.7445 - mae: 0.1781 - mse: 0.1115 - val_loss: 0.7337 - val_accuracy: 0.6503 - val_mae: 0.2343 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2491/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2872 - accuracy: 0.7412 - mae: 0.1763 - mse: 0.1102\n",
            "Epoch 2491: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2875 - accuracy: 0.7390 - mae: 0.1771 - mse: 0.1105 - val_loss: 0.7351 - val_accuracy: 0.6513 - val_mae: 0.2348 - val_mse: 0.1592 - lr: 1.0000e-04\n",
            "Epoch 2492/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2841 - accuracy: 0.7363 - mae: 0.1822 - mse: 0.1145\n",
            "Epoch 2492: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.2863 - accuracy: 0.7385 - mae: 0.1812 - mse: 0.1139 - val_loss: 0.7353 - val_accuracy: 0.6513 - val_mae: 0.2352 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2493/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3027 - accuracy: 0.7305 - mae: 0.1866 - mse: 0.1178\n",
            "Epoch 2493: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3026 - accuracy: 0.7330 - mae: 0.1862 - mse: 0.1174 - val_loss: 0.7346 - val_accuracy: 0.6513 - val_mae: 0.2353 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2494/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2999 - accuracy: 0.7441 - mae: 0.1822 - mse: 0.1141\n",
            "Epoch 2494: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3031 - accuracy: 0.7417 - mae: 0.1833 - mse: 0.1147 - val_loss: 0.7275 - val_accuracy: 0.6524 - val_mae: 0.2342 - val_mse: 0.1582 - lr: 1.0000e-04\n",
            "Epoch 2495/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3055 - accuracy: 0.7368 - mae: 0.1836 - mse: 0.1140\n",
            "Epoch 2495: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3068 - accuracy: 0.7330 - mae: 0.1848 - mse: 0.1150 - val_loss: 0.7267 - val_accuracy: 0.6471 - val_mae: 0.2343 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2496/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2992 - accuracy: 0.7344 - mae: 0.1841 - mse: 0.1143\n",
            "Epoch 2496: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2983 - accuracy: 0.7326 - mae: 0.1850 - mse: 0.1150 - val_loss: 0.7142 - val_accuracy: 0.6524 - val_mae: 0.2312 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2497/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3048 - accuracy: 0.7314 - mae: 0.1824 - mse: 0.1134\n",
            "Epoch 2497: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3036 - accuracy: 0.7349 - mae: 0.1810 - mse: 0.1122 - val_loss: 0.7035 - val_accuracy: 0.6567 - val_mae: 0.2284 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2498/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2982 - accuracy: 0.7485 - mae: 0.1768 - mse: 0.1090\n",
            "Epoch 2498: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2973 - accuracy: 0.7486 - mae: 0.1759 - mse: 0.1083 - val_loss: 0.6990 - val_accuracy: 0.6567 - val_mae: 0.2272 - val_mse: 0.1517 - lr: 1.0000e-04\n",
            "Epoch 2499/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2997 - accuracy: 0.7485 - mae: 0.1751 - mse: 0.1088\n",
            "Epoch 2499: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 0.3022 - accuracy: 0.7509 - mae: 0.1755 - mse: 0.1090 - val_loss: 0.7097 - val_accuracy: 0.6556 - val_mae: 0.2300 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2500/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2894 - accuracy: 0.7529 - mae: 0.1754 - mse: 0.1092\n",
            "Epoch 2500: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2903 - accuracy: 0.7514 - mae: 0.1767 - mse: 0.1098 - val_loss: 0.7258 - val_accuracy: 0.6449 - val_mae: 0.2335 - val_mse: 0.1580 - lr: 1.0000e-04\n",
            "Epoch 2501/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2865 - accuracy: 0.7427 - mae: 0.1803 - mse: 0.1122\n",
            "Epoch 2501: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2837 - accuracy: 0.7445 - mae: 0.1795 - mse: 0.1121 - val_loss: 0.7235 - val_accuracy: 0.6481 - val_mae: 0.2317 - val_mse: 0.1568 - lr: 1.0000e-04\n",
            "Epoch 2502/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3013 - accuracy: 0.7466 - mae: 0.1801 - mse: 0.1126\n",
            "Epoch 2502: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.3013 - accuracy: 0.7491 - mae: 0.1795 - mse: 0.1121 - val_loss: 0.7116 - val_accuracy: 0.6620 - val_mae: 0.2282 - val_mse: 0.1536 - lr: 1.0000e-04\n",
            "Epoch 2503/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.7615 - mae: 0.1708 - mse: 0.1047\n",
            "Epoch 2503: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.2783 - accuracy: 0.7615 - mae: 0.1708 - mse: 0.1047 - val_loss: 0.7004 - val_accuracy: 0.6706 - val_mae: 0.2248 - val_mse: 0.1506 - lr: 1.0000e-04\n",
            "Epoch 2504/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2954 - accuracy: 0.7632 - mae: 0.1694 - mse: 0.1025\n",
            "Epoch 2504: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.2970 - accuracy: 0.7647 - mae: 0.1681 - mse: 0.1021 - val_loss: 0.7021 - val_accuracy: 0.6706 - val_mae: 0.2249 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2505/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.7583 - mae: 0.1720 - mse: 0.1036\n",
            "Epoch 2505: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.2967 - accuracy: 0.7583 - mae: 0.1720 - mse: 0.1036 - val_loss: 0.7308 - val_accuracy: 0.6567 - val_mae: 0.2316 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2506/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2810 - accuracy: 0.7534 - mae: 0.1741 - mse: 0.1097\n",
            "Epoch 2506: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.2786 - accuracy: 0.7537 - mae: 0.1740 - mse: 0.1094 - val_loss: 0.7594 - val_accuracy: 0.6396 - val_mae: 0.2379 - val_mse: 0.1635 - lr: 1.0000e-04\n",
            "Epoch 2507/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.7399 - mae: 0.1803 - mse: 0.1144\n",
            "Epoch 2507: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.2976 - accuracy: 0.7399 - mae: 0.1803 - mse: 0.1144 - val_loss: 0.7671 - val_accuracy: 0.6385 - val_mae: 0.2400 - val_mse: 0.1653 - lr: 1.0000e-04\n",
            "Epoch 2508/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2979 - accuracy: 0.7461 - mae: 0.1854 - mse: 0.1177\n",
            "Epoch 2508: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.2977 - accuracy: 0.7450 - mae: 0.1848 - mse: 0.1169 - val_loss: 0.7619 - val_accuracy: 0.6353 - val_mae: 0.2398 - val_mse: 0.1647 - lr: 1.0000e-04\n",
            "Epoch 2509/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.7394 - mae: 0.1840 - mse: 0.1162\n",
            "Epoch 2509: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.2951 - accuracy: 0.7394 - mae: 0.1840 - mse: 0.1162 - val_loss: 0.7496 - val_accuracy: 0.6396 - val_mae: 0.2374 - val_mse: 0.1622 - lr: 1.0000e-04\n",
            "Epoch 2510/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.7422 - mae: 0.1838 - mse: 0.1144\n",
            "Epoch 2510: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.2957 - accuracy: 0.7422 - mae: 0.1838 - mse: 0.1144 - val_loss: 0.7292 - val_accuracy: 0.6449 - val_mae: 0.2327 - val_mse: 0.1576 - lr: 1.0000e-04\n",
            "Epoch 2511/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.7454 - mae: 0.1807 - mse: 0.1134\n",
            "Epoch 2511: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.2970 - accuracy: 0.7454 - mae: 0.1807 - mse: 0.1134 - val_loss: 0.7018 - val_accuracy: 0.6652 - val_mae: 0.2258 - val_mse: 0.1511 - lr: 1.0000e-04\n",
            "Epoch 2512/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.7518 - mae: 0.1735 - mse: 0.1063\n",
            "Epoch 2512: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.2969 - accuracy: 0.7518 - mae: 0.1735 - mse: 0.1063 - val_loss: 0.6919 - val_accuracy: 0.6684 - val_mae: 0.2233 - val_mse: 0.1486 - lr: 1.0000e-04\n",
            "Epoch 2513/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2891 - accuracy: 0.7681 - mae: 0.1677 - mse: 0.1017\n",
            "Epoch 2513: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.2888 - accuracy: 0.7674 - mae: 0.1685 - mse: 0.1024 - val_loss: 0.6935 - val_accuracy: 0.6674 - val_mae: 0.2236 - val_mse: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 2514/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3029 - accuracy: 0.7598 - mae: 0.1714 - mse: 0.1031\n",
            "Epoch 2514: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 0.2993 - accuracy: 0.7601 - mae: 0.1708 - mse: 0.1029 - val_loss: 0.7041 - val_accuracy: 0.6588 - val_mae: 0.2271 - val_mse: 0.1516 - lr: 1.0000e-04\n",
            "Epoch 2515/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2905 - accuracy: 0.7612 - mae: 0.1712 - mse: 0.1034\n",
            "Epoch 2515: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2878 - accuracy: 0.7633 - mae: 0.1702 - mse: 0.1028 - val_loss: 0.7193 - val_accuracy: 0.6556 - val_mae: 0.2310 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2516/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.7509 - mae: 0.1748 - mse: 0.1074\n",
            "Epoch 2516: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.2895 - accuracy: 0.7509 - mae: 0.1748 - mse: 0.1074 - val_loss: 0.7297 - val_accuracy: 0.6481 - val_mae: 0.2336 - val_mse: 0.1578 - lr: 1.0000e-04\n",
            "Epoch 2517/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2864 - accuracy: 0.7480 - mae: 0.1776 - mse: 0.1095\n",
            "Epoch 2517: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2849 - accuracy: 0.7463 - mae: 0.1783 - mse: 0.1104 - val_loss: 0.7246 - val_accuracy: 0.6481 - val_mae: 0.2324 - val_mse: 0.1567 - lr: 1.0000e-04\n",
            "Epoch 2518/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2848 - accuracy: 0.7490 - mae: 0.1773 - mse: 0.1097\n",
            "Epoch 2518: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2863 - accuracy: 0.7477 - mae: 0.1776 - mse: 0.1099 - val_loss: 0.7052 - val_accuracy: 0.6578 - val_mae: 0.2275 - val_mse: 0.1520 - lr: 1.0000e-04\n",
            "Epoch 2519/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3001 - accuracy: 0.7554 - mae: 0.1723 - mse: 0.1058\n",
            "Epoch 2519: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2955 - accuracy: 0.7550 - mae: 0.1722 - mse: 0.1056 - val_loss: 0.6935 - val_accuracy: 0.6652 - val_mae: 0.2240 - val_mse: 0.1489 - lr: 1.0000e-04\n",
            "Epoch 2520/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.7564 - mae: 0.1714 - mse: 0.1055\n",
            "Epoch 2520: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.2944 - accuracy: 0.7564 - mae: 0.1714 - mse: 0.1055 - val_loss: 0.6896 - val_accuracy: 0.6684 - val_mae: 0.2224 - val_mse: 0.1478 - lr: 1.0000e-04\n",
            "Epoch 2521/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2920 - accuracy: 0.7637 - mae: 0.1677 - mse: 0.1015\n",
            "Epoch 2521: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2904 - accuracy: 0.7665 - mae: 0.1669 - mse: 0.1011 - val_loss: 0.7002 - val_accuracy: 0.6652 - val_mae: 0.2247 - val_mse: 0.1502 - lr: 1.0000e-04\n",
            "Epoch 2522/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2868 - accuracy: 0.7622 - mae: 0.1724 - mse: 0.1057\n",
            "Epoch 2522: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2865 - accuracy: 0.7596 - mae: 0.1728 - mse: 0.1062 - val_loss: 0.7152 - val_accuracy: 0.6695 - val_mae: 0.2276 - val_mse: 0.1533 - lr: 1.0000e-04\n",
            "Epoch 2523/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2994 - accuracy: 0.7515 - mae: 0.1757 - mse: 0.1092\n",
            "Epoch 2523: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3002 - accuracy: 0.7495 - mae: 0.1758 - mse: 0.1096 - val_loss: 0.7299 - val_accuracy: 0.6652 - val_mae: 0.2304 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 2524/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3133 - accuracy: 0.7461 - mae: 0.1812 - mse: 0.1144\n",
            "Epoch 2524: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.3068 - accuracy: 0.7491 - mae: 0.1796 - mse: 0.1130 - val_loss: 0.7452 - val_accuracy: 0.6513 - val_mae: 0.2343 - val_mse: 0.1601 - lr: 1.0000e-04\n",
            "Epoch 2525/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.7459 - mae: 0.1785 - mse: 0.1128\n",
            "Epoch 2525: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.2859 - accuracy: 0.7459 - mae: 0.1785 - mse: 0.1128 - val_loss: 0.7497 - val_accuracy: 0.6524 - val_mae: 0.2356 - val_mse: 0.1612 - lr: 1.0000e-04\n",
            "Epoch 2526/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2877 - accuracy: 0.7295 - mae: 0.1825 - mse: 0.1158\n",
            "Epoch 2526: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2862 - accuracy: 0.7317 - mae: 0.1816 - mse: 0.1151 - val_loss: 0.7505 - val_accuracy: 0.6439 - val_mae: 0.2356 - val_mse: 0.1612 - lr: 1.0000e-04\n",
            "Epoch 2527/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3008 - accuracy: 0.7451 - mae: 0.1820 - mse: 0.1157\n",
            "Epoch 2527: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2975 - accuracy: 0.7459 - mae: 0.1814 - mse: 0.1154 - val_loss: 0.7328 - val_accuracy: 0.6535 - val_mae: 0.2307 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2528/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2905 - accuracy: 0.7563 - mae: 0.1753 - mse: 0.1104\n",
            "Epoch 2528: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2852 - accuracy: 0.7569 - mae: 0.1751 - mse: 0.1099 - val_loss: 0.6956 - val_accuracy: 0.6791 - val_mae: 0.2220 - val_mse: 0.1478 - lr: 1.0000e-04\n",
            "Epoch 2529/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3031 - accuracy: 0.7588 - mae: 0.1732 - mse: 0.1050\n",
            "Epoch 2529: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2982 - accuracy: 0.7624 - mae: 0.1714 - mse: 0.1039 - val_loss: 0.6691 - val_accuracy: 0.6930 - val_mae: 0.2151 - val_mse: 0.1414 - lr: 1.0000e-04\n",
            "Epoch 2530/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3130 - accuracy: 0.7798 - mae: 0.1613 - mse: 0.0964\n",
            "Epoch 2530: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.3117 - accuracy: 0.7771 - mae: 0.1625 - mse: 0.0976 - val_loss: 0.6726 - val_accuracy: 0.6920 - val_mae: 0.2165 - val_mse: 0.1426 - lr: 1.0000e-04\n",
            "Epoch 2531/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3025 - accuracy: 0.7681 - mae: 0.1673 - mse: 0.1004\n",
            "Epoch 2531: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3036 - accuracy: 0.7674 - mae: 0.1672 - mse: 0.1004 - val_loss: 0.7012 - val_accuracy: 0.6749 - val_mae: 0.2250 - val_mse: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 2532/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2828 - accuracy: 0.7593 - mae: 0.1717 - mse: 0.1050\n",
            "Epoch 2532: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.2838 - accuracy: 0.7601 - mae: 0.1714 - mse: 0.1048 - val_loss: 0.7443 - val_accuracy: 0.6492 - val_mae: 0.2357 - val_mse: 0.1605 - lr: 1.0000e-04\n",
            "Epoch 2533/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3084 - accuracy: 0.7310 - mae: 0.1850 - mse: 0.1172\n",
            "Epoch 2533: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.3078 - accuracy: 0.7321 - mae: 0.1857 - mse: 0.1182 - val_loss: 0.7663 - val_accuracy: 0.6364 - val_mae: 0.2406 - val_mse: 0.1656 - lr: 1.0000e-04\n",
            "Epoch 2534/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.7294 - mae: 0.1857 - mse: 0.1184\n",
            "Epoch 2534: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.2964 - accuracy: 0.7294 - mae: 0.1857 - mse: 0.1184 - val_loss: 0.7495 - val_accuracy: 0.6449 - val_mae: 0.2371 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2535/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2995 - accuracy: 0.7441 - mae: 0.1813 - mse: 0.1143\n",
            "Epoch 2535: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 0.3022 - accuracy: 0.7422 - mae: 0.1822 - mse: 0.1150 - val_loss: 0.7133 - val_accuracy: 0.6599 - val_mae: 0.2294 - val_mse: 0.1536 - lr: 1.0000e-04\n",
            "Epoch 2536/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.7679 - mae: 0.1733 - mse: 0.1059\n",
            "Epoch 2536: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 0.2882 - accuracy: 0.7679 - mae: 0.1733 - mse: 0.1059 - val_loss: 0.6916 - val_accuracy: 0.6695 - val_mae: 0.2251 - val_mse: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 2537/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.7606 - mae: 0.1707 - mse: 0.1029\n",
            "Epoch 2537: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.2878 - accuracy: 0.7606 - mae: 0.1707 - mse: 0.1029 - val_loss: 0.6801 - val_accuracy: 0.6706 - val_mae: 0.2224 - val_mse: 0.1460 - lr: 1.0000e-04\n",
            "Epoch 2538/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3152 - accuracy: 0.7715 - mae: 0.1703 - mse: 0.1032\n",
            "Epoch 2538: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3103 - accuracy: 0.7697 - mae: 0.1703 - mse: 0.1035 - val_loss: 0.6854 - val_accuracy: 0.6738 - val_mae: 0.2241 - val_mse: 0.1476 - lr: 1.0000e-04\n",
            "Epoch 2539/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2939 - accuracy: 0.7554 - mae: 0.1718 - mse: 0.1036\n",
            "Epoch 2539: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3028 - accuracy: 0.7537 - mae: 0.1724 - mse: 0.1044 - val_loss: 0.6942 - val_accuracy: 0.6706 - val_mae: 0.2262 - val_mse: 0.1499 - lr: 1.0000e-04\n",
            "Epoch 2540/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.7573 - mae: 0.1724 - mse: 0.1042\n",
            "Epoch 2540: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2942 - accuracy: 0.7573 - mae: 0.1724 - mse: 0.1042 - val_loss: 0.7089 - val_accuracy: 0.6620 - val_mae: 0.2298 - val_mse: 0.1536 - lr: 1.0000e-04\n",
            "Epoch 2541/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3090 - accuracy: 0.7446 - mae: 0.1794 - mse: 0.1103\n",
            "Epoch 2541: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.3078 - accuracy: 0.7440 - mae: 0.1799 - mse: 0.1107 - val_loss: 0.7147 - val_accuracy: 0.6610 - val_mae: 0.2307 - val_mse: 0.1549 - lr: 1.0000e-04\n",
            "Epoch 2542/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2953 - accuracy: 0.7427 - mae: 0.1788 - mse: 0.1107\n",
            "Epoch 2542: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.2937 - accuracy: 0.7450 - mae: 0.1783 - mse: 0.1100 - val_loss: 0.7153 - val_accuracy: 0.6642 - val_mae: 0.2300 - val_mse: 0.1546 - lr: 1.0000e-04\n",
            "Epoch 2543/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2920 - accuracy: 0.7510 - mae: 0.1755 - mse: 0.1086\n",
            "Epoch 2543: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2908 - accuracy: 0.7509 - mae: 0.1756 - mse: 0.1089 - val_loss: 0.7156 - val_accuracy: 0.6567 - val_mae: 0.2294 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2544/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2868 - accuracy: 0.7603 - mae: 0.1738 - mse: 0.1078\n",
            "Epoch 2544: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2906 - accuracy: 0.7596 - mae: 0.1733 - mse: 0.1074 - val_loss: 0.7133 - val_accuracy: 0.6599 - val_mae: 0.2288 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2545/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2960 - accuracy: 0.7427 - mae: 0.1793 - mse: 0.1109\n",
            "Epoch 2545: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2953 - accuracy: 0.7459 - mae: 0.1774 - mse: 0.1094 - val_loss: 0.7263 - val_accuracy: 0.6599 - val_mae: 0.2318 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2546/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2814 - accuracy: 0.7471 - mae: 0.1787 - mse: 0.1110\n",
            "Epoch 2546: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2828 - accuracy: 0.7509 - mae: 0.1777 - mse: 0.1097 - val_loss: 0.7447 - val_accuracy: 0.6556 - val_mae: 0.2354 - val_mse: 0.1601 - lr: 1.0000e-04\n",
            "Epoch 2547/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2882 - accuracy: 0.7363 - mae: 0.1861 - mse: 0.1187\n",
            "Epoch 2547: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2842 - accuracy: 0.7422 - mae: 0.1828 - mse: 0.1161 - val_loss: 0.7549 - val_accuracy: 0.6492 - val_mae: 0.2366 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2548/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2947 - accuracy: 0.7280 - mae: 0.1819 - mse: 0.1156\n",
            "Epoch 2548: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2948 - accuracy: 0.7284 - mae: 0.1826 - mse: 0.1160 - val_loss: 0.7464 - val_accuracy: 0.6471 - val_mae: 0.2342 - val_mse: 0.1597 - lr: 1.0000e-04\n",
            "Epoch 2549/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.7372 - mae: 0.1810 - mse: 0.1149\n",
            "Epoch 2549: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.3040 - accuracy: 0.7372 - mae: 0.1810 - mse: 0.1149 - val_loss: 0.7225 - val_accuracy: 0.6556 - val_mae: 0.2290 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2550/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3026 - accuracy: 0.7559 - mae: 0.1738 - mse: 0.1078\n",
            "Epoch 2550: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2967 - accuracy: 0.7587 - mae: 0.1718 - mse: 0.1061 - val_loss: 0.6955 - val_accuracy: 0.6738 - val_mae: 0.2231 - val_mse: 0.1483 - lr: 1.0000e-04\n",
            "Epoch 2551/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2881 - accuracy: 0.7612 - mae: 0.1685 - mse: 0.1025\n",
            "Epoch 2551: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2895 - accuracy: 0.7661 - mae: 0.1672 - mse: 0.1009 - val_loss: 0.6893 - val_accuracy: 0.6781 - val_mae: 0.2226 - val_mse: 0.1472 - lr: 1.0000e-04\n",
            "Epoch 2552/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3009 - accuracy: 0.7593 - mae: 0.1730 - mse: 0.1055\n",
            "Epoch 2552: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.3001 - accuracy: 0.7596 - mae: 0.1727 - mse: 0.1054 - val_loss: 0.7130 - val_accuracy: 0.6642 - val_mae: 0.2302 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 2553/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2941 - accuracy: 0.7456 - mae: 0.1732 - mse: 0.1062\n",
            "Epoch 2553: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2946 - accuracy: 0.7450 - mae: 0.1745 - mse: 0.1070 - val_loss: 0.7320 - val_accuracy: 0.6567 - val_mae: 0.2356 - val_mse: 0.1592 - lr: 1.0000e-04\n",
            "Epoch 2554/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2841 - accuracy: 0.7402 - mae: 0.1820 - mse: 0.1143\n",
            "Epoch 2554: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2848 - accuracy: 0.7372 - mae: 0.1828 - mse: 0.1150 - val_loss: 0.7271 - val_accuracy: 0.6610 - val_mae: 0.2343 - val_mse: 0.1582 - lr: 1.0000e-04\n",
            "Epoch 2555/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3027 - accuracy: 0.7422 - mae: 0.1822 - mse: 0.1149\n",
            "Epoch 2555: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.3011 - accuracy: 0.7436 - mae: 0.1818 - mse: 0.1146 - val_loss: 0.7097 - val_accuracy: 0.6663 - val_mae: 0.2294 - val_mse: 0.1538 - lr: 1.0000e-04\n",
            "Epoch 2556/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2959 - accuracy: 0.7427 - mae: 0.1790 - mse: 0.1104\n",
            "Epoch 2556: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2918 - accuracy: 0.7454 - mae: 0.1782 - mse: 0.1096 - val_loss: 0.6896 - val_accuracy: 0.6727 - val_mae: 0.2239 - val_mse: 0.1488 - lr: 1.0000e-04\n",
            "Epoch 2557/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2806 - accuracy: 0.7632 - mae: 0.1710 - mse: 0.1043\n",
            "Epoch 2557: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2848 - accuracy: 0.7628 - mae: 0.1713 - mse: 0.1045 - val_loss: 0.6703 - val_accuracy: 0.6834 - val_mae: 0.2191 - val_mse: 0.1442 - lr: 1.0000e-04\n",
            "Epoch 2558/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.7679 - mae: 0.1684 - mse: 0.1021\n",
            "Epoch 2558: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 210ms/step - loss: 0.3053 - accuracy: 0.7679 - mae: 0.1684 - mse: 0.1021 - val_loss: 0.6738 - val_accuracy: 0.6791 - val_mae: 0.2201 - val_mse: 0.1451 - lr: 1.0000e-04\n",
            "Epoch 2559/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.7569 - mae: 0.1700 - mse: 0.1036\n",
            "Epoch 2559: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.2995 - accuracy: 0.7569 - mae: 0.1700 - mse: 0.1036 - val_loss: 0.6974 - val_accuracy: 0.6706 - val_mae: 0.2259 - val_mse: 0.1508 - lr: 1.0000e-04\n",
            "Epoch 2560/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2972 - accuracy: 0.7490 - mae: 0.1763 - mse: 0.1101\n",
            "Epoch 2560: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.2932 - accuracy: 0.7477 - mae: 0.1765 - mse: 0.1102 - val_loss: 0.7224 - val_accuracy: 0.6610 - val_mae: 0.2323 - val_mse: 0.1567 - lr: 1.0000e-04\n",
            "Epoch 2561/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.7482 - mae: 0.1774 - mse: 0.1109\n",
            "Epoch 2561: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.2873 - accuracy: 0.7482 - mae: 0.1774 - mse: 0.1109 - val_loss: 0.7170 - val_accuracy: 0.6610 - val_mae: 0.2309 - val_mse: 0.1551 - lr: 1.0000e-04\n",
            "Epoch 2562/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.7500 - mae: 0.1751 - mse: 0.1083\n",
            "Epoch 2562: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.2942 - accuracy: 0.7500 - mae: 0.1751 - mse: 0.1083 - val_loss: 0.7106 - val_accuracy: 0.6674 - val_mae: 0.2293 - val_mse: 0.1533 - lr: 1.0000e-04\n",
            "Epoch 2563/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.7514 - mae: 0.1778 - mse: 0.1095\n",
            "Epoch 2563: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3058 - accuracy: 0.7514 - mae: 0.1778 - mse: 0.1095 - val_loss: 0.7141 - val_accuracy: 0.6695 - val_mae: 0.2307 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2564/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2821 - accuracy: 0.7676 - mae: 0.1719 - mse: 0.1038\n",
            "Epoch 2564: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.2832 - accuracy: 0.7674 - mae: 0.1718 - mse: 0.1036 - val_loss: 0.7157 - val_accuracy: 0.6610 - val_mae: 0.2310 - val_mse: 0.1547 - lr: 1.0000e-04\n",
            "Epoch 2565/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.7532 - mae: 0.1795 - mse: 0.1095\n",
            "Epoch 2565: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.2946 - accuracy: 0.7532 - mae: 0.1795 - mse: 0.1095 - val_loss: 0.7335 - val_accuracy: 0.6513 - val_mae: 0.2349 - val_mse: 0.1589 - lr: 1.0000e-04\n",
            "Epoch 2566/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2838 - accuracy: 0.7461 - mae: 0.1791 - mse: 0.1112\n",
            "Epoch 2566: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.2813 - accuracy: 0.7463 - mae: 0.1789 - mse: 0.1111 - val_loss: 0.7506 - val_accuracy: 0.6439 - val_mae: 0.2394 - val_mse: 0.1631 - lr: 1.0000e-04\n",
            "Epoch 2567/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.7362 - mae: 0.1850 - mse: 0.1183\n",
            "Epoch 2567: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2995 - accuracy: 0.7362 - mae: 0.1850 - mse: 0.1183 - val_loss: 0.7385 - val_accuracy: 0.6449 - val_mae: 0.2373 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2568/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2891 - accuracy: 0.7373 - mae: 0.1825 - mse: 0.1138\n",
            "Epoch 2568: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.2899 - accuracy: 0.7381 - mae: 0.1819 - mse: 0.1134 - val_loss: 0.7236 - val_accuracy: 0.6492 - val_mae: 0.2337 - val_mse: 0.1570 - lr: 1.0000e-04\n",
            "Epoch 2569/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2954 - accuracy: 0.7349 - mae: 0.1812 - mse: 0.1129\n",
            "Epoch 2569: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2962 - accuracy: 0.7344 - mae: 0.1821 - mse: 0.1134 - val_loss: 0.7170 - val_accuracy: 0.6524 - val_mae: 0.2319 - val_mse: 0.1552 - lr: 1.0000e-04\n",
            "Epoch 2570/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2911 - accuracy: 0.7461 - mae: 0.1796 - mse: 0.1120\n",
            "Epoch 2570: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.2880 - accuracy: 0.7472 - mae: 0.1783 - mse: 0.1107 - val_loss: 0.7072 - val_accuracy: 0.6578 - val_mae: 0.2293 - val_mse: 0.1526 - lr: 1.0000e-04\n",
            "Epoch 2571/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2837 - accuracy: 0.7573 - mae: 0.1739 - mse: 0.1065\n",
            "Epoch 2571: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2839 - accuracy: 0.7573 - mae: 0.1741 - mse: 0.1065 - val_loss: 0.6995 - val_accuracy: 0.6642 - val_mae: 0.2266 - val_mse: 0.1504 - lr: 1.0000e-04\n",
            "Epoch 2572/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3089 - accuracy: 0.7515 - mae: 0.1734 - mse: 0.1073\n",
            "Epoch 2572: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.3077 - accuracy: 0.7523 - mae: 0.1732 - mse: 0.1069 - val_loss: 0.6998 - val_accuracy: 0.6717 - val_mae: 0.2260 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2573/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2745 - accuracy: 0.7754 - mae: 0.1674 - mse: 0.0997\n",
            "Epoch 2573: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2737 - accuracy: 0.7702 - mae: 0.1685 - mse: 0.1008 - val_loss: 0.7116 - val_accuracy: 0.6684 - val_mae: 0.2278 - val_mse: 0.1524 - lr: 1.0000e-04\n",
            "Epoch 2574/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2920 - accuracy: 0.7622 - mae: 0.1709 - mse: 0.1041\n",
            "Epoch 2574: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2899 - accuracy: 0.7642 - mae: 0.1705 - mse: 0.1034 - val_loss: 0.7208 - val_accuracy: 0.6674 - val_mae: 0.2285 - val_mse: 0.1538 - lr: 1.0000e-04\n",
            "Epoch 2575/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2936 - accuracy: 0.7607 - mae: 0.1726 - mse: 0.1053\n",
            "Epoch 2575: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2904 - accuracy: 0.7610 - mae: 0.1721 - mse: 0.1050 - val_loss: 0.7252 - val_accuracy: 0.6620 - val_mae: 0.2293 - val_mse: 0.1549 - lr: 1.0000e-04\n",
            "Epoch 2576/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2934 - accuracy: 0.7568 - mae: 0.1743 - mse: 0.1083\n",
            "Epoch 2576: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2987 - accuracy: 0.7550 - mae: 0.1744 - mse: 0.1088 - val_loss: 0.7308 - val_accuracy: 0.6567 - val_mae: 0.2310 - val_mse: 0.1565 - lr: 1.0000e-04\n",
            "Epoch 2577/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2918 - accuracy: 0.7490 - mae: 0.1772 - mse: 0.1108\n",
            "Epoch 2577: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2919 - accuracy: 0.7495 - mae: 0.1761 - mse: 0.1103 - val_loss: 0.7466 - val_accuracy: 0.6449 - val_mae: 0.2348 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2578/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2856 - accuracy: 0.7471 - mae: 0.1784 - mse: 0.1139\n",
            "Epoch 2578: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2880 - accuracy: 0.7459 - mae: 0.1794 - mse: 0.1149 - val_loss: 0.7481 - val_accuracy: 0.6374 - val_mae: 0.2354 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2579/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2997 - accuracy: 0.7451 - mae: 0.1786 - mse: 0.1122\n",
            "Epoch 2579: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2974 - accuracy: 0.7431 - mae: 0.1798 - mse: 0.1133 - val_loss: 0.7327 - val_accuracy: 0.6535 - val_mae: 0.2328 - val_mse: 0.1577 - lr: 1.0000e-04\n",
            "Epoch 2580/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2749 - accuracy: 0.7515 - mae: 0.1735 - mse: 0.1062\n",
            "Epoch 2580: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2739 - accuracy: 0.7537 - mae: 0.1726 - mse: 0.1057 - val_loss: 0.7041 - val_accuracy: 0.6652 - val_mae: 0.2260 - val_mse: 0.1511 - lr: 1.0000e-04\n",
            "Epoch 2581/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.7739 - mae: 0.1720 - mse: 0.1044\n",
            "Epoch 2581: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.3070 - accuracy: 0.7739 - mae: 0.1720 - mse: 0.1044 - val_loss: 0.6963 - val_accuracy: 0.6717 - val_mae: 0.2235 - val_mse: 0.1490 - lr: 1.0000e-04\n",
            "Epoch 2582/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2870 - accuracy: 0.7710 - mae: 0.1673 - mse: 0.1006\n",
            "Epoch 2582: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2835 - accuracy: 0.7720 - mae: 0.1669 - mse: 0.1002 - val_loss: 0.7064 - val_accuracy: 0.6674 - val_mae: 0.2251 - val_mse: 0.1511 - lr: 1.0000e-04\n",
            "Epoch 2583/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2932 - accuracy: 0.7690 - mae: 0.1698 - mse: 0.1022\n",
            "Epoch 2583: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2895 - accuracy: 0.7720 - mae: 0.1680 - mse: 0.1011 - val_loss: 0.7180 - val_accuracy: 0.6610 - val_mae: 0.2269 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2584/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2936 - accuracy: 0.7612 - mae: 0.1709 - mse: 0.1055\n",
            "Epoch 2584: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2912 - accuracy: 0.7596 - mae: 0.1720 - mse: 0.1065 - val_loss: 0.7305 - val_accuracy: 0.6545 - val_mae: 0.2292 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2585/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2903 - accuracy: 0.7554 - mae: 0.1754 - mse: 0.1092\n",
            "Epoch 2585: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2937 - accuracy: 0.7573 - mae: 0.1743 - mse: 0.1084 - val_loss: 0.7320 - val_accuracy: 0.6524 - val_mae: 0.2295 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2586/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.7477 - mae: 0.1744 - mse: 0.1097\n",
            "Epoch 2586: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.2806 - accuracy: 0.7477 - mae: 0.1744 - mse: 0.1097 - val_loss: 0.7364 - val_accuracy: 0.6524 - val_mae: 0.2310 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2587/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.7436 - mae: 0.1785 - mse: 0.1125\n",
            "Epoch 2587: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2983 - accuracy: 0.7436 - mae: 0.1785 - mse: 0.1125 - val_loss: 0.7436 - val_accuracy: 0.6449 - val_mae: 0.2337 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2588/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.7362 - mae: 0.1797 - mse: 0.1140\n",
            "Epoch 2588: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.2858 - accuracy: 0.7362 - mae: 0.1797 - mse: 0.1140 - val_loss: 0.7618 - val_accuracy: 0.6310 - val_mae: 0.2390 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 2589/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.7257 - mae: 0.1852 - mse: 0.1184\n",
            "Epoch 2589: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.2820 - accuracy: 0.7257 - mae: 0.1852 - mse: 0.1184 - val_loss: 0.7730 - val_accuracy: 0.6289 - val_mae: 0.2418 - val_mse: 0.1666 - lr: 1.0000e-04\n",
            "Epoch 2590/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.7261 - mae: 0.1885 - mse: 0.1209\n",
            "Epoch 2590: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3076 - accuracy: 0.7261 - mae: 0.1885 - mse: 0.1209 - val_loss: 0.7676 - val_accuracy: 0.6321 - val_mae: 0.2408 - val_mse: 0.1654 - lr: 1.0000e-04\n",
            "Epoch 2591/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.7321 - mae: 0.1858 - mse: 0.1180\n",
            "Epoch 2591: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.3014 - accuracy: 0.7321 - mae: 0.1858 - mse: 0.1180 - val_loss: 0.7564 - val_accuracy: 0.6396 - val_mae: 0.2382 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2592/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.7358 - mae: 0.1830 - mse: 0.1176\n",
            "Epoch 2592: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3021 - accuracy: 0.7358 - mae: 0.1830 - mse: 0.1176 - val_loss: 0.7330 - val_accuracy: 0.6599 - val_mae: 0.2324 - val_mse: 0.1570 - lr: 1.0000e-04\n",
            "Epoch 2593/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.7518 - mae: 0.1746 - mse: 0.1079\n",
            "Epoch 2593: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.2855 - accuracy: 0.7518 - mae: 0.1746 - mse: 0.1079 - val_loss: 0.7078 - val_accuracy: 0.6717 - val_mae: 0.2260 - val_mse: 0.1509 - lr: 1.0000e-04\n",
            "Epoch 2594/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.7697 - mae: 0.1690 - mse: 0.1014\n",
            "Epoch 2594: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3011 - accuracy: 0.7697 - mae: 0.1690 - mse: 0.1014 - val_loss: 0.7062 - val_accuracy: 0.6684 - val_mae: 0.2258 - val_mse: 0.1508 - lr: 1.0000e-04\n",
            "Epoch 2595/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.7670 - mae: 0.1672 - mse: 0.1001\n",
            "Epoch 2595: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.2887 - accuracy: 0.7670 - mae: 0.1672 - mse: 0.1001 - val_loss: 0.7424 - val_accuracy: 0.6449 - val_mae: 0.2343 - val_mse: 0.1594 - lr: 1.0000e-04\n",
            "Epoch 2596/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2836 - accuracy: 0.7563 - mae: 0.1770 - mse: 0.1102\n",
            "Epoch 2596: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.2814 - accuracy: 0.7569 - mae: 0.1774 - mse: 0.1106 - val_loss: 0.7599 - val_accuracy: 0.6406 - val_mae: 0.2370 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2597/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.7349 - mae: 0.1819 - mse: 0.1168\n",
            "Epoch 2597: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2972 - accuracy: 0.7349 - mae: 0.1819 - mse: 0.1168 - val_loss: 0.7396 - val_accuracy: 0.6513 - val_mae: 0.2313 - val_mse: 0.1576 - lr: 1.0000e-04\n",
            "Epoch 2598/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.7546 - mae: 0.1753 - mse: 0.1103\n",
            "Epoch 2598: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2924 - accuracy: 0.7546 - mae: 0.1753 - mse: 0.1103 - val_loss: 0.7106 - val_accuracy: 0.6610 - val_mae: 0.2235 - val_mse: 0.1504 - lr: 1.0000e-04\n",
            "Epoch 2599/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.7679 - mae: 0.1668 - mse: 0.1021\n",
            "Epoch 2599: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 0.2773 - accuracy: 0.7679 - mae: 0.1668 - mse: 0.1021 - val_loss: 0.6988 - val_accuracy: 0.6759 - val_mae: 0.2205 - val_mse: 0.1475 - lr: 1.0000e-04\n",
            "Epoch 2600/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.7780 - mae: 0.1649 - mse: 0.0994\n",
            "Epoch 2600: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 0.2954 - accuracy: 0.7780 - mae: 0.1649 - mse: 0.0994 - val_loss: 0.6974 - val_accuracy: 0.6749 - val_mae: 0.2202 - val_mse: 0.1472 - lr: 1.0000e-04\n",
            "Epoch 2601/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.7798 - mae: 0.1638 - mse: 0.0982\n",
            "Epoch 2601: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.2821 - accuracy: 0.7798 - mae: 0.1638 - mse: 0.0982 - val_loss: 0.7077 - val_accuracy: 0.6738 - val_mae: 0.2230 - val_mse: 0.1497 - lr: 1.0000e-04\n",
            "Epoch 2602/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3134 - accuracy: 0.7632 - mae: 0.1695 - mse: 0.1053\n",
            "Epoch 2602: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.3184 - accuracy: 0.7610 - mae: 0.1702 - mse: 0.1058 - val_loss: 0.7380 - val_accuracy: 0.6545 - val_mae: 0.2305 - val_mse: 0.1570 - lr: 1.0000e-04\n",
            "Epoch 2603/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.7431 - mae: 0.1792 - mse: 0.1126\n",
            "Epoch 2603: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.2866 - accuracy: 0.7431 - mae: 0.1792 - mse: 0.1126 - val_loss: 0.7640 - val_accuracy: 0.6406 - val_mae: 0.2368 - val_mse: 0.1632 - lr: 1.0000e-04\n",
            "Epoch 2604/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2986 - accuracy: 0.7319 - mae: 0.1856 - mse: 0.1202\n",
            "Epoch 2604: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.2964 - accuracy: 0.7330 - mae: 0.1852 - mse: 0.1197 - val_loss: 0.7664 - val_accuracy: 0.6364 - val_mae: 0.2379 - val_mse: 0.1639 - lr: 1.0000e-04\n",
            "Epoch 2605/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2901 - accuracy: 0.7324 - mae: 0.1843 - mse: 0.1176\n",
            "Epoch 2605: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.2918 - accuracy: 0.7367 - mae: 0.1826 - mse: 0.1161 - val_loss: 0.7508 - val_accuracy: 0.6449 - val_mae: 0.2355 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2606/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2766 - accuracy: 0.7466 - mae: 0.1770 - mse: 0.1097\n",
            "Epoch 2606: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2764 - accuracy: 0.7450 - mae: 0.1773 - mse: 0.1101 - val_loss: 0.7286 - val_accuracy: 0.6599 - val_mae: 0.2309 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 2607/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2954 - accuracy: 0.7593 - mae: 0.1746 - mse: 0.1071\n",
            "Epoch 2607: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2973 - accuracy: 0.7560 - mae: 0.1760 - mse: 0.1083 - val_loss: 0.7065 - val_accuracy: 0.6652 - val_mae: 0.2263 - val_mse: 0.1509 - lr: 1.0000e-04\n",
            "Epoch 2608/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2860 - accuracy: 0.7534 - mae: 0.1702 - mse: 0.1024\n",
            "Epoch 2608: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2846 - accuracy: 0.7505 - mae: 0.1715 - mse: 0.1036 - val_loss: 0.6910 - val_accuracy: 0.6727 - val_mae: 0.2231 - val_mse: 0.1475 - lr: 1.0000e-04\n",
            "Epoch 2609/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2857 - accuracy: 0.7769 - mae: 0.1652 - mse: 0.0985\n",
            "Epoch 2609: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2811 - accuracy: 0.7789 - mae: 0.1648 - mse: 0.0981 - val_loss: 0.6802 - val_accuracy: 0.6770 - val_mae: 0.2203 - val_mse: 0.1449 - lr: 1.0000e-04\n",
            "Epoch 2610/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2955 - accuracy: 0.7715 - mae: 0.1640 - mse: 0.0981\n",
            "Epoch 2610: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.2965 - accuracy: 0.7693 - mae: 0.1654 - mse: 0.0991 - val_loss: 0.6823 - val_accuracy: 0.6770 - val_mae: 0.2209 - val_mse: 0.1455 - lr: 1.0000e-04\n",
            "Epoch 2611/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2950 - accuracy: 0.7744 - mae: 0.1644 - mse: 0.0981\n",
            "Epoch 2611: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2922 - accuracy: 0.7766 - mae: 0.1634 - mse: 0.0972 - val_loss: 0.7003 - val_accuracy: 0.6631 - val_mae: 0.2261 - val_mse: 0.1503 - lr: 1.0000e-04\n",
            "Epoch 2612/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2800 - accuracy: 0.7632 - mae: 0.1694 - mse: 0.1018\n",
            "Epoch 2612: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2818 - accuracy: 0.7624 - mae: 0.1699 - mse: 0.1025 - val_loss: 0.7213 - val_accuracy: 0.6513 - val_mae: 0.2313 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2613/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2783 - accuracy: 0.7588 - mae: 0.1724 - mse: 0.1046\n",
            "Epoch 2613: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2779 - accuracy: 0.7592 - mae: 0.1721 - mse: 0.1047 - val_loss: 0.7405 - val_accuracy: 0.6449 - val_mae: 0.2359 - val_mse: 0.1604 - lr: 1.0000e-04\n",
            "Epoch 2614/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2770 - accuracy: 0.7412 - mae: 0.1804 - mse: 0.1126\n",
            "Epoch 2614: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.2798 - accuracy: 0.7394 - mae: 0.1812 - mse: 0.1132 - val_loss: 0.7420 - val_accuracy: 0.6460 - val_mae: 0.2357 - val_mse: 0.1606 - lr: 1.0000e-04\n",
            "Epoch 2615/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2790 - accuracy: 0.7461 - mae: 0.1782 - mse: 0.1118\n",
            "Epoch 2615: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.2871 - accuracy: 0.7454 - mae: 0.1786 - mse: 0.1123 - val_loss: 0.7441 - val_accuracy: 0.6428 - val_mae: 0.2354 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2616/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2905 - accuracy: 0.7520 - mae: 0.1777 - mse: 0.1112\n",
            "Epoch 2616: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.2894 - accuracy: 0.7472 - mae: 0.1788 - mse: 0.1123 - val_loss: 0.7460 - val_accuracy: 0.6481 - val_mae: 0.2355 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2617/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2909 - accuracy: 0.7344 - mae: 0.1817 - mse: 0.1146\n",
            "Epoch 2617: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.2900 - accuracy: 0.7358 - mae: 0.1812 - mse: 0.1144 - val_loss: 0.7240 - val_accuracy: 0.6610 - val_mae: 0.2303 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2618/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.7541 - mae: 0.1718 - mse: 0.1060\n",
            "Epoch 2618: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.2744 - accuracy: 0.7541 - mae: 0.1718 - mse: 0.1060 - val_loss: 0.7023 - val_accuracy: 0.6706 - val_mae: 0.2246 - val_mse: 0.1502 - lr: 1.0000e-04\n",
            "Epoch 2619/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2826 - accuracy: 0.7617 - mae: 0.1715 - mse: 0.1042\n",
            "Epoch 2619: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.2826 - accuracy: 0.7610 - mae: 0.1710 - mse: 0.1039 - val_loss: 0.7023 - val_accuracy: 0.6695 - val_mae: 0.2238 - val_mse: 0.1497 - lr: 1.0000e-04\n",
            "Epoch 2620/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.7720 - mae: 0.1671 - mse: 0.1013\n",
            "Epoch 2620: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2728 - accuracy: 0.7720 - mae: 0.1671 - mse: 0.1013 - val_loss: 0.7098 - val_accuracy: 0.6684 - val_mae: 0.2246 - val_mse: 0.1510 - lr: 1.0000e-04\n",
            "Epoch 2621/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3128 - accuracy: 0.7622 - mae: 0.1710 - mse: 0.1055\n",
            "Epoch 2621: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3122 - accuracy: 0.7606 - mae: 0.1722 - mse: 0.1066 - val_loss: 0.7319 - val_accuracy: 0.6599 - val_mae: 0.2301 - val_mse: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 2622/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.7500 - mae: 0.1790 - mse: 0.1124\n",
            "Epoch 2622: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.2999 - accuracy: 0.7500 - mae: 0.1790 - mse: 0.1124 - val_loss: 0.7377 - val_accuracy: 0.6535 - val_mae: 0.2317 - val_mse: 0.1576 - lr: 1.0000e-04\n",
            "Epoch 2623/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.7445 - mae: 0.1790 - mse: 0.1124\n",
            "Epoch 2623: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.2959 - accuracy: 0.7445 - mae: 0.1790 - mse: 0.1124 - val_loss: 0.7278 - val_accuracy: 0.6599 - val_mae: 0.2298 - val_mse: 0.1553 - lr: 1.0000e-04\n",
            "Epoch 2624/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.7546 - mae: 0.1759 - mse: 0.1104\n",
            "Epoch 2624: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.2926 - accuracy: 0.7546 - mae: 0.1759 - mse: 0.1104 - val_loss: 0.7152 - val_accuracy: 0.6578 - val_mae: 0.2274 - val_mse: 0.1525 - lr: 1.0000e-04\n",
            "Epoch 2625/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2971 - accuracy: 0.7471 - mae: 0.1775 - mse: 0.1086\n",
            "Epoch 2625: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.2947 - accuracy: 0.7505 - mae: 0.1754 - mse: 0.1067 - val_loss: 0.7106 - val_accuracy: 0.6588 - val_mae: 0.2268 - val_mse: 0.1516 - lr: 1.0000e-04\n",
            "Epoch 2626/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3021 - accuracy: 0.7573 - mae: 0.1748 - mse: 0.1071\n",
            "Epoch 2626: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 190ms/step - loss: 0.3023 - accuracy: 0.7601 - mae: 0.1740 - mse: 0.1066 - val_loss: 0.7249 - val_accuracy: 0.6567 - val_mae: 0.2302 - val_mse: 0.1548 - lr: 1.0000e-04\n",
            "Epoch 2627/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2910 - accuracy: 0.7559 - mae: 0.1747 - mse: 0.1074\n",
            "Epoch 2627: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2905 - accuracy: 0.7564 - mae: 0.1748 - mse: 0.1077 - val_loss: 0.7408 - val_accuracy: 0.6492 - val_mae: 0.2332 - val_mse: 0.1582 - lr: 1.0000e-04\n",
            "Epoch 2628/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2822 - accuracy: 0.7485 - mae: 0.1776 - mse: 0.1105\n",
            "Epoch 2628: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2803 - accuracy: 0.7486 - mae: 0.1775 - mse: 0.1107 - val_loss: 0.7402 - val_accuracy: 0.6556 - val_mae: 0.2322 - val_mse: 0.1576 - lr: 1.0000e-04\n",
            "Epoch 2629/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2890 - accuracy: 0.7427 - mae: 0.1784 - mse: 0.1115\n",
            "Epoch 2629: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2867 - accuracy: 0.7431 - mae: 0.1783 - mse: 0.1115 - val_loss: 0.7240 - val_accuracy: 0.6749 - val_mae: 0.2270 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2630/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2830 - accuracy: 0.7671 - mae: 0.1710 - mse: 0.1053\n",
            "Epoch 2630: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2793 - accuracy: 0.7720 - mae: 0.1681 - mse: 0.1028 - val_loss: 0.7086 - val_accuracy: 0.6866 - val_mae: 0.2222 - val_mse: 0.1490 - lr: 1.0000e-04\n",
            "Epoch 2631/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2877 - accuracy: 0.7705 - mae: 0.1665 - mse: 0.1013\n",
            "Epoch 2631: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2885 - accuracy: 0.7702 - mae: 0.1666 - mse: 0.1015 - val_loss: 0.7115 - val_accuracy: 0.6834 - val_mae: 0.2226 - val_mse: 0.1497 - lr: 1.0000e-04\n",
            "Epoch 2632/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.7628 - mae: 0.1695 - mse: 0.1043\n",
            "Epoch 2632: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 0.2873 - accuracy: 0.7628 - mae: 0.1695 - mse: 0.1043 - val_loss: 0.7256 - val_accuracy: 0.6706 - val_mae: 0.2263 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2633/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2981 - accuracy: 0.7573 - mae: 0.1738 - mse: 0.1084\n",
            "Epoch 2633: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2956 - accuracy: 0.7578 - mae: 0.1734 - mse: 0.1081 - val_loss: 0.7428 - val_accuracy: 0.6524 - val_mae: 0.2306 - val_mse: 0.1574 - lr: 1.0000e-04\n",
            "Epoch 2634/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2772 - accuracy: 0.7427 - mae: 0.1757 - mse: 0.1129\n",
            "Epoch 2634: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2813 - accuracy: 0.7454 - mae: 0.1750 - mse: 0.1117 - val_loss: 0.7457 - val_accuracy: 0.6545 - val_mae: 0.2311 - val_mse: 0.1580 - lr: 1.0000e-04\n",
            "Epoch 2635/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2855 - accuracy: 0.7539 - mae: 0.1757 - mse: 0.1103\n",
            "Epoch 2635: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2900 - accuracy: 0.7532 - mae: 0.1758 - mse: 0.1107 - val_loss: 0.7616 - val_accuracy: 0.6460 - val_mae: 0.2349 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2636/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2961 - accuracy: 0.7412 - mae: 0.1789 - mse: 0.1143\n",
            "Epoch 2636: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2997 - accuracy: 0.7381 - mae: 0.1804 - mse: 0.1155 - val_loss: 0.7822 - val_accuracy: 0.6321 - val_mae: 0.2409 - val_mse: 0.1673 - lr: 1.0000e-04\n",
            "Epoch 2637/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2939 - accuracy: 0.7329 - mae: 0.1848 - mse: 0.1198\n",
            "Epoch 2637: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2944 - accuracy: 0.7317 - mae: 0.1857 - mse: 0.1203 - val_loss: 0.7778 - val_accuracy: 0.6299 - val_mae: 0.2412 - val_mse: 0.1670 - lr: 1.0000e-04\n",
            "Epoch 2638/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2794 - accuracy: 0.7310 - mae: 0.1879 - mse: 0.1213\n",
            "Epoch 2638: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2792 - accuracy: 0.7335 - mae: 0.1870 - mse: 0.1206 - val_loss: 0.7335 - val_accuracy: 0.6439 - val_mae: 0.2325 - val_mse: 0.1575 - lr: 1.0000e-04\n",
            "Epoch 2639/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2950 - accuracy: 0.7539 - mae: 0.1754 - mse: 0.1090\n",
            "Epoch 2639: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2972 - accuracy: 0.7555 - mae: 0.1747 - mse: 0.1083 - val_loss: 0.6983 - val_accuracy: 0.6610 - val_mae: 0.2253 - val_mse: 0.1498 - lr: 1.0000e-04\n",
            "Epoch 2640/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3052 - accuracy: 0.7549 - mae: 0.1715 - mse: 0.1044\n",
            "Epoch 2640: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.3025 - accuracy: 0.7514 - mae: 0.1729 - mse: 0.1055 - val_loss: 0.6903 - val_accuracy: 0.6684 - val_mae: 0.2246 - val_mse: 0.1484 - lr: 1.0000e-04\n",
            "Epoch 2641/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2825 - accuracy: 0.7622 - mae: 0.1702 - mse: 0.1013\n",
            "Epoch 2641: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2846 - accuracy: 0.7638 - mae: 0.1699 - mse: 0.1011 - val_loss: 0.6854 - val_accuracy: 0.6684 - val_mae: 0.2239 - val_mse: 0.1474 - lr: 1.0000e-04\n",
            "Epoch 2642/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3069 - accuracy: 0.7661 - mae: 0.1689 - mse: 0.1006\n",
            "Epoch 2642: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3088 - accuracy: 0.7656 - mae: 0.1699 - mse: 0.1016 - val_loss: 0.7101 - val_accuracy: 0.6588 - val_mae: 0.2302 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2643/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2928 - accuracy: 0.7617 - mae: 0.1740 - mse: 0.1049\n",
            "Epoch 2643: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2910 - accuracy: 0.7642 - mae: 0.1727 - mse: 0.1040 - val_loss: 0.7505 - val_accuracy: 0.6406 - val_mae: 0.2393 - val_mse: 0.1628 - lr: 1.0000e-04\n",
            "Epoch 2644/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2831 - accuracy: 0.7290 - mae: 0.1848 - mse: 0.1157\n",
            "Epoch 2644: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.2846 - accuracy: 0.7257 - mae: 0.1858 - mse: 0.1167 - val_loss: 0.7729 - val_accuracy: 0.6267 - val_mae: 0.2433 - val_mse: 0.1675 - lr: 1.0000e-04\n",
            "Epoch 2645/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.7280 - mae: 0.1862 - mse: 0.1193\n",
            "Epoch 2645: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.2942 - accuracy: 0.7280 - mae: 0.1862 - mse: 0.1193 - val_loss: 0.7707 - val_accuracy: 0.6289 - val_mae: 0.2423 - val_mse: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 2646/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.7349 - mae: 0.1838 - mse: 0.1157\n",
            "Epoch 2646: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.2856 - accuracy: 0.7349 - mae: 0.1838 - mse: 0.1157 - val_loss: 0.7645 - val_accuracy: 0.6385 - val_mae: 0.2415 - val_mse: 0.1655 - lr: 1.0000e-04\n",
            "Epoch 2647/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.7317 - mae: 0.1848 - mse: 0.1162\n",
            "Epoch 2647: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.2915 - accuracy: 0.7317 - mae: 0.1848 - mse: 0.1162 - val_loss: 0.7491 - val_accuracy: 0.6406 - val_mae: 0.2388 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 2648/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.7394 - mae: 0.1779 - mse: 0.1107\n",
            "Epoch 2648: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.2829 - accuracy: 0.7394 - mae: 0.1779 - mse: 0.1107 - val_loss: 0.7332 - val_accuracy: 0.6481 - val_mae: 0.2355 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2649/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2858 - accuracy: 0.7344 - mae: 0.1779 - mse: 0.1102\n",
            "Epoch 2649: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.2841 - accuracy: 0.7394 - mae: 0.1767 - mse: 0.1087 - val_loss: 0.7260 - val_accuracy: 0.6556 - val_mae: 0.2336 - val_mse: 0.1565 - lr: 1.0000e-04\n",
            "Epoch 2650/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2857 - accuracy: 0.7471 - mae: 0.1783 - mse: 0.1098\n",
            "Epoch 2650: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.2873 - accuracy: 0.7477 - mae: 0.1785 - mse: 0.1098 - val_loss: 0.7197 - val_accuracy: 0.6588 - val_mae: 0.2310 - val_mse: 0.1545 - lr: 1.0000e-04\n",
            "Epoch 2651/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2917 - accuracy: 0.7612 - mae: 0.1712 - mse: 0.1030\n",
            "Epoch 2651: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.2890 - accuracy: 0.7633 - mae: 0.1706 - mse: 0.1027 - val_loss: 0.7208 - val_accuracy: 0.6620 - val_mae: 0.2300 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2652/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.7541 - mae: 0.1762 - mse: 0.1107\n",
            "Epoch 2652: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.3022 - accuracy: 0.7541 - mae: 0.1762 - mse: 0.1107 - val_loss: 0.7155 - val_accuracy: 0.6684 - val_mae: 0.2277 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2653/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2895 - accuracy: 0.7637 - mae: 0.1757 - mse: 0.1075\n",
            "Epoch 2653: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.2959 - accuracy: 0.7670 - mae: 0.1755 - mse: 0.1071 - val_loss: 0.7177 - val_accuracy: 0.6695 - val_mae: 0.2277 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2654/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2883 - accuracy: 0.7603 - mae: 0.1742 - mse: 0.1058\n",
            "Epoch 2654: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2934 - accuracy: 0.7624 - mae: 0.1739 - mse: 0.1058 - val_loss: 0.7509 - val_accuracy: 0.6535 - val_mae: 0.2355 - val_mse: 0.1609 - lr: 1.0000e-04\n",
            "Epoch 2655/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2615 - accuracy: 0.7485 - mae: 0.1779 - mse: 0.1104\n",
            "Epoch 2655: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2699 - accuracy: 0.7454 - mae: 0.1791 - mse: 0.1120 - val_loss: 0.7848 - val_accuracy: 0.6310 - val_mae: 0.2435 - val_mse: 0.1689 - lr: 1.0000e-04\n",
            "Epoch 2656/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2943 - accuracy: 0.7290 - mae: 0.1871 - mse: 0.1218\n",
            "Epoch 2656: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2905 - accuracy: 0.7280 - mae: 0.1866 - mse: 0.1213 - val_loss: 0.7912 - val_accuracy: 0.6267 - val_mae: 0.2449 - val_mse: 0.1703 - lr: 1.0000e-04\n",
            "Epoch 2657/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2979 - accuracy: 0.7295 - mae: 0.1867 - mse: 0.1201\n",
            "Epoch 2657: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2973 - accuracy: 0.7307 - mae: 0.1862 - mse: 0.1192 - val_loss: 0.7649 - val_accuracy: 0.6299 - val_mae: 0.2386 - val_mse: 0.1640 - lr: 1.0000e-04\n",
            "Epoch 2658/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2849 - accuracy: 0.7300 - mae: 0.1839 - mse: 0.1178\n",
            "Epoch 2658: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2863 - accuracy: 0.7307 - mae: 0.1832 - mse: 0.1169 - val_loss: 0.7342 - val_accuracy: 0.6449 - val_mae: 0.2312 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2659/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2889 - accuracy: 0.7412 - mae: 0.1778 - mse: 0.1111\n",
            "Epoch 2659: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2882 - accuracy: 0.7463 - mae: 0.1761 - mse: 0.1094 - val_loss: 0.7114 - val_accuracy: 0.6588 - val_mae: 0.2258 - val_mse: 0.1514 - lr: 1.0000e-04\n",
            "Epoch 2660/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3046 - accuracy: 0.7524 - mae: 0.1734 - mse: 0.1071\n",
            "Epoch 2660: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.3000 - accuracy: 0.7596 - mae: 0.1705 - mse: 0.1045 - val_loss: 0.7129 - val_accuracy: 0.6674 - val_mae: 0.2257 - val_mse: 0.1517 - lr: 1.0000e-04\n",
            "Epoch 2661/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2809 - accuracy: 0.7627 - mae: 0.1728 - mse: 0.1049\n",
            "Epoch 2661: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2818 - accuracy: 0.7628 - mae: 0.1722 - mse: 0.1040 - val_loss: 0.7267 - val_accuracy: 0.6642 - val_mae: 0.2286 - val_mse: 0.1549 - lr: 1.0000e-04\n",
            "Epoch 2662/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2752 - accuracy: 0.7598 - mae: 0.1735 - mse: 0.1065\n",
            "Epoch 2662: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 0.2728 - accuracy: 0.7596 - mae: 0.1726 - mse: 0.1064 - val_loss: 0.7308 - val_accuracy: 0.6545 - val_mae: 0.2296 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2663/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2765 - accuracy: 0.7563 - mae: 0.1721 - mse: 0.1064\n",
            "Epoch 2663: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2792 - accuracy: 0.7560 - mae: 0.1731 - mse: 0.1073 - val_loss: 0.7236 - val_accuracy: 0.6556 - val_mae: 0.2276 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2664/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2671 - accuracy: 0.7676 - mae: 0.1668 - mse: 0.1035\n",
            "Epoch 2664: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2777 - accuracy: 0.7665 - mae: 0.1676 - mse: 0.1041 - val_loss: 0.7191 - val_accuracy: 0.6588 - val_mae: 0.2265 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2665/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2882 - accuracy: 0.7383 - mae: 0.1775 - mse: 0.1124\n",
            "Epoch 2665: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2890 - accuracy: 0.7376 - mae: 0.1776 - mse: 0.1118 - val_loss: 0.7322 - val_accuracy: 0.6620 - val_mae: 0.2301 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 2666/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2831 - accuracy: 0.7441 - mae: 0.1759 - mse: 0.1106\n",
            "Epoch 2666: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2873 - accuracy: 0.7445 - mae: 0.1760 - mse: 0.1107 - val_loss: 0.7395 - val_accuracy: 0.6578 - val_mae: 0.2320 - val_mse: 0.1582 - lr: 1.0000e-04\n",
            "Epoch 2667/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2847 - accuracy: 0.7534 - mae: 0.1765 - mse: 0.1104\n",
            "Epoch 2667: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2864 - accuracy: 0.7537 - mae: 0.1765 - mse: 0.1103 - val_loss: 0.7504 - val_accuracy: 0.6535 - val_mae: 0.2347 - val_mse: 0.1608 - lr: 1.0000e-04\n",
            "Epoch 2668/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2847 - accuracy: 0.7505 - mae: 0.1726 - mse: 0.1089\n",
            "Epoch 2668: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2882 - accuracy: 0.7472 - mae: 0.1743 - mse: 0.1103 - val_loss: 0.7592 - val_accuracy: 0.6535 - val_mae: 0.2364 - val_mse: 0.1625 - lr: 1.0000e-04\n",
            "Epoch 2669/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2912 - accuracy: 0.7368 - mae: 0.1828 - mse: 0.1151\n",
            "Epoch 2669: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2880 - accuracy: 0.7408 - mae: 0.1798 - mse: 0.1131 - val_loss: 0.7544 - val_accuracy: 0.6524 - val_mae: 0.2355 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 2670/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2857 - accuracy: 0.7397 - mae: 0.1785 - mse: 0.1127\n",
            "Epoch 2670: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2825 - accuracy: 0.7436 - mae: 0.1774 - mse: 0.1116 - val_loss: 0.7466 - val_accuracy: 0.6513 - val_mae: 0.2338 - val_mse: 0.1595 - lr: 1.0000e-04\n",
            "Epoch 2671/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2933 - accuracy: 0.7461 - mae: 0.1773 - mse: 0.1113\n",
            "Epoch 2671: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2927 - accuracy: 0.7463 - mae: 0.1766 - mse: 0.1110 - val_loss: 0.7361 - val_accuracy: 0.6610 - val_mae: 0.2307 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2672/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.7518 - mae: 0.1761 - mse: 0.1107\n",
            "Epoch 2672: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.2950 - accuracy: 0.7518 - mae: 0.1761 - mse: 0.1107 - val_loss: 0.7207 - val_accuracy: 0.6749 - val_mae: 0.2262 - val_mse: 0.1525 - lr: 1.0000e-04\n",
            "Epoch 2673/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2787 - accuracy: 0.7632 - mae: 0.1667 - mse: 0.1031\n",
            "Epoch 2673: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.2777 - accuracy: 0.7642 - mae: 0.1670 - mse: 0.1033 - val_loss: 0.6984 - val_accuracy: 0.6824 - val_mae: 0.2203 - val_mse: 0.1470 - lr: 1.0000e-04\n",
            "Epoch 2674/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2876 - accuracy: 0.7773 - mae: 0.1634 - mse: 0.0980\n",
            "Epoch 2674: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.2874 - accuracy: 0.7807 - mae: 0.1619 - mse: 0.0967 - val_loss: 0.6885 - val_accuracy: 0.6802 - val_mae: 0.2177 - val_mse: 0.1447 - lr: 1.0000e-04\n",
            "Epoch 2675/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.7752 - mae: 0.1628 - mse: 0.0983\n",
            "Epoch 2675: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2861 - accuracy: 0.7752 - mae: 0.1628 - mse: 0.0983 - val_loss: 0.7075 - val_accuracy: 0.6802 - val_mae: 0.2226 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2676/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.7702 - mae: 0.1700 - mse: 0.1041\n",
            "Epoch 2676: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2829 - accuracy: 0.7702 - mae: 0.1700 - mse: 0.1041 - val_loss: 0.7372 - val_accuracy: 0.6695 - val_mae: 0.2295 - val_mse: 0.1565 - lr: 1.0000e-04\n",
            "Epoch 2677/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.7716 - mae: 0.1699 - mse: 0.1038\n",
            "Epoch 2677: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.2747 - accuracy: 0.7716 - mae: 0.1699 - mse: 0.1038 - val_loss: 0.7608 - val_accuracy: 0.6588 - val_mae: 0.2349 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2678/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.7523 - mae: 0.1792 - mse: 0.1138\n",
            "Epoch 2678: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.2851 - accuracy: 0.7523 - mae: 0.1792 - mse: 0.1138 - val_loss: 0.7634 - val_accuracy: 0.6545 - val_mae: 0.2352 - val_mse: 0.1624 - lr: 1.0000e-04\n",
            "Epoch 2679/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2942 - accuracy: 0.7407 - mae: 0.1824 - mse: 0.1172\n",
            "Epoch 2679: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.2946 - accuracy: 0.7413 - mae: 0.1819 - mse: 0.1169 - val_loss: 0.7528 - val_accuracy: 0.6567 - val_mae: 0.2325 - val_mse: 0.1599 - lr: 1.0000e-04\n",
            "Epoch 2680/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.7573 - mae: 0.1730 - mse: 0.1096\n",
            "Epoch 2680: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.2877 - accuracy: 0.7573 - mae: 0.1730 - mse: 0.1096 - val_loss: 0.7481 - val_accuracy: 0.6535 - val_mae: 0.2311 - val_mse: 0.1587 - lr: 1.0000e-04\n",
            "Epoch 2681/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2858 - accuracy: 0.7490 - mae: 0.1757 - mse: 0.1119\n",
            "Epoch 2681: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.2879 - accuracy: 0.7477 - mae: 0.1761 - mse: 0.1124 - val_loss: 0.7519 - val_accuracy: 0.6631 - val_mae: 0.2319 - val_mse: 0.1596 - lr: 1.0000e-04\n",
            "Epoch 2682/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2855 - accuracy: 0.7500 - mae: 0.1759 - mse: 0.1114\n",
            "Epoch 2682: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2834 - accuracy: 0.7482 - mae: 0.1766 - mse: 0.1121 - val_loss: 0.7403 - val_accuracy: 0.6674 - val_mae: 0.2297 - val_mse: 0.1571 - lr: 1.0000e-04\n",
            "Epoch 2683/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3035 - accuracy: 0.7495 - mae: 0.1766 - mse: 0.1112\n",
            "Epoch 2683: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.3001 - accuracy: 0.7509 - mae: 0.1764 - mse: 0.1107 - val_loss: 0.7145 - val_accuracy: 0.6791 - val_mae: 0.2245 - val_mse: 0.1515 - lr: 1.0000e-04\n",
            "Epoch 2684/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.7537 - mae: 0.1703 - mse: 0.1055\n",
            "Epoch 2684: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.2906 - accuracy: 0.7537 - mae: 0.1703 - mse: 0.1055 - val_loss: 0.6940 - val_accuracy: 0.6791 - val_mae: 0.2205 - val_mse: 0.1471 - lr: 1.0000e-04\n",
            "Epoch 2685/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2738 - accuracy: 0.7822 - mae: 0.1633 - mse: 0.0996\n",
            "Epoch 2685: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2767 - accuracy: 0.7826 - mae: 0.1632 - mse: 0.0992 - val_loss: 0.6862 - val_accuracy: 0.6856 - val_mae: 0.2195 - val_mse: 0.1454 - lr: 1.0000e-04\n",
            "Epoch 2686/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2683 - accuracy: 0.7773 - mae: 0.1630 - mse: 0.0975\n",
            "Epoch 2686: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2638 - accuracy: 0.7807 - mae: 0.1612 - mse: 0.0959 - val_loss: 0.6983 - val_accuracy: 0.6695 - val_mae: 0.2227 - val_mse: 0.1483 - lr: 1.0000e-04\n",
            "Epoch 2687/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2907 - accuracy: 0.7632 - mae: 0.1675 - mse: 0.1029\n",
            "Epoch 2687: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.2906 - accuracy: 0.7606 - mae: 0.1691 - mse: 0.1046 - val_loss: 0.7122 - val_accuracy: 0.6599 - val_mae: 0.2256 - val_mse: 0.1514 - lr: 1.0000e-04\n",
            "Epoch 2688/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2938 - accuracy: 0.7524 - mae: 0.1717 - mse: 0.1066\n",
            "Epoch 2688: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.2967 - accuracy: 0.7509 - mae: 0.1723 - mse: 0.1070 - val_loss: 0.7194 - val_accuracy: 0.6620 - val_mae: 0.2276 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2689/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2809 - accuracy: 0.7583 - mae: 0.1725 - mse: 0.1049\n",
            "Epoch 2689: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2818 - accuracy: 0.7546 - mae: 0.1733 - mse: 0.1063 - val_loss: 0.7280 - val_accuracy: 0.6556 - val_mae: 0.2304 - val_mse: 0.1555 - lr: 1.0000e-04\n",
            "Epoch 2690/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2904 - accuracy: 0.7451 - mae: 0.1772 - mse: 0.1117\n",
            "Epoch 2690: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2964 - accuracy: 0.7450 - mae: 0.1776 - mse: 0.1119 - val_loss: 0.7263 - val_accuracy: 0.6535 - val_mae: 0.2309 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2691/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2886 - accuracy: 0.7515 - mae: 0.1735 - mse: 0.1068\n",
            "Epoch 2691: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2891 - accuracy: 0.7500 - mae: 0.1748 - mse: 0.1079 - val_loss: 0.7281 - val_accuracy: 0.6567 - val_mae: 0.2321 - val_mse: 0.1565 - lr: 1.0000e-04\n",
            "Epoch 2692/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2882 - accuracy: 0.7529 - mae: 0.1748 - mse: 0.1099\n",
            "Epoch 2692: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2875 - accuracy: 0.7509 - mae: 0.1752 - mse: 0.1100 - val_loss: 0.7212 - val_accuracy: 0.6599 - val_mae: 0.2305 - val_mse: 0.1548 - lr: 1.0000e-04\n",
            "Epoch 2693/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2803 - accuracy: 0.7607 - mae: 0.1727 - mse: 0.1054\n",
            "Epoch 2693: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2825 - accuracy: 0.7596 - mae: 0.1739 - mse: 0.1063 - val_loss: 0.7177 - val_accuracy: 0.6674 - val_mae: 0.2290 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2694/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2872 - accuracy: 0.7578 - mae: 0.1735 - mse: 0.1056\n",
            "Epoch 2694: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2873 - accuracy: 0.7592 - mae: 0.1722 - mse: 0.1045 - val_loss: 0.7175 - val_accuracy: 0.6684 - val_mae: 0.2280 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2695/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2925 - accuracy: 0.7529 - mae: 0.1729 - mse: 0.1058\n",
            "Epoch 2695: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2926 - accuracy: 0.7528 - mae: 0.1722 - mse: 0.1051 - val_loss: 0.7262 - val_accuracy: 0.6631 - val_mae: 0.2292 - val_mse: 0.1545 - lr: 1.0000e-04\n",
            "Epoch 2696/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2663 - accuracy: 0.7568 - mae: 0.1713 - mse: 0.1049\n",
            "Epoch 2696: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2753 - accuracy: 0.7560 - mae: 0.1725 - mse: 0.1052 - val_loss: 0.7425 - val_accuracy: 0.6492 - val_mae: 0.2318 - val_mse: 0.1577 - lr: 1.0000e-04\n",
            "Epoch 2697/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.7505 - mae: 0.1757 - mse: 0.1118\n",
            "Epoch 2697: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 185ms/step - loss: 0.2835 - accuracy: 0.7505 - mae: 0.1757 - mse: 0.1118 - val_loss: 0.7621 - val_accuracy: 0.6439 - val_mae: 0.2357 - val_mse: 0.1620 - lr: 1.0000e-04\n",
            "Epoch 2698/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2901 - accuracy: 0.7456 - mae: 0.1811 - mse: 0.1151\n",
            "Epoch 2698: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2890 - accuracy: 0.7445 - mae: 0.1813 - mse: 0.1151 - val_loss: 0.7624 - val_accuracy: 0.6417 - val_mae: 0.2354 - val_mse: 0.1619 - lr: 1.0000e-04\n",
            "Epoch 2699/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2818 - accuracy: 0.7471 - mae: 0.1789 - mse: 0.1132\n",
            "Epoch 2699: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2812 - accuracy: 0.7495 - mae: 0.1781 - mse: 0.1122 - val_loss: 0.7456 - val_accuracy: 0.6545 - val_mae: 0.2314 - val_mse: 0.1579 - lr: 1.0000e-04\n",
            "Epoch 2700/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.7505 - mae: 0.1763 - mse: 0.1112\n",
            "Epoch 2700: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.2998 - accuracy: 0.7505 - mae: 0.1763 - mse: 0.1112 - val_loss: 0.7338 - val_accuracy: 0.6620 - val_mae: 0.2290 - val_mse: 0.1553 - lr: 1.0000e-04\n",
            "Epoch 2701/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.7573 - mae: 0.1737 - mse: 0.1084\n",
            "Epoch 2701: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.2860 - accuracy: 0.7573 - mae: 0.1737 - mse: 0.1084 - val_loss: 0.7151 - val_accuracy: 0.6642 - val_mae: 0.2248 - val_mse: 0.1510 - lr: 1.0000e-04\n",
            "Epoch 2702/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2807 - accuracy: 0.7607 - mae: 0.1686 - mse: 0.1041\n",
            "Epoch 2702: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.2865 - accuracy: 0.7628 - mae: 0.1684 - mse: 0.1038 - val_loss: 0.7063 - val_accuracy: 0.6695 - val_mae: 0.2229 - val_mse: 0.1491 - lr: 1.0000e-04\n",
            "Epoch 2703/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.7651 - mae: 0.1679 - mse: 0.1035\n",
            "Epoch 2703: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.2849 - accuracy: 0.7651 - mae: 0.1679 - mse: 0.1035 - val_loss: 0.7348 - val_accuracy: 0.6545 - val_mae: 0.2295 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2704/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.7495 - mae: 0.1756 - mse: 0.1124\n",
            "Epoch 2704: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.2977 - accuracy: 0.7495 - mae: 0.1756 - mse: 0.1124 - val_loss: 0.7639 - val_accuracy: 0.6428 - val_mae: 0.2359 - val_mse: 0.1623 - lr: 1.0000e-04\n",
            "Epoch 2705/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.7459 - mae: 0.1790 - mse: 0.1145\n",
            "Epoch 2705: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.2758 - accuracy: 0.7459 - mae: 0.1790 - mse: 0.1145 - val_loss: 0.7614 - val_accuracy: 0.6439 - val_mae: 0.2351 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 2706/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.7491 - mae: 0.1749 - mse: 0.1102\n",
            "Epoch 2706: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.2801 - accuracy: 0.7491 - mae: 0.1749 - mse: 0.1102 - val_loss: 0.7403 - val_accuracy: 0.6578 - val_mae: 0.2299 - val_mse: 0.1565 - lr: 1.0000e-04\n",
            "Epoch 2707/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.7560 - mae: 0.1712 - mse: 0.1057\n",
            "Epoch 2707: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.2837 - accuracy: 0.7560 - mae: 0.1712 - mse: 0.1057 - val_loss: 0.7277 - val_accuracy: 0.6749 - val_mae: 0.2260 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2708/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2858 - accuracy: 0.7588 - mae: 0.1714 - mse: 0.1052\n",
            "Epoch 2708: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.2889 - accuracy: 0.7638 - mae: 0.1693 - mse: 0.1038 - val_loss: 0.7186 - val_accuracy: 0.6813 - val_mae: 0.2228 - val_mse: 0.1504 - lr: 1.0000e-04\n",
            "Epoch 2709/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.7743 - mae: 0.1631 - mse: 0.0992\n",
            "Epoch 2709: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.2852 - accuracy: 0.7743 - mae: 0.1631 - mse: 0.0992 - val_loss: 0.7382 - val_accuracy: 0.6717 - val_mae: 0.2274 - val_mse: 0.1549 - lr: 1.0000e-04\n",
            "Epoch 2710/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2915 - accuracy: 0.7695 - mae: 0.1678 - mse: 0.1030\n",
            "Epoch 2710: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.2915 - accuracy: 0.7683 - mae: 0.1685 - mse: 0.1035 - val_loss: 0.7619 - val_accuracy: 0.6578 - val_mae: 0.2329 - val_mse: 0.1605 - lr: 1.0000e-04\n",
            "Epoch 2711/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2713 - accuracy: 0.7573 - mae: 0.1727 - mse: 0.1093\n",
            "Epoch 2711: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2728 - accuracy: 0.7555 - mae: 0.1738 - mse: 0.1102 - val_loss: 0.7661 - val_accuracy: 0.6524 - val_mae: 0.2338 - val_mse: 0.1616 - lr: 1.0000e-04\n",
            "Epoch 2712/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.7431 - mae: 0.1783 - mse: 0.1125\n",
            "Epoch 2712: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 0.2952 - accuracy: 0.7431 - mae: 0.1783 - mse: 0.1125 - val_loss: 0.7591 - val_accuracy: 0.6513 - val_mae: 0.2324 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2713/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2993 - accuracy: 0.7446 - mae: 0.1752 - mse: 0.1128\n",
            "Epoch 2713: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2989 - accuracy: 0.7436 - mae: 0.1763 - mse: 0.1136 - val_loss: 0.7500 - val_accuracy: 0.6556 - val_mae: 0.2316 - val_mse: 0.1590 - lr: 1.0000e-04\n",
            "Epoch 2714/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2865 - accuracy: 0.7441 - mae: 0.1759 - mse: 0.1132\n",
            "Epoch 2714: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2845 - accuracy: 0.7486 - mae: 0.1750 - mse: 0.1118 - val_loss: 0.7337 - val_accuracy: 0.6717 - val_mae: 0.2285 - val_mse: 0.1556 - lr: 1.0000e-04\n",
            "Epoch 2715/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.7606 - mae: 0.1713 - mse: 0.1051\n",
            "Epoch 2715: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.2880 - accuracy: 0.7606 - mae: 0.1713 - mse: 0.1051 - val_loss: 0.7225 - val_accuracy: 0.6706 - val_mae: 0.2258 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2716/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2756 - accuracy: 0.7637 - mae: 0.1695 - mse: 0.1051\n",
            "Epoch 2716: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2730 - accuracy: 0.7651 - mae: 0.1679 - mse: 0.1039 - val_loss: 0.7119 - val_accuracy: 0.6781 - val_mae: 0.2226 - val_mse: 0.1503 - lr: 1.0000e-04\n",
            "Epoch 2717/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2925 - accuracy: 0.7778 - mae: 0.1635 - mse: 0.0995\n",
            "Epoch 2717: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2913 - accuracy: 0.7807 - mae: 0.1623 - mse: 0.0987 - val_loss: 0.7136 - val_accuracy: 0.6759 - val_mae: 0.2226 - val_mse: 0.1505 - lr: 1.0000e-04\n",
            "Epoch 2718/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3051 - accuracy: 0.7637 - mae: 0.1702 - mse: 0.1053\n",
            "Epoch 2718: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.3040 - accuracy: 0.7665 - mae: 0.1701 - mse: 0.1051 - val_loss: 0.7313 - val_accuracy: 0.6674 - val_mae: 0.2267 - val_mse: 0.1547 - lr: 1.0000e-04\n",
            "Epoch 2719/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2764 - accuracy: 0.7520 - mae: 0.1706 - mse: 0.1068\n",
            "Epoch 2719: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2732 - accuracy: 0.7555 - mae: 0.1699 - mse: 0.1055 - val_loss: 0.7426 - val_accuracy: 0.6578 - val_mae: 0.2285 - val_mse: 0.1569 - lr: 1.0000e-04\n",
            "Epoch 2720/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2877 - accuracy: 0.7539 - mae: 0.1720 - mse: 0.1104\n",
            "Epoch 2720: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 0.2897 - accuracy: 0.7518 - mae: 0.1731 - mse: 0.1112 - val_loss: 0.7401 - val_accuracy: 0.6610 - val_mae: 0.2278 - val_mse: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 2721/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2851 - accuracy: 0.7627 - mae: 0.1704 - mse: 0.1060\n",
            "Epoch 2721: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 0.2817 - accuracy: 0.7638 - mae: 0.1689 - mse: 0.1054 - val_loss: 0.7364 - val_accuracy: 0.6663 - val_mae: 0.2268 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2722/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2689 - accuracy: 0.7612 - mae: 0.1692 - mse: 0.1053\n",
            "Epoch 2722: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2704 - accuracy: 0.7642 - mae: 0.1677 - mse: 0.1042 - val_loss: 0.7311 - val_accuracy: 0.6727 - val_mae: 0.2247 - val_mse: 0.1538 - lr: 1.0000e-04\n",
            "Epoch 2723/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2877 - accuracy: 0.7583 - mae: 0.1702 - mse: 0.1070\n",
            "Epoch 2723: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2857 - accuracy: 0.7564 - mae: 0.1708 - mse: 0.1074 - val_loss: 0.7324 - val_accuracy: 0.6695 - val_mae: 0.2246 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 2724/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3004 - accuracy: 0.7632 - mae: 0.1709 - mse: 0.1077\n",
            "Epoch 2724: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2957 - accuracy: 0.7651 - mae: 0.1694 - mse: 0.1066 - val_loss: 0.7224 - val_accuracy: 0.6770 - val_mae: 0.2229 - val_mse: 0.1518 - lr: 1.0000e-04\n",
            "Epoch 2725/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2755 - accuracy: 0.7661 - mae: 0.1669 - mse: 0.1030\n",
            "Epoch 2725: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2725 - accuracy: 0.7679 - mae: 0.1656 - mse: 0.1019 - val_loss: 0.7196 - val_accuracy: 0.6663 - val_mae: 0.2223 - val_mse: 0.1510 - lr: 1.0000e-04\n",
            "Epoch 2726/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2783 - accuracy: 0.7583 - mae: 0.1663 - mse: 0.1042\n",
            "Epoch 2726: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2784 - accuracy: 0.7596 - mae: 0.1650 - mse: 0.1028 - val_loss: 0.7264 - val_accuracy: 0.6610 - val_mae: 0.2237 - val_mse: 0.1523 - lr: 1.0000e-04\n",
            "Epoch 2727/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2822 - accuracy: 0.7578 - mae: 0.1675 - mse: 0.1050\n",
            "Epoch 2727: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2806 - accuracy: 0.7573 - mae: 0.1670 - mse: 0.1047 - val_loss: 0.7390 - val_accuracy: 0.6652 - val_mae: 0.2268 - val_mse: 0.1553 - lr: 1.0000e-04\n",
            "Epoch 2728/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2838 - accuracy: 0.7578 - mae: 0.1703 - mse: 0.1079\n",
            "Epoch 2728: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.2841 - accuracy: 0.7592 - mae: 0.1701 - mse: 0.1073 - val_loss: 0.7481 - val_accuracy: 0.6620 - val_mae: 0.2290 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2729/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.7482 - mae: 0.1737 - mse: 0.1098\n",
            "Epoch 2729: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.2899 - accuracy: 0.7482 - mae: 0.1737 - mse: 0.1098 - val_loss: 0.7558 - val_accuracy: 0.6578 - val_mae: 0.2312 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2730/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2824 - accuracy: 0.7524 - mae: 0.1735 - mse: 0.1106\n",
            "Epoch 2730: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 0.2823 - accuracy: 0.7495 - mae: 0.1743 - mse: 0.1112 - val_loss: 0.7619 - val_accuracy: 0.6588 - val_mae: 0.2333 - val_mse: 0.1611 - lr: 1.0000e-04\n",
            "Epoch 2731/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.7500 - mae: 0.1754 - mse: 0.1104\n",
            "Epoch 2731: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.2808 - accuracy: 0.7500 - mae: 0.1754 - mse: 0.1104 - val_loss: 0.7539 - val_accuracy: 0.6652 - val_mae: 0.2316 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2732/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3107 - accuracy: 0.7559 - mae: 0.1756 - mse: 0.1121\n",
            "Epoch 2732: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3068 - accuracy: 0.7592 - mae: 0.1746 - mse: 0.1109 - val_loss: 0.7376 - val_accuracy: 0.6759 - val_mae: 0.2288 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2733/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.7592 - mae: 0.1722 - mse: 0.1054\n",
            "Epoch 2733: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.2954 - accuracy: 0.7592 - mae: 0.1722 - mse: 0.1054 - val_loss: 0.7267 - val_accuracy: 0.6674 - val_mae: 0.2265 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2734/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.7628 - mae: 0.1709 - mse: 0.1048\n",
            "Epoch 2734: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.2860 - accuracy: 0.7628 - mae: 0.1709 - mse: 0.1048 - val_loss: 0.7132 - val_accuracy: 0.6706 - val_mae: 0.2226 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2735/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.7716 - mae: 0.1661 - mse: 0.1022\n",
            "Epoch 2735: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.2832 - accuracy: 0.7716 - mae: 0.1661 - mse: 0.1022 - val_loss: 0.7014 - val_accuracy: 0.6781 - val_mae: 0.2196 - val_mse: 0.1473 - lr: 1.0000e-04\n",
            "Epoch 2736/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.7651 - mae: 0.1676 - mse: 0.1033\n",
            "Epoch 2736: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.2926 - accuracy: 0.7651 - mae: 0.1676 - mse: 0.1033 - val_loss: 0.6930 - val_accuracy: 0.6824 - val_mae: 0.2182 - val_mse: 0.1458 - lr: 1.0000e-04\n",
            "Epoch 2737/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2879 - accuracy: 0.7734 - mae: 0.1643 - mse: 0.1000\n",
            "Epoch 2737: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.2912 - accuracy: 0.7729 - mae: 0.1652 - mse: 0.1008 - val_loss: 0.7071 - val_accuracy: 0.6749 - val_mae: 0.2233 - val_mse: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 2738/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2746 - accuracy: 0.7690 - mae: 0.1667 - mse: 0.0999\n",
            "Epoch 2738: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2735 - accuracy: 0.7661 - mae: 0.1678 - mse: 0.1012 - val_loss: 0.7162 - val_accuracy: 0.6727 - val_mae: 0.2266 - val_mse: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 2739/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2790 - accuracy: 0.7754 - mae: 0.1660 - mse: 0.0994\n",
            "Epoch 2739: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 191ms/step - loss: 0.2815 - accuracy: 0.7752 - mae: 0.1660 - mse: 0.0990 - val_loss: 0.7230 - val_accuracy: 0.6674 - val_mae: 0.2291 - val_mse: 0.1551 - lr: 1.0000e-04\n",
            "Epoch 2740/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2916 - accuracy: 0.7510 - mae: 0.1747 - mse: 0.1081\n",
            "Epoch 2740: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2873 - accuracy: 0.7523 - mae: 0.1744 - mse: 0.1076 - val_loss: 0.7350 - val_accuracy: 0.6567 - val_mae: 0.2324 - val_mse: 0.1582 - lr: 1.0000e-04\n",
            "Epoch 2741/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2823 - accuracy: 0.7412 - mae: 0.1783 - mse: 0.1121\n",
            "Epoch 2741: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2852 - accuracy: 0.7440 - mae: 0.1777 - mse: 0.1115 - val_loss: 0.7350 - val_accuracy: 0.6535 - val_mae: 0.2320 - val_mse: 0.1581 - lr: 1.0000e-04\n",
            "Epoch 2742/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.7404 - mae: 0.1776 - mse: 0.1120\n",
            "Epoch 2742: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2934 - accuracy: 0.7404 - mae: 0.1776 - mse: 0.1120 - val_loss: 0.7410 - val_accuracy: 0.6513 - val_mae: 0.2328 - val_mse: 0.1593 - lr: 1.0000e-04\n",
            "Epoch 2743/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2876 - accuracy: 0.7549 - mae: 0.1765 - mse: 0.1091\n",
            "Epoch 2743: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2876 - accuracy: 0.7523 - mae: 0.1776 - mse: 0.1108 - val_loss: 0.7329 - val_accuracy: 0.6567 - val_mae: 0.2307 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2744/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2941 - accuracy: 0.7563 - mae: 0.1748 - mse: 0.1096\n",
            "Epoch 2744: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2957 - accuracy: 0.7528 - mae: 0.1758 - mse: 0.1106 - val_loss: 0.7175 - val_accuracy: 0.6642 - val_mae: 0.2267 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2745/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2877 - accuracy: 0.7588 - mae: 0.1696 - mse: 0.1048\n",
            "Epoch 2745: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2880 - accuracy: 0.7555 - mae: 0.1712 - mse: 0.1062 - val_loss: 0.7026 - val_accuracy: 0.6759 - val_mae: 0.2226 - val_mse: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 2746/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2875 - accuracy: 0.7734 - mae: 0.1675 - mse: 0.1027\n",
            "Epoch 2746: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2865 - accuracy: 0.7775 - mae: 0.1661 - mse: 0.1009 - val_loss: 0.6952 - val_accuracy: 0.6845 - val_mae: 0.2197 - val_mse: 0.1469 - lr: 1.0000e-04\n",
            "Epoch 2747/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2780 - accuracy: 0.7891 - mae: 0.1630 - mse: 0.0972\n",
            "Epoch 2747: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2785 - accuracy: 0.7881 - mae: 0.1625 - mse: 0.0966 - val_loss: 0.7172 - val_accuracy: 0.6781 - val_mae: 0.2240 - val_mse: 0.1515 - lr: 1.0000e-04\n",
            "Epoch 2748/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2785 - accuracy: 0.7754 - mae: 0.1687 - mse: 0.1029\n",
            "Epoch 2748: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2811 - accuracy: 0.7757 - mae: 0.1684 - mse: 0.1029 - val_loss: 0.7472 - val_accuracy: 0.6642 - val_mae: 0.2307 - val_mse: 0.1584 - lr: 1.0000e-04\n",
            "Epoch 2749/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2794 - accuracy: 0.7549 - mae: 0.1765 - mse: 0.1114\n",
            "Epoch 2749: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2818 - accuracy: 0.7532 - mae: 0.1773 - mse: 0.1117 - val_loss: 0.7597 - val_accuracy: 0.6513 - val_mae: 0.2345 - val_mse: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 2750/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2897 - accuracy: 0.7334 - mae: 0.1825 - mse: 0.1191\n",
            "Epoch 2750: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.2874 - accuracy: 0.7335 - mae: 0.1820 - mse: 0.1189 - val_loss: 0.7564 - val_accuracy: 0.6428 - val_mae: 0.2339 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 2751/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2796 - accuracy: 0.7422 - mae: 0.1771 - mse: 0.1130\n",
            "Epoch 2751: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2766 - accuracy: 0.7413 - mae: 0.1767 - mse: 0.1128 - val_loss: 0.7255 - val_accuracy: 0.6513 - val_mae: 0.2263 - val_mse: 0.1540 - lr: 1.0000e-04\n",
            "Epoch 2752/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2741 - accuracy: 0.7681 - mae: 0.1679 - mse: 0.1037\n",
            "Epoch 2752: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2754 - accuracy: 0.7670 - mae: 0.1676 - mse: 0.1039 - val_loss: 0.6858 - val_accuracy: 0.6727 - val_mae: 0.2167 - val_mse: 0.1445 - lr: 1.0000e-04\n",
            "Epoch 2753/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2919 - accuracy: 0.7798 - mae: 0.1615 - mse: 0.0980\n",
            "Epoch 2753: val_loss did not improve from 0.66434\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2877 - accuracy: 0.7807 - mae: 0.1614 - mse: 0.0978 - val_loss: 0.6659 - val_accuracy: 0.6877 - val_mae: 0.2119 - val_mse: 0.1398 - lr: 1.0000e-04\n",
            "Epoch 2754/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2806 - accuracy: 0.7979 - mae: 0.1556 - mse: 0.0920\n",
            "Epoch 2754: val_loss improved from 0.66434 to 0.66430, saving model to models/stock_cnn_best_model.h5\n",
            "3/3 [==============================] - 1s 474ms/step - loss: 0.2794 - accuracy: 0.7982 - mae: 0.1559 - mse: 0.0921 - val_loss: 0.6643 - val_accuracy: 0.6856 - val_mae: 0.2119 - val_mse: 0.1397 - lr: 1.0000e-04\n",
            "Epoch 2755/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.7931 - mae: 0.1578 - mse: 0.0933\n",
            "Epoch 2755: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.2873 - accuracy: 0.7931 - mae: 0.1578 - mse: 0.0933 - val_loss: 0.6806 - val_accuracy: 0.6813 - val_mae: 0.2172 - val_mse: 0.1441 - lr: 1.0000e-04\n",
            "Epoch 2756/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2865 - accuracy: 0.7783 - mae: 0.1636 - mse: 0.0985\n",
            "Epoch 2756: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.2820 - accuracy: 0.7798 - mae: 0.1626 - mse: 0.0982 - val_loss: 0.7049 - val_accuracy: 0.6717 - val_mae: 0.2235 - val_mse: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 2757/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.7651 - mae: 0.1685 - mse: 0.1033\n",
            "Epoch 2757: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.2868 - accuracy: 0.7651 - mae: 0.1685 - mse: 0.1033 - val_loss: 0.7239 - val_accuracy: 0.6620 - val_mae: 0.2281 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2758/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2831 - accuracy: 0.7578 - mae: 0.1704 - mse: 0.1054\n",
            "Epoch 2758: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.2815 - accuracy: 0.7606 - mae: 0.1693 - mse: 0.1043 - val_loss: 0.7341 - val_accuracy: 0.6578 - val_mae: 0.2300 - val_mse: 0.1565 - lr: 1.0000e-04\n",
            "Epoch 2759/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.7656 - mae: 0.1694 - mse: 0.1045\n",
            "Epoch 2759: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.2661 - accuracy: 0.7656 - mae: 0.1694 - mse: 0.1045 - val_loss: 0.7303 - val_accuracy: 0.6631 - val_mae: 0.2280 - val_mse: 0.1551 - lr: 1.0000e-04\n",
            "Epoch 2760/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2671 - accuracy: 0.7686 - mae: 0.1680 - mse: 0.1055\n",
            "Epoch 2760: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.2733 - accuracy: 0.7670 - mae: 0.1690 - mse: 0.1057 - val_loss: 0.7090 - val_accuracy: 0.6759 - val_mae: 0.2219 - val_mse: 0.1495 - lr: 1.0000e-04\n",
            "Epoch 2761/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.7720 - mae: 0.1631 - mse: 0.1001\n",
            "Epoch 2761: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.2647 - accuracy: 0.7720 - mae: 0.1631 - mse: 0.1001 - val_loss: 0.6933 - val_accuracy: 0.6877 - val_mae: 0.2172 - val_mse: 0.1453 - lr: 1.0000e-04\n",
            "Epoch 2762/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2657 - accuracy: 0.7715 - mae: 0.1616 - mse: 0.0990\n",
            "Epoch 2762: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.2699 - accuracy: 0.7743 - mae: 0.1607 - mse: 0.0985 - val_loss: 0.6970 - val_accuracy: 0.6866 - val_mae: 0.2174 - val_mse: 0.1457 - lr: 1.0000e-04\n",
            "Epoch 2763/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.7702 - mae: 0.1635 - mse: 0.1000\n",
            "Epoch 2763: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.2913 - accuracy: 0.7702 - mae: 0.1635 - mse: 0.1000 - val_loss: 0.7262 - val_accuracy: 0.6695 - val_mae: 0.2247 - val_mse: 0.1526 - lr: 1.0000e-04\n",
            "Epoch 2764/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2871 - accuracy: 0.7646 - mae: 0.1677 - mse: 0.1042\n",
            "Epoch 2764: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2857 - accuracy: 0.7606 - mae: 0.1695 - mse: 0.1063 - val_loss: 0.7396 - val_accuracy: 0.6642 - val_mae: 0.2284 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2765/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2853 - accuracy: 0.7456 - mae: 0.1731 - mse: 0.1088\n",
            "Epoch 2765: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2865 - accuracy: 0.7486 - mae: 0.1731 - mse: 0.1088 - val_loss: 0.7261 - val_accuracy: 0.6695 - val_mae: 0.2256 - val_mse: 0.1527 - lr: 1.0000e-04\n",
            "Epoch 2766/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2850 - accuracy: 0.7603 - mae: 0.1683 - mse: 0.1040\n",
            "Epoch 2766: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2870 - accuracy: 0.7624 - mae: 0.1683 - mse: 0.1040 - val_loss: 0.7183 - val_accuracy: 0.6759 - val_mae: 0.2243 - val_mse: 0.1510 - lr: 1.0000e-04\n",
            "Epoch 2767/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2837 - accuracy: 0.7529 - mae: 0.1703 - mse: 0.1069\n",
            "Epoch 2767: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2872 - accuracy: 0.7495 - mae: 0.1727 - mse: 0.1085 - val_loss: 0.7158 - val_accuracy: 0.6738 - val_mae: 0.2244 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2768/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2851 - accuracy: 0.7588 - mae: 0.1706 - mse: 0.1057\n",
            "Epoch 2768: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2807 - accuracy: 0.7633 - mae: 0.1685 - mse: 0.1039 - val_loss: 0.7086 - val_accuracy: 0.6781 - val_mae: 0.2231 - val_mse: 0.1492 - lr: 1.0000e-04\n",
            "Epoch 2769/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2784 - accuracy: 0.7788 - mae: 0.1658 - mse: 0.1001\n",
            "Epoch 2769: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2758 - accuracy: 0.7789 - mae: 0.1657 - mse: 0.0999 - val_loss: 0.7092 - val_accuracy: 0.6738 - val_mae: 0.2233 - val_mse: 0.1494 - lr: 1.0000e-04\n",
            "Epoch 2770/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2696 - accuracy: 0.7700 - mae: 0.1666 - mse: 0.1001\n",
            "Epoch 2770: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2728 - accuracy: 0.7670 - mae: 0.1677 - mse: 0.1014 - val_loss: 0.7092 - val_accuracy: 0.6717 - val_mae: 0.2226 - val_mse: 0.1490 - lr: 1.0000e-04\n",
            "Epoch 2771/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2877 - accuracy: 0.7803 - mae: 0.1682 - mse: 0.1017\n",
            "Epoch 2771: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2867 - accuracy: 0.7798 - mae: 0.1673 - mse: 0.1010 - val_loss: 0.7191 - val_accuracy: 0.6695 - val_mae: 0.2239 - val_mse: 0.1509 - lr: 1.0000e-04\n",
            "Epoch 2772/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2886 - accuracy: 0.7671 - mae: 0.1673 - mse: 0.1033\n",
            "Epoch 2772: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2847 - accuracy: 0.7670 - mae: 0.1668 - mse: 0.1027 - val_loss: 0.7389 - val_accuracy: 0.6631 - val_mae: 0.2276 - val_mse: 0.1550 - lr: 1.0000e-04\n",
            "Epoch 2773/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2815 - accuracy: 0.7627 - mae: 0.1690 - mse: 0.1048\n",
            "Epoch 2773: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2800 - accuracy: 0.7647 - mae: 0.1692 - mse: 0.1048 - val_loss: 0.7447 - val_accuracy: 0.6631 - val_mae: 0.2277 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2774/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2680 - accuracy: 0.7588 - mae: 0.1693 - mse: 0.1062\n",
            "Epoch 2774: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2724 - accuracy: 0.7596 - mae: 0.1691 - mse: 0.1060 - val_loss: 0.7451 - val_accuracy: 0.6706 - val_mae: 0.2274 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2775/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2838 - accuracy: 0.7563 - mae: 0.1735 - mse: 0.1097\n",
            "Epoch 2775: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2811 - accuracy: 0.7564 - mae: 0.1734 - mse: 0.1097 - val_loss: 0.7479 - val_accuracy: 0.6738 - val_mae: 0.2278 - val_mse: 0.1564 - lr: 1.0000e-04\n",
            "Epoch 2776/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2839 - accuracy: 0.7651 - mae: 0.1678 - mse: 0.1040\n",
            "Epoch 2776: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 0.2780 - accuracy: 0.7674 - mae: 0.1668 - mse: 0.1030 - val_loss: 0.7326 - val_accuracy: 0.6813 - val_mae: 0.2245 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2777/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2856 - accuracy: 0.7666 - mae: 0.1664 - mse: 0.1038\n",
            "Epoch 2777: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2867 - accuracy: 0.7688 - mae: 0.1662 - mse: 0.1032 - val_loss: 0.7161 - val_accuracy: 0.6802 - val_mae: 0.2207 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2778/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3018 - accuracy: 0.7559 - mae: 0.1717 - mse: 0.1085\n",
            "Epoch 2778: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2980 - accuracy: 0.7596 - mae: 0.1703 - mse: 0.1070 - val_loss: 0.7216 - val_accuracy: 0.6706 - val_mae: 0.2225 - val_mse: 0.1513 - lr: 1.0000e-04\n",
            "Epoch 2779/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2832 - accuracy: 0.7744 - mae: 0.1642 - mse: 0.1017\n",
            "Epoch 2779: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2810 - accuracy: 0.7729 - mae: 0.1645 - mse: 0.1013 - val_loss: 0.7284 - val_accuracy: 0.6674 - val_mae: 0.2248 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2780/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2786 - accuracy: 0.7642 - mae: 0.1667 - mse: 0.1032\n",
            "Epoch 2780: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2777 - accuracy: 0.7596 - mae: 0.1679 - mse: 0.1045 - val_loss: 0.7241 - val_accuracy: 0.6663 - val_mae: 0.2238 - val_mse: 0.1520 - lr: 1.0000e-04\n",
            "Epoch 2781/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2690 - accuracy: 0.7769 - mae: 0.1638 - mse: 0.1004\n",
            "Epoch 2781: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2719 - accuracy: 0.7766 - mae: 0.1636 - mse: 0.1007 - val_loss: 0.7160 - val_accuracy: 0.6706 - val_mae: 0.2220 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2782/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.7711 - mae: 0.1646 - mse: 0.1002\n",
            "Epoch 2782: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2761 - accuracy: 0.7711 - mae: 0.1646 - mse: 0.1002 - val_loss: 0.7156 - val_accuracy: 0.6695 - val_mae: 0.2223 - val_mse: 0.1502 - lr: 1.0000e-04\n",
            "Epoch 2783/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.7633 - mae: 0.1660 - mse: 0.1025\n",
            "Epoch 2783: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.2728 - accuracy: 0.7633 - mae: 0.1660 - mse: 0.1025 - val_loss: 0.7124 - val_accuracy: 0.6727 - val_mae: 0.2219 - val_mse: 0.1495 - lr: 1.0000e-04\n",
            "Epoch 2784/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2677 - accuracy: 0.7666 - mae: 0.1644 - mse: 0.1016\n",
            "Epoch 2784: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.2644 - accuracy: 0.7674 - mae: 0.1644 - mse: 0.1011 - val_loss: 0.7110 - val_accuracy: 0.6684 - val_mae: 0.2217 - val_mse: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 2785/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.7610 - mae: 0.1664 - mse: 0.1028\n",
            "Epoch 2785: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.2804 - accuracy: 0.7610 - mae: 0.1664 - mse: 0.1028 - val_loss: 0.7038 - val_accuracy: 0.6727 - val_mae: 0.2197 - val_mse: 0.1474 - lr: 1.0000e-04\n",
            "Epoch 2786/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.7633 - mae: 0.1677 - mse: 0.1032\n",
            "Epoch 2786: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.2801 - accuracy: 0.7633 - mae: 0.1677 - mse: 0.1032 - val_loss: 0.6977 - val_accuracy: 0.6834 - val_mae: 0.2179 - val_mse: 0.1457 - lr: 1.0000e-04\n",
            "Epoch 2787/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.7936 - mae: 0.1566 - mse: 0.0931\n",
            "Epoch 2787: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.2650 - accuracy: 0.7936 - mae: 0.1566 - mse: 0.0931 - val_loss: 0.7001 - val_accuracy: 0.6824 - val_mae: 0.2181 - val_mse: 0.1458 - lr: 1.0000e-04\n",
            "Epoch 2788/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.7835 - mae: 0.1620 - mse: 0.0975\n",
            "Epoch 2788: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.2827 - accuracy: 0.7835 - mae: 0.1620 - mse: 0.0975 - val_loss: 0.7160 - val_accuracy: 0.6791 - val_mae: 0.2217 - val_mse: 0.1494 - lr: 1.0000e-04\n",
            "Epoch 2789/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2844 - accuracy: 0.7690 - mae: 0.1670 - mse: 0.1031\n",
            "Epoch 2789: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.2822 - accuracy: 0.7702 - mae: 0.1662 - mse: 0.1024 - val_loss: 0.7276 - val_accuracy: 0.6759 - val_mae: 0.2247 - val_mse: 0.1522 - lr: 1.0000e-04\n",
            "Epoch 2790/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2850 - accuracy: 0.7632 - mae: 0.1680 - mse: 0.1034\n",
            "Epoch 2790: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.2836 - accuracy: 0.7674 - mae: 0.1663 - mse: 0.1015 - val_loss: 0.7427 - val_accuracy: 0.6631 - val_mae: 0.2287 - val_mse: 0.1560 - lr: 1.0000e-04\n",
            "Epoch 2791/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2896 - accuracy: 0.7544 - mae: 0.1738 - mse: 0.1082\n",
            "Epoch 2791: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.2892 - accuracy: 0.7505 - mae: 0.1752 - mse: 0.1096 - val_loss: 0.7589 - val_accuracy: 0.6524 - val_mae: 0.2326 - val_mse: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 2792/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.7459 - mae: 0.1775 - mse: 0.1120\n",
            "Epoch 2792: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.2731 - accuracy: 0.7459 - mae: 0.1775 - mse: 0.1120 - val_loss: 0.7476 - val_accuracy: 0.6578 - val_mae: 0.2299 - val_mse: 0.1573 - lr: 1.0000e-04\n",
            "Epoch 2793/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.7486 - mae: 0.1769 - mse: 0.1115\n",
            "Epoch 2793: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 186ms/step - loss: 0.2917 - accuracy: 0.7486 - mae: 0.1769 - mse: 0.1115 - val_loss: 0.7432 - val_accuracy: 0.6599 - val_mae: 0.2292 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2794/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2880 - accuracy: 0.7520 - mae: 0.1755 - mse: 0.1107\n",
            "Epoch 2794: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2874 - accuracy: 0.7514 - mae: 0.1753 - mse: 0.1107 - val_loss: 0.7473 - val_accuracy: 0.6556 - val_mae: 0.2315 - val_mse: 0.1578 - lr: 1.0000e-04\n",
            "Epoch 2795/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2892 - accuracy: 0.7495 - mae: 0.1754 - mse: 0.1102\n",
            "Epoch 2795: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2879 - accuracy: 0.7477 - mae: 0.1756 - mse: 0.1103 - val_loss: 0.7400 - val_accuracy: 0.6642 - val_mae: 0.2304 - val_mse: 0.1563 - lr: 1.0000e-04\n",
            "Epoch 2796/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2761 - accuracy: 0.7593 - mae: 0.1737 - mse: 0.1084\n",
            "Epoch 2796: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2754 - accuracy: 0.7615 - mae: 0.1726 - mse: 0.1072 - val_loss: 0.7228 - val_accuracy: 0.6791 - val_mae: 0.2264 - val_mse: 0.1522 - lr: 1.0000e-04\n",
            "Epoch 2797/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2707 - accuracy: 0.7827 - mae: 0.1639 - mse: 0.0989\n",
            "Epoch 2797: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2756 - accuracy: 0.7812 - mae: 0.1649 - mse: 0.1000 - val_loss: 0.7127 - val_accuracy: 0.6824 - val_mae: 0.2241 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2798/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2759 - accuracy: 0.7695 - mae: 0.1642 - mse: 0.0991\n",
            "Epoch 2798: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2758 - accuracy: 0.7683 - mae: 0.1654 - mse: 0.1004 - val_loss: 0.7052 - val_accuracy: 0.6888 - val_mae: 0.2222 - val_mse: 0.1485 - lr: 1.0000e-04\n",
            "Epoch 2799/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2782 - accuracy: 0.7695 - mae: 0.1643 - mse: 0.1003\n",
            "Epoch 2799: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2820 - accuracy: 0.7693 - mae: 0.1644 - mse: 0.1002 - val_loss: 0.7077 - val_accuracy: 0.6856 - val_mae: 0.2226 - val_mse: 0.1490 - lr: 1.0000e-04\n",
            "Epoch 2800/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2869 - accuracy: 0.7681 - mae: 0.1671 - mse: 0.1014\n",
            "Epoch 2800: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2867 - accuracy: 0.7693 - mae: 0.1670 - mse: 0.1013 - val_loss: 0.7354 - val_accuracy: 0.6695 - val_mae: 0.2288 - val_mse: 0.1551 - lr: 1.0000e-04\n",
            "Epoch 2801/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2823 - accuracy: 0.7563 - mae: 0.1727 - mse: 0.1069\n",
            "Epoch 2801: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2800 - accuracy: 0.7578 - mae: 0.1721 - mse: 0.1063 - val_loss: 0.7501 - val_accuracy: 0.6684 - val_mae: 0.2320 - val_mse: 0.1583 - lr: 1.0000e-04\n",
            "Epoch 2802/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2856 - accuracy: 0.7637 - mae: 0.1742 - mse: 0.1069\n",
            "Epoch 2802: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2818 - accuracy: 0.7656 - mae: 0.1728 - mse: 0.1058 - val_loss: 0.7509 - val_accuracy: 0.6631 - val_mae: 0.2318 - val_mse: 0.1585 - lr: 1.0000e-04\n",
            "Epoch 2803/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2836 - accuracy: 0.7539 - mae: 0.1752 - mse: 0.1080\n",
            "Epoch 2803: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2858 - accuracy: 0.7518 - mae: 0.1759 - mse: 0.1085 - val_loss: 0.7436 - val_accuracy: 0.6663 - val_mae: 0.2292 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2804/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2961 - accuracy: 0.7505 - mae: 0.1758 - mse: 0.1083\n",
            "Epoch 2804: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2936 - accuracy: 0.7500 - mae: 0.1754 - mse: 0.1081 - val_loss: 0.7410 - val_accuracy: 0.6674 - val_mae: 0.2281 - val_mse: 0.1558 - lr: 1.0000e-04\n",
            "Epoch 2805/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2671 - accuracy: 0.7651 - mae: 0.1682 - mse: 0.1024\n",
            "Epoch 2805: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 185ms/step - loss: 0.2661 - accuracy: 0.7683 - mae: 0.1673 - mse: 0.1017 - val_loss: 0.7311 - val_accuracy: 0.6759 - val_mae: 0.2253 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2806/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2789 - accuracy: 0.7695 - mae: 0.1669 - mse: 0.1016\n",
            "Epoch 2806: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2775 - accuracy: 0.7670 - mae: 0.1665 - mse: 0.1014 - val_loss: 0.7238 - val_accuracy: 0.6749 - val_mae: 0.2237 - val_mse: 0.1518 - lr: 1.0000e-04\n",
            "Epoch 2807/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2766 - accuracy: 0.7627 - mae: 0.1672 - mse: 0.1023\n",
            "Epoch 2807: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2744 - accuracy: 0.7615 - mae: 0.1682 - mse: 0.1030 - val_loss: 0.7107 - val_accuracy: 0.6770 - val_mae: 0.2205 - val_mse: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 2808/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2693 - accuracy: 0.7720 - mae: 0.1627 - mse: 0.0986\n",
            "Epoch 2808: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2702 - accuracy: 0.7743 - mae: 0.1617 - mse: 0.0977 - val_loss: 0.7001 - val_accuracy: 0.6824 - val_mae: 0.2171 - val_mse: 0.1457 - lr: 1.0000e-04\n",
            "Epoch 2809/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2803 - accuracy: 0.7725 - mae: 0.1628 - mse: 0.0998\n",
            "Epoch 2809: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2857 - accuracy: 0.7739 - mae: 0.1626 - mse: 0.0993 - val_loss: 0.7129 - val_accuracy: 0.6759 - val_mae: 0.2199 - val_mse: 0.1485 - lr: 1.0000e-04\n",
            "Epoch 2810/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.7647 - mae: 0.1653 - mse: 0.1023\n",
            "Epoch 2810: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.2905 - accuracy: 0.7647 - mae: 0.1653 - mse: 0.1023 - val_loss: 0.7350 - val_accuracy: 0.6631 - val_mae: 0.2260 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2811/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2810 - accuracy: 0.7615 - mae: 0.1707 - mse: 0.1068\n",
            "Epoch 2811: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.2810 - accuracy: 0.7615 - mae: 0.1707 - mse: 0.1068 - val_loss: 0.7611 - val_accuracy: 0.6513 - val_mae: 0.2333 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 2812/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2816 - accuracy: 0.7427 - mae: 0.1783 - mse: 0.1140\n",
            "Epoch 2812: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.2823 - accuracy: 0.7440 - mae: 0.1778 - mse: 0.1139 - val_loss: 0.7762 - val_accuracy: 0.6513 - val_mae: 0.2367 - val_mse: 0.1642 - lr: 1.0000e-04\n",
            "Epoch 2813/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2718 - accuracy: 0.7334 - mae: 0.1826 - mse: 0.1176\n",
            "Epoch 2813: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.2725 - accuracy: 0.7381 - mae: 0.1811 - mse: 0.1160 - val_loss: 0.7660 - val_accuracy: 0.6620 - val_mae: 0.2341 - val_mse: 0.1615 - lr: 1.0000e-04\n",
            "Epoch 2814/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2618 - accuracy: 0.7456 - mae: 0.1748 - mse: 0.1111\n",
            "Epoch 2814: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.2670 - accuracy: 0.7454 - mae: 0.1757 - mse: 0.1112 - val_loss: 0.7417 - val_accuracy: 0.6738 - val_mae: 0.2280 - val_mse: 0.1555 - lr: 1.0000e-04\n",
            "Epoch 2815/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2848 - accuracy: 0.7476 - mae: 0.1758 - mse: 0.1106\n",
            "Epoch 2815: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2858 - accuracy: 0.7505 - mae: 0.1742 - mse: 0.1097 - val_loss: 0.7287 - val_accuracy: 0.6717 - val_mae: 0.2247 - val_mse: 0.1522 - lr: 1.0000e-04\n",
            "Epoch 2816/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.7601 - mae: 0.1706 - mse: 0.1066\n",
            "Epoch 2816: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.2711 - accuracy: 0.7601 - mae: 0.1706 - mse: 0.1066 - val_loss: 0.7267 - val_accuracy: 0.6588 - val_mae: 0.2238 - val_mse: 0.1515 - lr: 1.0000e-04\n",
            "Epoch 2817/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.7739 - mae: 0.1671 - mse: 0.1035\n",
            "Epoch 2817: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.2809 - accuracy: 0.7739 - mae: 0.1671 - mse: 0.1035 - val_loss: 0.7201 - val_accuracy: 0.6663 - val_mae: 0.2217 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2818/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.7697 - mae: 0.1664 - mse: 0.1029\n",
            "Epoch 2818: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.2843 - accuracy: 0.7697 - mae: 0.1664 - mse: 0.1029 - val_loss: 0.7219 - val_accuracy: 0.6663 - val_mae: 0.2221 - val_mse: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 2819/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.7679 - mae: 0.1655 - mse: 0.1019\n",
            "Epoch 2819: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.2883 - accuracy: 0.7679 - mae: 0.1655 - mse: 0.1019 - val_loss: 0.7323 - val_accuracy: 0.6652 - val_mae: 0.2248 - val_mse: 0.1525 - lr: 1.0000e-04\n",
            "Epoch 2820/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.7587 - mae: 0.1687 - mse: 0.1051\n",
            "Epoch 2820: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.2648 - accuracy: 0.7587 - mae: 0.1687 - mse: 0.1051 - val_loss: 0.7503 - val_accuracy: 0.6599 - val_mae: 0.2290 - val_mse: 0.1566 - lr: 1.0000e-04\n",
            "Epoch 2821/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.7656 - mae: 0.1674 - mse: 0.1056\n",
            "Epoch 2821: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.2650 - accuracy: 0.7656 - mae: 0.1674 - mse: 0.1056 - val_loss: 0.7454 - val_accuracy: 0.6684 - val_mae: 0.2276 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2822/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2826 - accuracy: 0.7549 - mae: 0.1724 - mse: 0.1079\n",
            "Epoch 2822: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2858 - accuracy: 0.7541 - mae: 0.1730 - mse: 0.1087 - val_loss: 0.7368 - val_accuracy: 0.6759 - val_mae: 0.2260 - val_mse: 0.1536 - lr: 1.0000e-04\n",
            "Epoch 2823/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2668 - accuracy: 0.7646 - mae: 0.1661 - mse: 0.1027\n",
            "Epoch 2823: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2660 - accuracy: 0.7642 - mae: 0.1660 - mse: 0.1025 - val_loss: 0.7266 - val_accuracy: 0.6695 - val_mae: 0.2243 - val_mse: 0.1518 - lr: 1.0000e-04\n",
            "Epoch 2824/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2771 - accuracy: 0.7676 - mae: 0.1687 - mse: 0.1033\n",
            "Epoch 2824: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2750 - accuracy: 0.7679 - mae: 0.1686 - mse: 0.1033 - val_loss: 0.7167 - val_accuracy: 0.6727 - val_mae: 0.2218 - val_mse: 0.1495 - lr: 1.0000e-04\n",
            "Epoch 2825/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2752 - accuracy: 0.7788 - mae: 0.1613 - mse: 0.0981\n",
            "Epoch 2825: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2768 - accuracy: 0.7798 - mae: 0.1607 - mse: 0.0976 - val_loss: 0.7034 - val_accuracy: 0.6727 - val_mae: 0.2182 - val_mse: 0.1464 - lr: 1.0000e-04\n",
            "Epoch 2826/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2728 - accuracy: 0.7886 - mae: 0.1590 - mse: 0.0960\n",
            "Epoch 2826: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2749 - accuracy: 0.7872 - mae: 0.1597 - mse: 0.0964 - val_loss: 0.7070 - val_accuracy: 0.6781 - val_mae: 0.2190 - val_mse: 0.1472 - lr: 1.0000e-04\n",
            "Epoch 2827/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2755 - accuracy: 0.7812 - mae: 0.1627 - mse: 0.0990\n",
            "Epoch 2827: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2728 - accuracy: 0.7821 - mae: 0.1617 - mse: 0.0987 - val_loss: 0.7129 - val_accuracy: 0.6824 - val_mae: 0.2202 - val_mse: 0.1485 - lr: 1.0000e-04\n",
            "Epoch 2828/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2736 - accuracy: 0.7651 - mae: 0.1648 - mse: 0.1014\n",
            "Epoch 2828: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2774 - accuracy: 0.7642 - mae: 0.1655 - mse: 0.1021 - val_loss: 0.7167 - val_accuracy: 0.6791 - val_mae: 0.2216 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2829/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2679 - accuracy: 0.7700 - mae: 0.1654 - mse: 0.1012\n",
            "Epoch 2829: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2724 - accuracy: 0.7702 - mae: 0.1662 - mse: 0.1018 - val_loss: 0.7242 - val_accuracy: 0.6738 - val_mae: 0.2243 - val_mse: 0.1519 - lr: 1.0000e-04\n",
            "Epoch 2830/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2618 - accuracy: 0.7632 - mae: 0.1652 - mse: 0.1013\n",
            "Epoch 2830: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2712 - accuracy: 0.7624 - mae: 0.1667 - mse: 0.1027 - val_loss: 0.7398 - val_accuracy: 0.6578 - val_mae: 0.2291 - val_mse: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 2831/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2702 - accuracy: 0.7500 - mae: 0.1732 - mse: 0.1097\n",
            "Epoch 2831: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2704 - accuracy: 0.7509 - mae: 0.1735 - mse: 0.1099 - val_loss: 0.7540 - val_accuracy: 0.6471 - val_mae: 0.2333 - val_mse: 0.1601 - lr: 1.0000e-04\n",
            "Epoch 2832/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2646 - accuracy: 0.7368 - mae: 0.1776 - mse: 0.1134\n",
            "Epoch 2832: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2691 - accuracy: 0.7349 - mae: 0.1783 - mse: 0.1138 - val_loss: 0.7387 - val_accuracy: 0.6503 - val_mae: 0.2309 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2833/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2910 - accuracy: 0.7422 - mae: 0.1801 - mse: 0.1128\n",
            "Epoch 2833: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2875 - accuracy: 0.7431 - mae: 0.1791 - mse: 0.1123 - val_loss: 0.7219 - val_accuracy: 0.6535 - val_mae: 0.2291 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Epoch 2834/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2653 - accuracy: 0.7568 - mae: 0.1732 - mse: 0.1068\n",
            "Epoch 2834: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2626 - accuracy: 0.7583 - mae: 0.1718 - mse: 0.1059 - val_loss: 0.6960 - val_accuracy: 0.6727 - val_mae: 0.2235 - val_mse: 0.1482 - lr: 1.0000e-04\n",
            "Epoch 2835/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2788 - accuracy: 0.7749 - mae: 0.1651 - mse: 0.0995\n",
            "Epoch 2835: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2782 - accuracy: 0.7739 - mae: 0.1659 - mse: 0.1000 - val_loss: 0.6786 - val_accuracy: 0.6856 - val_mae: 0.2184 - val_mse: 0.1436 - lr: 1.0000e-04\n",
            "Epoch 2836/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2611 - accuracy: 0.7905 - mae: 0.1594 - mse: 0.0931\n",
            "Epoch 2836: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2619 - accuracy: 0.7922 - mae: 0.1588 - mse: 0.0928 - val_loss: 0.6741 - val_accuracy: 0.6877 - val_mae: 0.2158 - val_mse: 0.1418 - lr: 1.0000e-04\n",
            "Epoch 2837/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2850 - accuracy: 0.7856 - mae: 0.1580 - mse: 0.0932\n",
            "Epoch 2837: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2877 - accuracy: 0.7830 - mae: 0.1597 - mse: 0.0944 - val_loss: 0.6892 - val_accuracy: 0.6845 - val_mae: 0.2185 - val_mse: 0.1450 - lr: 1.0000e-04\n",
            "Epoch 2838/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.7739 - mae: 0.1633 - mse: 0.0987\n",
            "Epoch 2838: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.2874 - accuracy: 0.7739 - mae: 0.1633 - mse: 0.0987 - val_loss: 0.7080 - val_accuracy: 0.6738 - val_mae: 0.2225 - val_mse: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 2839/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.7780 - mae: 0.1628 - mse: 0.0992\n",
            "Epoch 2839: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.2759 - accuracy: 0.7780 - mae: 0.1628 - mse: 0.0992 - val_loss: 0.7303 - val_accuracy: 0.6642 - val_mae: 0.2266 - val_mse: 0.1540 - lr: 1.0000e-04\n",
            "Epoch 2840/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2809 - accuracy: 0.7622 - mae: 0.1696 - mse: 0.1057\n",
            "Epoch 2840: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.2787 - accuracy: 0.7619 - mae: 0.1694 - mse: 0.1057 - val_loss: 0.7386 - val_accuracy: 0.6674 - val_mae: 0.2277 - val_mse: 0.1557 - lr: 1.0000e-04\n",
            "Epoch 2841/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.7642 - mae: 0.1683 - mse: 0.1051\n",
            "Epoch 2841: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.2764 - accuracy: 0.7642 - mae: 0.1683 - mse: 0.1051 - val_loss: 0.7425 - val_accuracy: 0.6631 - val_mae: 0.2271 - val_mse: 0.1560 - lr: 1.0000e-04\n",
            "Epoch 2842/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2604 - accuracy: 0.7676 - mae: 0.1653 - mse: 0.1014\n",
            "Epoch 2842: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.2663 - accuracy: 0.7647 - mae: 0.1669 - mse: 0.1029 - val_loss: 0.7453 - val_accuracy: 0.6652 - val_mae: 0.2268 - val_mse: 0.1561 - lr: 1.0000e-04\n",
            "Epoch 2843/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2788 - accuracy: 0.7729 - mae: 0.1641 - mse: 0.1018\n",
            "Epoch 2843: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.2823 - accuracy: 0.7661 - mae: 0.1673 - mse: 0.1050 - val_loss: 0.7392 - val_accuracy: 0.6684 - val_mae: 0.2253 - val_mse: 0.1547 - lr: 1.0000e-04\n",
            "Epoch 2844/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.7583 - mae: 0.1683 - mse: 0.1070\n",
            "Epoch 2844: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.2759 - accuracy: 0.7583 - mae: 0.1683 - mse: 0.1070 - val_loss: 0.7158 - val_accuracy: 0.6781 - val_mae: 0.2204 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2845/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.7661 - mae: 0.1680 - mse: 0.1060\n",
            "Epoch 2845: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.2842 - accuracy: 0.7661 - mae: 0.1680 - mse: 0.1060 - val_loss: 0.7098 - val_accuracy: 0.6738 - val_mae: 0.2195 - val_mse: 0.1484 - lr: 1.0000e-04\n",
            "Epoch 2846/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.7702 - mae: 0.1626 - mse: 0.0997\n",
            "Epoch 2846: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2746 - accuracy: 0.7702 - mae: 0.1626 - mse: 0.0997 - val_loss: 0.7106 - val_accuracy: 0.6706 - val_mae: 0.2197 - val_mse: 0.1486 - lr: 1.0000e-04\n",
            "Epoch 2847/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.7665 - mae: 0.1641 - mse: 0.1006\n",
            "Epoch 2847: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.2785 - accuracy: 0.7665 - mae: 0.1641 - mse: 0.1006 - val_loss: 0.7022 - val_accuracy: 0.6791 - val_mae: 0.2178 - val_mse: 0.1467 - lr: 1.0000e-04\n",
            "Epoch 2848/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.7780 - mae: 0.1589 - mse: 0.0976\n",
            "Epoch 2848: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.2660 - accuracy: 0.7780 - mae: 0.1589 - mse: 0.0976 - val_loss: 0.6838 - val_accuracy: 0.6898 - val_mae: 0.2130 - val_mse: 0.1420 - lr: 1.0000e-04\n",
            "Epoch 2849/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2703 - accuracy: 0.7891 - mae: 0.1569 - mse: 0.0925\n",
            "Epoch 2849: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2676 - accuracy: 0.7936 - mae: 0.1545 - mse: 0.0909 - val_loss: 0.6755 - val_accuracy: 0.6930 - val_mae: 0.2105 - val_mse: 0.1397 - lr: 1.0000e-04\n",
            "Epoch 2850/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2711 - accuracy: 0.7930 - mae: 0.1534 - mse: 0.0898\n",
            "Epoch 2850: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 0.2709 - accuracy: 0.7922 - mae: 0.1536 - mse: 0.0902 - val_loss: 0.6856 - val_accuracy: 0.6888 - val_mae: 0.2127 - val_mse: 0.1420 - lr: 1.0000e-04\n",
            "Epoch 2851/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2758 - accuracy: 0.7769 - mae: 0.1610 - mse: 0.0988\n",
            "Epoch 2851: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2732 - accuracy: 0.7798 - mae: 0.1599 - mse: 0.0976 - val_loss: 0.7017 - val_accuracy: 0.6781 - val_mae: 0.2162 - val_mse: 0.1457 - lr: 1.0000e-04\n",
            "Epoch 2852/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2752 - accuracy: 0.7808 - mae: 0.1613 - mse: 0.0989\n",
            "Epoch 2852: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2727 - accuracy: 0.7826 - mae: 0.1604 - mse: 0.0983 - val_loss: 0.7264 - val_accuracy: 0.6706 - val_mae: 0.2222 - val_mse: 0.1517 - lr: 1.0000e-04\n",
            "Epoch 2853/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2738 - accuracy: 0.7720 - mae: 0.1651 - mse: 0.1028\n",
            "Epoch 2853: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2735 - accuracy: 0.7683 - mae: 0.1665 - mse: 0.1036 - val_loss: 0.7383 - val_accuracy: 0.6684 - val_mae: 0.2249 - val_mse: 0.1545 - lr: 1.0000e-04\n",
            "Epoch 2854/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2668 - accuracy: 0.7651 - mae: 0.1670 - mse: 0.1052\n",
            "Epoch 2854: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2645 - accuracy: 0.7661 - mae: 0.1664 - mse: 0.1047 - val_loss: 0.7341 - val_accuracy: 0.6706 - val_mae: 0.2237 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2855/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.7683 - mae: 0.1656 - mse: 0.1040\n",
            "Epoch 2855: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 182ms/step - loss: 0.2712 - accuracy: 0.7683 - mae: 0.1656 - mse: 0.1040 - val_loss: 0.7240 - val_accuracy: 0.6824 - val_mae: 0.2204 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2856/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2593 - accuracy: 0.7935 - mae: 0.1562 - mse: 0.0948\n",
            "Epoch 2856: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2595 - accuracy: 0.7908 - mae: 0.1576 - mse: 0.0959 - val_loss: 0.7066 - val_accuracy: 0.6866 - val_mae: 0.2161 - val_mse: 0.1465 - lr: 1.0000e-04\n",
            "Epoch 2857/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2658 - accuracy: 0.7886 - mae: 0.1536 - mse: 0.0921\n",
            "Epoch 2857: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2680 - accuracy: 0.7867 - mae: 0.1553 - mse: 0.0938 - val_loss: 0.6891 - val_accuracy: 0.6941 - val_mae: 0.2120 - val_mse: 0.1422 - lr: 1.0000e-04\n",
            "Epoch 2858/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2698 - accuracy: 0.7930 - mae: 0.1525 - mse: 0.0928\n",
            "Epoch 2858: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2715 - accuracy: 0.7922 - mae: 0.1531 - mse: 0.0927 - val_loss: 0.6868 - val_accuracy: 0.6995 - val_mae: 0.2112 - val_mse: 0.1414 - lr: 1.0000e-04\n",
            "Epoch 2859/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2823 - accuracy: 0.7866 - mae: 0.1574 - mse: 0.0957\n",
            "Epoch 2859: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2815 - accuracy: 0.7881 - mae: 0.1559 - mse: 0.0950 - val_loss: 0.7070 - val_accuracy: 0.6877 - val_mae: 0.2167 - val_mse: 0.1464 - lr: 1.0000e-04\n",
            "Epoch 2860/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.3048 - accuracy: 0.7637 - mae: 0.1663 - mse: 0.1033\n",
            "Epoch 2860: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.3045 - accuracy: 0.7647 - mae: 0.1662 - mse: 0.1030 - val_loss: 0.7437 - val_accuracy: 0.6695 - val_mae: 0.2260 - val_mse: 0.1554 - lr: 1.0000e-04\n",
            "Epoch 2861/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2676 - accuracy: 0.7642 - mae: 0.1687 - mse: 0.1061\n",
            "Epoch 2861: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2702 - accuracy: 0.7642 - mae: 0.1695 - mse: 0.1071 - val_loss: 0.7689 - val_accuracy: 0.6535 - val_mae: 0.2318 - val_mse: 0.1613 - lr: 1.0000e-04\n",
            "Epoch 2862/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2776 - accuracy: 0.7441 - mae: 0.1769 - mse: 0.1146\n",
            "Epoch 2862: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2758 - accuracy: 0.7459 - mae: 0.1758 - mse: 0.1134 - val_loss: 0.7624 - val_accuracy: 0.6610 - val_mae: 0.2308 - val_mse: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 2863/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2832 - accuracy: 0.7471 - mae: 0.1748 - mse: 0.1119\n",
            "Epoch 2863: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2794 - accuracy: 0.7454 - mae: 0.1753 - mse: 0.1120 - val_loss: 0.7379 - val_accuracy: 0.6727 - val_mae: 0.2252 - val_mse: 0.1543 - lr: 1.0000e-04\n",
            "Epoch 2864/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2674 - accuracy: 0.7666 - mae: 0.1644 - mse: 0.1023\n",
            "Epoch 2864: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2692 - accuracy: 0.7661 - mae: 0.1651 - mse: 0.1030 - val_loss: 0.7005 - val_accuracy: 0.6898 - val_mae: 0.2165 - val_mse: 0.1456 - lr: 1.0000e-04\n",
            "Epoch 2865/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2897 - accuracy: 0.7729 - mae: 0.1608 - mse: 0.0985\n",
            "Epoch 2865: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 185ms/step - loss: 0.2892 - accuracy: 0.7761 - mae: 0.1598 - mse: 0.0973 - val_loss: 0.6892 - val_accuracy: 0.6877 - val_mae: 0.2147 - val_mse: 0.1434 - lr: 1.0000e-04\n",
            "Epoch 2866/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2722 - accuracy: 0.7856 - mae: 0.1570 - mse: 0.0932\n",
            "Epoch 2866: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.2746 - accuracy: 0.7853 - mae: 0.1581 - mse: 0.0938 - val_loss: 0.7061 - val_accuracy: 0.6802 - val_mae: 0.2199 - val_mse: 0.1478 - lr: 1.0000e-04\n",
            "Epoch 2867/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2842 - accuracy: 0.7695 - mae: 0.1647 - mse: 0.1007\n",
            "Epoch 2867: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.2831 - accuracy: 0.7679 - mae: 0.1650 - mse: 0.1012 - val_loss: 0.7280 - val_accuracy: 0.6588 - val_mae: 0.2256 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2868/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2774 - accuracy: 0.7615 - mae: 0.1680 - mse: 0.1043\n",
            "Epoch 2868: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.2774 - accuracy: 0.7615 - mae: 0.1680 - mse: 0.1043 - val_loss: 0.7310 - val_accuracy: 0.6620 - val_mae: 0.2266 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 2869/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.7665 - mae: 0.1679 - mse: 0.1039\n",
            "Epoch 2869: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.2771 - accuracy: 0.7665 - mae: 0.1679 - mse: 0.1039 - val_loss: 0.7234 - val_accuracy: 0.6802 - val_mae: 0.2245 - val_mse: 0.1519 - lr: 1.0000e-04\n",
            "Epoch 2870/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.7757 - mae: 0.1635 - mse: 0.0999\n",
            "Epoch 2870: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.2704 - accuracy: 0.7757 - mae: 0.1635 - mse: 0.0999 - val_loss: 0.7324 - val_accuracy: 0.6749 - val_mae: 0.2253 - val_mse: 0.1533 - lr: 1.0000e-04\n",
            "Epoch 2871/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.7638 - mae: 0.1690 - mse: 0.1043\n",
            "Epoch 2871: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 0.2818 - accuracy: 0.7638 - mae: 0.1690 - mse: 0.1043 - val_loss: 0.7398 - val_accuracy: 0.6759 - val_mae: 0.2258 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2872/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.7661 - mae: 0.1639 - mse: 0.1014\n",
            "Epoch 2872: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.2674 - accuracy: 0.7661 - mae: 0.1639 - mse: 0.1014 - val_loss: 0.7399 - val_accuracy: 0.6781 - val_mae: 0.2247 - val_mse: 0.1539 - lr: 1.0000e-04\n",
            "Epoch 2873/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.7711 - mae: 0.1666 - mse: 0.1041\n",
            "Epoch 2873: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.2683 - accuracy: 0.7711 - mae: 0.1666 - mse: 0.1041 - val_loss: 0.7386 - val_accuracy: 0.6749 - val_mae: 0.2231 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2874/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.7752 - mae: 0.1637 - mse: 0.1014\n",
            "Epoch 2874: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 0.2786 - accuracy: 0.7752 - mae: 0.1637 - mse: 0.1014 - val_loss: 0.7369 - val_accuracy: 0.6749 - val_mae: 0.2225 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2875/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2724 - accuracy: 0.7661 - mae: 0.1654 - mse: 0.1024\n",
            "Epoch 2875: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.2721 - accuracy: 0.7656 - mae: 0.1656 - mse: 0.1023 - val_loss: 0.7407 - val_accuracy: 0.6663 - val_mae: 0.2237 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Epoch 2876/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.7674 - mae: 0.1685 - mse: 0.1071\n",
            "Epoch 2876: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.2879 - accuracy: 0.7674 - mae: 0.1685 - mse: 0.1071 - val_loss: 0.7346 - val_accuracy: 0.6663 - val_mae: 0.2227 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2877/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2842 - accuracy: 0.7642 - mae: 0.1679 - mse: 0.1059\n",
            "Epoch 2877: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2800 - accuracy: 0.7656 - mae: 0.1671 - mse: 0.1053 - val_loss: 0.7143 - val_accuracy: 0.6791 - val_mae: 0.2184 - val_mse: 0.1486 - lr: 1.0000e-04\n",
            "Epoch 2878/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2740 - accuracy: 0.7769 - mae: 0.1588 - mse: 0.0984\n",
            "Epoch 2878: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2853 - accuracy: 0.7757 - mae: 0.1603 - mse: 0.0994 - val_loss: 0.6999 - val_accuracy: 0.6834 - val_mae: 0.2158 - val_mse: 0.1456 - lr: 1.0000e-04\n",
            "Epoch 2879/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2613 - accuracy: 0.7788 - mae: 0.1592 - mse: 0.0965\n",
            "Epoch 2879: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2597 - accuracy: 0.7789 - mae: 0.1585 - mse: 0.0960 - val_loss: 0.7019 - val_accuracy: 0.6802 - val_mae: 0.2177 - val_mse: 0.1465 - lr: 1.0000e-04\n",
            "Epoch 2880/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2838 - accuracy: 0.7798 - mae: 0.1613 - mse: 0.0988\n",
            "Epoch 2880: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2835 - accuracy: 0.7757 - mae: 0.1629 - mse: 0.1003 - val_loss: 0.7077 - val_accuracy: 0.6727 - val_mae: 0.2199 - val_mse: 0.1483 - lr: 1.0000e-04\n",
            "Epoch 2881/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2669 - accuracy: 0.7739 - mae: 0.1627 - mse: 0.0993\n",
            "Epoch 2881: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 181ms/step - loss: 0.2654 - accuracy: 0.7748 - mae: 0.1623 - mse: 0.0991 - val_loss: 0.7040 - val_accuracy: 0.6813 - val_mae: 0.2191 - val_mse: 0.1475 - lr: 1.0000e-04\n",
            "Epoch 2882/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2599 - accuracy: 0.7788 - mae: 0.1608 - mse: 0.0987\n",
            "Epoch 2882: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2589 - accuracy: 0.7798 - mae: 0.1602 - mse: 0.0981 - val_loss: 0.6962 - val_accuracy: 0.6845 - val_mae: 0.2165 - val_mse: 0.1453 - lr: 1.0000e-04\n",
            "Epoch 2883/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2745 - accuracy: 0.7886 - mae: 0.1559 - mse: 0.0937\n",
            "Epoch 2883: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2713 - accuracy: 0.7872 - mae: 0.1556 - mse: 0.0935 - val_loss: 0.6949 - val_accuracy: 0.6824 - val_mae: 0.2152 - val_mse: 0.1446 - lr: 1.0000e-04\n",
            "Epoch 2884/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2940 - accuracy: 0.7705 - mae: 0.1624 - mse: 0.0995\n",
            "Epoch 2884: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2895 - accuracy: 0.7729 - mae: 0.1611 - mse: 0.0984 - val_loss: 0.7022 - val_accuracy: 0.6845 - val_mae: 0.2162 - val_mse: 0.1459 - lr: 1.0000e-04\n",
            "Epoch 2885/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2855 - accuracy: 0.7886 - mae: 0.1553 - mse: 0.0941\n",
            "Epoch 2885: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2893 - accuracy: 0.7881 - mae: 0.1563 - mse: 0.0946 - val_loss: 0.7295 - val_accuracy: 0.6749 - val_mae: 0.2224 - val_mse: 0.1520 - lr: 1.0000e-04\n",
            "Epoch 2886/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2844 - accuracy: 0.7607 - mae: 0.1679 - mse: 0.1061\n",
            "Epoch 2886: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2823 - accuracy: 0.7615 - mae: 0.1673 - mse: 0.1059 - val_loss: 0.7673 - val_accuracy: 0.6471 - val_mae: 0.2305 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2887/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2633 - accuracy: 0.7534 - mae: 0.1706 - mse: 0.1095\n",
            "Epoch 2887: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2703 - accuracy: 0.7509 - mae: 0.1723 - mse: 0.1111 - val_loss: 0.7769 - val_accuracy: 0.6503 - val_mae: 0.2319 - val_mse: 0.1620 - lr: 1.0000e-04\n",
            "Epoch 2888/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2771 - accuracy: 0.7427 - mae: 0.1750 - mse: 0.1125\n",
            "Epoch 2888: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2757 - accuracy: 0.7413 - mae: 0.1754 - mse: 0.1124 - val_loss: 0.7563 - val_accuracy: 0.6545 - val_mae: 0.2272 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2889/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2800 - accuracy: 0.7563 - mae: 0.1684 - mse: 0.1079\n",
            "Epoch 2889: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2812 - accuracy: 0.7550 - mae: 0.1693 - mse: 0.1087 - val_loss: 0.7256 - val_accuracy: 0.6738 - val_mae: 0.2199 - val_mse: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2890/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2825 - accuracy: 0.7729 - mae: 0.1595 - mse: 0.0988\n",
            "Epoch 2890: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2848 - accuracy: 0.7688 - mae: 0.1617 - mse: 0.1011 - val_loss: 0.7059 - val_accuracy: 0.6824 - val_mae: 0.2148 - val_mse: 0.1452 - lr: 1.0000e-04\n",
            "Epoch 2891/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2699 - accuracy: 0.7954 - mae: 0.1531 - mse: 0.0921\n",
            "Epoch 2891: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2733 - accuracy: 0.7936 - mae: 0.1539 - mse: 0.0934 - val_loss: 0.7016 - val_accuracy: 0.6813 - val_mae: 0.2137 - val_mse: 0.1441 - lr: 1.0000e-04\n",
            "Epoch 2892/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2679 - accuracy: 0.7974 - mae: 0.1553 - mse: 0.0930\n",
            "Epoch 2892: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2739 - accuracy: 0.7908 - mae: 0.1574 - mse: 0.0947 - val_loss: 0.7057 - val_accuracy: 0.6802 - val_mae: 0.2159 - val_mse: 0.1458 - lr: 1.0000e-04\n",
            "Epoch 2893/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2801 - accuracy: 0.7979 - mae: 0.1577 - mse: 0.0938\n",
            "Epoch 2893: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2765 - accuracy: 0.7972 - mae: 0.1575 - mse: 0.0939 - val_loss: 0.7178 - val_accuracy: 0.6727 - val_mae: 0.2210 - val_mse: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 2894/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.7821 - mae: 0.1591 - mse: 0.0954\n",
            "Epoch 2894: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2528 - accuracy: 0.7821 - mae: 0.1591 - mse: 0.0954 - val_loss: 0.7236 - val_accuracy: 0.6674 - val_mae: 0.2235 - val_mse: 0.1520 - lr: 1.0000e-04\n",
            "Epoch 2895/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.7693 - mae: 0.1672 - mse: 0.1034\n",
            "Epoch 2895: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.2689 - accuracy: 0.7693 - mae: 0.1672 - mse: 0.1034 - val_loss: 0.7242 - val_accuracy: 0.6642 - val_mae: 0.2242 - val_mse: 0.1524 - lr: 1.0000e-04\n",
            "Epoch 2896/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2822 - accuracy: 0.7617 - mae: 0.1714 - mse: 0.1073\n",
            "Epoch 2896: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.2797 - accuracy: 0.7633 - mae: 0.1705 - mse: 0.1066 - val_loss: 0.7199 - val_accuracy: 0.6642 - val_mae: 0.2236 - val_mse: 0.1516 - lr: 1.0000e-04\n",
            "Epoch 2897/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.7702 - mae: 0.1635 - mse: 0.1006\n",
            "Epoch 2897: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2756 - accuracy: 0.7702 - mae: 0.1635 - mse: 0.1006 - val_loss: 0.7133 - val_accuracy: 0.6663 - val_mae: 0.2222 - val_mse: 0.1502 - lr: 1.0000e-04\n",
            "Epoch 2898/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.7665 - mae: 0.1687 - mse: 0.1031\n",
            "Epoch 2898: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 0.2838 - accuracy: 0.7665 - mae: 0.1687 - mse: 0.1031 - val_loss: 0.7103 - val_accuracy: 0.6695 - val_mae: 0.2213 - val_mse: 0.1492 - lr: 1.0000e-04\n",
            "Epoch 2899/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2640 - accuracy: 0.7734 - mae: 0.1623 - mse: 0.0987\n",
            "Epoch 2899: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.2653 - accuracy: 0.7757 - mae: 0.1615 - mse: 0.0981 - val_loss: 0.7062 - val_accuracy: 0.6717 - val_mae: 0.2198 - val_mse: 0.1479 - lr: 1.0000e-04\n",
            "Epoch 2900/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.7670 - mae: 0.1654 - mse: 0.1020\n",
            "Epoch 2900: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.2958 - accuracy: 0.7670 - mae: 0.1654 - mse: 0.1020 - val_loss: 0.7226 - val_accuracy: 0.6642 - val_mae: 0.2241 - val_mse: 0.1519 - lr: 1.0000e-04\n",
            "Epoch 2901/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.7665 - mae: 0.1666 - mse: 0.1009\n",
            "Epoch 2901: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.2692 - accuracy: 0.7665 - mae: 0.1666 - mse: 0.1009 - val_loss: 0.7386 - val_accuracy: 0.6545 - val_mae: 0.2283 - val_mse: 0.1559 - lr: 1.0000e-04\n",
            "Epoch 2902/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.7610 - mae: 0.1696 - mse: 0.1056\n",
            "Epoch 2902: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.2667 - accuracy: 0.7610 - mae: 0.1696 - mse: 0.1056 - val_loss: 0.7273 - val_accuracy: 0.6652 - val_mae: 0.2253 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2903/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2873 - accuracy: 0.7759 - mae: 0.1641 - mse: 0.1001\n",
            "Epoch 2903: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 206ms/step - loss: 0.2854 - accuracy: 0.7743 - mae: 0.1656 - mse: 0.1013 - val_loss: 0.7205 - val_accuracy: 0.6727 - val_mae: 0.2236 - val_mse: 0.1512 - lr: 1.0000e-04\n",
            "Epoch 2904/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2845 - accuracy: 0.7690 - mae: 0.1642 - mse: 0.0999\n",
            "Epoch 2904: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.2842 - accuracy: 0.7693 - mae: 0.1646 - mse: 0.1003 - val_loss: 0.7133 - val_accuracy: 0.6824 - val_mae: 0.2217 - val_mse: 0.1492 - lr: 1.0000e-04\n",
            "Epoch 2905/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2639 - accuracy: 0.7705 - mae: 0.1641 - mse: 0.1006\n",
            "Epoch 2905: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2716 - accuracy: 0.7674 - mae: 0.1647 - mse: 0.1015 - val_loss: 0.7100 - val_accuracy: 0.6802 - val_mae: 0.2206 - val_mse: 0.1481 - lr: 1.0000e-04\n",
            "Epoch 2906/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2776 - accuracy: 0.7734 - mae: 0.1646 - mse: 0.0994\n",
            "Epoch 2906: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2781 - accuracy: 0.7743 - mae: 0.1649 - mse: 0.0993 - val_loss: 0.7197 - val_accuracy: 0.6663 - val_mae: 0.2232 - val_mse: 0.1507 - lr: 1.0000e-04\n",
            "Epoch 2907/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2678 - accuracy: 0.7646 - mae: 0.1682 - mse: 0.1046\n",
            "Epoch 2907: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.2672 - accuracy: 0.7670 - mae: 0.1676 - mse: 0.1042 - val_loss: 0.7264 - val_accuracy: 0.6674 - val_mae: 0.2244 - val_mse: 0.1523 - lr: 1.0000e-04\n",
            "Epoch 2908/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2688 - accuracy: 0.7686 - mae: 0.1652 - mse: 0.1014\n",
            "Epoch 2908: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2686 - accuracy: 0.7651 - mae: 0.1655 - mse: 0.1018 - val_loss: 0.7304 - val_accuracy: 0.6674 - val_mae: 0.2248 - val_mse: 0.1530 - lr: 1.0000e-04\n",
            "Epoch 2909/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2603 - accuracy: 0.7563 - mae: 0.1686 - mse: 0.1056\n",
            "Epoch 2909: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2593 - accuracy: 0.7583 - mae: 0.1674 - mse: 0.1047 - val_loss: 0.7317 - val_accuracy: 0.6674 - val_mae: 0.2244 - val_mse: 0.1528 - lr: 1.0000e-04\n",
            "Epoch 2910/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.7624 - mae: 0.1659 - mse: 0.1016\n",
            "Epoch 2910: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2715 - accuracy: 0.7624 - mae: 0.1659 - mse: 0.1016 - val_loss: 0.7263 - val_accuracy: 0.6759 - val_mae: 0.2228 - val_mse: 0.1513 - lr: 1.0000e-04\n",
            "Epoch 2911/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.7670 - mae: 0.1671 - mse: 0.1027\n",
            "Epoch 2911: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.2777 - accuracy: 0.7670 - mae: 0.1671 - mse: 0.1027 - val_loss: 0.7184 - val_accuracy: 0.6824 - val_mae: 0.2205 - val_mse: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 2912/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2563 - accuracy: 0.7832 - mae: 0.1591 - mse: 0.0958\n",
            "Epoch 2912: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.2587 - accuracy: 0.7817 - mae: 0.1596 - mse: 0.0961 - val_loss: 0.7112 - val_accuracy: 0.6856 - val_mae: 0.2185 - val_mse: 0.1475 - lr: 1.0000e-04\n",
            "Epoch 2913/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2733 - accuracy: 0.7754 - mae: 0.1613 - mse: 0.0981\n",
            "Epoch 2913: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.2772 - accuracy: 0.7729 - mae: 0.1630 - mse: 0.0994 - val_loss: 0.7162 - val_accuracy: 0.6738 - val_mae: 0.2192 - val_mse: 0.1483 - lr: 1.0000e-04\n",
            "Epoch 2914/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.7725 - mae: 0.1630 - mse: 0.0997\n",
            "Epoch 2914: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.2757 - accuracy: 0.7725 - mae: 0.1630 - mse: 0.0997 - val_loss: 0.7276 - val_accuracy: 0.6620 - val_mae: 0.2222 - val_mse: 0.1510 - lr: 1.0000e-04\n",
            "Epoch 2915/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2604 - accuracy: 0.7695 - mae: 0.1639 - mse: 0.1017\n",
            "Epoch 2915: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.2612 - accuracy: 0.7693 - mae: 0.1644 - mse: 0.1017 - val_loss: 0.7186 - val_accuracy: 0.6620 - val_mae: 0.2200 - val_mse: 0.1488 - lr: 1.0000e-04\n",
            "Epoch 2916/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.7628 - mae: 0.1632 - mse: 0.1020\n",
            "Epoch 2916: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2606 - accuracy: 0.7628 - mae: 0.1632 - mse: 0.1020 - val_loss: 0.7067 - val_accuracy: 0.6781 - val_mae: 0.2166 - val_mse: 0.1455 - lr: 1.0000e-04\n",
            "Epoch 2917/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.7826 - mae: 0.1594 - mse: 0.0973\n",
            "Epoch 2917: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2811 - accuracy: 0.7826 - mae: 0.1594 - mse: 0.0973 - val_loss: 0.7069 - val_accuracy: 0.6824 - val_mae: 0.2170 - val_mse: 0.1458 - lr: 1.0000e-04\n",
            "Epoch 2918/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2689 - accuracy: 0.7793 - mae: 0.1598 - mse: 0.0987\n",
            "Epoch 2918: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.2671 - accuracy: 0.7794 - mae: 0.1594 - mse: 0.0983 - val_loss: 0.7211 - val_accuracy: 0.6759 - val_mae: 0.2217 - val_mse: 0.1497 - lr: 1.0000e-04\n",
            "Epoch 2919/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.7835 - mae: 0.1594 - mse: 0.0963\n",
            "Epoch 2919: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.2633 - accuracy: 0.7835 - mae: 0.1594 - mse: 0.0963 - val_loss: 0.7247 - val_accuracy: 0.6717 - val_mae: 0.2229 - val_mse: 0.1508 - lr: 1.0000e-04\n",
            "Epoch 2920/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2819 - accuracy: 0.7734 - mae: 0.1680 - mse: 0.1035\n",
            "Epoch 2920: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.2812 - accuracy: 0.7748 - mae: 0.1668 - mse: 0.1025 - val_loss: 0.7159 - val_accuracy: 0.6791 - val_mae: 0.2204 - val_mse: 0.1487 - lr: 1.0000e-04\n",
            "Epoch 2921/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.7766 - mae: 0.1652 - mse: 0.1020\n",
            "Epoch 2921: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.2821 - accuracy: 0.7766 - mae: 0.1652 - mse: 0.1020 - val_loss: 0.7106 - val_accuracy: 0.6834 - val_mae: 0.2183 - val_mse: 0.1469 - lr: 1.0000e-04\n",
            "Epoch 2922/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.7867 - mae: 0.1582 - mse: 0.0953\n",
            "Epoch 2922: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.2711 - accuracy: 0.7867 - mae: 0.1582 - mse: 0.0953 - val_loss: 0.7162 - val_accuracy: 0.6845 - val_mae: 0.2185 - val_mse: 0.1477 - lr: 1.0000e-04\n",
            "Epoch 2923/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.7931 - mae: 0.1564 - mse: 0.0924\n",
            "Epoch 2923: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.2595 - accuracy: 0.7931 - mae: 0.1564 - mse: 0.0924 - val_loss: 0.7235 - val_accuracy: 0.6824 - val_mae: 0.2197 - val_mse: 0.1493 - lr: 1.0000e-04\n",
            "Epoch 2924/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.7849 - mae: 0.1617 - mse: 0.0990\n",
            "Epoch 2924: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.2684 - accuracy: 0.7849 - mae: 0.1617 - mse: 0.0990 - val_loss: 0.7183 - val_accuracy: 0.6824 - val_mae: 0.2180 - val_mse: 0.1481 - lr: 1.0000e-04\n",
            "Epoch 2925/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2707 - accuracy: 0.7778 - mae: 0.1593 - mse: 0.0974\n",
            "Epoch 2925: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.2675 - accuracy: 0.7766 - mae: 0.1600 - mse: 0.0982 - val_loss: 0.7034 - val_accuracy: 0.6909 - val_mae: 0.2137 - val_mse: 0.1444 - lr: 1.0000e-04\n",
            "Epoch 2926/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.8028 - mae: 0.1511 - mse: 0.0902\n",
            "Epoch 2926: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2649 - accuracy: 0.8028 - mae: 0.1511 - mse: 0.0902 - val_loss: 0.6931 - val_accuracy: 0.6920 - val_mae: 0.2108 - val_mse: 0.1418 - lr: 1.0000e-04\n",
            "Epoch 2927/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.7881 - mae: 0.1570 - mse: 0.0957\n",
            "Epoch 2927: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 305ms/step - loss: 0.2766 - accuracy: 0.7881 - mae: 0.1570 - mse: 0.0957 - val_loss: 0.6997 - val_accuracy: 0.6856 - val_mae: 0.2127 - val_mse: 0.1434 - lr: 1.0000e-04\n",
            "Epoch 2928/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.7794 - mae: 0.1574 - mse: 0.0947\n",
            "Epoch 2928: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.2814 - accuracy: 0.7794 - mae: 0.1574 - mse: 0.0947 - val_loss: 0.7301 - val_accuracy: 0.6727 - val_mae: 0.2210 - val_mse: 0.1509 - lr: 1.0000e-04\n",
            "Epoch 2929/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2662 - accuracy: 0.7832 - mae: 0.1604 - mse: 0.0987\n",
            "Epoch 2929: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2685 - accuracy: 0.7794 - mae: 0.1617 - mse: 0.0999 - val_loss: 0.7706 - val_accuracy: 0.6578 - val_mae: 0.2309 - val_mse: 0.1603 - lr: 1.0000e-04\n",
            "Epoch 2930/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2693 - accuracy: 0.7510 - mae: 0.1742 - mse: 0.1113\n",
            "Epoch 2930: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2743 - accuracy: 0.7514 - mae: 0.1748 - mse: 0.1118 - val_loss: 0.7734 - val_accuracy: 0.6503 - val_mae: 0.2322 - val_mse: 0.1611 - lr: 1.0000e-04\n",
            "Epoch 2931/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2667 - accuracy: 0.7524 - mae: 0.1716 - mse: 0.1074\n",
            "Epoch 2931: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 0.2702 - accuracy: 0.7541 - mae: 0.1718 - mse: 0.1076 - val_loss: 0.7601 - val_accuracy: 0.6556 - val_mae: 0.2297 - val_mse: 0.1583 - lr: 1.0000e-04\n",
            "Epoch 2932/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2656 - accuracy: 0.7573 - mae: 0.1706 - mse: 0.1079\n",
            "Epoch 2932: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2694 - accuracy: 0.7555 - mae: 0.1716 - mse: 0.1085 - val_loss: 0.7431 - val_accuracy: 0.6652 - val_mae: 0.2262 - val_mse: 0.1545 - lr: 1.0000e-04\n",
            "Epoch 2933/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.7679 - mae: 0.1659 - mse: 0.1010\n",
            "Epoch 2933: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.2766 - accuracy: 0.7679 - mae: 0.1659 - mse: 0.1010 - val_loss: 0.7361 - val_accuracy: 0.6674 - val_mae: 0.2250 - val_mse: 0.1531 - lr: 1.0000e-04\n",
            "Epoch 2934/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2661 - accuracy: 0.7681 - mae: 0.1639 - mse: 0.1001\n",
            "Epoch 2934: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2663 - accuracy: 0.7665 - mae: 0.1649 - mse: 0.1007 - val_loss: 0.7260 - val_accuracy: 0.6684 - val_mae: 0.2227 - val_mse: 0.1508 - lr: 1.0000e-04\n",
            "Epoch 2935/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2701 - accuracy: 0.7729 - mae: 0.1652 - mse: 0.1006\n",
            "Epoch 2935: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.2707 - accuracy: 0.7720 - mae: 0.1649 - mse: 0.1006 - val_loss: 0.7173 - val_accuracy: 0.6759 - val_mae: 0.2208 - val_mse: 0.1488 - lr: 1.0000e-04\n",
            "Epoch 2936/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2561 - accuracy: 0.7817 - mae: 0.1583 - mse: 0.0958\n",
            "Epoch 2936: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2583 - accuracy: 0.7821 - mae: 0.1587 - mse: 0.0956 - val_loss: 0.7143 - val_accuracy: 0.6791 - val_mae: 0.2202 - val_mse: 0.1482 - lr: 1.0000e-04\n",
            "Epoch 2937/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2725 - accuracy: 0.7695 - mae: 0.1640 - mse: 0.1000\n",
            "Epoch 2937: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2709 - accuracy: 0.7688 - mae: 0.1642 - mse: 0.1005 - val_loss: 0.7197 - val_accuracy: 0.6706 - val_mae: 0.2211 - val_mse: 0.1494 - lr: 1.0000e-04\n",
            "Epoch 2938/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2663 - accuracy: 0.7720 - mae: 0.1625 - mse: 0.0998\n",
            "Epoch 2938: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.2633 - accuracy: 0.7729 - mae: 0.1619 - mse: 0.0998 - val_loss: 0.7151 - val_accuracy: 0.6727 - val_mae: 0.2194 - val_mse: 0.1481 - lr: 1.0000e-04\n",
            "Epoch 2939/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2716 - accuracy: 0.7769 - mae: 0.1602 - mse: 0.0974\n",
            "Epoch 2939: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2723 - accuracy: 0.7766 - mae: 0.1606 - mse: 0.0977 - val_loss: 0.7095 - val_accuracy: 0.6834 - val_mae: 0.2177 - val_mse: 0.1467 - lr: 1.0000e-04\n",
            "Epoch 2940/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2762 - accuracy: 0.7817 - mae: 0.1613 - mse: 0.1002\n",
            "Epoch 2940: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2707 - accuracy: 0.7817 - mae: 0.1612 - mse: 0.0999 - val_loss: 0.7040 - val_accuracy: 0.6866 - val_mae: 0.2157 - val_mse: 0.1452 - lr: 1.0000e-04\n",
            "Epoch 2941/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2629 - accuracy: 0.7915 - mae: 0.1518 - mse: 0.0920\n",
            "Epoch 2941: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2613 - accuracy: 0.7927 - mae: 0.1523 - mse: 0.0922 - val_loss: 0.6898 - val_accuracy: 0.6898 - val_mae: 0.2114 - val_mse: 0.1414 - lr: 1.0000e-04\n",
            "Epoch 2942/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2573 - accuracy: 0.8052 - mae: 0.1483 - mse: 0.0881\n",
            "Epoch 2942: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2621 - accuracy: 0.8009 - mae: 0.1505 - mse: 0.0894 - val_loss: 0.6853 - val_accuracy: 0.6963 - val_mae: 0.2095 - val_mse: 0.1399 - lr: 1.0000e-04\n",
            "Epoch 2943/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2696 - accuracy: 0.7959 - mae: 0.1508 - mse: 0.0916\n",
            "Epoch 2943: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2659 - accuracy: 0.7936 - mae: 0.1511 - mse: 0.0917 - val_loss: 0.6919 - val_accuracy: 0.6930 - val_mae: 0.2111 - val_mse: 0.1414 - lr: 1.0000e-04\n",
            "Epoch 2944/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2613 - accuracy: 0.7861 - mae: 0.1518 - mse: 0.0906\n",
            "Epoch 2944: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2657 - accuracy: 0.7812 - mae: 0.1541 - mse: 0.0925 - val_loss: 0.7001 - val_accuracy: 0.6856 - val_mae: 0.2136 - val_mse: 0.1435 - lr: 1.0000e-04\n",
            "Epoch 2945/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2664 - accuracy: 0.7930 - mae: 0.1545 - mse: 0.0933\n",
            "Epoch 2945: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2749 - accuracy: 0.7899 - mae: 0.1555 - mse: 0.0942 - val_loss: 0.7179 - val_accuracy: 0.6781 - val_mae: 0.2190 - val_mse: 0.1483 - lr: 1.0000e-04\n",
            "Epoch 2946/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2763 - accuracy: 0.7798 - mae: 0.1619 - mse: 0.0996\n",
            "Epoch 2946: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.2773 - accuracy: 0.7748 - mae: 0.1643 - mse: 0.1014 - val_loss: 0.7348 - val_accuracy: 0.6727 - val_mae: 0.2239 - val_mse: 0.1526 - lr: 1.0000e-04\n",
            "Epoch 2947/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2661 - accuracy: 0.7622 - mae: 0.1672 - mse: 0.1029\n",
            "Epoch 2947: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.2674 - accuracy: 0.7656 - mae: 0.1656 - mse: 0.1017 - val_loss: 0.7368 - val_accuracy: 0.6684 - val_mae: 0.2248 - val_mse: 0.1532 - lr: 1.0000e-04\n",
            "Epoch 2948/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.7739 - mae: 0.1652 - mse: 0.1025\n",
            "Epoch 2948: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.2588 - accuracy: 0.7739 - mae: 0.1652 - mse: 0.1025 - val_loss: 0.7400 - val_accuracy: 0.6706 - val_mae: 0.2252 - val_mse: 0.1538 - lr: 1.0000e-04\n",
            "Epoch 2949/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.7601 - mae: 0.1675 - mse: 0.1038\n",
            "Epoch 2949: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.2615 - accuracy: 0.7601 - mae: 0.1675 - mse: 0.1038 - val_loss: 0.7236 - val_accuracy: 0.6845 - val_mae: 0.2204 - val_mse: 0.1496 - lr: 1.0000e-04\n",
            "Epoch 2950/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2644 - accuracy: 0.7812 - mae: 0.1609 - mse: 0.0987\n",
            "Epoch 2950: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.2666 - accuracy: 0.7784 - mae: 0.1617 - mse: 0.0997 - val_loss: 0.7058 - val_accuracy: 0.6920 - val_mae: 0.2148 - val_mse: 0.1449 - lr: 1.0000e-04\n",
            "Epoch 2951/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2535 - accuracy: 0.7886 - mae: 0.1553 - mse: 0.0928\n",
            "Epoch 2951: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.2509 - accuracy: 0.7908 - mae: 0.1538 - mse: 0.0918 - val_loss: 0.6958 - val_accuracy: 0.7016 - val_mae: 0.2106 - val_mse: 0.1418 - lr: 1.0000e-04\n",
            "Epoch 2952/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.7917 - mae: 0.1537 - mse: 0.0927\n",
            "Epoch 2952: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.2864 - accuracy: 0.7917 - mae: 0.1537 - mse: 0.0927 - val_loss: 0.6953 - val_accuracy: 0.7005 - val_mae: 0.2095 - val_mse: 0.1411 - lr: 1.0000e-04\n",
            "Epoch 2953/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.7991 - mae: 0.1503 - mse: 0.0908\n",
            "Epoch 2953: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2746 - accuracy: 0.7991 - mae: 0.1503 - mse: 0.0908 - val_loss: 0.7053 - val_accuracy: 0.6963 - val_mae: 0.2119 - val_mse: 0.1433 - lr: 1.0000e-04\n",
            "Epoch 2954/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2693 - accuracy: 0.7939 - mae: 0.1507 - mse: 0.0916\n",
            "Epoch 2954: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.2667 - accuracy: 0.7950 - mae: 0.1511 - mse: 0.0916 - val_loss: 0.7069 - val_accuracy: 0.6930 - val_mae: 0.2124 - val_mse: 0.1437 - lr: 1.0000e-04\n",
            "Epoch 2955/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2673 - accuracy: 0.7856 - mae: 0.1545 - mse: 0.0960\n",
            "Epoch 2955: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2674 - accuracy: 0.7881 - mae: 0.1538 - mse: 0.0948 - val_loss: 0.7084 - val_accuracy: 0.6877 - val_mae: 0.2130 - val_mse: 0.1441 - lr: 1.0000e-04\n",
            "Epoch 2956/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2626 - accuracy: 0.7842 - mae: 0.1545 - mse: 0.0939\n",
            "Epoch 2956: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2644 - accuracy: 0.7817 - mae: 0.1559 - mse: 0.0955 - val_loss: 0.7184 - val_accuracy: 0.6791 - val_mae: 0.2157 - val_mse: 0.1467 - lr: 1.0000e-04\n",
            "Epoch 2957/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2663 - accuracy: 0.7773 - mae: 0.1598 - mse: 0.0995\n",
            "Epoch 2957: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2676 - accuracy: 0.7794 - mae: 0.1588 - mse: 0.0986 - val_loss: 0.7184 - val_accuracy: 0.6770 - val_mae: 0.2159 - val_mse: 0.1470 - lr: 1.0000e-04\n",
            "Epoch 2958/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2818 - accuracy: 0.7808 - mae: 0.1612 - mse: 0.1011\n",
            "Epoch 2958: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2811 - accuracy: 0.7807 - mae: 0.1605 - mse: 0.1005 - val_loss: 0.7302 - val_accuracy: 0.6706 - val_mae: 0.2197 - val_mse: 0.1504 - lr: 1.0000e-04\n",
            "Epoch 2959/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2540 - accuracy: 0.7832 - mae: 0.1594 - mse: 0.0979\n",
            "Epoch 2959: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 0.2501 - accuracy: 0.7867 - mae: 0.1585 - mse: 0.0966 - val_loss: 0.7384 - val_accuracy: 0.6717 - val_mae: 0.2222 - val_mse: 0.1526 - lr: 1.0000e-04\n",
            "Epoch 2960/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2607 - accuracy: 0.7666 - mae: 0.1652 - mse: 0.1039\n",
            "Epoch 2960: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 175ms/step - loss: 0.2642 - accuracy: 0.7638 - mae: 0.1670 - mse: 0.1051 - val_loss: 0.7319 - val_accuracy: 0.6770 - val_mae: 0.2205 - val_mse: 0.1510 - lr: 1.0000e-04\n",
            "Epoch 2961/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2715 - accuracy: 0.7842 - mae: 0.1587 - mse: 0.0984\n",
            "Epoch 2961: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 0.2717 - accuracy: 0.7812 - mae: 0.1606 - mse: 0.0998 - val_loss: 0.7220 - val_accuracy: 0.6824 - val_mae: 0.2182 - val_mse: 0.1488 - lr: 1.0000e-04\n",
            "Epoch 2962/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2763 - accuracy: 0.7803 - mae: 0.1597 - mse: 0.0987\n",
            "Epoch 2962: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2781 - accuracy: 0.7803 - mae: 0.1596 - mse: 0.0985 - val_loss: 0.7115 - val_accuracy: 0.6856 - val_mae: 0.2167 - val_mse: 0.1469 - lr: 1.0000e-04\n",
            "Epoch 2963/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2635 - accuracy: 0.7798 - mae: 0.1572 - mse: 0.0975\n",
            "Epoch 2963: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2618 - accuracy: 0.7794 - mae: 0.1576 - mse: 0.0974 - val_loss: 0.7037 - val_accuracy: 0.6824 - val_mae: 0.2159 - val_mse: 0.1457 - lr: 1.0000e-04\n",
            "Epoch 2964/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2742 - accuracy: 0.7886 - mae: 0.1582 - mse: 0.0972\n",
            "Epoch 2964: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.2713 - accuracy: 0.7872 - mae: 0.1578 - mse: 0.0967 - val_loss: 0.6966 - val_accuracy: 0.6813 - val_mae: 0.2143 - val_mse: 0.1441 - lr: 1.0000e-04\n",
            "Epoch 2965/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2581 - accuracy: 0.7861 - mae: 0.1591 - mse: 0.0962\n",
            "Epoch 2965: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.2605 - accuracy: 0.7890 - mae: 0.1585 - mse: 0.0955 - val_loss: 0.6976 - val_accuracy: 0.6813 - val_mae: 0.2139 - val_mse: 0.1440 - lr: 1.0000e-04\n",
            "Epoch 2966/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2555 - accuracy: 0.7964 - mae: 0.1516 - mse: 0.0905\n",
            "Epoch 2966: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2562 - accuracy: 0.7931 - mae: 0.1522 - mse: 0.0912 - val_loss: 0.7125 - val_accuracy: 0.6802 - val_mae: 0.2171 - val_mse: 0.1474 - lr: 1.0000e-04\n",
            "Epoch 2967/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2520 - accuracy: 0.7852 - mae: 0.1559 - mse: 0.0964\n",
            "Epoch 2967: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.2594 - accuracy: 0.7803 - mae: 0.1582 - mse: 0.0983 - val_loss: 0.7236 - val_accuracy: 0.6770 - val_mae: 0.2195 - val_mse: 0.1498 - lr: 1.0000e-04\n",
            "Epoch 2968/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2908 - accuracy: 0.7778 - mae: 0.1606 - mse: 0.0994\n",
            "Epoch 2968: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 0.2917 - accuracy: 0.7757 - mae: 0.1620 - mse: 0.1008 - val_loss: 0.7469 - val_accuracy: 0.6759 - val_mae: 0.2242 - val_mse: 0.1546 - lr: 1.0000e-04\n",
            "Epoch 2969/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.7674 - mae: 0.1647 - mse: 0.1020\n",
            "Epoch 2969: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.2805 - accuracy: 0.7674 - mae: 0.1647 - mse: 0.1020 - val_loss: 0.7606 - val_accuracy: 0.6727 - val_mae: 0.2271 - val_mse: 0.1571 - lr: 1.0000e-04\n",
            "Epoch 2970/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2763 - accuracy: 0.7715 - mae: 0.1670 - mse: 0.1050\n",
            "Epoch 2970: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2735 - accuracy: 0.7697 - mae: 0.1671 - mse: 0.1051 - val_loss: 0.7472 - val_accuracy: 0.6738 - val_mae: 0.2249 - val_mse: 0.1544 - lr: 1.0000e-04\n",
            "Epoch 2971/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2772 - accuracy: 0.7725 - mae: 0.1661 - mse: 0.1019\n",
            "Epoch 2971: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2767 - accuracy: 0.7711 - mae: 0.1662 - mse: 0.1023 - val_loss: 0.7205 - val_accuracy: 0.6813 - val_mae: 0.2191 - val_mse: 0.1483 - lr: 1.0000e-04\n",
            "Epoch 2972/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2823 - accuracy: 0.7759 - mae: 0.1629 - mse: 0.0989\n",
            "Epoch 2972: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.2821 - accuracy: 0.7757 - mae: 0.1633 - mse: 0.0993 - val_loss: 0.7074 - val_accuracy: 0.6866 - val_mae: 0.2146 - val_mse: 0.1443 - lr: 1.0000e-04\n",
            "Epoch 2973/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2817 - accuracy: 0.7890 - mae: 0.1547 - mse: 0.0924\n",
            "Epoch 2973: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.2817 - accuracy: 0.7890 - mae: 0.1547 - mse: 0.0924 - val_loss: 0.7081 - val_accuracy: 0.6856 - val_mae: 0.2133 - val_mse: 0.1436 - lr: 1.0000e-04\n",
            "Epoch 2974/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.7817 - mae: 0.1578 - mse: 0.0959\n",
            "Epoch 2974: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.2797 - accuracy: 0.7817 - mae: 0.1578 - mse: 0.0959 - val_loss: 0.7108 - val_accuracy: 0.6845 - val_mae: 0.2133 - val_mse: 0.1440 - lr: 1.0000e-04\n",
            "Epoch 2975/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2718 - accuracy: 0.7793 - mae: 0.1582 - mse: 0.0969\n",
            "Epoch 2975: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.2698 - accuracy: 0.7798 - mae: 0.1582 - mse: 0.0970 - val_loss: 0.7252 - val_accuracy: 0.6845 - val_mae: 0.2171 - val_mse: 0.1477 - lr: 1.0000e-04\n",
            "Epoch 2976/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.7775 - mae: 0.1566 - mse: 0.0956\n",
            "Epoch 2976: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.2600 - accuracy: 0.7775 - mae: 0.1566 - mse: 0.0956 - val_loss: 0.7437 - val_accuracy: 0.6749 - val_mae: 0.2210 - val_mse: 0.1519 - lr: 1.0000e-04\n",
            "Epoch 2977/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.7725 - mae: 0.1621 - mse: 0.1015\n",
            "Epoch 2977: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.2583 - accuracy: 0.7725 - mae: 0.1621 - mse: 0.1015 - val_loss: 0.7518 - val_accuracy: 0.6749 - val_mae: 0.2224 - val_mse: 0.1535 - lr: 1.0000e-04\n",
            "Epoch 2978/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.7688 - mae: 0.1645 - mse: 0.1029\n",
            "Epoch 2978: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.2664 - accuracy: 0.7688 - mae: 0.1645 - mse: 0.1029 - val_loss: 0.7412 - val_accuracy: 0.6770 - val_mae: 0.2205 - val_mse: 0.1513 - lr: 1.0000e-04\n",
            "Epoch 2979/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2539 - accuracy: 0.7861 - mae: 0.1591 - mse: 0.0968\n",
            "Epoch 2979: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.2519 - accuracy: 0.7858 - mae: 0.1587 - mse: 0.0968 - val_loss: 0.7225 - val_accuracy: 0.6866 - val_mae: 0.2166 - val_mse: 0.1470 - lr: 1.0000e-04\n",
            "Epoch 2980/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2810 - accuracy: 0.7676 - mae: 0.1632 - mse: 0.1024\n",
            "Epoch 2980: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.2785 - accuracy: 0.7734 - mae: 0.1609 - mse: 0.1006 - val_loss: 0.7112 - val_accuracy: 0.6952 - val_mae: 0.2139 - val_mse: 0.1444 - lr: 1.0000e-04\n",
            "Epoch 2981/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.7839 - mae: 0.1568 - mse: 0.0962\n",
            "Epoch 2981: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.2737 - accuracy: 0.7839 - mae: 0.1568 - mse: 0.0962 - val_loss: 0.7166 - val_accuracy: 0.6898 - val_mae: 0.2149 - val_mse: 0.1456 - lr: 1.0000e-04\n",
            "Epoch 2982/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.7881 - mae: 0.1553 - mse: 0.0952\n",
            "Epoch 2982: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.2629 - accuracy: 0.7881 - mae: 0.1553 - mse: 0.0952 - val_loss: 0.7265 - val_accuracy: 0.6824 - val_mae: 0.2165 - val_mse: 0.1478 - lr: 1.0000e-04\n",
            "Epoch 2983/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2686 - accuracy: 0.7710 - mae: 0.1606 - mse: 0.1009\n",
            "Epoch 2983: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2669 - accuracy: 0.7729 - mae: 0.1596 - mse: 0.0999 - val_loss: 0.7261 - val_accuracy: 0.6845 - val_mae: 0.2157 - val_mse: 0.1475 - lr: 1.0000e-04\n",
            "Epoch 2984/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2681 - accuracy: 0.7749 - mae: 0.1605 - mse: 0.1009\n",
            "Epoch 2984: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.2651 - accuracy: 0.7794 - mae: 0.1594 - mse: 0.0997 - val_loss: 0.7236 - val_accuracy: 0.6877 - val_mae: 0.2143 - val_mse: 0.1465 - lr: 1.0000e-04\n",
            "Epoch 2985/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2768 - accuracy: 0.7773 - mae: 0.1576 - mse: 0.0989\n",
            "Epoch 2985: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2771 - accuracy: 0.7739 - mae: 0.1588 - mse: 0.0998 - val_loss: 0.7191 - val_accuracy: 0.6888 - val_mae: 0.2133 - val_mse: 0.1454 - lr: 1.0000e-04\n",
            "Epoch 2986/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2672 - accuracy: 0.7817 - mae: 0.1551 - mse: 0.0963\n",
            "Epoch 2986: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.2666 - accuracy: 0.7835 - mae: 0.1541 - mse: 0.0959 - val_loss: 0.7191 - val_accuracy: 0.6877 - val_mae: 0.2141 - val_mse: 0.1457 - lr: 1.0000e-04\n",
            "Epoch 2987/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2590 - accuracy: 0.7783 - mae: 0.1572 - mse: 0.0976\n",
            "Epoch 2987: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.2582 - accuracy: 0.7798 - mae: 0.1557 - mse: 0.0967 - val_loss: 0.7266 - val_accuracy: 0.6845 - val_mae: 0.2166 - val_mse: 0.1478 - lr: 1.0000e-04\n",
            "Epoch 2988/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2604 - accuracy: 0.7837 - mae: 0.1563 - mse: 0.0974\n",
            "Epoch 2988: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2639 - accuracy: 0.7784 - mae: 0.1589 - mse: 0.0993 - val_loss: 0.7359 - val_accuracy: 0.6781 - val_mae: 0.2204 - val_mse: 0.1508 - lr: 1.0000e-04\n",
            "Epoch 2989/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2599 - accuracy: 0.7686 - mae: 0.1668 - mse: 0.1044\n",
            "Epoch 2989: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 164ms/step - loss: 0.2622 - accuracy: 0.7688 - mae: 0.1662 - mse: 0.1041 - val_loss: 0.7390 - val_accuracy: 0.6706 - val_mae: 0.2224 - val_mse: 0.1523 - lr: 1.0000e-04\n",
            "Epoch 2990/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2733 - accuracy: 0.7607 - mae: 0.1680 - mse: 0.1068\n",
            "Epoch 2990: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.2769 - accuracy: 0.7615 - mae: 0.1672 - mse: 0.1062 - val_loss: 0.7425 - val_accuracy: 0.6717 - val_mae: 0.2237 - val_mse: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 2991/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2539 - accuracy: 0.7671 - mae: 0.1636 - mse: 0.1022\n",
            "Epoch 2991: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.2521 - accuracy: 0.7697 - mae: 0.1625 - mse: 0.1012 - val_loss: 0.7447 - val_accuracy: 0.6695 - val_mae: 0.2245 - val_mse: 0.1542 - lr: 1.0000e-04\n",
            "Epoch 2992/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2653 - accuracy: 0.7603 - mae: 0.1659 - mse: 0.1056\n",
            "Epoch 2992: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 0.2642 - accuracy: 0.7619 - mae: 0.1652 - mse: 0.1047 - val_loss: 0.7336 - val_accuracy: 0.6738 - val_mae: 0.2216 - val_mse: 0.1515 - lr: 1.0000e-04\n",
            "Epoch 2993/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2606 - accuracy: 0.7778 - mae: 0.1602 - mse: 0.0997\n",
            "Epoch 2993: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 0.2587 - accuracy: 0.7784 - mae: 0.1601 - mse: 0.0994 - val_loss: 0.7182 - val_accuracy: 0.6834 - val_mae: 0.2166 - val_mse: 0.1472 - lr: 1.0000e-04\n",
            "Epoch 2994/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2784 - accuracy: 0.7773 - mae: 0.1591 - mse: 0.0985\n",
            "Epoch 2994: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.2781 - accuracy: 0.7775 - mae: 0.1594 - mse: 0.0987 - val_loss: 0.7094 - val_accuracy: 0.6877 - val_mae: 0.2140 - val_mse: 0.1449 - lr: 1.0000e-04\n",
            "Epoch 2995/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2561 - accuracy: 0.7852 - mae: 0.1538 - mse: 0.0936\n",
            "Epoch 2995: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 0.2574 - accuracy: 0.7853 - mae: 0.1535 - mse: 0.0934 - val_loss: 0.7072 - val_accuracy: 0.6941 - val_mae: 0.2131 - val_mse: 0.1441 - lr: 1.0000e-04\n",
            "Epoch 2996/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2668 - accuracy: 0.7900 - mae: 0.1534 - mse: 0.0926\n",
            "Epoch 2996: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.2706 - accuracy: 0.7862 - mae: 0.1547 - mse: 0.0936 - val_loss: 0.7212 - val_accuracy: 0.6920 - val_mae: 0.2169 - val_mse: 0.1476 - lr: 1.0000e-04\n",
            "Epoch 2997/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2707 - accuracy: 0.7729 - mae: 0.1614 - mse: 0.1006\n",
            "Epoch 2997: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.2710 - accuracy: 0.7752 - mae: 0.1607 - mse: 0.0996 - val_loss: 0.7424 - val_accuracy: 0.6749 - val_mae: 0.2223 - val_mse: 0.1529 - lr: 1.0000e-04\n",
            "Epoch 2998/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2625 - accuracy: 0.7778 - mae: 0.1626 - mse: 0.1004\n",
            "Epoch 2998: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.2622 - accuracy: 0.7757 - mae: 0.1632 - mse: 0.1011 - val_loss: 0.7620 - val_accuracy: 0.6652 - val_mae: 0.2262 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 2999/3000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 0.2695 - accuracy: 0.7607 - mae: 0.1665 - mse: 0.1067\n",
            "Epoch 2999: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 0.2715 - accuracy: 0.7592 - mae: 0.1683 - mse: 0.1078 - val_loss: 0.7624 - val_accuracy: 0.6631 - val_mae: 0.2259 - val_mse: 0.1572 - lr: 1.0000e-04\n",
            "Epoch 3000/3000\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.7674 - mae: 0.1667 - mse: 0.1060\n",
            "Epoch 3000: val_loss did not improve from 0.66430\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 0.2714 - accuracy: 0.7674 - mae: 0.1667 - mse: 0.1060 - val_loss: 0.7480 - val_accuracy: 0.6674 - val_mae: 0.2229 - val_mse: 0.1540 - lr: 1.0000e-04\n",
            "CPU times: user 36min 50s, sys: 27.7 s, total: 37min 18s\n",
            "Wall time: 32min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "hist = model.fit(X_train_images, y_train,\n",
        "          batch_size=params[\"batch_size\"],\n",
        "          epochs=params[\"epochs\"],\n",
        "          callbacks=[mcp, rlp],\n",
        "          validation_data = (X_val_images, y_val),\n",
        "          sample_weight = sample_weights,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xuHbJlZKHKP"
      },
      "source": [
        "###Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpItXRXEKMDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "3e5f4ab4-911d-4e58-d5a6-f3f1b0de81f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'mae', 'mse', 'val_loss', 'val_accuracy', 'val_mae', 'val_mse', 'lr'])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.plot(hist.history['accuracy'])\n",
        "\n",
        "plt.title(f'Model Accuracy and Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['val_loss', 'accuracy'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# print(\"Model Accuracy:\", hist.history['accuracy'][9])\n",
        "# print(\"Model Validation Loss:\", hist.history['val_loss'][9])\n",
        "\n",
        "hist.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQd0Ucp70uUp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "f359e40d-202f-439b-e278-04b864985904"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.plot(hist.history['accuracy'])\n",
        "\n",
        "plt.title(f'Validation Accuracy and Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['val_accuracy', 'train_accuracy'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b5OIjTC2AS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "00afd627-74bd-4c92-edcf-1be10a24fffd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.plot(hist.history['loss'])\n",
        "\n",
        "plt.title(f'Validation Loss and Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['val_loss', 'train_loss'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEsII-Qu2z7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "10e14b68-fb87-49b6-b708-de3ef386c6d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "\n",
        "plt.title(f'Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_accuracy'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0aYnVRiM9K7"
      },
      "source": [
        "###Test CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Alml5e7VND8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19fa3ac-b49a-4ebe-e37b-c4b898fd89b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 6ms/step\n",
            "[[467 114  99]\n",
            " [ 24  25   0]\n",
            " [ 15   0  35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.69      0.79       680\n",
            "           1       0.18      0.51      0.27        49\n",
            "           2       0.26      0.70      0.38        50\n",
            "\n",
            "    accuracy                           0.68       779\n",
            "   macro avg       0.45      0.63      0.48       779\n",
            "weighted avg       0.83      0.68      0.73       779\n",
            "\n",
            "779\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# convert one-hot encoded labels to integer labels\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# get model predictions\n",
        "y_predict = model.predict(X_test_images)\n",
        "\n",
        "# convert predictions to integers\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "#rounded_labels = np.argmax(y_test, axis=1) # convert label to single-digit\n",
        "\n",
        "cm = confusion_matrix(y_true, y_predict)\n",
        "print(cm)\n",
        "print(classification_report(y_true, y_predict))\n",
        "\n",
        "print(len(y_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQ4OIC4CW5g"
      },
      "source": [
        "###Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpYiKMq7CZDT"
      },
      "outputs": [],
      "source": [
        "#model.save(\"models/stock_cnn.h5\", include_optimizer=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}